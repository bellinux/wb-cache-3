34|10000|Public
50|$|Easy Trace Pro is a {{proprietary}} computer application for doing <b>raster</b> <b>to</b> <b>vector</b> conversion. It is only available for versions of Microsoft Windows. This <b>raster</b> <b>to</b> <b>vector</b> conversion program is {{released by the}} Easy Trace Group, a company based in Russia. Easy Trace is very feature-rich and integrates very closely with ArcGIS, MapInfo, AutoCAD.On 27 October 2010 an old version, 7.99, was released for free download. All newer versions are paid and cost €750-1500.|$|E
50|$|MagicTracer is a {{proprietary}} Microsoft Windows computer application for doing <b>raster</b> <b>to</b> <b>vector</b> conversion. This program has {{the capability to}} automatically convert raster images to vector output. There are over 100 functions {{that can be used}} to further customize and fine-tune the conversion results.|$|E
30|$|Data {{conversion}} error: <b>raster</b> <b>to</b> <b>vector</b> and vector to raster.|$|E
40|$|ABSTRACT: The {{high-resolution}} {{patterns of}} surface circulation and {{waves in the}} upper Gulf of Thailand (GoT) were studied in 2013. Geo-information systems (GIS) and high-frequency radar software packages were integrated to obtain the high-frequency radar data as an ESRI shape file. The model builder introduced in the analysis 1) converted the data from point <b>to</b> <b>raster</b> using a spline interpolation, 2) analyzed the daily averages using a raster calculation, 3) converted <b>rasters</b> <b>to</b> <b>vectors,</b> and 4) compiled the average velocity and direction data using a spatial join and analyzed the monthly averages using the daily averages. Monthly mapping was conducted using GIS software, a coastal radar model, and satellite imagery. In 2013, the significant wave height in the GoT was 0. 52 – 2. 99 m. The highest waves were found primarily in September and October. The residual flow was 0. 05 – 32. 82 cm/s and the circulation pattern {{was consistent with the}} season (i. e., northeast monsoon currents flowed mainly south in an anti-clockwise pattern, whereas the southwest monsoon currents flowed east in a clockwise pattern). The current velocity was higher for the northeast monsoon than for the southwest monsoon. 1...|$|R
40|$|Our {{report is}} {{concerned}} with data converting from medical body scanners such as CT and MRI into computer systems of FEM for biomechanical and medical applications. It also includes an overview of basic steps of our algorithm as image segmentation based on edge detectors and active contours, transformation of <b>raster</b> type data <b>to</b> <b>vector</b> data by a marching cubes method...|$|R
40|$|The growing use {{of remote}} sensed imagery and D. E. M., for instance, in land {{planning}} and environmental studies is {{in favour of}} G. I. S. raster-based. Nevertheless, the availability and the selectivity of vector formated data force their joint processing. This communication deals with techniques allowing simultaneous handling of vector information and <b>raster</b> imagery, according <b>to</b> <b>raster,</b> <b>vector,</b> or hybrid algorithms. The <b>vector</b> <b>to</b> <b>raster</b> technology used by the current display devices makes the implementation of such procedures easier. Exemples of different classes of vector representation are used jointly with remote sensed images to illustrate the items under discussion. Peer reviewe...|$|R
40|$|Large area {{thematic}} mapping is usually performed through the digital classification of satellite imagery. Regardless {{of the method}} selected, pixel-wise classified images typically suffer from ‘salt and pepper ’ noise that hinders <b>raster</b> <b>to</b> <b>vector</b> conversion. In order to enable a correct vectorization, classified images require a post-processing step that removes gaps within areas covered by a predominant class. However, conventional post-classification and vectorization methods often distort boundaries, erase linear features and lead to intricate vector outlines of jagged appearance. In an effort to tackle these problems, we introduce Natvec, an 'intelligent ' <b>raster</b> <b>to</b> <b>vector</b> conversion tool that produces an automated generalization of a raster map according to a user specified Minimum Mapping Unit (MMU). The main advantages of Natvec over currently available commercial tools are its speed, simplicity of use and ‘natural ’ looking vector output- that is, polygons appear similar to those digitized by a draftsperson. Natvec is intended for users interested in structures significantly larger than a pixel, who need to produce ‘natural-looking ’ thematic vector layers from pixel-wise classified satellite images. We briefly explain the Natvec workflow and compare its results in a sample classified image with these of a conventional tool...|$|E
40|$|This paper {{summed up}} 3 kinds of GIS data update ways started {{from the actual}} production, as these data are raster to raster data, <b>raster</b> <b>to</b> <b>vector</b> data and vector to vector data. We {{described}} the most advanced and most effective ways to update each kind of data, solved lots of insufficient exist in current GIS data update ways effectively, such as long update time, low update efficiency, data redundancy and can’t query and analysis based on time. From the actual production project, those ways we described were proven to be effective and feasible...|$|E
40|$|This work {{deals with}} {{questions}} {{how to take}} advantage of modern technology for support purposes in the projection in electro engineering. It the introduction it informs about common bases of the projecting, purposes and grades of processed documentations. It is followed by the categorization and dividing types of software tools according to the purpose of use linked with the description of historical development of graphic systems, from <b>raster</b> <b>to</b> <b>vector.</b> In the end there is a practical show of documentation realization processed by a specialized instrument Astra 92 Inc...|$|E
40|$|Vectorization, i. e. <b>raster</b> [...] <b>to</b> [...] <b>vector</b> conversion, is {{a central}} part of {{graphics}} recognition problems. In this paper, we discuss the pros and the cons of basing one's vectorization process on skeletonization. While distance skeletons have proven to be robust and precise, they tend to distort the results at line extremities and junctions. In these cases, contour-matching approaches yield better results, but they have their own specific problems. A perspective is probably to combine the best of both methods...|$|R
40|$|This {{bachelor}} {{thesis is}} concerned about raster and vector graphic and is aimed on conversion of raster draft into vector images. This process is called vectorization or tracing. Theoretical part define the terms raster and vector graphic and subjects linked to them. It illustrates {{strengths and weaknesses of}} both and how they can be used. In the second part - practical section the software of vectorization is examined and its tracing tools have been tested. In conclusion, the test results of graphic editors is evaluated and its tracing tools as well as assess the images that have been vectorized. The contribution of this thesis is to suggest which software is being most effective for transforming <b>raster</b> images <b>to</b> <b>vector</b> ones and on factors along. Next I describe the transformation of specific images and rate the results of vectorization...|$|R
40|$|The {{investigation}} of coastline change from Laem Pho, Pattani to Pak Nam Tak Bai, Narathiwat {{was performed by}} using techniques of image processing based on measurement systems. The data were digital Landsat- 5 TM imageries (1988 and 1997 - 1998). The procedures on image processing were the image color composite, exponential stretching, unsupervised and supervised and supervised classifications and low pass filtering. These images were transformed from <b>raster</b> data <b>to</b> <b>vector</b> data and registrated them to calculate the changing areas. This technique revealed that total changing areas covered approximately 4. 64 km 2 (eroded area 1. 82 km 2 and deposited area 2. 82 km 2). Particularly, Laem Pho sand spit moved seaward approximately 500 m. Consequently, Pattani bay will be encolsed in 46 years, if the sedimentation process continues without any disturbance to the ecosystem...|$|R
40|$|Vector {{representation}} of digital images offers {{a number of}} advantages over the more common raster representation, such as scalability and resolution independence. Many efforts {{have been made to}} deploy scalable raster standards for photographic imagery addressed to portable applications. However, they lack the flessibility and simplicity of vector representation. Vector graphics is a new and little explored alternative to the more common representation. In this paper we present our <b>raster</b> <b>to</b> <b>vector</b> technique, called SVGStat, improved with a new boundaries simplification algorithm. Categories and Subject Descriptors (according to ACM CCS) : Vectorization, Segmentation, SVG. 1...|$|E
40|$|AbstractMicro-scale {{numerical}} simulation were {{often used to}} study the deformation, flow or heat transfer mechanism of material, among the simulation, one important step is to get simulation mesh. Taking rock as an example, this paper illustrated a method of creating pore-scale finite element calculation mesh from rock Scanning Electron Microscope (SEM) image with image processing toolbox of MATLAB, Algolab <b>Raster</b> <b>to</b> <b>Vector</b> Conversion Toolkit and COMSOL Multiphysics software. It established a more accurate numerical model of the microscopic pore structure of rock. Simulation results demonstrate that the method is efficiency {{in the application of}} image processing and the study of microscopic pore structure...|$|E
40|$|Abstract. In {{this paper}} a novel {{algorithm}} for <b>raster</b> <b>to</b> <b>vector</b> conversion is presented. The technique is mainly devoted to vectorize digital picture maintaining an {{high degree of}} photorealistic appearance specifically addressed to the human visual system. The algorithm makes use of an advanced segmentation strategy based on statistical region analysis together with a few ad-hoc heuristics devoted to track boundaries of segmented regions. The final output is rendered by Standard Vector Graphics. Experimental results confirm {{the effectiveness of the}} proposed approach both in terms of perceived and measured quality. Moreover, the final overall size of the vectorized images outperforms existing methods. ...|$|E
40|$|A {{method for}} human {{settlements}} extraction from high resolution remote sensing imagery using feature-level-based fusion of right-angle-corners and right-angle-sides is proposed in this paper. First, the corners and line segments are detected, the right-angle-corners and right-angle-sides {{are determined by}} cross verification of the detected corners and line segments, and {{these two types of}} features are rasterized. Second, a human settlement index image is built based on the density and distance of the right-angle-corners and right-angle-sides in a local region. Finally, the polygons of human settlements are generated through binary thresholding of the index image, conversion from <b>raster</b> format <b>to</b> <b>vector</b> format, and sieving. Three images are used for testing the proposed method. The experimental results show that our proposed method has higher accuracy than the existed method. Specifically, the correctrate, completeness, and quality of our method is higher 6. 76 %, 10. 12 %, 12. 14 % respectively than the existed method...|$|R
40|$|This thesis {{proposes a}} novel image {{primitive}} — the diffusion curve. This primitive {{relies on the}} principle that images can be defined via their discontinuities, and concentrates image features along contours. The diffusion curve can be defined in vector graphics, as well as in <b>raster</b> graphics, <b>to</b> increase user control during the process of art creation. The vectorial diffusion curve primitive augments the expressive powers of vector images by capturing complex spatial appearance behaviors. Diffusion curves represent a simple and easyto-manipulate support for complex content representation and edition. In raster images, diffusion curves define a higher level structural organization of the pixel image. This structure is used to create simplified or exaggerated representations of photographs in a way consistent with the original image content. Finally, a fully automatic vectorization method is presented, that converts <b>raster</b> diffusion curve <b>to</b> <b>vector</b> diffusion curve. Content...|$|R
40|$|Raster maps contain {{valuable}} road information, {{which is}} especially important for the areas where road vector data are otherwise not readily accessible. However, converting the road information in <b>raster</b> maps <b>to</b> road <b>vector</b> data usually requires significant user effort to achieve high accuracy. In this demo, we present Strabo, which is a system that extracts road vector data from heterogeneous raster maps. We demonstrate Strabo’s fully automatic technique for extracting road vector data from raster maps with good image quality and the semi-automatic technique for handling raster maps with poor image quality. We show that Strabo requires minimal user input for extracting road vector data from raster maps with varying map complexity (i. e., overlapping features in maps) and image quality...|$|R
40|$|As a space-filling method, Voronoi Treemaps {{are used}} for {{showcasing}} hierarchies. Previously presented algorithms are limited to visualize nonspatial data. The approach of spatial Voronoi Treemaps is proposed in this paper to eliminate these problems by enabling the subdivisions for points, lines, and polygons with spatial coordinates and references. The digital distance transformation is recursively used to generate nested raster Voronoi polygons while the <b>raster</b> <b>to</b> <b>vector</b> conversion is {{used to create a}} vector-based Treemap visualization in a GIS (geographic information system) environment. The objective is to establish a spatial data model to better visualize and understand the hierarchies in the geographic field...|$|E
40|$|In {{this paper}} a novel {{algorithm}} for <b>raster</b> <b>to</b> <b>vector</b> conversion is presented. The technique is mainly devoted to vectorize digital picture maintaining an {{high degree of}} photorealistic appearance specifically addressed to the human visual system. The algorithm makes use of an advanced segmentation strategy based on statistical region analysis together with a few ad-hoc heuristics devoted to track boundaries of segmented regions. The final output is rendered by Standard Vector Graphics. Experimental results confirm {{the effectiveness of the}} proposed approach both in terms of perceived and measured quality. Moreover, the final overall size of the vectorized images outperforms existing methods...|$|E
40|$|The paper {{presents}} {{two techniques}} to convert raster images in a Scalable Vector Graphics format. The first method {{is a technique}} that generates a Data Dependent Triangulation just by swapping the edges generated by a regular triangulation; the second technique is a Wavelet Based Triangulation and generates a multi-level triangulation based on the data collected from the wavelet multi-level transformation. After triangulation step a further reduction is introduced by a suitable polygonalization step. The proposed techniques have been compared with other <b>raster</b> <b>to</b> <b>vector</b> conversions {{in terms of both}} perceptual and measured quality. Keywords: SVG, Triangulation, Watershed, Wavelet, Polygonalization. I...|$|E
40|$|The {{process of}} <b>vector</b> <b>to</b> <b>raster</b> {{conversion}} has information losses {{to a certain}} extent, and generates the error problems. The thesis discussed a few types of <b>vector</b> <b>to</b> <b>raster</b> conversion and some reasons of the errors, and systematically analyzed the progress that the error analysis methods have progressed in <b>vector</b> <b>to</b> <b>raster</b> conversion of areal feature, meanwhile analyzed the current existent key problems. The thesis put forward a new error analysis method, which made use of proportion component method <b>to</b> create structure <b>raster</b> data and carried on error analysis in <b>vector</b> <b>to</b> <b>raster</b> conversion of areal feature based structure raster data. Finally, the thesis took the <b>vector</b> <b>to</b> <b>raster</b> conversion of land-use data as an example carried on the verification research. The result discovered that the normal analysis method underrated the error of <b>vector</b> <b>to</b> <b>raster</b> conversion, because none full considered this reduce, simultaneity that increment problem that errors were not distributed equably on space in the <b>vector</b> <b>to</b> <b>raster</b> conversion. The thesis suggested that we might adopt structure <b>raster</b> data <b>to</b> improve the error analysis in <b>vector</b> <b>to</b> <b>raster</b> conversion. The method can distinguish errors from {{the cause of this}} reduce and the cause of that increment, and the error analysis is more overall, objective and accurate. In the meanwhile, we easily make visualization and create error map on the results of error analysis...|$|R
40|$|Existing {{vectorization}} {{systems for}} engineering drawings usually take a two-phase workflow: convert a <b>raster</b> image <b>to</b> raw <b>vectors</b> and recognize graphic {{objects from the}} raw vectors. The first phase usually separates a ground truth graphic object that intersects or touches other graphic objects into several parts, thus, the second phase faces the difficulty of searching for and merging raw <b>vectors</b> belonging <b>to</b> the same object. These operations slow down vectorization and degrade the recognition quality. Imitating the way humans read engineering drawings, we propose an efficient one-phase object-oriented vectorization model that recognizes each class of graphic objects from their natural characteristics. Each ground truth graphic object is recognized directly in its entirety at the pixel level. The raster image is progressively simplified by erasing recognized graphic objects to eliminate their interference with subsequent recognition. To evaluate {{the performance of the}} proposed model, we present experimental results on real-life drawings and quantitative analysis using third party protocols. The evaluation results show significant improvement in speed and recognition rate...|$|R
40|$|In this paper, {{we discuss}} the {{elements}} {{to be taken into}} account when choosing one's vectorization method. The paper is extensively based on our own implementations and tests, and concentrates on methods designed to have few, if any, parameters. 1 Introduction Vectorization, i. e. <b>raster</b> [...] <b>to</b> [...] <b>vector</b> conversion, has been at the center of graphics recognition problems since the beginning. Despite a lot of efforts, and many proposed solutions [...] - including a lot of commercial software [...] -, we have not yet reached methods which can be considered as sufficiently stable and robust to work as standalone "black boxes". The commercial software packages solve this problem by providing their vectorization method with a number of parameters, adapted to the various categories of drawings to be processed. The user is then in control of the whole process, although families of drawings can be associated with standard sets of parameters. We believe in another way: one important factor for robustness i [...] ...|$|R
40|$|This paper {{presents}} {{a technique to}} convert surfaces, obtained through a Data Dependent Triangulation, in Bezier Curves by using a Scalable Vector Graphics File format. The method starts from a Data Dependent Triangulation, traces {{a map of the}} boundaries present into the triangulation, using the characteristics of the triangles, then the estimated barycenters are connected, and a final conversion of the resulting polylines in curves is performed. After the curves have been estimated and closed the final representation is obtained by sorting the surfaces in a decreasing order. The proposed techniques have been compared with other <b>raster</b> <b>to</b> <b>vector</b> conversions in terms of perceptual quality...|$|E
40|$|Analysis of 3 D brain {{angiography}} images {{implemented in}} this paper consists of several steps: (1) segmentation to extract the vascular tree; (2) cavity deletion to fill possible 3 D holes inside the vasculature; (3) skeletonization to extract the central line of the vascular network; (4) characteristic table building, including <b>raster</b> <b>to</b> <b>vector</b> conversion and length, area and volume computation. This approach produces the characteristic table of the vasculature. The description includes length, cross section area and volume measurements of the tree. The table also stores the topology structure of the tree, so that the vasculature can be restored. The result is saved in XML file. The paper describes all these steps in details...|$|E
40|$|Digital {{data has}} {{replaced}} most paper maps for managers, {{aided by the}} increasing ease of transformation from <b>raster</b> <b>to</b> <b>vector,</b> and the capture of data in digital format natively. Some data will remain in raster format where it is intrinsically continuous, primarily remotely sensed data from satellite and aerial platforms. GIS has matured into {{a powerful tool for}} the storage, analysis and display of data from disparate sources. It is the central tool in our daily spatial data management. There are about ten FMS (Flight Management Systems) in the marketplace, but only a few of them are GIS-based. In our paper, we highlight the benefits of GIS based workflows in the planning and execution of data capture, and a widening range of other, related, aerial tasks. 1...|$|E
40|$|In this paper, {{we develop}} a new {{approach}} for automated georeferencing of a <b>raster</b> image <b>to</b> a <b>vector</b> road network. Our approach improves existing solutions by: (1) eliminating the same scene constraint between an image and the vector road network; (2) requiring no pre-knowledge of the image’s placement in the vector road network; (3) necessitating only a few points from the image; (4) tolerating point location distortion, missing points, and spurious points; (5) providing high performance and scalability. Our key contribution relies {{on the use of}} the topology of point patterns, which we call topological point pattern (TPP) analysis, along with a set of corresponding matching algorithms, to automatically link image and vector data sets. The biggest advantage of TPP is its flexibility to capture the spatial information of any portion of a point set. The TPP matching algorithms can identify control point pairs between an image and a vector road network by systematically searching the vector road network. The automated scheme is very efficient and highly scalable...|$|R
5000|$|... <b>raster</b> <b>to</b> Zebra Programming Language or ZPL (a Zebra Technologies printer language) ...|$|R
5000|$|... <b>raster</b> <b>to</b> ESC/P or ESC/P2 (an Epson printer language, now largely {{superseded}} by their new ESC/P-Raster format) ...|$|R
40|$|This paper {{describes}} {{a method for}} extracting arbitrarily oriented text in documents containing both text and graphics. The technique presented is inspired by the tracking algorithms frequently found in <b>raster</b> <b>to</b> <b>vector</b> conversion systems. By identifying text components in the document, reducing {{the resolution of the}} image {{by the size of the}} characters, and then tracking the centers of the character components, all text strings can be removed and subsequently reoriented to the horizontal. They can then be presented for automated character recognition. A by-product of the method is that characters are automatically grouped together to form words and/or phrases. We give a detailed description of the algorithm, discuss its strengths and weaknesses, and present some sample results obtained from a typical city street map...|$|E
40|$|Abstract. In {{this paper}} we study {{different}} {{factors that affect}} vector quality. Noise level, cleaning method, and vectorization software are three factors that may influence the resulting vector data. Real scanned images from GREC’ 03 contest {{are used in the}} experiment. Three different levels of salt-and-pepper noise (5 %, 10 %, and 15 %) are used. Noisy images are cleaned by six cleaning algorithms and then three different commercial <b>raster</b> <b>to</b> <b>vector</b> software are used to vectorize the cleaned images. Vector Recovery Index (VRI) is the performance evaluation criteria used in this study to judge the quality of the resulting vectors compared to their ground truth data. Statistical analysis on the VRI values shows that vectorization software have the biggest influence {{on the quality of the}} resulting vectors...|$|E
40|$|Abstract—In this paper, an {{extended}} study is {{performed on the}} effect of different factors on the quality of vector data based on a previous study. In the noise factor, one kind of noise that appears in document images namely Gaussian noise is studied while the previous study involved only salt-and-pepper noise. High and low levels of noise are studied. For the noise cleaning methods, algorithms that were not covered in the previous study are used namely Median filters and its variants. For the vectorization factor, one of the best available commercial <b>raster</b> <b>to</b> <b>vector</b> software namely VPstudio is used to convert raster images into vector format. The performance of line detection will be judged based on objective performance evaluation method. The output of the performance evaluation is then analyzed statistically to highlight the factors that affect vector quality...|$|E
5000|$|... other {{proprietary}} languages like GDI or SPL (Samsung Printer Language) {{are supported}} by Splix, a <b>raster</b> <b>to</b> SPL translator.|$|R
5000|$|A {{digital image}} is a numeric {{representation}} (normally binary) of a two-dimensional image. Depending on whether the image resolution is fixed, it may be of vector or raster type. By itself, the term [...] "digital image" [...] usually refers <b>to</b> <b>raster</b> images or bitmapped images (as opposed <b>to</b> <b>vector</b> images).|$|R
40|$|The {{watershed}} delineation is {{the basis}} of hydrology routing andflood control engineering. In order to reduce the disadvantage of delineating watershed by manual option and save the time of dataprocessing, the DTM of Liyutan watershed and Chungkongshi watershedwere used in this research to investigate the problem that may cause inwatershed automatic delineating with image processing softwareEASI/PACE. The results of watersheds which were delineated by (1) automatic delineation approach via computer, (2) by manual operationwith the topographic map and by field check with GPS were comparedaccordingly to discuss their accuracy. Four space processing methodswere utilized to modify the watershed boundary delineation with computer. In addition, the different resolution of DTM which weremodified with resampling were used to process the watershed automaticdelineation. These were to investigate the effect that caused by the inaccuracy of the automatic delineation. The results was summarized as following: 1. Even though there were some restrictions in using DTM to acquire the boundary of automatic delineated watershed,with some help of manual judgment we might increase its accuracy. 2. The area error percent of automatic delineated watershed was far less than the perimeter,circularity ratio and compactness error percent. 3. The error percent of perimeter,circularity ratio and compactness of automatic delineated watershed increase with respect to the circularity ratio and compactness ratio. The major reason was the difference of data format between raster and vector. 4. In order to decrease the error of perimeter,circularity ratio and compactness of delineated watersheds, both commands-CLEAN and GENERALIZE of Arc/Info,attributed the most significant effect in converting <b>raster</b> format <b>to</b> <b>vector</b> format. 5. Although it might reduce the area error percent by means of resampling with higher resolution of DTM data and delineating watershed boundary automatically,it might also increase the error percent of perimeter,circularity ratio and compactness simultaneously. So one should weigh its advantage and disadvantage when he wants to delineate the watershed boundary automatically. 集水區之劃定為水文演算、防洪工程等之基礎，為改善人為劃定集水 區之缺失及節省處理時間，本研究以鯉魚潭集水區及中港溪集水區之DTM ，利用加拿大PCI公司出版之影像處理軟體EASI/PACE進行集水區自動劃定 之研究。首先將由電腦自動劃定所得的集水區，與由人為依地形圖判釋所 得之集水區相互比較，並利用GPS進行現場檢測，並以此探討自動劃定過 程可能產生的問題及自動劃定結果的準確性。其次將自動劃定集水區所得 網格式之資料轉換成向量式後，分別以四種方法加以處理，並比較其改善 誤差的程度。最後利用再取樣方式改變DTM的解析度，以不同解析度的DTM 再次進行集水區自動劃定，比較其劃定結果以探討提高或降低DTM解析度 對集水區自動劃定所生誤差率的影響。茲將研究結果摘述如后: 1. 以DTM為 材料進行自動劃定集水區邊界雖有其限制，然若輔以一 些人為之判釋， 即可提高其效率與準確度。 2. 以DTM自動劃定所得之集水區面積誤差率， 遠小於周長、圓比值、 密集度等之誤差率。 3. 集水區自動劃定所得的周 長、圓比值興密集度等之誤差率，由於 網格式與向量式資料間格式的差 異，會隨著集水區圓比值與密集 度的增加而增加。 4. 對於改善自動劃定 所得集水區周長、圓比值與密集度等之誤差 率，以Arc/Info之指令 Clean 及Generalize的處理最具顯著效 果。 5. 以再取樣方式提高DTM的 解析度再進行集水區自動劃定，雖可減 少自動劃定集水區的面積誤差率 ，但相對地卻會增加周長、圓比 值與密集度等的誤差率，宜斟酌為之...|$|R
