3|11|Public
40|$|The aim of {{this study}} is to {{investigate}} the structure of the tax system for the accession states Estonia, Poland, Hungary, the Czech Republic and Slovenia in this same format. This involves: Identification of appropriate data sources and description of the available data, Drawing up an inventory of all taxes for each country, Construction of a tax <b>revenue</b> <b>database,</b> Classification of tax revenues according to different types of categorizations, Analysis of the tax structure and comparison with that of present Member States, Documentation of the database and of the calculations. European Union, taxation...|$|E
40|$|International {{corporate}} tax {{is an important}} source of government revenue, especially in lower-income countries. An important recent study of the scale of this problem was carried out by International Monetary Fund researchers Ernesto Crivelli, Ruud De Mooij, and Michael Keen. We first re-estimate their innovative model, and then explore the effects of introducing higher-quality revenue data from the ICTD-WIDER Government <b>Revenue</b> <b>Database.</b> Whereas Crivelli et al. report results for two country groups only, we present country-level results to make the most detailed estimates available. Our findings support a somewhat lower estimate of global revenue losses of around US$ 500 billion annually and indicate that the greatest intensity of losses occurs in low- and lower middle-income countries, and across sub-Saharan Africa, Latin America and the Caribbean, and South Asia...|$|E
40|$|The {{attached}} {{draft report}} is submitted for review and comment. It was prepared {{in response to}} two bills concerning government transparency that were referred to the Commission for study by the 107 th General Assembly. Senate Bill 2831 (Ketron) [House Bill 3327 (Carr) ], known as the Taxpayer Transparency Act, was referred by the Senate Finance, Ways and Means Committee. This bill would have required the state Department of Finance and Administration to create and maintain a searchable budget database website detailing where, for what purpose, and what results are achieved for all taxpayer investments in state government. Senate Bill 2832 (Ketron) [House Bill 3328 (Carr) ], known as the Local Government Transparency Act, was referred by the House State and Local Government Subcommittee. This bill would have required each county, city, and school district to have a single, searchable expenditure and <b>revenue</b> <b>database</b> accessible from its main website. Both bills require such features as searchability, historical data, and information abou...|$|E
50|$|According to a 2008 {{article in}} Computerworld, Yahoo has a 2-petabyte, {{specially}} built data warehouse that it uses {{to analyze the}} behavior of its half-billion Web visitors per month, processing 24 billion daily events. In contrast, the United States Internal <b>Revenue</b> Service (IRS) <b>database</b> of all United States taxpayers weighs in at only 150 terabytes.|$|R
50|$|The {{database}} itself, Celera Discovery System (CDS), {{would remain}} with Celera, because of shareholder approval complications. Celera would retain responsibility for its maintenance {{and support to}} existing customers, and would receive royalties from Applied Biosystems. The <b>database</b> <b>revenues</b> were expected to reach US$100 million for the June fiscal year end, which would be its first profitable year. But it had always faced the problem that its public competitor, the consortium project, provides free data from its own database.|$|R
40|$|A short {{look back}} to the {{beginnings}} of patent documentation in industry shows that the austerity of data available in the old patent databases of the 1960 s and 1970 s (because of insufficient memory and disk space) still has effects on the multitude of present databases. Millions of patent records added each year may lead to frustration of many users when confronted with rising costs and search times. The resulting non-use of some bases is dangerous for patent departments and leads to diminishing <b>revenues</b> for <b>database</b> producers. This {{gives rise to the}} proposal of one and only one comprehensive logical (not necessarily physical) patent database containing extended data. Many of them are available in {{one or the other of}} the existing databases, but not all together in one file. EPO, Derwent and CA are regarded as centers of competence for bibliographic data collecting and correcting; abstracting; indexing and deep analysis, respectively. ...|$|R
40|$|National Tax Census is {{implemented}} {{to improve the}} obedience of taxpayers. The expected goals of National Tax Census include improving tax bases, increasing the obedience to submit Tax Annual Report, improving tax <b>revenue,</b> updating <b>database,</b> and socializing and educating taxpayers. Research type is explanatory. The sample includes private taxpayers who are subjected to National Tax Census and registered at KPP Pratama Batu. Sampling method is non-probability sampling with accidental sampling technique. Data analysis method involves descriptive analysis and multiple linear regression analysis. Result of research indicates that Fcount is 175, 149 and Ftable is 2. 45 (Fcount > Ftable). It is concluded that simultaneously, National Tax Census implementation service quality and tax knowledge have significant influence on the obedience of taxpayers. Result of dominant test with Standardized Coefficients Beta has indicated that National Tax Census implementation has beta of 0. 220, while service quality and tax knowledge have 0. 275 and 0. 617 for their betas. Based on these results, {{it can be said}} that the most dominant variable influencing the obedience of taxpayers is tax knowledge...|$|R
40|$|Benford's Law (BL) is a {{logarithmic}} distribution {{which is}} useful to detect abnormal patterns of digits in number sets. It is often used as a primary data auditing method for detecting traces of errors, illegal practices or undesired occurrences, such as fraud and earning management. In this descriptive study, I analyzed the financial information (revenue and expenditure) of the registered charitable hospitals located in Ontario and Quebec, which have the majority (71. 4 %) of these organizations within Canada. The {{aim of this study}} was to verify the reliability of the financial data of the respective hospitals, using the probability distribution predicted by Benford’s Law as a proxy of reliability. The sample was composed by 1, 334 observations related to 339 entities operating in the tax year 2009 and 328 entities in 2010, gathered from the Canada <b>Revenue</b> Agency’s <b>database.</b> To analyze the discrepancies between the actual and expected frequencies of the significant-digit, two statistics were calculated: Z-test and Pearson’s chi-square test. The results show that, with a confidence level of 95 %, the data set of the organizations located in Ontario and Quebec have similar distribution to the BL, suggesting that, in a preliminary analysis, their financial data are free from bias...|$|R
40|$|This paper {{attempts}} {{to shed light}} on the impact of foreign taxes on the behavior of US multinationals. Considering the relative capital export neutrality of the US tax credit system-where an investor residing in the US is taxed at one rate regardless of where in the world the investment is located- this empirical investigation try to synthesize the different elements that can explain the strong negative relationship, clearly demonstrated by a large literature, between taxes and US capital invested abroad. Using the International <b>Revenue</b> Service’s <b>database</b> of US Treasury Controlled Foreign Corporations between 1992 and 2000, the econometric analysis reveals that the investment of capital abroad is deterred by the level of taxes in both high and low-tax jurisdictions. The possibility of deferring US taxes until the repatriation of earnings, to realize cross-crediting and to manipulate transfer pricing can explain why multinationals invest in low-tax jurisdictions. The relationship between taxes and earnings and profit before taxation, dividends repatriated and Subpart F income indicate that US multinationals do indulge in tax planning practices. Furthermore, by distinguishing countries by their level of development and their legislative maturity, the results indicate that US multinationals shift their income from high-tax countries to low-tax developing countries and more precisely to low-tax low-legislation countries...|$|R
40|$|The {{assessment}} of financial sustainability and resilience of non-profit organisations has primarily been conducted by examining government <b>revenue</b> tax <b>databases</b> within developed countries. The use and applicability of health assessment metrics and financial vulnerability indices {{has not yet}} been validated among NPOs in developing or emerging economies. This research paper attempts to identify the influencing factors and variables involved in the financial sustainability and resilience of a non-profit public health organisation in a developing country. A case study methodology is used to evaluate the applicability of current popular financial metrics. In addition, qualitative interviews were conducted to consider other potential influencing factors. The research aims to provide a basis for an ongoing research agenda by establishing assertions and hypotheses for further empirical research. This is done in an attempt to construct more robust financial health metrics to improve management strategies for organisations in developing or emerging countries. Findings highlight four main areas of discussion regarding financial sustainability. First, the need for diversified funding sources, discussing in detail the role of donor diversity and concerns regarding greater compliance requirements inherent in diversity. Second, the importance of determining asset ownership and control. Third, the role of liabilities and their perception by donors. Fourth, the need to value and include networks and formal partnerships as intangible assets...|$|R
40|$|Objective: The {{objective}} {{of this paper is}} to provide a deeper insight into the main characteristics of Hungarian exporters between 1999 and 2013. Research Design & Methods: The text addresses the questions how exporters can be grouped according to their export performance, what kind of groups can be identified, and what their main characteristics are. The research is based on Hungarian Competitiveness Research of 1999, 2004, 2009, 2013. Cluster analysis was selected as a key research method. Findings: Four different clusters were identified. The most successful export-oriented companies produced more than 60 % of export <b>revenue</b> in all <b>databases,</b> they had the highest export revenue, highest export intensity, and their profitability was over industry average except in 2009. Significant differences can be observed between the two groups. Leading minor exporters had significant higher profitability and better operation than minor exporters. Implications & Recommendations: The implication of the research can be beneficial for both those studying exporters and the firms themselves. The research suggested that lower price is a less important success factor than quality, relationships, fast and flexible delivery. The applied methodology can be useful for export researchers. Contribution & Value Added: The paper highlights the heterogeneous feature of exporters. Each cluster has special characteristics which required different analysis. The research underpins that operational excellence is necessary to export success, but it is not enough...|$|R
40|$|The {{emergence}} of less restricted fare {{structures in the}} airline industry reduced the capability of airlines to segment demand through restrictions such as Saturday night minimum stay, advance purchase, non-refundability, and cancellation fees. As a result, new forecasting techniques such as Hybrid Forecasting and optimization methods such as Fare Adjustment were developed to account for passenger willingness-to- pay. This thesis explores statistical methods for estimating sell-up, or the likelihood of a passenger to purchase a higher fare class than they originally intended, based solely on historical booking data available in <b>revenue</b> management <b>databases.</b> Due to the inherent sparseness of sell-up data over the booking period, sell-up estimation is often difficult to perform on a per-market basis. On the other hand, estimating sell-up over an entire airline network creates estimates that are too broad and over-generalized. We apply the K-Means clustering algorithm to cluster markets with similar sell-up estimates in an attempt to address this problem, creating a middle ground between system-wide and per-market sell-up estimation. This thesis also formally introduces a new regression-based forecasting method known as Rational Choice. Rational Choice Forecasting creates passenger type categories based on potential willingness-to-pay levels and the lowest open fare class. Using this information, sell-up is accounted for within the passenger type categories, making Rational Choice Forecasting less complex than Hybrid Forecasting. This thesis uses the Passenger Origin-Destination Simulator to analyze the impact of these forecasting and sell-up methods in a controlled, competitive airline environment. The simulation results indicate that determining an appropriate level of market sell-up aggregation through clustering both increases revenue and generates sell-up estimates with a sufficient number of observations. In addition, the findings show that Hybrid Forecasting creates aggressive forecasts that result in more low fare class closures, leaving room for not only sell-up, but for recapture and spill-in passengers in higher fare classes. On the contrary, Rational Choice Forecasting, while simpler than Hybrid Forecasting with sell-up estimation, consistently generates lower revenues than Hybrid Forecasting (but still better than standard pick-up forecasting). To {{gain a better understanding of}} why different markets are grouped into different clusters, this thesis uses regression analysis to determine the relationship between a market's characteristics and its estimated sell-up rate. These results indicate that several market factors, in addition to the actual historical bookings, may predict to some degree passenger willingness-to-pay within a market. Consequently, this research illustrates the importance of passenger willingness-to-pay estimation and its relationship to forecasting in airline revenue management. by Christopher A. Boyer. Thesis (S. M.) [...] Massachusetts Institute of Technology, Sloan School of Management, Operations Research Center, 2010. Page 170 blank. Cataloged from PDF version of thesis. Includes bibliographical references (p. 167 - 169) ...|$|R
40|$|The {{growing demand}} for {{ubiquitous}} broadband network connectivity and continuously falling prices in hardware operating on the unlicensed bands have put Wi-Fi technology {{in a position to}} lead the way in rapid innovation towards high performance wireless for the future. The success story of Wi-Fi contributed to the development of widespread variety of options for unlicensed access (e. g., Bluetooth, Zigbee) and has even sparked regulatory bodies in several countries to permit access to unlicensed devices in portions of the spectrum initially licensed to TV services. In this thesis we present novel spectrum management algorithms for networks employing 802. 11 and TV white spaces broadly aimed at efficient use of spectrum under consideration, lower contention (interference) and high performance. One of the target scenarios of this thesis is neighbourhood or citywide wireless access. For this, we propose the use of IEEE 802. 11 -based multi-radio wireless mesh network using omnidirectional antennae. We develop a novel scalable protocol termed LCAP for efficient and adaptive distributed multi-radio channel allocation. In LCAP, nodes autonomously learn their channel allocation based on neighbourhood and channel usage information. This information is obtained via a novel neighbour discovery protocol, which is effective even when nodes do not share a common channel. Extensive simulation-based evaluation of LCAP relative to the state-of-the-art Asynchronous Distributed Colouring (ADC) protocol demonstrates that LCAP is able to achieve its stated objectives. These objectives include efficient channel utilisation across diverse traffic patterns, protocol scalability and adaptivity to factors such as external interference. Motivated by the non-stationary nature of the network scenario and the resulting difficulty of establishing convergence of LCAP, we consider a deterministic alternative. This approach employs a novel distributed priority-based mechanism where nodes decide on their channel allocations based on only local information. Key enabler of this approach is our neighbour discovery mechanism. We show via simulations that this mechanism exhibits similar performance to LCAP. Another application scenario considered in this thesis is broadband access to rural areas. For such scenarios, we consider the use of long-distance 802. 11 mesh networks and present a novel mechanism to address the channel allocation problem in a traffic-aware manner. The proposed approach employs a multi-radio architecture using directional antennae. Under this architecture, we exploit the capability of the 802. 11 hardware to use different channel widths and assign widths to links based on their relative traffic volume such that side-lobe interference is mitigated. We show that this problem is NP-complete and propose a polynomial time, greedy channel allocation algorithm that guarantees valid channel allocations for each node. Evaluation of the proposed algorithm via simulations of real network topologies shows that it consistently outperforms fixed width allocation due to its ability to adapt to spatio-temporal variations in traffic demands. Finally, we consider the use of TV-white-spaces to increase throughput for in-home wireless networking and relieve the already congested unlicensed bands. To the best of our knowledge, our work is the first to develop a scalable micro auctioning mechanism for sharing of TV white space spectrum through a geolocation database. The goal of our approach is to minimise contention among secondary users, while not interfering with primary users of TV white space spectrum (TV receivers and microphone users). It enables interference-free and dynamic sharing of TVWS among home networks with heterogeneous spectrum demands, while resulting in <b>revenue</b> generation for <b>database</b> and broadband providers. Using white space availability maps from the UK, we validate our approach in real rural, urban and dense-urban residential scenarios. Our results show that our mechanism is able to achieve its stated objectives of attractiveness to both the database provider and spectrum requesters, scalability and efficiency for dynamic spectrum distribution in an interference-free manner...|$|R
40|$|The Pacific Northwest Loads and Resources Study (White Book), {{which is}} {{published}} annually by the Bonneville Power Administration (BPA), establishes {{one of the}} planning bases for supplying electricity to customers. The White Book contains projections of regional and Federal system load and resource capabilities, along with relevant definitions and explanations. The White Book also contains information obtained from formalized resource planning reports and data submittals including those from individual utilities, the Northwest Power and Conservation Council (Council), and the Pacific Northwest Utilities Conference Committee (PNUCC). The White Book is not an operational planning guide, nor is it used for determining BPA <b>revenues,</b> although the <b>database</b> that generates {{the data for the}} White Book analysis contributes to the development of BPA's inventory and ratemaking processes. Operation of the Federal Columbia River Power System (FCRPS) is based on a set of criteria different from that used for resource planning decisions. Operational planning is dependent upon real-time or near-term knowledge of system conditions that include expectations of river flows and runoff, market opportunities, availability of reservoir storage, energy exchanges, and other factors affecting the dynamics of operating a power system. In this loads and resources study, resource availability is compared to an expected level of total retail electricity consumption. The forecasted annual energy electricity retail load plus contract obligations are subtracted from the sum of the projected annual energy capability of existing resources and contract purchases to determine whether BPA and/or the region will be surplus or deficit. Surplus energy is available when resources are greater than loads. This energy could be marketed to increase revenues. Deficits occur when resources are less than loads. Energy deficits could be met by any combination of the following: better-than-critical water conditions, demand-side management and conservation programs, permanent loss of a load (i. e., due to economic conditions or closures), additional contract purchases, and/or new generating resources. The loads and resources analysis in this study simulates the operation of the power system under the Pacific Northwest Coordination Agreement (PNCA). The PNCA defines the planning and operation of seventeen U. S. Pacific Northwest utilities and other parties with generating facilities within the region's hydroelectric (hydro) system. The hydroregulation study used for the 2003 White Book incorporates measures from the National Oceanographic and Atmospheric Administration Fisheries (NOAA Fisheries) Biological Opinion dated December 2000, and the U. S. Fish and Wildlife Service's 2000 Biological Opinion (2000 FCRPS BiOps) for the Snake River and Columbia River projects. These measures include: (1) Increased flow augmentation for juvenile fish migrations in the Snake and Columbia rivers in the spring and summer; (2) Mandatory spill requirements at the Lower Snake and Columbia dams to provide for non-turbine passage routes for juvenile fish migrants; and (3) Additional flows for Kootenai River white sturgeon in the spring. The hydroregulation criteria for this analysis includes: an updated Detailed Operation Plan for Treaty reservoirs for Operating Year (OY) 2004, updated PNCA planning criteria for OY 2003, and revised juvenile fish bypass spill levels for 2000 FCRPS BiOps implementation. The 2003 White Book is presented in two documents: (1) this summary document of Federal system and PNW region loads and resources, and (2) a technical appendix which presents regional loads, grouped by major PNW utility categories, and detailed contract and resource information. The technical appendix is available only in electronic form. Individual customer information regarding marketer contracts is not detailed due to confidentiality agreements. The 2003 White Book analysis updates the December 2002 White Book. This analysis projects the yearly average energy consumption and resource availability for the study period, OY 2005 through 2014. The study shows the Federal system's and the region's expected monthly peak demand, monthly energy demand, monthly peak generating capability, and monthly energy generation for OY 2005, 2009, and 2014. The Federal system and regional monthly capacity surplus/deficit projections are summarized for the 10 operating years of the study period. This document analyzes the PNW's projected loads and available generating resources in two parts: (1) the loads and resources of the Federal system, for which BPA is the marketing agency; and (2) the larger PNW regional power system loads and resources that include the Federal system as well other PNW entities...|$|R

