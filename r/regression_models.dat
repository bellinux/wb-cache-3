10000|10000|Public
5|$|Von Neumann made {{fundamental}} {{contributions to}} mathematical statistics. In 1941, he derived the exact {{distribution of the}} ratio of the mean square of successive differences to the sample variance for independent and identically normally distributed variables. This ratio was applied to the residuals from <b>regression</b> <b>models</b> and is commonly known as the Durbin–Watson statistic for testing the null hypothesis that the errors are serially independent against the alternative that they follow a stationary first order autoregression.|$|E
25|$|Mahalanobis {{distance}} and leverage {{are often used}} to detect outliers, especially {{in the development of}} linear <b>regression</b> <b>models.</b>|$|E
25|$|Least-angle {{regression}} is an estimation {{procedure for}} linear <b>regression</b> <b>models</b> {{that was developed}} to handle high-dimensional covariate vectors, potentially with more covariates than observations.|$|E
40|$|In this article, a {{seemingly}} unrelated Poisson <b>regression</b> <b>model</b> {{is presented as}} an alternative to using Zellner's seemingly unrelated <b>regression</b> <b>model</b> for estimating a system of recreation demand functions. The seemingly unrelated Poisson <b>regression</b> <b>model</b> provides estimates that are asymptotically more efficient than equation-by-equation Poisson estimates and circumvents the bias and inconsistency problems that result when using A. Zellner's seemingly unrelated <b>regression</b> <b>model.</b> Additionally, the seemingly unrelated Poisson <b>regression</b> <b>model</b> is applied to an empirical problem dealing with the value of recreational boating and the findings indicate that the seemingly unrelated <b>regression</b> <b>model</b> consumer surplus estimates are substantially {{different from those of the}} seemingly unrelated Poisson <b>regression</b> <b>model.</b> Copyright 1994 by MIT Press. ...|$|R
5000|$|... #Subtitle level 2: Relationship between factor <b>regression</b> <b>model,</b> factor <b>model</b> and <b>regression</b> <b>model</b> ...|$|R
40|$|Abstract: This paper {{represents}} {{the comparison between}} Negative Binomial <b>Regression</b> <b>model</b> and Generalized Poisson <b>Regression</b> <b>model</b> for over-dispersion count data. For this comparison, we used BDHS 2007 data in where the response variable is the total children ever born which is a count data. When the response variable is count, then Poisson <b>Regression</b> <b>Model</b> as a Generalized Linear Model is widely and popularly used to analyze such type of response variable and Poisson <b>Regression</b> <b>model</b> gives better result than the usual <b>regression</b> <b>model</b> for analyzing count data. In this paper, the descriptive statistics of the total children ever born data exhibit the presence of over-dispersion in the data set. Since the total children ever born data {{used in this study}} exhibit over-dispersion, we can use Negative Binomial <b>Regression</b> <b>Model</b> and Generalized Poisson <b>Regression</b> <b>Model.</b> These two models have statistical advantages over standard Poisson <b>regression</b> <b>model</b> and are suitable for analysis of count data that exhibit either over-dispersion or under-dispersion...|$|R
25|$|In addition, {{there are}} various {{mathematical}} models, such as logistic <b>regression</b> <b>models</b> and Bayesian networks, for the prediction of PUL outcome based on multiple parameters. Mathematical models also aim to identify PULs that are low risk, that is, failing PULs and IUPs.|$|E
25|$|Quantile {{regression}} {{focuses on}} the conditional quantiles of y given X rather than the conditional mean of y given X. Linear quantile <b>regression</b> <b>models</b> a particular conditional quantile, for example the conditional median, as a linear function βTx of the predictors.|$|E
25|$|In Dempster–Shafer theory, or {{a linear}} belief {{function}} in particular, a linear regression model may be {{represented as a}} partially swept matrix, which can be combined with similar matrices representing observations and other assumed normal distributions and state equations. The combination of swept or unswept matrices provides an alternative method for estimating linear <b>regression</b> <b>models.</b>|$|E
5000|$|The factor <b>regression</b> <b>model</b> can {{be viewed}} as a {{combination}} of factor analysis <b>model</b> (...) and <b>regression</b> <b>model</b> (...) [...]|$|R
40|$|Real life data often {{includes}} {{information from}} different channels. For example, in computer vision, we can describe an image using different image features, such as pixel intensity, color, HOG, GIST feature, SIFT features, etc [...] These {{different aspects of}} the same objects are often called multi-view (or multi-modal) data. Low-rank <b>regression</b> <b>model</b> has been proved to be an effective learning mechanism by exploring the low-rank structure of real life data. But previous low-rank <b>regression</b> <b>model</b> only works on single view data. In this paper, we propose a multi-view low-rank <b>regression</b> <b>model</b> by imposing low-rank constraints on multi-view <b>regression</b> <b>model.</b> Most importantly, we provide a closed-form solution to the multi-view low-rank <b>regression</b> <b>model.</b> Extensive experiments on 4 multi-view datasets show that the multi-view low-rank <b>regression</b> <b>model</b> outperforms single-view <b>regression</b> <b>model</b> and reveals that multi-view low-rank structure is very helpful. Comment: Twenty-Ninth AAAI Conference on Artificial Intelligence, AAAI, 201...|$|R
40|$|Most {{automated}} essay scoring programs use {{a linear}} <b>regression</b> <b>model</b> to predict an essay score from several essay features. This article applied a cumulative logit model {{instead of the}} linear <b>regression</b> <b>model</b> to automated essay scoring. Comparison of the performances of the linear <b>regression</b> <b>model</b> and the cumulative logit model was performed on a large variety of data sets. It appears that the cumulative logit model performed somewhat better than did the linear <b>regression</b> <b>model...</b>|$|R
25|$|The gamma {{distribution}} {{has been used}} to model the size of insurance claims and rainfalls. This means that aggregate insurance claims and the amount of rainfall accumulated in a reservoir are modelled by a gamma process. The {{gamma distribution}} is also used to model errors in multi-level Poisson <b>regression</b> <b>models,</b> because the combination of the Poisson distribution and a gamma distribution is a negative binomial distribution.|$|E
25|$|The {{numerical}} {{methods for}} linear least squares {{are important because}} linear <b>regression</b> <b>models</b> {{are among the most}} important types of model, both as formal statistical models and for exploration of data-sets. The majority of statistical computer packages contain facilities for regression analysis that make use of linear least squares computations. Hence it is appropriate that considerable effort has been devoted to the task of ensuring that these computations are undertaken efficiently and with due regard to round-off error.|$|E
25|$|In {{statistics}} and numerical analysis, {{the problem of}} numerical methods for linear least squares {{is an important one}} because linear <b>regression</b> <b>models</b> {{are one of the most}} important types of model, both as formal statistical models and for exploration of data sets. The majority of statistical computer packages contain facilities for regression analysis that make use of linear least squares computations. Hence it is appropriate that considerable effort has been devoted to the task of ensuring that these computations are undertaken efficiently and with due regard to numerical precision.|$|E
40|$|This paper {{presents}} the comparative study for fuzzy <b>regression</b> <b>model</b> using linear programming, fuzzy <b>regression</b> <b>model</b> using genetic algorithms and standard <b>regression</b> <b>model.</b> The fuzzy and standard models were developed for estimation of electric power losses in electrical networks. Simulation {{was carried out}} with a tool developed in MATLAB...|$|R
30|$|Establish the <b>regression</b> <b>model</b> of the {{historical}} failure rate and weather intensity and select the suitable <b>regression</b> <b>model</b> via the hypothesis test.|$|R
40|$|The paper {{deals with}} the {{classical}} linear <b>regression</b> <b>model</b> of the dependence of conveyor belt life on some selected parameters: thickness of paint layer, width and length of the belt, conveyor speed and quantity of transported material. The {{first part of the}} article is about <b>regression</b> <b>model</b> design, point and interval estimation of parameters, verification of statistical significance of the model, and about the parameters of the proposed <b>regression</b> <b>model.</b> The second part of the article deals with identification of influential and extreme values that can have an impact on estimation of <b>regression</b> <b>model</b> parameters. The third part focuses on assumptions of the classical <b>regression</b> <b>model,</b> i. e. on verification of independence assumptions, normality and homoscedasticity of residuals...|$|R
25|$|In statistics, linear {{least squares}} {{problems}} correspond to a particularly important type of statistical model called linear regression which arises as a {{particular form of}} regression analysis. One basic form of such a model is an ordinary least squares model. The present article concentrates on the mathematical aspects of linear least squares problems, with discussion of the formulation and interpretation of statistical <b>regression</b> <b>models</b> and statistical inferences related to these being {{dealt with in the}} articles just mentioned. See outline of regression analysis for an outline of the topic.|$|E
25|$|In another {{empirical}} study, Chaudhry (2009) investigated {{factors affecting}} rural poverty in Southern Punjab (Pakistan), and {{he concluded that}} alleviation of poverty is possible by lowering the household size and dependency ratio, improving education, increasing female labor participation. He employed Logit <b>regression</b> <b>models</b> and used primary source of data from the project area of Asian Development Bank for estimation. Results indicate that as dependency level and household size increase the probability of being poor increases too. Education has the significant inverse relationship with poverty because it provides employment opportunities and rejects poverty. The inclusion of trained and education women workforce will not only ensure women's welfare, it will also increase the overall productivity of the workforce due to more competitiveness. Hence, the developmental and feminist economists {{argue that it is}} desirable for the government to allocate more resources towards women's education, as it is going to benefit the whole society.|$|E
2500|$|C24 	Truncated and Censored Models • Switching <b>Regression</b> <b>Models</b> • Threshold <b>Regression</b> <b>Models</b> ...|$|E
40|$|This paper {{presents}} and evaluates an adaptive linear <b>regression</b> <b>model</b> for {{the prediction of}} unknown anthropometric data based on a flexible set of known predictive data. The method is based on conditional regression and includes use of principal component analysis to reduce effects of multicollinearity between the predictive variables. Results from the study show that the proposed adaptive <b>regression</b> <b>model</b> produces more accurate predictions compared to a flat <b>regression</b> <b>model</b> based on stature and weight, and also compared to a hierarchical <b>regression</b> <b>model,</b> that uses geometric and statistical relationships between body measurements to create specific linear regression equations in a hierarchical structure. An additional evaluation shows that {{the accuracy of the}} adaptive <b>regression</b> <b>model</b> increases logarithmically with the sample size. Apart from the sample size, the accuracy of the <b>regression</b> <b>model</b> is affected by the number of, and on which measurements that are, variables in the predictive dataset...|$|R
40|$|In this paper, {{the scale}} {{response}} functional multivariate <b>regression</b> <b>model</b> is considered. By using the basis functions representation of functional predictors and <b>regression</b> coefficients, this <b>model</b> is rewritten as a multivariate <b>regression</b> <b>model.</b> This {{representation of the}} functional multivariate <b>regression</b> <b>model</b> is used for multiclass classification for multivariate functional data. Computational experiments performed on real labelled data sets demonstrate {{the effectiveness of the}} proposed method for classification for functional data...|$|R
30|$|Upon {{comparing}} the R 2 {{of the first}} linear <b>regression</b> <b>model</b> (Table[*] 3) {{with that of the}} second linear <b>regression</b> <b>model</b> (Table[*] 5), we can then report that the second model provides a better prediction of the sentence in years. In addition, because the error variance in the first <b>regression</b> <b>model,</b> S 2 = 1.90, is larger than that of the second <b>regression</b> <b>model,</b> S 2 = 1.62, the second model generates errors that are less dispersed. This implies that using the additional set of proposed indicators generates a better prediction.|$|R
2500|$|The {{following}} are the major assumptions made by standard linear <b>regression</b> <b>models</b> with standard estimation techniques (e.g. ordinary least squares): ...|$|E
2500|$|The {{most popular}} {{statistical}} technique used is logistic regression to predict a binary outcome: bad debt or no bad debt. [...] Some banks also build <b>regression</b> <b>models</b> that predict {{the amount of}} bad debt a customer may incur. Typically this is much harder to predict, and most banks focus only on the binary outcome.|$|E
2500|$|An {{important}} consideration when carrying out statistical inference using <b>regression</b> <b>models</b> {{is how the}} data were sampled. [...] In this example, the data are averages rather than measurements on individual women. [...] The fit of the model is very good, {{but this does not}} imply that the weight of an individual woman can be predicted with high accuracy based only on her height.|$|E
30|$|The {{significance}} of the <b>regression</b> <b>model</b> is tested with an F-statistic. The summarized result is shown in Table  7. The hypotheses are as follows: H 0 : the <b>regression</b> <b>model</b> does not explain {{a significant proportion of}} the variation in the economic growth and Ha: the <b>regression</b> <b>model</b> explains a significant proportion of the variation in economic growth. The regression F test results (F[*]=[*] 5.191) is significant at p[*]<[*] 0.01. Therefore, the null hypothesis is rejected. Thus, there is support that the <b>regression</b> <b>model</b> explains the dependent variable, economic growth.|$|R
30|$|Tobit <b>regression</b> <b>model</b> {{is adapted}} for this study. This is {{because most of}} the {{responses}} for the dependent variable were zero (Greene, 2003). The normal <b>regression</b> <b>model</b> is not suitable for analysis when the most of the responses are zero, since that will result in the violation of the assumptions (Greene, 2003, Newman et al., 2015). Censoring of data is a common phenomenon in the microeconomic data analysis. In censoring a given range of data in the dependent variable are transformed into a single value. In such instances, the conventional <b>regression</b> <b>model</b> fails {{to take care of the}} variations between the limit of (0) observations and non-limit thus continuous observations. The <b>regression</b> <b>model</b> that is based on this is called censored or tobit <b>regression</b> <b>model.</b>|$|R
40|$|Cancer is a {{dangerous}} disease causing the most deaths {{in the world today}} and around 550, 000 deaths in America per year (American Cancer Society). Larynx cancer data was recorded by Kardaun (1983). The data was collected at a Dutch hospital during 1970 – 1978. Ninety male adults with cancer of larynx were involved into the study. Each patient was divided into one of four groups depending on his or her illness condition. The data also recorded their age, lifetime, and year of entering the research. These are common factors as factors of other cancer data. The purpose of this thesis is to apply proportional hazard <b>regression</b> <b>model,</b> additive hazard <b>regression</b> <b>model,</b> censored quantiles <b>regression</b> <b>model,</b> and censored linear <b>regression</b> <b>model</b> to analyze the above larynx cancer data and find the best <b>regression</b> <b>model</b> of data by using each method. Comparison and suggestion for which method should be used in specific situation are also made. Some related topics are also mentioned so we can have resource for future study. Key words: right censoring, proportional risk model, additive risk <b>model,</b> quantiles <b>regression</b> <b>model,</b> linear <b>regression</b> <b>model...</b>|$|R
2500|$|Various {{models have}} been created that allow for heteroscedasticity, i.e. the errors for {{different}} response variables may have different variances. [...] For example, weighted least squares is a method for estimating linear <b>regression</b> <b>models</b> when the response variables may have different error variances, possibly with correlated errors. (See also Weighted linear least squares, and Generalized least squares.) Heteroscedasticity-consistent standard errors is an improved method for use with uncorrelated but potentially heteroscedastic errors.|$|E
2500|$|Linear <b>regression</b> <b>models</b> {{are often}} fitted using the least squares approach, {{but they may}} also be fitted in other ways, such as by {{minimizing}} the [...] "lack of fit" [...] in some other norm (as with least absolute deviations regression), or by minimizing a penalized version of the least squares loss function as in ridge regression (L2-norm penalty) and lasso (L1-norm penalty). Conversely, the least squares approach can be used to fit models that are not linear models. Thus, although the terms [...] "least squares" [...] and [...] "linear model" [...] are closely linked, they are not synonymous.|$|E
2500|$|Standard linear <b>regression</b> <b>models</b> with {{standard}} estimation techniques make {{a number of}} assumptions about the predictor variables, the response variables and their relationship. [...] Numerous extensions have been developed that allow each of these assumptions to be relaxed (i.e. reduced to a weaker form), {{and in some cases}} eliminated entirely. [...] Some methods are general enough that they can relax multiple assumptions at once, and in other cases this can ns. [...] Generally these extensions make the estimation procedure more complex and time-consuming, and may also require more data in order to produce an equally precise model.|$|E
40|$|Doctor of PhilosophyDepartment of StatisticsShie-Shien YangLogistic <b>regression</b> <b>model</b> is {{a branch}} of the {{generalized}} linear models and is widely used in many areas of scientific research. The logit link function and the binary dependent variable of interest make the logistic <b>regression</b> <b>model</b> distinct from linear <b>regression</b> <b>model.</b> The conclusion drawn from a fitted logistic <b>regression</b> <b>model</b> could be incorrect or misleading when the covariates can not explain and /or predict the response variable accurately based on the fitted model- that is, lack-of-fit is present in the fitted logistic <b>regression</b> <b>model.</b> The current goodness-of-fit tests can be roughly categorized into four types. (1) The tests are based on covariate patterns, e. g., Pearson's Chi-square test, Deviance D test, and Osius and Rojek's normal approximation test. (2) Hosmer-Lemeshow's C and Hosmer-Lemeshow's H tests are based on the estimated probabilities. (3) Score tests are based on the comparison of two models, where the assumed logistic <b>regression</b> <b>model</b> is embedded into a more general parametric family of models, e. g., Stukel's Score test and Tsiatis's test. (4) Smoothed residual tests include le Cessie and van Howelingen's test and Hosmer and Lemeshow's test. All of them have advantages and disadvantages. In this dissertation, we proposed a partition logistic <b>regression</b> <b>model</b> which {{can be viewed as a}} generalized logistic <b>regression</b> <b>model,</b> since it includes the logistic <b>regression</b> <b>model</b> as a special case. This partition model is used to construct goodness-of- fit test for a logistic <b>regression</b> <b>model</b> which can also identify the nature of lack-of-fit is due to the tail or middle part of the probabilities of success. Several simulation results showed that the proposed test performs as well as or better than many of the known tests...|$|R
30|$|From the {{statistical}} reports {{obtained from the}} present work, {{it was observed that}} the calibration curve in bioanalytical experiments was susceptible to heteroscedasticity using the unweighted linear <b>regression</b> <b>model.</b> Hence, to obtain homoscedasticity in the calibration curve experiments, {{there is a need for}} a weighted linear <b>regression</b> <b>model.</b> The appropriate <b>regression</b> <b>model</b> was further selected by evaluating the % RE for different weighting factors.|$|R
40|$|We {{propose a}} new {{parametric}} <b>regression</b> <b>model,</b> Hybrid Linear <b>Regression</b> <b>Model</b> (or simply HLRM), which has partially additive and multiplicative covariate structure. In an ordinary linear <b>regression</b> <b>model</b> or generalized linear model, {{it is assumed}} that the covariates have either an additive or multiplicative effect on the response. A family of HLRM includes an ordinary linear <b>regression</b> <b>model,</b> logarithmic linear model and generalized linear model with normal errors as special cases. In analysis of HLRM, estimating unknown parameters or searching for the best fitting optimal model, we assume the log-normal distribution. Some illustrative analyses applying HLRM to actual data sets are also demonstrated...|$|R
