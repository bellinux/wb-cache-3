344|626|Public
25|$|Rutgers {{developed}} water-soluble {{sustained release}} polymers, tetraploids, <b>robotic</b> <b>hands,</b> artificial bovine insemination, and the ceramic tiles for the heat shield on the Space Shuttle. In health related field, Rutgers has the Environmental & Occupational Health Science Institute (EOHSI).|$|E
25|$|In robotics, {{almost all}} <b>robotic</b> <b>hands</b> {{have a long}} and strong opposable thumb. Like human hands, the thumb of a robotic hand also {{plays a key role}} in {{gripping}} an object. One inspiring approach of robotic grip planning is to mimic human thumb placement.|$|E
2500|$|The {{album was}} {{released}} internationally on December 7, 2009, {{and in the}} US on December 8, 2009. It was released on all major formats and, {{in addition to the}} standard edition, an extended deluxe edition was also released, containing an additional six songs. The international edition differs slightly from the US edition, with one extra song ("Girlfriend") appearing on the standard edition and another ("Chase Our Love") appearing on the deluxe extended edition with the inclusion of track ("Movie") omitted. The European deluxe edition was issued as a single-CD, while US and Japanese deluxe editions are two-disc sets. The album cover displays Brown with <b>robotic</b> <b>hands,</b> wearing black clothing and sunglasses, holding a guitar over his shoulder, and spray-painting the album title, which is written in a font similar to that of Purple Rain by Prince and the Revolution. To promote the album, Brown embarked on the [...] "Fan Appreciation Tour" [...] on October 27, 2009, in New Jersey. The tour took place in the US. The tour ended on December 15, 2009, in New York and a portion of the proceeds from the tour will go to charity to help the victims of domestic violence as well as people with developmental disabilities.|$|E
40|$|This {{research}} {{focuses on}} the working and development of wireless <b>robotic</b> <b>hand</b> system. In this research previously developed models have been studied. After analysis of those models, a better approach has been presented in this research. The objective {{of this research is}} to design and develop a tele-operated <b>robotic</b> <b>hand</b> system. The <b>robotic</b> <b>hand</b> is intended for providing solutions to industrial problems like robot reprogramming, industrial automation and replacement for the workers working in hostile environments. The <b>robotic</b> <b>hand</b> system works in the master slave configuration where Bluetooth is being used as the communication channel for the tele-operation. The master is a glove, embedded with sensors to detect the movement of every joint present in the hand, which a human operator can wear. This joint movement is transferred to the slave <b>robotic</b> <b>hand</b> which will mimic the movement of human operator. The <b>robotic</b> <b>hand</b> is a multi fingered dexterous and anthropomorphic hand. The hand is designed by using commercially available version of SolidWorkBOIO. The <b>robotic</b> <b>hand</b> comprises of five fingers (four fingers and one thumb), each having four degrees of fieedom @OF). All the fingers are capable of performing flexion, extension, abduction, adduction and hence circumduction. A new combination of pneumatic muscles and springs has been used for the actuation purpose. This combination reduces the size of the <b>robotic</b> <b>hand</b> by decreasing the number of pneumatic muscles used. The pneumatic muscles are controlled by the opening and closing of solenoid valves. A novel technique has been used in the <b>robotic</b> <b>hand</b> for tendon routing, which gives the ability of independence to all finger joints. Each of the finger joints can bend independently. The heart of all the control mechanism is rnbed microcontroller. The sensors used in the glove for sensing the joint angles are BendSensors. The controller processes the angles provided by these sensors and hen transmit to the <b>robotic</b> <b>hand.</b> The <b>robotic</b> <b>hand</b> also has mbed microcontrolIer to acquire the angles from master and control the opening and closing of solenoid valves according to the required angle...|$|R
40|$|A novel {{method to}} {{calculate}} the bended finger’s angle has presented here {{which could be used}} to control the electro-mechanical <b>robotic</b> <b>hand.</b> It is assumed that the <b>robotic</b> <b>hand</b> has the human hand like joints and same number of degree of freedom as human hand. In many applications an equipment like human hand is needed, to do the same kind of operation like human do. These days it is easy to make the electro-mechanical <b>robotic</b> <b>hand</b> which has five fingers and same joint but it is not easily controllable as the human hand for accurate work. In our method the hand gesture will be interpreted for controlling the <b>robotic</b> <b>hand.</b> The angles for all the fingers will be calculated and that could be further passed to the <b>robotic</b> <b>hand</b> for controlling its finger. User would perform gesture according to the action as he wants to be done by <b>robotic</b> <b>hand.</b> Here finger positions are detected using geometric modeling of hand in the extracted image Region of interest cropping from the image made the algorithm faster. </p...|$|R
40|$|Humanoid robots {{have become}} more {{important}} in the military applications, space exploration missions and hazardous environments like mining. The purpose of a humanoid robot is to walk, jump, run, grasp the objects, manipulate the objects etc., <b>Robotic</b> <b>hand</b> plays an important role for a humanoid robot. This thesis focuses on the development of <b>robotic</b> <b>hand</b> for the humanoid robot. It includes (a) Development of <b>robotic</b> <b>hand</b> (only four fingers) with tendons and servomotors, (b) Development of <b>robotic</b> <b>hand</b> only with the servo motors for practicing the human grasps and the heavy wrap has been demonstrated, (c) Design of robotic Arm and the experimental setup to conduct experiments for improvising the robot efficiency...|$|R
5000|$|A robot that {{performs}} street begging, {{made from}} recycled computer parts, with a voice and <b>robotic</b> <b>hands.</b>|$|E
50|$|His work on <b>robotic</b> <b>hands</b> {{has been}} {{featured}} in popular publications on robotics. In January 2017 he was interviewed for the Robots Podcast.|$|E
50|$|Domenico Prattichizzo {{from the}} Universita di Siena, Italy was named Fellow of the Institute of Electrical and Electronics Engineers (IEEE) in 2016 for {{contributions}} to haptics and multi-fingered <b>robotic</b> <b>hands.</b>|$|E
40|$|This paper {{presents}} {{the implementation of}} a robust grasp mapping between a 3 -finger haptic device (master) and a <b>robotic</b> <b>hand</b> (slave). Mapping is based on a grasp equivalence defined considering the manipulation capabilities of the master and slave devices. The metrics that translate the human hand gesture to the <b>robotic</b> <b>hand</b> workspace are obtained through an analytical user study. This allows a natural control of the <b>robotic</b> <b>hand.</b> The grasp mapping is accomplished defining 4 control modes that encapsulate all the grasps gestures considered...|$|R
5000|$|... #Caption: Gold medal winner <b>robotic</b> <b>hand</b> from Belgrade University.|$|R
40|$|As of now, {{the missile}} {{launchers}} which use <b>Robotic</b> <b>Hand</b> for holding and releasing of missiles in defense organizations are being {{controlled by the}} microcontroller. As {{a result of this}} there are many problems associated. One is that the controlling of the whole process is not perfect. Therefore we have proposed a paper where the <b>robotic</b> <b>hand</b> which controls the missile launcher will be controlled by a PLC and secured image authentication technique. In our project, the hand which is holding the missile that to be launch is controlled by the PLC. The <b>robotic</b> <b>hand</b> is operated by with the help of DC motor. The PLC controls the two kind of position of <b>robotic</b> <b>hand.</b> One is holding the missile and another one is releasing the missile. Actually the PLC is controlling the DC motor in two conditions which is holding and releasing. In the Space research center, applying the missile is very important and secure process also. So, operating with the missile launching process, secured by image authentication technique is highly required. PLC controls the <b>robotic</b> <b>hand</b> by means of ladder diagram which is nothing but programming of PLC. In that programming only our secure technique will be used. The pass code and image synchronizations are needed to execute the programming of PLC. Until the authorization the <b>robotic</b> <b>hand</b> it will not release or hold the missile...|$|R
50|$|Rutgers {{developed}} water-soluble {{sustained release}} polymers, tetraploids, <b>robotic</b> <b>hands,</b> artificial bovine insemination, and the ceramic tiles for the heat shield on the Space Shuttle. In health related field, Rutgers has the Environmental & Occupational Health Science Institute (EOHSI).|$|E
50|$|According to the university's project page, {{some of the}} {{objectives}} of the Kanguera project are to develop strategies for dexterous robotic manipulation and to create new designs for <b>robotic</b> <b>hands</b> which are biologically inspired. These new designs and strategies will be used for user friendly human machine interface and for upper limb rehabilitation technologies.|$|E
50|$|The page {{showed a}} stylized {{representation}} of hello.jpg, which featured {{a pair of}} silver <b>robotic</b> <b>hands</b> 'stretching' a metallic, circular wall aperture in {{what appears to be}} a futuristic factory setting. Later in May, a new page was hosted at goatse.cx, for the stated purpose of offering email service at the site, featuring a sketch with hands spreading wide a view onto a mailing envelope.|$|E
40|$|A multi-jointed multi-fingered <b>robotic</b> <b>hand</b> has {{potential}} capability of dexterous and versatile manipulation. We {{have developed a}} novel fingertip equipped with soft skin and hard nail to increase {{the ability of the}} multi-fingered <b>robotic</b> <b>hand.</b> This paper describes its design and implementation together with the result of experiments to demonstrate new functions. 1...|$|R
40|$|A {{method of}} motion control for {{robotics}} and other automatically controlled machinery using a neural network controller with real-time environmental feedback. The method is illustrated with a two-finger <b>robotic</b> <b>hand</b> having proximity sensors and force sensors that provide environmental feedback signals. The neural network controller is taught {{to control the}} <b>robotic</b> <b>hand</b> through training sets using back- propagation methods. The training sets are created by recording the control signals and the feedback signal as the <b>robotic</b> <b>hand</b> or a simulation of the <b>robotic</b> <b>hand</b> is moved through a representative grasping motion. The data recorded is divided into discrete increments {{of time and the}} feedback data is shifted out of phase with the control signal data so that the feedback signal data lag one time increment behind the control signal data. The modified data is presented to the neural network controller as a training set. The time lag introduced into the data allows the neural network controller to account for the temporal component of the robotic motion. Thus trained, the neural network controlled <b>robotic</b> <b>hand</b> is able to grasp a wide variety of different objects by generalizing from the training sets...|$|R
40|$|From {{the last}} three decades {{creating}} human <b>robotic</b> <b>hand</b> replica with enhanced capabilities is of concern and lot of efforts have been put into it. This paper focuses on understanding the different techniques that are used for human robot interaction in <b>robotic</b> <b>hand</b> arm systems. Diversification is stated in areas of human and <b>robotic</b> <b>hand</b> interaction, the degrees of freedom, the grasping ability, number of fingers and materials used for the hand. The flexibility of grasp is compared in terms of Degrees Of Freedom (DOF) and the number of finger end effectors. The controlling method is either through sensor based or gesture controlled or simulation based or pre-defined positions...|$|R
50|$|The {{three of}} them go to {{investigate}} at a mental asylum, where they encounter {{the base of the}} Men In Black. They are detected, and the Men In Black go to confront them. They discover that Ocean Waters was abducted in 1972 and encountered the Men In Black. The Men In Black then arrive to confront them, and activate their <b>robotic</b> <b>hands.</b> They tell Sarah Jane she must hand over Androvax and their disc, or prepare to be incinerated.|$|E
50|$|In robotics, {{almost all}} <b>robotic</b> <b>hands</b> {{have a long}} and strong opposable thumb. Like human hands, the thumb of a robotic hand also {{plays a key role}} in {{gripping}} an object. One inspiring approach of robotic grip planning is to mimic human thumb placement. In a sense, human thumb placement indicates which surface or part of the object is good for grip. Then the robot places its thumb to the same location and plans the other fingers based on the thumb placement.|$|E
5000|$|CubeStormer 3 is a robot built {{primarily}} with Lego Mindstorms and the Samsung Galaxy S4. On 15 March 2014, at the Big Bang fair in Birmingham, England, the CubeStormer 3 broke the previous record, held by its predecessor, the CubeStormer II, for the fastest time {{to solve a}} Rubik's Cube. The previous Guinness World Records time was 5.270 seconds. The official time taken to solve the Rubik's Cube by the CubeStormer 3 was 3.253 seconds. This robot was created by inventors David Gilday and Mike Dobson. It took {{the two of them}} 18 months to perfect the technology of this robot. The robot was able to conquer the cube by use of four <b>robotic</b> <b>hands.</b> The robot is made out of LEGO and ARM architecture.|$|E
40|$|Abstract ─ This work {{describes}} a multifingered anthropomorphic <b>robotic</b> <b>hand</b> with fourteen Degrees of Freedom (DOF) which {{is able to}} mimic the functional motions of a biological hand especially in handling complex objects. The actuation mechanisms consisting of micro servo-motors, pulleys and belts {{are connected to the}} finger joints and thus promote bending and extending of the fingers. Two kinds of sensors, i. e. force sensor and light dependent resistor, are integrated into the system. The <b>robotic</b> <b>hand</b> can be controlled via a graphical user interface embedded with control codes or a joy stick integrated to a control board. Furthermore, the <b>robotic</b> <b>hand</b> is able to operate autonomously with the aid of sensory elements and embedded control software. Workability tests showed the capability of the system to move every finger individually and to perform grasping tasks on objects with varying sizes and geometries such as a tennis ball and a screw driver. Index Terms- <b>robotic</b> <b>hand,</b> degree of freedom, mechanis...|$|R
40|$|Teleoperating a <b>robotic</b> <b>hand</b> {{with the}} aid of a sensorized glove {{presents}} some particular problems. A certain problem is due to the kinematic differences between the human <b>hand</b> and the <b>robotic</b> <b>hand,</b> which do not allow a simple direct mapping of the sensor readings from the glove to the <b>robotic</b> <b>hand.</b> This problem is addressed with different types of mapping, but none of them is of general use. This paper proposes two new mappings within two existing mapping types, as well as a new hybrid mapping that combines the best features of these existing mapping types. This hybrid mapping allows intuitive free space movements (where the gesture is more important than the precise positions of the fingers) and grasp movements (where the precise positions of the fingers is more important than the gesture), despite kinematic differences between the human <b>hand</b> and the <b>robotic</b> <b>hand.</b> The approach has been implemented, and some illustrative examples are presented in this paper. Postprint (published version...|$|R
50|$|A 3D printed <b>robotic</b> <b>hand</b> {{developed}} by The Open Hand Project using desktop 3D printers.|$|R
50|$|Prosthetic {{hands are}} {{available}} in both voluntary opening and voluntary closing versions and because of their more complex mechanics and cosmetic glove covering require a relatively large activation force, which, {{depending on the type}} of harness used, may be uncomfortable. A recent study by the Delft University of Technology, The Netherlands, showed that the development of mechanical prosthetic hands has been neglected during the past decades. The study showed that the pinch force level of most current mechanical hands is too low for practical use. The best tested hand was a prosthetic hand developed around 1945. In 2017 however, a research has been started with bionic hands by Laura Hruby of the Medical University of Vienna. Some companies are also producing <b>robotic</b> <b>hands</b> with integrated forearm, for fitting unto a patient's upper arm.|$|E
50|$|In 2004, Puppet Master vs. Demonic Toys {{aired on}} the Scifi channel and was {{released}} on DVD in 2006, a concept which had been planned {{as far back as}} 1994. Only four puppets appeared in the actual movie: Blade, Jester, Pinhead and Six-Shooter. The idea was also to re-use the old look of the toys, but the inclusion of characters was limited to Jack Attack, Baby Oopsy Daisy and Grizzly Teddy. However, the end result was a change in design for the toys, notably utilizing designs for Six-Shooter that incorporated a 'Terminator'- influenced exoskeleton, and <b>robotic</b> <b>hands</b> for Pinhead. The fight scenes between the Toys and the Puppets are limited to the climactic end battles. It has been revealed by head executive of Full Moon Features, Charles Band, that the film was considered to be non-canon.|$|E
5000|$|The hand has an {{anthropomorphic}} shape, and is {{the size}} of a large human hand. It has 4 fingers, and a simplified thumb, each one with four degrees of freedom (DOF). [...] Each finger is treated as an individual robot, giving the overall system, from the wrist on, 20 DOF in total. The fingers are constructed from a special resin, and the joints are designed to mimic human joints - they are not physically joined, but in close contact, using the resin's friction and cables to work together. The motion of each DOF driven though a servo, and a cable transmission system. This transmission system is more accurate than the ones uses by previous <b>robotic</b> <b>hands,</b> and is thus more suitable for the implementation of complex trajectory algorithms, such as adduction and abduction capacity for both the fingers and the thumb.|$|E
50|$|Second {{version of}} the 3D printed <b>robotic</b> <b>hand</b> {{developed}} by Open Bionics using desktop 3D printers.|$|R
40|$|Study, {{mechanical}} {{design and implementation}} of a poly-articulated <b>robotic</b> <b>hand,</b> used for partial hand amputation or malformation rehabilitation. Feasibility study, set up and production of some custom design solutions (using plastic and metal 3 D rapid prototyping technologies and 3 D scanning techniques) to interfacing the <b>robotic</b> <b>hand</b> above as a prosthetic device with patients who had undergone a partial hand amputation or malformation...|$|R
40|$|This quarter, work {{continued}} {{on the design}} and construction of a <b>robotic</b> fingerspelling <b>hand.</b> The hand is being designed to aid in communication for individuals who are both deaf and blind. In the winter quarter, research was centered on determining an effective method of actuation for the <b>robotic</b> <b>hand.</b> This spring 2008 quarter, time was spent designing the mechanisms needed to mimic the size and motions of a human hand. Several methods {{were used to determine}} a proper size for the <b>robotic</b> <b>hand,</b> including using the ManneQuinPro human modeling system to approximate the size of an average male human hand and using the golden ratio to approximate the length of bone sections within the hand. After a proper average hand size was determined, a finger mechanism was designed in the SolidWorks design program that could be built and used in the <b>robotic</b> <b>hand...</b>|$|R
50|$|Scott and Vince board Cyclones, {{and prepare}} to head into the space station. Liberty has the {{remaining}} stockpile of Neutron-S missiles, and Vince sets one to self-destruct. The Ark Angel is able to depart as planned, with the Icarus following closely. The Haydonites, unaware of Grants plan, move their fleet towards Liberty to destroy the Ark Angel as Skull Squadron continues to engage the Haydonite fighters. During the battle, Maias fighter takes damage and she is forced to eject. Marcus uses his fighters <b>robotic</b> <b>hands</b> to grab Maias ejection pod and throw it towards the Ark Angel as it prepares to enter a spacefold. Marcus, deciding he {{has no reason to}} live, holds down his weapon triggers and launches a suicide run against the Haydonites to hold them off long enough for Ark Angel to escape. Just as the Ark Angel initiates a spacefold, the Neutron-S warheads detonate with a massive explosion, destroying Liberty and the entire Haydonite fleet.|$|E
5000|$|The {{history of}} {{automatic}} sign language translation {{started with the}} development of hardware such as finger-spelling <b>robotic</b> <b>hands.</b> In 1977, a finger-spelling hand project, Ralph created a robotic hand that can translate alphabets into finger-spellings. Later, the use of gloves with motion sensors became the mainstream, and some projects such as the CyberGlove and VPL Data Glove were born. The wearable hardware made it possible to capture the signers’ hand shapes and movements {{with the help of the}} computer software. However, the cameras {{with the development of}} computer vision replaced those wearable devices due to the efficiency and less physical restrictions on signers. To process the data collected through the devices, researchers implemented neural networks such as the Stuttgart Neural Network Simulator for the pattern recognition in their projects such as the CyberGlove. Researchers also use many other approaches for sign recognition. For example, Hidden Markov Models is used to analyze the data statistically,and the GRASP and other machine learning programs use the training sets to improve the accuracy of sign recognition.|$|E
5000|$|The {{album was}} {{released}} internationally on December 7, 2009, {{and in the}} US on December 8, 2009. It was released on all major formats and, {{in addition to the}} standard edition, an extended deluxe edition was also released, containing an additional six songs. The international edition differs slightly from the US edition, with one extra song ("Girlfriend") appearing on the standard edition and another ("Chase Our Love") appearing on the deluxe extended edition with the inclusion of track ("Movie") omitted. The European deluxe edition was issued as a single-CD, while US and Japanese deluxe editions are two-disc sets. The album cover displays Brown with <b>robotic</b> <b>hands,</b> wearing black clothing and sunglasses, holding a guitar over his shoulder, and spray-painting the album title, which is written in a font similar to that of Purple Rain by Prince and the Revolution. To promote the album, Brown embarked on the [...] "Fan Appreciation Tour" [...] on October 27, 2009, in New Jersey. The tour took place in the US. The tour ended on December 15, 2009, in New York and a portion of the proceeds from the tour will go to charity to help the victims of domestic violence as well as people with developmental disabilities.|$|E
40|$|A {{multiple}} degree-of-freedom hand {{has been}} developed which can interact with a human on a fundamental level. Th e <b>robotic</b> <b>hand</b> is closely modelled on a human hand, consisting of four fingers a nd a thumb. The digits are actuated using five servo motors to provide independen t motion and control. The <b>robotic</b> <b>hand</b> uses a webcam and artificial intelligence to detect and process a user?s hand position. This human interaction capab ility has allowed the <b>robotic</b> <b>hand</b> to perform simple operations such as playin g a human {{in a game of}} rock paper scissors. The latter has been showcased at a number of events to promote engineering as a career choice. Basic artificial intelligence has been inte grated into the system to allow the <b>robotic</b> <b>hand</b> to process and react to a video input stream. This has been used to allow the hand to make a more inform ed choice based on the current scenario. Potential future applications of the r obotic hand in manufacturing are explored. KEYWORDS...|$|R
40|$|This paper discuss about novel design {{approach}} to {{control of a}} <b>robotic</b> <b>hand</b> using flex sensors which indicates a biomechatronic multi fingered <b>robotic</b> <b>hand.</b> This <b>robotic</b> <b>hand</b> consists of base unit, upper arm, lower arm, palm and five fingers. The aim is to develop an anthropomorphic five fingered <b>robotic</b> <b>hand.</b> The proposed design illustrates the use of 5 micro DC motors with 9 Degrees of Freedom (DOF). Each finger is controlled independently. Further three extra motors {{were used for the}} control of wrist elbow and base movement. The study of the DC motor is being carried out using the transfer function model for constant excitation. The micro DC motor performance was analyzed using MATLAB simulation environment. The whole system is implemented using flex sensors. The flex sensors placed on the human hand gloves appear as if they look like real human hand.   89 v 51 microcontroller was used for all the controlling actions along with RF transmitter/receiver. The performance of the system has been conducted experimentally and studied. </p...|$|R
40|$|International audienceThis paper proposes robust tactile {{descriptors}} and,for {{the first}} time, a novel online tactile transfer learning strategy for discriminating objects through surface texture properties via a <b>robotic</b> <b>hand</b> and an artificial robotic skin. Using the proposed tactile descriptors the <b>robotic</b> <b>hand</b> can extract robust tactile information from generated vibro-tactile signals during in-hand object exploration. Tactile transfer learning algorithm enables the robotic system to autonomously select and then exploit the previously learned multiple texture models when classifying new objects {{with a few}} training samples or even one. The experimental outcomes demonstrate that employing the proposed methods and 10 prior texture models, the <b>robotic</b> <b>hand</b> could identify 12 objects through their surface textures properties with 97 % and 100 % recognition rate respectively with only one and ten training samples...|$|R
