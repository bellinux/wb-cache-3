13|206|Public
40|$|International audienceThe authors {{investigated}} {{the accuracy of}} horizontal pointing movements toward a visual target viewed on a vertical video monitor; the view included a directional distortion between perceptual and action spaces. Although accurate coding of the movement vector in a relative (visual) system of coordinates {{has been found to}} occur when there is a prismatic perturbation, provided that the hand and the target are continuously visible, such accurate performance has never been reported for video-controlled situations with larger deviations. To evaluate whether visual <b>relative</b> <b>coding</b> is task specific or depends on the magnitude of the induced misalignment, the authors manipulated the intensity of directional perturbation (10 ° or 40 °) in a video-controlled task. Whatever the directional bias, participants (N = 40) were initially inaccurate but adapted quickly within a few trial rehearsals, with a concomitant recalibration of segmental proprioception. In contrast with prism studies, <b>relative</b> <b>coding</b> of the hand-to-target vector seemed not to be operative in video-controlled situations, suggesting that target location is specified in an egocentric system of reference that includes hand-related proprioceptive signals, despite the presence of a (consciously) detected misalignment between visual and kinesthetic systems...|$|E
40|$|Vocalizations or speech {{constitute}} dynamic inputs {{that are}} represented in auditory cortices by precise time-varying activity patterns. Such response patterns are typically analyzed by aligning spikes and sensory events using the experimenter’s clock, a laboratory-based reference not available to the brain. In contrast, neural systems must interpret time-varying responses using only intrinsic reference frames, a particularly challenging task for stimuli appearing suddenly or unpredictably. One solution {{could be provided by}} encoding information in the relative timing of neural responses, thereby exploiting intrinsic temporal reference frames. But it remains unclear whether and how sensory cortices implement a neural reference suitable for <b>relative</b> <b>coding</b> schemes. We investigate the viability of such a <b>relative</b> <b>coding</b> scheme in primate auditory cortex using a paradigm where naturalistic sounds were presented at random (unexpected) times. Recording neural responses in macaque auditory cortex we found that neurons clustered in two subsets with different properties. A set of stereotypical neurons responded rapidly and unselectively to individual stimuli with minimally varying latency, while another set of stimulus-selective neurons responded slowly and selectively with high latency variability. We then tested the hypothesis that the latency of the stereotypical neurons can provide a reliable and intrinsic reference frame for <b>relative</b> <b>coding</b> schemes. Specifically, we calculated the stimulus information carried by the selective neurons in different neural codes based on the relative timing of their neural responses to either a stereotypical neuron or another selective neuron. Two codes were considered: the relative onset latency between neurons and the full spike train of the selective neuron aligned to the response onset of a reference neuron. Information in latency relative to stereotypical neurons reached 91 of the information in latency with respect to the stimulus onset. The spike trains of the selective neurons relative to the stereotypical neurons contains 84 of the information in spike trains aligned to the stimulus onset, but only 41 relative to another selective neuron. At the population level, an estimate of the latency based on 20 stereotypical neurons allows preserving 95 of the information as measured with the experimenter's clock. We thus demonstrate that information in response latencies and sustained time-varying responses may be decoded by measuring these relative to another neuron’s or a population response. Stereotypical neurons responding unselectively and rapidly to various complex stimuli may serve as an early saliency signal that provides a reliable temporal reference frame {{that can be used to}} extract information in the responses of more selective neurons...|$|E
40|$|This work {{deals with}} the problem of {{function}} learning by genetic algorithms where the function is used as a preference predicate. In such a case, learning the exact function is not necessary since any function that preserves the order induced by the target function is sufficient. The paper presents a methodology for solving the problem with genetic algorithms. We first consider the representation issues involved in learning such a function, and conclude that canonical representation, <b>relative</b> <b>coding,</b> and search restrictions, are required. We then show that the traditional homologous genetic operators are not appropriate for such learning, and introduce a new configurable analogous genetic operator, named derivative crossover. This operator works on the derivative of the chromosomes and is therefore suitable for preference predicate learning where only the relative values of the functions are important. We support our methodology by a set of experiments performed in the domain of cont [...] ...|$|E
40|$|In this paper, {{relative}} two-weight and three-weight {{codes are}} studied, which are both called <b>relative</b> constant-weight <b>codes.</b> A geometric approach is introduced {{to construct and}} characterize <b>relative</b> constant-weight <b>codes,</b> using the finite projective geometry. A sufficient and necessary condition is derived for linear <b>codes</b> to be <b>relative</b> constant-weight <b>codes,</b> based on the geometric approach. A family of infinite number of <b>relative</b> constant-weight <b>codes</b> are constructed, which includes dual Hamming codes and subcodes of punctured Reed-Muller codes as special instances. It {{is well known that}} determining all the minimal codewords is a hard problem for an arbitrary linear <b>code.</b> For <b>relative</b> constant-weight <b>codes,</b> minimal codewords are completely determined in this paper. Based on the above-mentioned results, applications of <b>relative</b> constant-weight <b>codes</b> to wire-tap channel of type II and secret sharing are discussed. A comparative study shows that <b>relative</b> constant-weight <b>codes</b> form a new family. They are not covered by the previously well-known three-weight codes or linear codes for which minimal codewords can be determined. No Full Tex...|$|R
40|$|A new {{approach}} of <b>relative</b> fractal <b>coding</b> {{has been presented}} in this paper. In this technique given the fractal code of a reference image, one can generate a <b>relative</b> fractal <b>code</b> of any other image of same size. The convergence of the <b>relative</b> <b>code</b> is also guaranteed. This method found to be useful for satellite remote sensing image compression as the spectral bands are correlated. It produces pure fractal code where the inter-band spectral changes are coded and the convergence is guaranteed for individual bands. Several experimental results are also presented...|$|R
40|$|Software systems evolve {{over time}} due {{to changes in}} requirements, {{optimization}} of code, fixes for security and reliability bugs etc. Code churn, which measures the changes made to a component {{over a period of}} time, quantifies the extent of this change. We present a technique for early prediction of system defect density using a set of <b>relative</b> <b>code</b> churn measures that relate the amount of churn to other variables such as component size and the temporal extent of churn. Using statistical regression models, we show that while absolute measures of code churn are poor predictors of defect density, our set of <b>relative</b> measures of <b>code</b> churn is highly predictive of defect density. A case study performed on Windows Server 2003 indicates the validity of the <b>relative</b> <b>code</b> churn measures as early indicators of system defect density. Furthermore, our code churn metric suite is able to discriminate between fault and not faultprone binaries with an accuracy of 89. 0 percent...|$|R
40|$|Over time, {{changes in}} coding have the {{potential}} to influence the trends observed within hospital morbidity data with diabetes as a principal diagnosis. Second edition ICD- 10 -AM (July 2000 onwards) changes potentially increased the scope for diabetes surveillance. Seventh edition ICD- 10 -AM (July 2010 onwards) changes potentially decreased the scope for diabetes surveillance. Hospital morbidity data for diabetes as a principal diagnosis from the third to the sixth editions of the ICD- 10 -AM (July 2002 - June 2010) represents a period of <b>relative</b> <b>coding</b> consistency. Over this period {{it is unlikely that the}} increase in the prevalence of diabetes in the community, directly accounts for all of the increase in episodes with diabetes as a principal diagnosis. 1. 0 Background and purpose of the report Morbidity data is collected on all admitted patients in Queensland hospitals as per the requirements of the Queensland Hospital Admitted Patient Data Collection (QHAPDC). 1 This data is represented b...|$|E
40|$|Abstract—The most {{powerful}} channel-coding schemes, namely, those based on turbo codes and low-density parity-check (LDPC) Gallager codes, {{have in common}} the principle of iterative decoding. However, the <b>relative</b> <b>coding</b> structures and decoding algorithms are substantially different. This paper shows that recently pro-posed novel coding structures {{bridge the gap between}} these two schemes. In fact, with properly chosen component convolutional codes, a turbo code can be successfully decoded by means of the decoding algorithm used for LDPC codes, i. e., the belief-propaga-tion algorithm working on the code Tanner graph. These new turbo codes are here nicknamed “turbo Gallager codes. ” Besides being interesting from a conceptual viewpoint, these schemes are impor-tant on the practical side because they can be decoded in a fully parallel manner. In addition to the encoding complexity advantage of turbo codes, the low decoding complexity allows the design of very efficient channel-coding schemes. Index Terms—Belief propagation (BP), iterative decoding, low-density parity-check (LDPC) codes, turbo codes. I...|$|E
40|$|The {{auditory}} {{system uses}} three cues to decode sound location: interaural time differences (ITDs), interaural level differences (ILDs), and spectral notches (SNs). Initial processing of these cues is performed in several auditory brainstem nuclei that send projections to neurons of the inferior colliculus (IC). This work addresses how information about these different sound localization cues is {{integrated into the}} responses of single neurons of the IC. Virtual space techniques were used to create stimulus sets varying in two soundlocalization parameters each. By manipulating pairs of cues within a stimulus set, the <b>relative</b> <b>coding</b> of each cue could be compared. Using a variety of information theoretic methods, the mutual information between the localization cues and the neural response was quantified under the assumption of several different encoding schemes. The {{results show that the}} three localization cues are best represented by different codes. ITD information is conveyed by spike rate alone, and is contained only in low frequency neurons. ILD information is best represented by a joint rate/first spike latency code. The coding of SNs changes with the best frequency (BF) of the neuron. Low B...|$|E
40|$|Detecting "similar code" is {{fundamental}} to many software engineering tasks. Current tools can help detect code with statically similar syntactic features (code clones). Unfortunately, some code fragments that behave alike without similar syntax may be missed. In this paper, we propose the term "code relatives" to refer to code with dynamically similar execution features. <b>Code</b> <b>relatives</b> {{can be used for}} such tasks as implementation-agnostic code search and classification of code with similar behavior for human understanding, which code clone detection cannot achieve. To detect <b>code</b> <b>relatives,</b> we present DyCLINK, which constructs an approximate runtime representation of code using a dynamic instruction graph. With our link analysis based subgraph matching algorithm, DyCLINK detects fine-grained <b>code</b> <b>relatives</b> efficiently. In our experiments, DyCLINK analyzed 290 + million prospective subgraph matches. The results show that DyCLINK detects not only <b>code</b> <b>relatives,</b> but also <b>code</b> clones that the state-of-the-art system is unable to identify. In a code classification problem, DyCLINK achieved 96 % precision on average compared with the competitor's 61 %...|$|R
40|$|Abstract. The {{application}} domain for automatical {{retrieval of}} melodic excerpts in musical collections is wide; e. g. it would facilitate {{the work of}} music researcher trying to find specific features in music. In this paper we consider several parts of the retrieving process. We present our representation for musical data. This inner representation is converted and established from MIDI-files. For the matching we use a par-ticular encoding (two dimensional <b>relative</b> <b>code),</b> which is formed out of the inner representation. This encoding can be interpreted differently depending {{on the way the}} key is given. Furthermore, in the match-ing phase we use an efficient indexing structure, well-known in string pattern matching, called suffix-trie. ...|$|R
30|$|According to this table, the RMS {{error of}} SVM model is quite {{smaller than that}} of the BPNN. In terms of running time, In addition, the SVM consumes a {{considerably}} less time for prediction compared with that of the BPNN. For determining the relative running time of each network, Matlab multipurpose software has been used (i.e. <b>relative</b> <b>codes</b> of both networks have written in the Matlab software environment). As it is completely clear in the Table, the associated running time of SVM in training set is even less {{than that of the}} BPNN in the testing process. All of these expressions can introduce the SVM as a robust algorithm for the prediction process.|$|R
40|$|The most {{powerful}} channel coding schemes, namely those based on turbo codes and low-density parity-check (LDPC) Gallager codes, {{have in common}} the principle of iterative decoding. However, the <b>relative</b> <b>coding</b> structures and decoding algorithms are substantially different. This paper presents a 2048 -bit, rate- 1 / 2 soft decision decoder for {{a new class of}} codes known as Turbo Gallager Codes. These codes are turbo codes with properly chosen component convolutional codes such that they can be successfully decoded by means of the decoding algorithm used for LDPC codes, i. e., the belief propagation algorithm working on the code Tanner graph. These coding schemes are important in practical terms for two reasons: (i) they can be encoded as classical turbo codes, giving a solution to the encoding problem of LDPC codes; (ii) they can also be decoded in a fully parallel manner, partially overcoming the routing congestion bottleneck of parallel decoder VLSI implementations thanks to the locality of the interconnections. The implemented decoder can support up to 1 Gbit/s data rate and performs up to 48 decoding iterations ensuring both high throughput and good coding gain. In order to evaluate the performance and the gate complexity of the decoder VLSI architecture, it has been synthesized in a 0. 18 mu m standard-cell CMOS technology...|$|E
40|$|A {{role for}} {{conceptual}} representations in cross-sensory correspondences {{has been linked}} to the relative (context-sensitive) mapping of feature values, whereas a role for sensory-perceptual representations {{has been linked to}} their absolute (context-insensitive) mapping. Demonstrating the relative nature of the automatic mapping underlying a cross-sensory correspondence therefore offers one way of confirming its conceptual basis. After identifying several prerequisites for relative and absolute mappings, we provide the first compelling demonstration that an automatically induced congruity effect based on a cross-sensory correspondence (i. e., that between haptic size and visual brightness) can be largely contingent on the relative mapping of the two features, thereby implying a conceptual basis for the correspondence. Participants in a speeded classification task were faster to classify a visual stimulus as brighter or darker when this required them to press a hidden response key that, incidentally, was relatively small or big, respectively. Importantly, the same levels of brightness (Experiment 1) and key size (Experiment 2) at different times corresponded to contrasting levels of the other feature depending on the context provided by the alternative stimuli with which they appeared. For example, the same medium key was congruent with a brighter stimulus when paired with a bigger key, but was congruent with a darker stimulus when paired with a smaller key. Reflecting on the broader implications of this finding, it is noted that the involvement of cross-sensory correspondences in some forms of sound symbolism in language also requires the <b>relative</b> <b>coding</b> of stimulus features...|$|E
40|$|The precise {{timing of}} spikes of {{cortical}} neurons relative to stimulus onset carries substantial sensory information. To access this information the sensory systems {{would need to}} maintain an internal temporal reference that reflects the precise stimulus timing. Whether and how sensory systems implement such reference frames to decode time-dependent responses, however, remains debated. Studying the encoding of naturalistic sounds in primate (Macaca mulatta) auditory cortex we here investigate potential intrinsic references for decoding temporally precise information. Within the population of recorded neurons, we found one subset responding with stereotyped fast latencies that varied little across trials or stimuli, while the remaining neurons had stimulus-modulated responses with longer and variable latencies. Computational analysis demonstrated that the neurons with stereotyped short latencies constitute an effective temporal reference for <b>relative</b> <b>coding.</b> Using the response onset of a simultaneously recorded stereotyped neuron allowed decoding most of the stimulus information carried by onset latencies and the full spike train of stimulus-modulated neurons. Computational modeling showed that few tens of such stereotyped reference neurons suffice to recover nearly all information that would be available when decoding the same responses relative to the actual stimulus onset. These findings reveal an explicit neural signature of an intrinsic reference for decoding temporal response patterns in the auditory cortex of alert animals. Furthermore, they highlight a role for apparently unselective neurons as an early saliency signal that provides a temporal reference for extracting stimulus information from other neurons...|$|E
40|$|This note {{provides}} several {{analyses of}} the combined function bending magnets of the SESAME storage ring. The objective is to develop tools to couple the magnetic design to the linear optics specifications. Such tools {{can be used to}} carry out a 3 D field optimization, at the design phase and following magnetic measurements, in particular in order to fine tune the end shims on the poles. The analyses take as input field maps on the midplane, which are then processed in different ways to obtain linear transfer matrices for the optics, in the horizontal and vertical planes. Some peculiarities of this kind of magnet are also highlighted, for example, the slight variation of gradient along the arc. For convenience, the <b>relative</b> <b>codes</b> and scripts are included in the appendix...|$|R
40|$|SummaryWhen {{reaching}} to grasp an object, we often move our arm and orient our gaze together. How are these movements coordinated? To investigate this question, we studied neuronal {{activity in the}} dorsal premotor area (PMd) and the medial intraparietal area (area MIP) of two monkeys while systematically varying the starting position of the hand and eye during reaching. PMd neurons encoded the relative position of the target, hand, and eye. MIP neurons encoded target location {{with respect to the}} eye only. These results indicate that whereas MIP encodes target locations in an eye-centered reference frame, PMd uses a <b>relative</b> position <b>code</b> that specifies the differences in locations between all three variables. Such a <b>relative</b> position <b>code</b> may {{play an important role in}} coordinating hand and eye movements by computing their relative position...|$|R
40|$|The {{protection}} of library's users' secrecy constitutes constant principle in the <b>relative</b> <b>codes</b> of deontology in Greece and abroad. Information regardless to the user's access {{in the internet}} via a library in concrete material constituting personal data, legally protected. However concrete exceptions, e. g. because of public safety and crimes' verification are in effect, so is possible the legal bending of secrecy. In the presentation will be analyzed the relative legal frame in Greece and in the USA, will be presented Library Awareness Program of American FBI and the relative with the libraries and the secrecy in the internet provisions of Patriot Act. Will be presented also certain thoughts for the altered role of library scientist, as professional but also as member of social total, against whom it brings probably certain obligations of providence...|$|R
40|$|The {{landmark}} JPEG 2000 {{image compression}} standard offers not only superior compression performance, but also incredible flexibility. The compressed bitstream of JPEG 2000 can be flexibly reorganized to another bitstream of different bitrate, resolution, and spatial {{region of interest}} (ROI) {{or a combination of}} any of the above. Such flexibility is achieved by multiplexing the compressed bitstream pieces of multiple code-blocks together into a combined bitstream, with the length of the code-block bitstream piece (LOCB) embedded in the combined bitstream. The LOCB serves both to reorganize the bitstream, and to decode the bitstream. It represents a significant overhead, especially since there is no correlation between the neighbor LOCBs. In this work, we introduce seamless multiplexing, and separate the information needed for the reorganization, i. e., the LOCB, from the compressed bitstream itself by using the decoder pointer to multiplex the bitstream pieces. As a result, the compressed bitstream consists of code-block bitstream pieces seamlessly concatenated to each other. With seamless multiplexing, only the compressed bitstream (without LOCB) needs to be delivered to the receiving client. It results in better compression performance and higher granularity of access. Another benefit of seamless multiplexing is that the <b>relative</b> <b>coding</b> orders of the code-blocks are preserved in the bitstream reorganization. As a result, the seamlessly multiplexed embedded codec (SMEC) may utilize the dependencies among the code-blocks in the coding, thus further boost the compression performance. 1...|$|E
30|$|Table  5 {{provides}} the simulation {{results of the}} proposed hybrid algorithm {{when compared with the}} original HM implementation and three state-of-the-art fast HEVC intra-coding algorithms, namely, those proposed by Gao [9], Shang [20] and Zhang [21]. It can be seen that the time reduction achieved by our algorithm is 55.24 % on average. The maximum time reduction is 70.68 % for the sequence of ‘Kimono 1 ’, which contains significant detail. This is because the evaluation of unlikely depth levels is effectively avoided. On the other hand, the encoding time reduction is achieved by no more than a 2.18 % increase in bit rate. Compared with Gao’, Shang’ and Zhang’s methods, the proposed algorithm saves additional time of 28, 17 and 3 % with similar rate distortion performance. It can be observed from Table  5 that, although the coding efficiency of Zhang’s method is slightly higher than our algorithm, its time reduction is less. Therefore, the comparative results demonstrate that our hybrid method outperforms the algorithms proposed by Gao and Shang and achieves a comparable performance to Zhang’s method. Specifically, when encoding low (416 × 240 pixels) and medium (832 × 480 pixels) resolution video sequences, our algorithm consistently outperforms Zhang’s method in terms of encoding time reduction. When encoding high definition (HD, 1280 × 720 pixels), full HD (FHD, 1920 × 1080 pixels) and 2 K (2560 × 1600 pixels) video sequences, the <b>relative</b> <b>coding</b> performance is affected by the content of the video test sequences. For video sequences that contain rich detail, such as ‘PeopleOnStreet’ and ‘Kimono 1 ’, our algorithm shows better performance than Zhang’s. Therefore, the proposed algorithm provides a better choice for high resolution sequences containing complex detail.|$|E
40|$|With a {{remarkable}} {{evolution in the}} development of digital cameras, non-contact 3 D measurement using computer vision has been rapidly developing in the past few decades. Excellent and well-accepted techniques include digital moiré and stereo vision. An obvious drawback of digital moiré {{is that it is not}} applicable to the measurement of significant discontinuities, which is common in this area of research. And in the process of measurement, error propagation is inevitable, especially under the condition of missing points. The reason for this shortcoming lies in its <b>relative</b> <b>coding</b> scheme. For stereo vision, it is based on triangulation which leads to an absolute measurement. However, correspondence searching and resolution limitation of measurement of lacking features are two of the major unsolved problems of stereo vision systems. Inspired by these two well-developed techniques, an absolute measuring method based on structured light is developed in this research, requiring only a camera and a projector. The philosophy behind the coding scheme is a hybrid of relativity to the center and absoluteness, or independence on every single point. The mathematical model of the system is described and theorems that relate to the guidance of designing such a system are introduced. Two important factors determine the accuracy of the 3 D measurement: correspondence matching and calibration of the camera and the projector’ parameters. For the correspondence matching, an image processing method is developed. Image subtraction, edge detection, grid permutation and establishment of sub-coordinate-systems are included in the algorithm. Aiming at the discontinuity measurement, discontinuous borders are marked out first by using a Gabor filter first. Epipolar geometry is then utilized in the process of searching out each corresponding points accurately on the image plane. Sub-pixel accuracy for correspondence matching can be achieved in this way. The second factor that affects the accuracy of the measurement system is concerned with the calibration of the whole system. A convenient calibration method for structured light systems is developed in this research. This calibration method significantly simplifies the calibration procedures, and experimental results are presented for the verification of this calibration method. And experiments verify accuracy of the whole measurement system. And its advantages over digital moiré and stereo vision are presented and verified by experiments. However, this calibration method for structured light system is applicable to the existing methods that are based on the least squares minimization effort. The assumptions made for the calibration system are not suitable to the nonlinear stereo vision system. Moreover, the 2 D planar pattern used in existing calibration methods cannot provide 3 D information in the 3 D space. To move it among different views will inadvertently introduce additional mechanical errors. An iterative calibration method is developed in order to solve the existing problems in the state-of-the-art calibration methods for stereo vision systems. It is the first time that an iterative calibration method is developed to solve the calibration of a two-camera system’s calibration with iterations in the 3 D space. Derivations are described for this iterative calibration algorithm using feedback control theory. Furthermore, the calibration target is designed and manufactured under specifications defined by the task has been created for. Experiments show the developed iterative calibration method based on feedback control can achieve convergent parameters. With the calibrated parameters, 3 D measurement of the calibration target verifies the correctness and accuracy of this iterative calibration method. Hence, the contributions of this work are significant. An absolute 3 D measurement system based on a 2 D pattern using digital moiré has been developed. At the same time, a novel calibration method for such a system has also been proposed and verified in this work. For investigation of calibration method on stereo vision system, an iterative method based on feedback control is developed. The presentation of such a complete system is a significant step forward in the field of 3 D measurement systems...|$|E
50|$|The Utrecht Haskell {{compiler}} {{can generate}} code for LLVM. Though the generator {{is in the}} early stages of development, in many cases it has been more efficient than the C code generator. The Glasgow Haskell Compiler (GHC) has a working LLVM backend that achieves a 30% speed-up of the compiled <b>code</b> <b>relative</b> to native <b>code</b> compiling via GHC or C code generation followed by compiling, missing only one of the many optimizing techniques implemented by the GHC.|$|R
40|$|Abstract:Depending on the {{prospect}} theory, the curve features of value function change with human’s risk attitude. But, through experiments, it is verified that the wealth {{level of a}} decision maker influences his value estimation and behaviours of decision-making under uncertain circumstances. In this paper, the endurable Maximum Loss Value (MLV), which means {{the amount of the}} maximum loss in a mental account can endure, is regarded as the measurement of the decision-maker’s risk-avoiding attitude to some extend and is used to qualify the code of the original value function. Hereafter, we use relatively coding method to construct the value function, which is called decision value function, under uncertain circumstances. It is found that the modified value function model which is amended by <b>relative</b> <b>code</b> well explains the experimental results of decisions under uncertainty. General speaking, the modified model has better unity and stability...|$|R
40|$|International audienceIntegrating several legacy {{software}} systems {{together is}} commonly performed with multiple {{applications of the}} Adapter Design Pattern in oo languages such as Java. The integration is based on specifying bi-directional translations between pairs of apis from different systems. Yet, manual development of wrappers to implement these translations is tedious, expensive and error-prone. In this paper, we explore how models, aspects and generative techniques {{can be used in}} conjunction to alleviate the implementation of multiple wrappers. Briefly the steps are, (1) the automatic reverse engineering of relevant concepts in apis to high-level models; (2) the manual definition of mapping relationships between concepts in different models of apis using an ad-hoc dsl; (3) the automatic generation of wrappers from these mapping specifications using aop. This approach is weighted against manual development of wrappers using an industrial case study. Criteria are the <b>relative</b> <b>code</b> length and the increase of automation...|$|R
40|$|Introduction: Underlying {{spatial memory}} {{and talking about}} spatial layouts are common {{cognitive}} processes (Haun et al. 2005). For example, to locate an object in space it is obligatory to choose a coordinate system called frame of reference in cognition {{as well as in}} its verbal expression. Coding space within different frames of reference requires different cognitive processes (e. g. Neggers et al. 2005). In relative frames of reference the origin of the coordinate system is the viewpoint of a person. In intrinsic frames of reference an object is located in relation to another object (Levinson 2003). FMRI data have suggested that different frames of reference show different patterns of neural activation (Burgess et al. 2002; Committeri et al. 2004). However, the number of existing frames of reference and their neural correlates remain controversial. In an event-related fMRI study we investigated whether differential neural networks for relative and intrinsic frames of reference can be isolated. Methods: In the present study an implicit sentence picture matching task was used to investigate differential neural correlates for relative and intrinsic frames of reference. Twenty-eight healthy human adults (16 women, 12 men) read a sentence describing a spatial scene followed by a picture, and decided whether the sentence matches the picture or not. Feedback was given either supporting a relative or an intrinsic frame of reference. After half of the trails the feedback switched from one reference frame to the respective other reference frame (Fig. 1). Participants were instructed to respond as accurately and as quickly as possible. They responded with their right hand by pressing a key with the index finger for a correct decision and a second key with the middle finger for an incorrect judgment. Two baseline tasks were included (Fig. 1) : a high level baseline (c 5) and a low level baseline (c 6). A 3 Tesla MRI system (Siemens TRIO, Erlangen, Germany) was used to acquire functional images of the whole brain. Using a gradient-echo echo planar scanning sequence 36 axial slices were obtained for each participant (voxel-size 3 x 3 x 3 mm, TR = 2310 ms, field of view = 192, TE = 30 ms, flip angle = 75). All functional images were acquired in one run that lasted for 50 minutes. Following the acquisition of functional images a high-resolution anatomical scan (T 1 -weighted MP-RAGE, 176 slices) was acquired. FMRI data were analyzed using BrainVoyager QX (Brain Innovation, Maastricht, The Netherlands). Random-effects whole brain group analyses were performed. The statistical threshold at the voxel level was set at p < 0. 001, uncorrected for multiple comparisons. Results: Intrinsic trials as compared to baseline trials revealed increased activity in the parietal lobe and in the parahippocampal gyrus. Relative as compared to baseline trails revealed a widespread network of activity. Increased activity was observed in occipitotemporal cortices, in the parietal lobe, and in frontal areas. We focused on the direct comparison between relative and intrinsic trials. Results showed increased activity in the left parahippocampal gyrus only for intrinsic trials as compared to relative trails. An ANOVA of the averaged beta-weights with the within factors Reference frame and Condition and the between factor Block order (relative-intrinsic and intrinsic-relative), obtained for all voxels in the parahippocampal gyrus, showed no main effect of Reference frames and Condition. A significant interaction between the factors Reference frame and Condition was observed (p < 0. 05). T-contrasts showed a significant effect for intrinsic (c 4) as compared to relative trials (c 3; p < 0. 001). Conversely, relative as compared to intrinsic trials showed strong increased activity in the left medial frontal gyrus. An ANOVA of the beta-weights in the brain area showed no main effects. A significant interaction between the factors Reference frame and Condition was observed (p < 0. 05). T-contrasts showed a significant effect for intrinsic (c 4) as compared to relative trials (c 3, p < 0. 01). When comparing all intrinsic and relative conditions together to the baseline we observed increased activity in the right and left frontal eye fields (Fig. 2). An ANOVA of the averaged beta-weights with the within factors Reference frame and the between factor Block order obtained for all voxels in the left frontal eye fields showed a main effect of Block order (p < 0. 001) and an trend effect of Reference frame (p = 0. 08). An ANOVA of the averaged beta-weights for all voxels in the right frontal eye fields showed a main effect of Block order (p < 0. 05) only. Conclusions: Using a sentence-picture matching task, we investigated whether differential neural correlates for intrinsic and relative frames of reference can be isolated. Intrinsic trials compared to relative trials showed increased activity in the parahippocampal gyrus whereas relative trails compared to intrinsic trials revealed increased neural activity in the frontal and parietal lobe. Both frames of reference together compared to a baseline show increased activity in the frontal eye fields which was stronger for the second block. This could be related to switching of reference frames (Wallentin et al. 2008). The present results confirm studies which report the parietal lobe to be involved in <b>relative</b> <b>coding</b> (Cohen & Andersen 2002). The neural correlates of intrinsic frames of reference were previously less well investigated. The present results show differential neural networks for both frames of reference that are crucial to spatial language. References: Burgess, N. (2002), 'The human hippocampus and spatial and episodic memory', Neuron, vol. 36, pp. 625 - 641. Cohen, Y. (2002), 'A common reference frame for movement plans in the posterior parietal cortex', Nature Reviews Neuroscience, vol. 3, pp. 553 - 562. Committeri, G. (2004), 'Reference frames for spatial cognition: Different brain areas are involved in viewer-, object-, and landmark centered judgments about object location', Cognitive Neuroscience, vol. 16, pp. 1517 - 1535. Haun, D. (2005), 'Bias in spatial memory: a categorical endorsement', Acta Psychologia, vol. 118, pp. 149 - 170. Levinson, S. (2003), 'Space in language and cognition: Explorations in cognitive diversity', Cambridge: CUP. Neggers, S. (2005), 'Quantifing the interactions between allo- and egocentric representation of space', Acta Psychologia, vol. 118, pp. 25 - 45. Wallentin, M. (2008), 'Frontal eye fields involved in shifting frames of reference within working memory for scenes', Neuropsychologia, vol. 46, pp. 399 - 408...|$|E
40|$|Competing {{models of}} {{sensorimotor}} computation predict different topological constraints in the brain. Some models propose population coding of particular reference frames in anatomically distinct nodes, whereas others require no such dedicated subpopulations and instead predict that regions will simultaneously code in multiple, intermediate, reference frames. Current empirical evidence is conflicting, {{partly due to}} difficulties involved in identifying underlying reference frames. Here, we independently varied the locations of hand, gaze, and target over many positions while recording from the dorsal aspect of parietal area 5. We find that the target is represented in a predominantly hand-centered reference frame here, contrasting with the <b>relative</b> <b>code</b> seen in dorsal premotor cortex and the mostly gaze-centered reference frame in the parietal reach region. This supports the hypothesis that different nodes of the sensorimotor circuit contain distinct and systematic representations, and this constrains the types of computational model that are neurobiologically relevant...|$|R
40|$|The Chinese BeiDou- 2 /COMPASS Navigation Satellite System has {{attained}} regional {{operational status}} {{and is expected}} to reach the same level of popularity as GPS once it has reached its full constellation. This contribution considers combined BeiDou+GPS <b>relative</b> <b>code</b> positioning and single- and multiple-frequency real time kinematic (RTK) positioning. A combined system increases the redundancy for solving the unknown GNSS parameters and thus allows for more precise position estimates, improved reliability and robustness against failure of any of the systems. The performance is evaluated by ambiguity success rates and by comparing the estimated positions to very precise benchmark coordinates. We make use of the LAMBDA method for integer ambiguity resolution, in combination with the Fixed Failure-rate Ratio Test to validate the resolved ambiguities. The combined model will be shown to allow for improved ambiguity resolution performance and positioning robustness and accuracy over the BeiDou- and GPS-only solutions...|$|R
40|$|SummaryCompeting {{models of}} {{sensorimotor}} computation predict different topological constraints in the brain. Some models propose population coding of particular reference frames in anatomically distinct nodes, whereas others require no such dedicated subpopulations and instead predict that regions will simultaneously code in multiple, intermediate, reference frames. Current empirical evidence is conflicting, {{partly due to}} difficulties involved in identifying underlying reference frames. Here, we independently varied the locations of hand, gaze, and target over many positions while recording from the dorsal aspect of parietal area 5. We find that the target is represented in a predominantly hand-centered reference frame here, contrasting with the <b>relative</b> <b>code</b> seen in dorsal premotor cortex and the mostly gaze-centered reference frame in the parietal reach region. This supports the hypothesis that different nodes of the sensorimotor circuit contain distinct and systematic representations, and this constrains the types of computational model that are neurobiologically relevant...|$|R
50|$|The Interstellar <b>Relative</b> Sapience <b>Code</b> is {{a number}} {{assigned}} to species determining their intelligence in the game. Barney has an IRSC of 93.7. The lower the IRSC, the higher the intelligence of the race. However, {{whether or not this}} applies outside the game is unclear; Barney exhibits superior critical thinking skills when fighting the aliens, even though they have lower IRSCs.|$|R
40|$|We {{measured}} {{the responses of}} neurons in auditory cortex {{of male and female}} ferrets to artificial vowels of varying fundamental frequency (f(0)), or periodicity, and compared these with the performance of animals trained to discriminate the periodicity of these sounds. Sensitivity to f(0) was found in all five auditory cortical fields examined, with most of those neurons exhibiting either low-pass or high-pass response functions. Only rarely was the stimulus dependence of individual neuron discharges sufficient to account for the discrimination performance of the ferrets. In contrast, when analyzed with a simple classifier, responses of small ensembles, comprising 3 - 61 simultaneously recorded neurons, often discriminated periodicity changes as well as the animals did. We examined four potential strategies for decoding ensemble responses: spike counts, relative first-spike latencies, a binary "spike or no-spike" code, and a spike-order code. All four codes represented stimulus periodicity effectively, and, surprisingly, the spike count and <b>relative</b> latency <b>codes</b> enabled an equally rapid readout, within 75 ms of stimulus onset. Thus, <b>relative</b> latency <b>codes</b> do not necessarily facilitate faster discrimination judgments. A joint spike count plus <b>relative</b> latency <b>code</b> was more informative than either code alone, indicating that the information captured by each measure was not wholly redundant. The responses of neural ensembles, but not of single neurons, reliably encoded f(0) changes even when stimulus intensity was varied randomly over a 20 dB range. Because trained animals can discriminate stimulus periodicity across different sound levels, this implies that ensemble codes are better suited to account for behavioral performance...|$|R
40|$|This thesis {{investigates the}} {{influence}} of linguistic factors {{on the distribution of}} pronoun case forms in Modem English and argues that the alternation between nominative and objective pronoun forms is a surface phenomenon best captured in a probabilistic constraint-based approach, where constraints are weighted and the combined weight of constraint violations determines the probability of occurrence of a particular variant. I propose that the distribution of both weak and strong pronoun forms in English is affected by the interaction of two structural case constraints: Argument Case, which restricts the overt case form of structural arguments of a predicate; and Positional Case, which constrains the form of pronouns that appear as the specifier of an agreement-related functional head at Spell-Out. Pronouns that occupy surface positions not covered by the Positional Case constraint are further influenced by a Default Case constraint that calls for objective pronoun forms. A survey of data reported in existing studies suggests that all instances of pronoun case variation that cannot be given a purely case-based account occur in strong pronoun contexts. The consistent nominative/objective case distinction found with weak pronouns is due to their syntactic deficiency and the increasing importance of Positional Case in English. Unlike strong pronouns, weak pronouns must be licensed by an agreement-related functional head at Spell-Out, which means that they will generally be subject to the Positional Case constraint as well as the Argument Case constraint. Strong pronouns, on the other hand, tend to occur in positions not covered by Positional Case, which leaves them open to other influences. I present results from a written survey of 90 speakers of English, which indicate that strong pronoun forms no longer merely identify the structural case of a pronoun, but also code its position within a syntactic construction, and identify its morphosyntactic status as a strong pronoun. These additional functions of strong pronoun forms are captured in two <b>Relative</b> Positional <b>Coding</b> constraints and a set of Invariant Strong Form constraints. Variation occurs where the demands of the case constraints clash with the requirements of <b>Relative</b> Positional <b>Coding</b> and the tendency towards invariant strong pronoun forms. The case trends reported in existing studies suggest that <b>Relative</b> Positional <b>Coding</b> and the tendency towards invariant forms affects not only personal pronouns but also wh-pronouns. For personal pronouns, the emerging invariant forms are the objectives me, him, her, us, them, but for wh-pronouns, the emerging invariant forms are the nominatives who and whoever. As a result, the Invariant wh-form constraints clash with the three case constraints in different environments than the remaining Invariant Strong Form constraints. Discrepancies between the grouping of pronoun forms associated with stmctural case and the grouping of pronoun forms associated with <b>Relative</b> Positional <b>Coding</b> are largely responsible for the distributional differences between strong Isg (l/me) and non-lsg forms (he/him, she/her, we/us, they/them, who/whom). For the purposes of stmctural case, I groups with the non-lsg nominatives he, she, we, they, who, and me groups with the non-lsg objectives him, her, us, them, whom. For <b>Relative</b> Positional <b>Coding,</b> on the other hand, I patterns with him, her, us, them, whom, and me patterns with he, she, we, they, who. All of the trends identified in this study point to an increasing influence of surface position on pronoun case choice, which {{can be seen as a}} correlate of the shift from morphological to positionallicensing at the end of the Middle English period...|$|R
50|$|This syntax, {{achieved}} {{through the use}} of object-oriented programming and operator overloading, enables users to create custom solvers with <b>relative</b> ease. However, <b>code</b> customization becomes more challenging with increasing depth into the OpenFOAM library, owing to a lack of documentation and heavy use of template metaprogramming.|$|R
40|$|In this paper, {{we study}} a {{relative}} two-weight Z_ 2 Z_ 4 -additive codes. It is {{shown that the}} Gray image of a two-distance Z_ 2 Z_ 4 -additive code is a binary two-distance code and that the Gray image of a relative two-weight Z_ 2 Z_ 4 -additive code, with nontrivial binary part, is a linear binary <b>relative</b> two-weight <b>code.</b> The structure of relative two-weight Z_ 2 Z_ 4 -additive codes are described. Finally, we discussed permutation automorphism group of a Z_ 2 Z_ 4 -additive codes...|$|R
50|$|Zena quickly briefs {{him on the}} rules: {{each player}} picks their {{character}} from a box of cards depicting different aliens. Every alien race has their own strengths, weaknesses, and IRSC (Interstellar <b>Relative</b> Sapience <b>Code,</b> with lower numbers favorable). When the time runs out, every home planet will be obliterated except the one belonging to the holder of the Piggy. Barney is amazed when the neighbors keep choosing the same character cards: Joe repeatedly picks water-breathing Jrlb; Zena always chooses Zulma, an arachnoid nymph; and Manny always picks Moyna, an octopus-like gas bag.|$|R
40|$|By {{extending}} {{the notion of}} minimum rank distance, this paper introduces two new <b>relative</b> <b>code</b> parameters of a linear code C_ 1 of length n over a field extension and its subcode C_ 2. One is called the relative dimension/intersection profile (RDIP), {{and the other is}} called the relative generalized rank weight (RGRW). We clarify their basic properties and the relation between the RGRW and the minimum rank distance. As applications of the RDIP and the RGRW, the security performance and the error correction capability of secure network coding, guaranteed independently of the underlying network code, are analyzed and clarified. We propose a construction of secure network coding scheme, and analyze its security performance and error correction capability as an example of applications of the RDIP and the RGRW. Silva and Kschischang showed the existence of a secure network coding in which no part of the secret message is revealed to the adversary even if any dim C_ 1 - 1 links are wiretapped, which is guaranteed over any underlying network code. However, the explicit construction of such a scheme remained an open problem. Our new construction is just one instance of secure network coding that solves this open problem. Comment: IEEEtran. cls, 25 pages, no figure, accepted for publication in IEEE Transactions on Information Theor...|$|R
40|$|In this paper, the {{set-theoretic}} {{approach in}} the logical theory of normative systems is extended using Broome’s definition of the normative code function. The syntax and semantics for first order metanormative language is defined, and metanormative language is applied in the formalization of the basic principles in Broome’s approach and {{in the construction of}} a logical typology of normative systems. Special attention is given to the types of normative systems which are not definable in terms of the properties of singular sets of requirements (e. g. the realization equivalence of codes, the social compatibility of codes, and the compatibility of codes issued by different normative sources). Examples are given of the application of the typology in the interpretation of philosophical texts. Von Wright’s hypothesis on the connection of logical properties of normative systems, conceived set-theoretically, with standard deontic logic is proved by introducing the translation function between the metanormative language and the restricted language of standard deontic logic. The translation reveals that von Wright’s hypothesis must be appended. The problems of narrow and wide scope readings of the deontic conditionals and of the meaning of iterated deontic operators are addressed using the distinction between relative and absolute normative codes. The theorem on the existence of a realization equivalent absolute <b>code</b> for any <b>relative</b> <b>code</b> is proved...|$|R
