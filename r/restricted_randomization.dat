47|8|Public
2500|$|To balance group sizes {{in smaller}} RCTs, {{some form of}} [...] "restricted" [...] {{randomization}} is recommended. [...] The major types of <b>restricted</b> <b>randomization</b> used in RCTs are: ...|$|E
50|$|As a {{consequence}} of this nesting, there are restrictions on the randomization that can occur in the experiment. This kind of <b>restricted</b> <b>randomization</b> always produces nested sources of variation. Examples of nested variation or <b>restricted</b> <b>randomization</b> discussed on this page are split-plot and strip-plot designs.|$|E
50|$|In statistics, <b>restricted</b> <b>randomization</b> {{occurs in}} the design of {{experiments}} and in particular in the context of randomized experiments and randomized controlled trials. <b>Restricted</b> <b>randomization</b> allows intuitively poor allocations of treatments to experimental units to be avoided, while retaining the theoretical benefits of randomization. For example, in a clinical trial of a new proposed treatment of obesity compared to a control, an experimenter would want to avoid outcomes of the randomization in which the new treatment was allocated only to the heaviest patients.|$|E
5000|$|Blocking: A {{schedule}} for conducting treatment combinations in an experimental study such that any {{effects on the}} experimental results due to a known change in raw materials, operators, machines, etc., become concentrated in the levels of the blocking variable. The reason for blocking is to isolate a systematic effect and prevent it from obscuring the main effects. Blocking is achieved by <b>restricting</b> <b>randomization.</b>|$|R
50|$|The {{effect of}} the {{randomization}} depends on the CPU. 32-bit CPUs will have 32 bits of virtual address space, allowing access to 4GiB of memory. Because Linux uses the top 1 GB for the kernel, this is shortened to 3GiB. SEGMEXEC supplies a split {{down the middle of}} this 3GiB address space, <b>restricting</b> <b>randomization</b> down to 1.5GiB. Pages are 4KiB in size, and randomizations are page aligned. The top four MSBs are discarded in the randomization, so that the heap exists at the beginning and the stack {{at the end of the}} program. This computes down to having the stack and heap exist at one of several million positions (23 and 24 bit randomization), and all libraries existing in any of approximately 65,000 positions.|$|R
40|$|Abstract Fire is a {{recurrent}} disturbance in savanna vegetation and savanna species are adapted to it. Even so, fire may affect {{various aspects of}} plant ecology, including phenology. We studied {{the effects of a}} spatially heterogeneous fire on the reproductive phenology of two dominant woody plant species, Miconia albicans (Melastomataceae) and Schefflera vinosa (Araliaceae), in a savanna area in South-eastern Brazil. The study site was partially burnt by a dry-season accidental fire in August 2006, and we monitored the phenolology of 30 burnt and 30 unburnt individuals of each species between September 2007 and September 2008. We used <b>restricted</b> <b>randomizations</b> to assess phenological differences between the burnt and unburnt individuals. Fire had negative effects on the phenology of M. albicans, with a smaller production of reproductive structures in general and of floral buds, total fruits, and ripe fruits in burnt plants. All unburnt but only 16 % of the burnt M. albicans plants produced ripe fruits during the study. Fire effects on S. vinosa were smaller, but there was a greater production of floral buds and fruits (but not ripe fruits) by burnt plants; approximately 90 % of the individuals of S. vinosa produced ripe fruits during the study, regardless of having been burnt or not. The differences between the two species may be related to S. vinosa’s faster growth and absence from the seed bank at the study site, whereas M. albicans grows more slowly and is dominant in the seed bank...|$|R
5000|$|To balance group sizes {{in smaller}} RCTs, {{some form of}} [...] "restricted" [...] {{randomization}} is recommended. [...] The major types of <b>restricted</b> <b>randomization</b> used in RCTs are: ...|$|E
50|$|Split-plot designs result when a {{particular}} type of <b>restricted</b> <b>randomization</b> has occurred during the experiment. A simple factorial experiment can result in a split-plot type of design {{because of the way the}} experiment was actually executed.|$|E
50|$|Similar to a split-plot design, a strip-plot design {{can result}} when {{some type of}} <b>restricted</b> <b>randomization</b> has {{occurred}} during the experiment. A simple factorial design {{can result in a}} strip-plot design depending on how the experiment was conducted. Strip-plot designs often result from experiments that are conducted over two or more process steps in which each process step is a batch process, i.e., completing each treatment combination of the experiment requires more than one processing step with experimental units processed together at each process step. As in the split-plot design, strip-plot designs result when the randomization in the experiment has been restricted in some way. As a result of the <b>restricted</b> <b>randomization</b> that occurs in strip-plot designs, there are multiple sizes of experimental units. Therefore, there are different error terms or different error variances that are used to test the factors of interest in the design. A traditional strip-plot design has three sizes of experimental units.|$|E
40|$|<b>Restricting</b> the <b>randomization</b> of hard-to-change {{factors in}} {{industrial}} experiments is often performed by employing a split-plot design structure. From an economic perspective, these designs minimize the experimental cost {{by reducing the}} number of resets of the hard-to- change factors. In this paper, unbalanced designs are considered for cases where the subplots are relatively expensive and the experimental apparatus accommodates an unequal number of runs per whole-plot. We provide construction methods for unbalanced second-order split- plot designs that possess the equivalence estimation optimality property, providing best linear unbiased estimates of the parameters; independent of the variance components. Unbalanced versions of the central composite and Box-Behnken designs are developed. For cases where the subplot cost approaches the whole-plot cost, minimal point designs are proposed and illustrated with a split-plot Notz design...|$|R
40|$|An {{important}} question within industrial statistics {{is how to}} find operating conditions that achieve some goal for the mean of a characteristic of interest while simultaneously minimizing the characteristic's process variance. Often, people refer {{to this kind of}} situation as the robust parameter design problem. The robust parameter design literature is rich with ways to create separate models for the mean and variance from this type of experiment. Many times time and/or cost constraints force certain factors of interest to be much more difficult to change than others. An appropriate approach to such an experiment <b>restricts</b> the <b>randomization,</b> which leads to a split-plot structure. The paper modifies the central composite design to allow the estimation of separate models for the characteristic's mean and variances under a split-plot structure. The paper goes on to discuss an appropriate analysis of the experimental results. It illustrates the methodology with an industrial experiment involving a chemical vapour deposition process for the manufacture of silicon wafers. The methodology was used to achieve a silicon layer thickness value of 485 � while minimizing the process variation. Copyright 2006 Royal Statistical Society. ...|$|R
40|$|This paper studies subset {{selection}} {{procedures for}} screening in two-factor treatment designs that employ either a split-plot or strip-plot <b>randomization</b> <b>restricted</b> experimental design {{laid out in}} blocks. The goal is to select a subset of treatment combinations associated with the largest mean. In the split-plot design, {{it is assumed that}} the block eects, the confounding effects (whole-plot error) and the measurement errors are normally distributed. None of the selection procedures developed depend on the block variances. Subset selection procedures are given for both the case of additive and non-additive factors and for a variety of circumstances concerning the confounding eect and measurement error variances. In particular, procedures are given for (1) known confounding eect and measurement error variances (2) unknown measurement error variance but known confounding eect (3) unknown confounding effect and measurement error variances. The constants required to implement the procedure [...] ...|$|R
5000|$|William John Youden (April 12, 1900 [...] - [...] March 31, 1971) was a {{statistician}} who formulated new statistical {{techniques in}} statistical analysis and in designs for experimenters. He developed the [...] "Youden square", an incomplete block design developed from a 1937 paper, [...] "Use of Incomplete Block Replications in Estimating Tobacco Mosaic Virus". He also helped {{to introduce the}} concept of <b>restricted</b> <b>randomization,</b> which he called constrained randomization.|$|E
40|$|A {{formula for}} the {{covariance}} of duration times between successive occurrences {{of two different}} outcomes in multinomial trials is derived. Its relationship to the Banach match-box problem and <b>restricted</b> <b>randomization</b> designs is mentioned. Allocation rules Banach match-box problem Probability generating function Randomization design...|$|E
40|$|Abstract—We {{explore the}} {{framework}} of permutation-based p-values for assessing {{the behavior of the}} classification error. In this paper we study two simple permutation tests. The first test estimates the null distribution by permuting the labels in the data; this has been used extensively in classification problems in computational biology. The second test produces permutations of the features within classes, inspired by <b>restricted</b> <b>randomization</b> techniques traditionally used in statistics. We study the properties of these tests and present an extensive empirical evaluation on real and synthetic data. Our analysis shows that studying the classification error via permutation tests is effective; in particular, the restricted permutation test clearly reveals whether the classifier exploits the interdependency between the features in the data. Keywords-classification, labeled data, permutation tests, <b>restricted</b> <b>randomization,</b> significance testing I...|$|E
40|$|Randomization {{is a key}} step in {{reducing}} selection bias during the treatment allocation phase in randomized clinical trials. The process of randomization follows specific steps, which include generation of the randomization list, allocation concealment, and implementation of randomization. The phenomenon in the dental and orthodontic literature of characterizing treatment allocation as random is frequent; however, often the randomization procedures followed are not appropriate. Randomization methods assign, at random, treatment to the trial arms without foreknowledge of allocation by either the participants or the investigators thus reducing selection bias. Randomization entails generation of random allocation, allocation concealment, and the actual methodology of implementing treatment allocation randomly and unpredictably. Most popular randomization methods include some form of <b>restricted</b> and/or stratified <b>randomization.</b> This article introduces the reasons, which make randomization {{an integral part of}} solid clinical trial methodology, and presents the main randomization schemes applicable to clinical trials in orthodontic...|$|R
40|$|Background: Cluster {{randomized}} trials (CRTs) {{are useful in}} practice-based research network transla-tional research. However, simple or stratified randomization often yields study groups that differ on key baseline variables {{when the number of}} clusters is small. Unbalanced study arms constitute a potentially serious methodological problem for CRTs. Methods: Covariate constrained randomization with data on relevant variables before randomization was used to achieve balanced study arms in 2 pragmatic CRTs. In study 1, 16 counties in Colorado were randomized to practice-based or population-based reminder recall for vaccinating children ages 19 to 35 months. In study 2, 18 primary care practices were randomized to computer decision support plus practice facilitation versus computer decision support alone to improve care for patients with stage 3 and 4 chronic kidney disease. For each study, a set of optimal randomizations, which minimized differ-ences of key variables between study arms, was identified from the set of all possible randomizations. Results: Differences between study arms were smaller in the optimal versus remaining randomiza-tions. Even for the randomization in the optimal set with the largest difference between groups, study arms did not differ significantly on any variable for either study (P>. 05). Conclusions: Covariate constrained <b>randomization,</b> which <b>restricts</b> the full <b>randomization</b> set to a subset in which differences between study arms are minimized, is a useful tool for achieving balanced study arms in CRTs. Because of the increasing recognition of the risk of imbalance in CRTs and implica-tions for interpreting study findings, procedures of this type should be considered in designing prac-tice-based or community-based trials. (J Am Board Fam Med 2015; 28 : 663 – 672. ...|$|R
40|$|Many {{agricultural}} {{experiments have}} say 7 - 12 treatments in 3 - 5 replicates, and {{are laid out}} in a rectangle. Is it better to do a standard randomized complete block design in rows, or a complete block design in rows but with <b>restricted</b> <b>randomization,</b> or an efficient row-column design? These approaches differ in the variance of the estimate of a difference between two treatments, and in the bias of the estimator of that variance, {{as well as in the}} mechanics of constructing the design and analysing the data. I conclude that when inter-column correlations are high then the row-column design is best but that when they are moderate the best procedure is to use an improved version of <b>restricted</b> <b>randomization,</b> which gives an unbiased estimator of the average variance in the single experiment performed. T 2. 2...|$|E
40|$|We {{consider}} {{the problem of}} how to assign treatment in a randomized experiment, in which the correlation among the outcomes is informed by a network available pre-intervention. Working within the potential outcome causal framework, we develop a class of models that posit such a correlation structure among the outcomes. Then we leverage these models to develop <b>restricted</b> <b>randomization</b> strategies for allocating treatment optimally, by minimizing the mean square error of the estimated average treatment effect. Analytical decompositions of the mean square error, due both to the model and to the randomization distribution, provide insights into aspects of the optimal designs. In particular, the analysis suggests new notions of balance based on specific network quantities, in addition to classical covariate balance. The resulting balanced, optimal <b>restricted</b> <b>randomization</b> strategies are still design unbiased, in situations where the model used to derive them does not hold. We illustrate how the proposed treatment allocation strategies improve on allocations that ignore the network structure, with extensive simulations. Comment: 56 pages, 6 figure...|$|E
40|$|Sequential {{monitoring}} {{in clinical}} trials is often employed to allow for early stopping and other interim decisions, while maintaining the type I error rate. However, sequential monitoring is typically described only {{in the context of}} a population model. We describe a computational method to implement sequential monitoring in a randomization-based context. In particular, we discuss a new technique for the computation of approximate conditional tests following <b>restricted</b> <b>randomization</b> procedures and then apply this technique to approximate the joint distribution of sequentially computed conditional randomization tests. We also describe the computation of a randomization-based analog of the information fraction. We apply these techniques to a <b>restricted</b> <b>randomization</b> procedure, Efron's [Biometrika 58 (1971) 403 [...] 417] biased coin design. These techniques require derivation of certain conditional probabilities and conditional covariances of the randomization procedure. We employ combinatoric techniques to derive these for the biased coin design. Comment: Published in at [URL] the Annals of Statistics ([URL] by the Institute of Mathematical Statistics ([URL]...|$|E
40|$|Many {{factorial}} experiments yield categorical response data. Moreover, {{the experiments}} are often run under a <b>restricted</b> <b>randomization</b> for logistical reasons and/or because {{of time and}} cost constraints. The combination of categorical data and <b>restricted</b> <b>randomization</b> necessitates the use of generalized linear mixed models. In this paper, we demonstrate the use of Hasse diagrams for laying out the randomization structure of a complex factorial design involving seven two-level factors, four three-level factors and a five-level factor, and three repeated observations for each experimental unit. The Hasse diagrams {{form the basis of}} the mixed model analysis of the ordered categorical data produced by the experiment. We also discuss the added value of categorical data over binary data and difficulties with the estimation of variance components and, consequently, with the statistical inference. Finally, we show how to deal with repeats in the presence of categorical data, and describe a general strategy for building a suitable generalized linear mixed model. Binary data, Cumulative logit regression, Generalized linear mixed model, Hasse diagram, Ordered categorical data, Split-plot analysis...|$|E
40|$|A two-sample Mood median test, {{along with}} an {{associated}} confidence interval, is developed for the contrast parameter of the treatment and control medians, under an order <b>restricted</b> <b>randomization.</b> The exact and asymptotic null distributions of the test statistic are derived. It is shown that the proposed test is superior to the corresponding procedures based on completely randomized and ranked set sampling designs both in asymptotic relative efficiency and in empirical power study. Design Unequal allocation Pitman efficiency Nonparametric testing Mode Information Mood test Median test Mann-Whitney-Wilcoxon test Ranked set sampling...|$|E
40|$|Split-plot design may be {{refer to}} a common {{experimental}} setting where {{a particular type of}} <b>restricted</b> <b>randomization</b> has occurred during a planned experiment. The aim {{of this article is to}} suggest a new method to perform inference on split-plot experiments by combination-based permutation tests. This novel nonparametric approach has been studied and validated using a Monte Carlo simulation study where we compared it with the parametric and nonparametric procedures proposed in the literature. Results suggest that in each experimental situation where normality is hard to justify and especially when errors have heavy-tailed distribution, the proposed nonparametric procedure can be considered as a valid solution...|$|E
40|$|In sensory experiments, often {{designs are}} used that are {{balanced}} for carryover effects. It {{is hoped that}} this controls for possible carryover effects, like, e. g., a lingering taste of the products. Proper randomization is essential to guarantee the usual model assumption of independent identically distributed (i. i. d.) errors. We consider a randomization procedure that permutes treatment labels and assessors. This <b>restricted</b> <b>randomization</b> leaves the neighbour structure unchanged and validates the assumption of i. i. d. errors if the design used is a Generalized Youden Design (GYD). However, {{the use of a}} neighbour balanced GYD may require too many assessors. The question arises, whether nearly balanced designs may be used without grossly violating the validity of the analysis. We therefore do a simulation study to assess the properties (under this <b>restricted</b> <b>randomization)</b> of nearly balanced designs like, e. g., the ones proposed by P 9 rinel and Pag?s (2004, Food Quality and Preference 15, 439 ? 446). We observe that, if there are no carryover effects, the variance estimates for treatment contrasts are not significantly biased whenever we use designs that are nearly GYD. Additionally, designs that are nearly carryover balanced still produce conservative variance estimates, even in the presence of large carryover effects. In all, ?nearly neighbour balanced nearly GYD? as proposed by P 9 rinel and Pag?s (2004) appear to be useful in experimental situations where the use of GYD is too restrictive. It should be stressed, however, that these results are true only if randomization is used as a protection against effects unaccounted for in the statistical model...|$|E
40|$|Alternating Treatments Designs (ATD) with random {{assignment}} of the treatments to the measurement times provide very powerful single-case experiments. However, complete randomization might cause too many consecutive administrations {{of the same}} treatment {{to occur in the}} design. In order to exclude these possibilities, an ATD with <b>restricted</b> <b>randomization</b> can be used. In this article we provide a general rationale for the random assignment procedure in such a Restricted Alternating Treatments Design (RATD), and derive the corresponding randomization test. A software package for randomization tests in RATD, ATD and other single-case experimental designs [Van Damme & Onghena Single-case randomization tests, version 1. 1, Department of Psychology, Katholieke Universiteit Leuven, Belgium] is discussed. status: publishe...|$|E
40|$|In this paper, we {{describe}} a new <b>restricted</b> <b>randomization</b> method called run-reversal equilibrium (RRE), {{which is a}} Nash equilibrium of a game where (1) the clinical trial statistician chooses a sequence of medical treatments, and (2) clinical investigators make treatment predictions. RRE randomization counteracts how each investigator could observe treatment histories in order to forecast upcoming treatments. Computation of a run-reversal equilibrium reflects how the treatment history at a particular site is imperfectly correlated with the treatment imbalance for the overall trial. An attractive feature of RRE randomization is that treatment imbalance follows a random walk at each site, while treatment balance is tightly constrained and regularly restored for the overall trial. Less predictable and therefore more scientifically valid experiments can be facilitated by run-reversal equilibrium for multi-site clinical trials...|$|E
30|$|All {{treatments}} {{were administered}} by a neurologist {{who did not}} participate in the randomization and investigation procedures. Physician raters were blinded to treatment assignment. After obtaining baseline measurements, patients meeting the study criteria were randomly divided into two groups. Group A received botulinum toxin type A injections guided by palpation, whereas group B received botulinum toxin type A injections guided by EMG. We allocated patients to one of the two groups using a <b>restricted</b> <b>randomization</b> scheme generated by SPSS. The overall duration of the study for each patient was 16  weeks, and follow-up visits were conducted every 4  weeks after the injection. Patients were free to discontinue the trial {{at any time during the}} study. Patients who were on antispasmodic and/or antidepressant medications were requested to remain on baseline medication doses for the duration of the study.|$|E
40|$|For model {{selection}} {{purposes in}} experimental contexts, researchers often use stepwise regression or subset selection. With currently available software, {{this has to}} be done manually and often involves numerous model estimations in situations involving <b>restricted</b> <b>randomization,</b> such as block experiments and split-plot experiments. Moreover, these selection procedures ignore the stochastic errors inherited in the variable selection stage. This leads to incorrect standard errors. In this paper, we investigate the usefulness of penalized least squares estimation, which performs model selection and model estimation simultaneously. Therefore, the method results in correct standard errors. A key property of the penalized least squares estimation approach is that it possesses the so-called oracle property, which means that it works as well as if the correct sub-model were known. We study the performance of the approach using various practical examples, and investigate its properties in a simulation study...|$|E
40|$|This {{research}} {{compares the}} performance of a sample of non-litigating participants with severe brain injury on both the WMT and TOMM under conditions of (1) full effort, (2) distraction, or (3) simulated malingering. The study included 60 participants with a severe brain injury and used <b>restricted</b> <b>randomization</b> to assign participants to the groups. Following Craik (1982) an auditory distraction task was used during the learning phase of each test in the distraction group, while a scenario adapted from Tombaugh (1997) was used to encourage simulation of memory impairment in the simulated malingering group. The results of this study clearly showed that while both tests demonstrated excellent sensitivity, the false positive rates for the WMT were significantly greater than those for the TOMM. It was concluded that the so-called "effort" components of the WMT required more cognitive capacity than was previously believed. 7 page(s...|$|E
40|$|We {{consider}} {{the problem of}} randomizing a known number of subjects into two or more treatment groups when recruitment occurs over an extended time period, and thus the potential for confounding factors related to time is a concern. Our proposed design generates more balanced allocations than complete randomization, but can have higher entropy than randomized-block designs. These conclusions follow a careful analysis of the probability distribution induced on the allocations. Furthermore, analysis and simulation indicate that this new design can exhibit power advantages over randomized blocking and complete randomization. Randomization tests have been applied {{in a series of}} cancer chemoprevention trials. The design may be useful in other experiments where experimental units are confined to some linear order, such as arrangement in space. Keywords: clinical trials, experimental design, one-way layout, permutation test, <b>restricted</b> <b>randomization,</b> relay randomization, urn sampling. 1 RELAY [...] ...|$|E
40|$|When {{planning}} an experimental investigation, we are frequently faced with {{factors that are}} difficult or time consuming to manipulate, thereby making complete randomization impractical. A split-plot structure differentiates between the experimental units associated with these hard-to-change factors and others that are relatively easy-to-change and provides an efficient strategy that integrates the restrictions imposed by the experimental apparatus. Several industrial and scientific examples are presented to illustrate design considerations encountered in the <b>restricted</b> <b>randomization</b> context. In this paper, we propose classes of split-plot response designs that provide an intuitive and natural extension from the completely randomized context. For these designs, the ordinary least squares estimates of the model are equivalent to the generalized least squares estimates. This property provides best linear unbiased estimators and simplifies model estimation. The design conditions that allow for equivalent estimation are presented enabling design construction strategies to transform completely randomized Box-Behnken, equiradial, and small composite designs into a split-plot structure...|$|E
40|$|Randomization is the {{key element}} of any {{sensible}} clinical trial. It {{is the only way}} we can be sure that the patients have been allocated into the treatment groups without bias and that the treatment groups are almost similar before the start of the trial. The randomization schemes used to allocate patients into the treatment groups play a role in achieving this goal. This study uses SAS simulations to do categorical data analysis and comparison of differences between two main randomization schemes namely unrestricted and <b>restricted</b> <b>randomization</b> in dental studies where there are small samples, i. e. simple randomization and the minimization method respectively. Results show that minimization produces almost equally sized treatment groups, but simple randomization is weak in balancing prognostic factors. Nevertheless, simple randomization can also produce balanced groups even in small samples, by chance. Statistical power is also improved when minimization is used than in simple randomization, but bigger samples might be needed to boost the power...|$|E
40|$|All {{those who}} like {{experimentation}} are sooner or later faced with a need of random selection of elements or objects of interest {{that they want to}} study (persons, patients, animals, cells, etc.). Randomization, a basic requirement in appropriate planning of experiment, may be performed either to select series of randomly assigned elements/objects or to allocate the studied objects to a given group, medical or diagnostic procedure, treatment protocol, etc. The principal advantage of random selection is to minimize effects of bias and confounding variables, two fundamental threats known to weaken research credibility. Simple, unrestricted random selection can lead to undesirable imbalance in baseline characteristics, thus affecting any credible reasoning. <b>Restricted</b> <b>randomization</b> (with blocking or stratification) includes procedures used along with random sampling that help to achieve balance between study groups in their baseline characteristics or in size. For all researchers conducting biomedical studies randomization ensures a straightforward and reliable analysis of the outcomes, and enables any further generalization of their findings...|$|E
40|$|Efron [Biometrika 58 (1971) 403 [...] 417] {{developed}} a <b>restricted</b> <b>randomization</b> procedure to promote balance between two treatment {{groups in a}} sequential clinical trial. He called this the biased coin design. He also introduced the concept of accidental bias, and investigated properties of the procedure with respect to both accidental and selection bias, balance, and randomization-based inference using the steady-state properties of the induced Markov chain. In this paper we revisit this procedure, and derive closed-form expressions for the exact properties of the measures derived asymptotically in Efron's paper. In particular, we derive the exact distribution of the treatment imbalance and the variance-covariance matrix of the treatment assignments. These results have application {{in the design and}} analysis of clinical trials, by providing exact formulas to determine the role of the coin's bias probability in the context of selection and accidental bias, balancing properties and randomization-based inference. Comment: Published in at [URL] the Annals of Statistics ([URL] by the Institute of Mathematical Statistics ([URL]...|$|E
40|$|Abstract Reviews have {{repeatedly}} noted important methodological {{issues in the}} conduct and reporting of cluster randomized controlled trials (C-RCTs). These reviews usually focus on whether the intracluster correlation was explicitly considered {{in the design and}} analysis of the C-RCT. However, another important aspect requiring special attention in C-RCTs is the risk for imbalance of covariates at baseline. Imbalance of important covariates at baseline decreases statistical power and precision of the results. Imbalance also reduces face validity and credibility of the trial results. The risk of imbalance is elevated in C-RCTs compared to trials randomizing individuals because of the difficulties in recruiting clusters and the nested nature of correlated patient-level data. A variety of <b>restricted</b> <b>randomization</b> methods have been proposed as way to minimize risk of imbalance. However, there is little guidance regarding how to best restrict randomization for any given C-RCT. The advantages and limitations of different allocation techniques, including stratification, matching, minimization, and covariate-constrained randomization are reviewed as they pertain to C-RCTs to provide investigators with guidance for choosing the best allocation technique for their trial. </p...|$|E
40|$|In {{industrial}} split-plot experiments, {{the number}} of runs within each whole plot is usually determined independently from the factor settings. As a matter of fact, it is often equal to {{the number of}} runs that can be done within a given period of time or {{to the number of}} samples that can be processed in one oven run or with one batch. In such cases, the size of every whole plot in the experiment is fixed no matter what factor levels are actually used in the experiment. In this article, we discuss the design of a real-life experiment on the production of coffee cream where the number of runs within a whole plot is not fixed, but depends on the level of one of the whole-plot factors. We provide a detailed discussion of various ways to set up the experiment and discuss how existing algorithms to construct optimal split-plot designs can be modified for that purpose. We conclude the paper with a few general recommendations. Coordinate-exchange algorithm, D-optimum designs, Point-exchange algorithm, <b>Restricted</b> <b>randomization...</b>|$|E
