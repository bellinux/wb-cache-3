170|31|Public
5000|$|Color by {{structure}} (i.e. by the <b>recursive</b> <b>path</b> taken) {{instead of}} monochrome or by density.|$|E
50|$|Plaisted's {{research}} interests include term rewriting systems, automated theorem proving, logic programming, and algorithms. His research accomplishments in theorem proving include work on the <b>recursive</b> <b>path</b> ordering, the associative path ordering, abstraction, the simplified and modified problem reduction formats, ground reducibility,nonstandard clause form translations, rigid E-unification, Knuth-Bendix completion, replacement rules in theorem proving, instance-based theorem proving strategies, and semantics in theorem proving.|$|E
40|$|The {{notion of}} computability closure has been {{introduced}} for proving the termination of the combination of higher-order rewriting and beta-reduction. It is also used for strengthening the higher-order <b>recursive</b> <b>path</b> ordering. In the present paper, we study in more details {{the relations between the}} computability closure and the (higher-order) <b>recursive</b> <b>path</b> ordering. We show that the first-order <b>recursive</b> <b>path</b> ordering is equal to an ordering naturally defined from the computability closure. In the higher-order case, we get an ordering containing the higher-order <b>recursive</b> <b>path</b> ordering whose well-foundedness relies on the correctness of the computability closure. This provides a simple way to extend the higher-order <b>recursive</b> <b>path</b> ordering to richer type systems...|$|E
40|$|Abstract. We employ {{recursion}} theoretic {{arguments to}} show that Hamilton paths for locally finite graphs {{are more difficult to}} find, in general, than Euler paths. A locally finite graph is recursive if we can effectively decide whether or not any two given vertices are adjacent, and highly recursive if we can effectively find all vertices adjacent to any given vertex. We find that there are recursive planar graphs with Euler or Hamilton paths but no such <b>recursive</b> <b>paths.</b> There are even particularly simple classes of connected, planar, highly recursive graphs for which we can show there is no effective way to decide about the existence of Euler or Hamilton paths. However, we obtain the following contrast: If a highly recursive graph has an Euler path we can effectively find a recursive Euler path; whereas, there is a planar, highly recursive graph with Hamilton <b>paths</b> but no <b>recursive</b> Hamilton <b>path.</b> 1. Introduction. Th...|$|R
30|$|As one can see, {{the search}} {{space of a}} {{homomorphic}} pattern mining can be larger than that of embedded pattern mining for low support levels. On Treebank, for instance, HomTreeMiner computes 17 times more candidates than EmbTreeMiner at minsup = 30  k. Since Treebank contains many deep, highly <b>recursive</b> <b>paths,</b> the search space of homomorphic patterns becomes substantially large at low support levels. Like Treebank, XMark has many deep paths, and therefore, the search space of homomorphic patterns becomes large at low support levels. For example, on XMark at minsup = 700, HomTreeMiner generates about 2.23 times more candidates than EmbTreeMiner. The number of candidates generated by HomTreeMiner and EmbTreeMiner is comparable on CSlogs. The difference {{in the number of}} candidates generated by sleuth and EmbTreeMiner is not noticeable on all the testing cases.|$|R
40|$|At least {{a subset}} of our {{vocabulary}} must be grounded in the sensorimotor world for the words to have meaning in our minds. Analysing definitions recursively in dictionaries which use a fixed vocabulary to define all their words can give some idea of how new meanings can be grounded in terms of already grounded ones. Concrete words should be easier to ground than abstract ones, because sensorimotor contact with their referents is more direct. Human participants rated the degree of abstractness of word-pairs from the controlled vocabularies of two dictionaries. The fixed defining vocabularies of both dictionaries {{were found to have}} more abstract words than concrete ones, according to these ratings. The abstract words had longer definitions and their <b>recursive</b> <b>paths</b> through definitional space encompassed more words, compared to concrete words. The results suggest that although the words are more widely used in grounding definitions. ...|$|R
40|$|Contents 1 Introduction 2 2 Semantical methods 3 2. 1 Well-founded {{monotone}} algebras.................... 3 2. 2 Polynomial interpretations........................ 7 2. 3 Polynomial interpretations modulo AC................. 13 2. 4 Lexicographic combinations....................... 14 2. 5 Other examples.............................. 15 3 A {{hierarchy of}} termination 17 3. 1 Simple termination............................ 17 3. 2 Total termination............................. 21 3. 3 The hierarchy............................... 23 4 Syntactical methods 25 4. 1 <b>Recursive</b> <b>path</b> order........................... 26 4. 2 Justi cation of <b>recursive</b> <b>path</b> order................... 30 4. 3 Extensions of <b>recursive</b> <b>path</b> order................... 36 4...|$|E
40|$|This paper studies three orderings, {{useful in}} theorem proving, espe-cially for proving {{termination}} of term rewriting systems: the recursive decomposition ordering with status, the <b>recursive</b> <b>path</b> ordering with {{status and the}} closure ordering. It proves the transitivity of the recur-sive path ordering, the strict inclusion of the <b>recursive</b> <b>path</b> ordering in the recursive decomposition ordering, {{the totality of the}} <b>recursive</b> <b>path</b> ordering { therefore of the recursive decomposition ordering {, the strict inclusion of the recursive decomposition ordering in the closure ordering and the stability of the closure ordering by instanciation. ...|$|E
40|$|Oblivious RAM (ORAM) is a {{cryptographic}} primitive that hides {{memory access}} patterns to untrusted storage. ORAM {{may be used}} in secure processors for encrypted computation and/or software protection. While <b>recursive</b> <b>Path</b> ORAM is currently the most practical ORAM for secure processors, it still incurs large performance and energy overhead and is the performance bottleneck of recently proposed secure processors. In this paper, we propose two optimizations to <b>recursive</b> <b>Path</b> ORAM. First, we identify a type of program local-ity in its operations to improve performance. Second, we use pseudorandom function to compress the position map. But applying these two techniques in <b>recursive</b> <b>Path</b> ORAM breaks ORAM security. To securely take advantage of the two ideas, we propose unified ORAM. Unified ORAM improves performance both asymptotically and empirically. Empiri-cally, our experiments show that unified ORAM reduces data movement from ORAM by half and improves benchmark performance by 61 % as compared to <b>recursive</b> <b>Path</b> ORAM. 1...|$|E
50|$|Path-based {{inference}} rules may be defined, although they, themselves,are {{not represented}} in SNePS. A path-based inference rule specifiesthat some labeled arc r may be inferred as present from some node nto some other node m {{just in case}} a given path exists from n to m.There is an extensive <b>recursive</b> set of <b>path</b> constructors available.|$|R
40|$|Abstract. Simply-typed term {{rewriting}} systems (STRSs) are {{an extension}} of term rewriting systems. STRSs can be naturally handle higher order functions, which are widely used in existing functional programming languages. In this paper we design <b>recursive</b> and lexicographic <b>path</b> orders, which can e±ciently prove the termination of STRSs. Moreover we discuss an application to the dependency pair and the argument ¯ltering methods, which are very e®ective and e±cient support methods for proving termination...|$|R
40|$|Abstract: In {{our current}} {{work with the}} Chord {{protocol}} [SMK+ 01] we had {{to decide whether to}} use iterative or recursive routing. Iterative routing provides the initiating node with a lot of information and influence on the routing <b>path.</b> <b>Recursive</b> routing on the other hand is faster and results in less overhead, most notably in stable networks. We present a hybrid routing solution that inherits the advantages of both approaches without increasing the overhead or slowing down the lookup procedure. ...|$|R
40|$|The <b>recursive</b> <b>path</b> {{ordering}} due to Dershowitz {{is one of}} {{the important}} methods to prove termination of first-order term rewriting. The generalization to the higher-order case is due to Jouannaud and Rubio. This work is concerned with a formalization in Coq of the proof of wellfoundedness of both the first- and the higher-order version of the <b>recursive</b> <b>path</b> ordering. The proof does not rely on Kruskal’s tree theorem. ...|$|E
40|$|We {{present an}} {{extension}} of the <b>recursive</b> <b>path</b> ordering for the purpose of showing termination of higher order rewrite systems. Keeping close to the general path ordering of Dershowitz and Hoot, we demonstrate the necessary properties of the termination functions for our method to apply, thus describe a class of different orderings. We also give a counterexample to a previously published extension of the <b>recursive</b> <b>path</b> ordering into the higher order setting...|$|E
40|$|Abstract. In {{this paper}} the <b>Recursive</b> <b>Path</b> Ordering is adapted for proving {{termination}} of rewriting incrementally. The new ordering, called <b>Recursive</b> <b>Path</b> Ordering with Modules, has as ingredients {{not only a}} precedence but also an underlying ordering ❂B. It {{can be used for}} incremental (innermost) termination proofs of hierarchical unions by defining ❂B {{as an extension of the}} termination proof obtained for the base system. Furthermore, there are practical situations in which such proofs can be done modularly. ...|$|E
40|$|Abstract. We {{develop a}} near-concrete interpretation, a program {{analysis}} {{that aims to}} cut very close to program execution while retaining interpretation, but models heaps with possibly <b>recursive</b> strucure, is <b>path</b> sensitive, and applies in a fully higher-order setting. The main technical contribution is a prune-rerun technique for analyzing higherorder recursive functions. To illustrate the expressiveness and usefulness of the system, we show {{how it can be}} used to enforce temporal program safety properties and information flow security, and show how it betters state-of-the-art systems on some examples. ...|$|R
40|$|Abstract. In {{this paper}} we study {{the problem of}} {{deciding}} boundedness of (<b>recursive)</b> reg-ular <b>path</b> queries over views in data integration systems, that is, whether a query can be re-expressed without recursion. This problem becomes challenging when the views contain recursion, thereby potentially making recursion in the query uncessary. We define and solve two related problems of boundedness of regular path queries. One of the problems asks {{for the existence of}} a bound, and the other, more restricted one, asks if the query is bounded within a given parameter. For the more restricted version we show it PSPACE complete, and obtain a constructive method for optimizing the queries. For the existential version of boundedness, we show it PTIME reducible to the notorious problem of limitedness in distance automata. This problem has received a lot attention in the formal language community, but only exponential time algorithms are currently known. ...|$|R
40|$|XML is well-suited for {{modelling}} {{structured data}} with textual content. However, most indexing approaches perform {{structure and content}} matching independently, combining the retrieved path and keyword occurrences in a third step. This paper shows that retrieval in XML documents can be accelerated significantly by processing text and structure simultaneously during all retrieval phases. To this end, the Content-Aware DataGuide (CADG) enhances the wellknown DataGuide with (1) simultaneous keyword and path matching and (2) a precomputed content/structure join. Extensive experiments prove the CADG to be 50 - 90 % faster than the DataGuide for various sorts of query and document, including difficult cases such as poorly structured queries and <b>recursive</b> document <b>paths.</b> A new query classification scheme identifies precise query characteristics with a predominant influence {{on the performance of}} the individual indices. The experiments show that the CADG is applicable to many real-world applications, in particular large collections of heterogeneously structured XML documents. ...|$|R
40|$|Abstract. Label stream {{partition}} is {{a useful}} technique to reduce the input I/O cost of holistic twig join by pruning useless streams beforehand. The Prefix Path Stream (PPS) partition scheme is effective for non-recursive XML documents, but inefficient for deep recursive XML documents due to the high CPU cost of pruning and merging too many streams for some twig pattern queries involving recursive tags. In this paper, we propose a general stream partition scheme called <b>Recursive</b> <b>Path</b> Stream (RPS), to control {{the total number of}} streams while providing pruning power. In particular, each <b>recursive</b> <b>path</b> in RPS represents a set of prefix paths which can be recursively expanded from the <b>recursive</b> <b>path.</b> We present the algorithms to build RPS scheme and prune RPS streams for queries. We also discuss the adaptability of RPS and provide a framework for performance tuning with general RPS based on different application requirements. ...|$|E
40|$|We give a short {{constructive}} {{proof of}} the fact that certain binary relations > are well-founded, given a lifting a la Ferreira-Zantema and a wellfounded relation [...] This construction generalizes several variants of the <b>recursive</b> <b>path</b> ordering on terms and of the Knuth-Bendix ordering. It also applies to other domains, of graphs, of infinite terms, of word and tree automata notably. We then extend this construction further; the resulting family of well-founded relations generalizes Jouannaud and Rubio's higher-order <b>recursive</b> <b>path</b> orderings. Keywords: Termination, well-foundedness, path orderings, Knuth-Bendix orderings, -calculus, higher-order path orderings, graphs, automata. ...|$|E
40|$|<b>Recursive</b> <b>path</b> {{ordering}} (RPO) is {{a well-known}} reduction ordering introduced by Dershowitz [6], that is useful for proving termination of term rewriting systems (TRSs). Jouannaud and Rubio generalized this ordering to the higher-order case thus creating the higher-order <b>recursive</b> <b>path</b> ordering (HORPO) [8]. They proved that this ordering {{can be used for}} proving termination of higher-order TRSs which essentially comes down to proving well-foundedness of the union of HORPO and #- reduction relation of simply typed lambda calculus (# #), [1]. This result entails well-foundedness of RPO and termination of # #. This pape...|$|E
40|$|The {{purpose of}} this {{multifaceted}} research project was to explain and predict mental health outcomes through testing of a systems research organizing model using pre-existing behavioral health consumer-oriented data. Community Partnership of Southern Arizona provided the setting for the participation of its members in the statewide 2001 Mental Health Statistics Improvement Program Consumer Perception Survey. The sample for this study consisted of 214 adult member survey respondents. The Systems Research Organizing Model for Behavioral Health (SROM-BH) provided the conceptual framework for examining client risk adjustment characteristics and cost and access factors that interact with consumer participation processes to affect consumer perception of quality and health related quality of life. The American Academy of Nursing's Quality Health Outcomes Model and The University of Arizona Nursing Systems Core's System Research Organizing Model informed {{the development of the}} SROM-BH that extends this work through its adaptation for use within the context of behavioral health. Composite indices were developed for five model variables, implying that composites or latent variables can be developed from existing data when there is fastidious attention to theory and the conceptual definitions of the constructs. Eight hypothesized positive predictor and three unhypothesized negative predictor relationships were supported. Three hypothesized positive predictor relationships were not supported. Consumer participation in treatment planning, the intervention of interest in this study had an effect (either direct or indirect) on all five outcome variables. Reexamination of model relationships with a larger sample and continued testing of the survey instrument for psychometric performance is recommended. Further model testing using separate scales or methods is needed in order to reduce method effect and to determine the full strength of the findings. Use of structural equation modeling may offer a more precise test of the theoretical framework, strengthen support for instrument subscale construct validity through confirmatory factor analysis, and may provide an opportunity for analysis of <b>recursive</b> <b>paths.</b> Further development of recovery authentication, a concept developed {{as a result of this}} study, may contribute to a broadened understanding of opportunities to promote recovery and moderate the loss of self that is associated with mental illness...|$|R
40|$|Graph {{theory is}} {{increasingly}} commonly utilised in genetics, proteomics and neuroimaging. In such fields, {{the data of}} interest generally constitute weighted graphs. Analysis of such weighted graphs often require the integration of topological metrics {{with respect to the}} density of the graph. Here, density refers to the proportion of the number of edges present in that graph. When topological metrics based on shortest paths are of interest, such density-integration usually necessitates the iterative application of Dijkstra's algorithm in order to compute the shortest path matrix at each density level. In this short note, we describe a <b>recursive</b> shortest <b>path</b> algorithm based on single edge updating, which replaces the need for the iterative use of Dijkstra's algorithm. Our proposed procedure is based on pairs of breadth-first searches around each of the vertices incident to the edge added at each recursion. An algorithmic analysis of the proposed technique is provided. When the graph of interest is coded as an adjacency list, our algorithm can be shown to be more efficient than an iterative use of Dijkstra's algorithm...|$|R
40|$|Calling {{contexts}} {{are very}} important {{for a wide range}} of applications such as profiling, debugging, and event logging. Most applications perform expensive stack walking to recover contexts. The resulting contexts are often explicitly represented as a sequence of call sites and hence bulky. We propose a technique to encode the current calling context of any point during an execution. In particular, an acyclic call path is encoded into one number through only integer additions. <b>Recursive</b> call <b>paths</b> are divided into acyclic subsequences and encoded independently. We leverage stack depth in a safe way to optimize encoding: if a calling context can be safely and uniquely identified by its stack depth, we do not perform encoding. We propose an algorithm to seamlessly fuse encoding and stack depth based identification. The algorithm is safe because different contexts are guaranteed to have different IDs. It also ensures contexts can be faithfully decoded. Our experiments show that our technique incurs negligible overhead (1. 89 % on average). For most medium-sized programs, it can encode all contexts with just one number. For large programs, we are able to encode most calling contexts to a few numbers. 1...|$|R
40|$|In {{this paper}} {{we present a}} {{formalization}} of the simply typed lambda calculus with constants and with typing a la Church. It has been accomplished using the theorem prover Coq. The formalization includes, among other results, definitions of typed terms over arbitrary many-sorted signature, a substitution operating on typing judgements, an equivalence relation generalizing the concept of #-convertibility to free variables and a proof of strong normalization of #-reduction. The formalization {{has been used in}} a bigger project of certification of the higher-order <b>recursive</b> <b>path</b> ordering where well-foundedness of the union of the higher-order <b>recursive</b> <b>path</b> ordering and #-reduction was the main result...|$|E
40|$|Abstract. Semantic {{labelling}} is a transformational {{technique for}} proving termination of Term Rewriting Systems (TRSs). Only its variant with finite sets of labels was used {{so far in}} tools for automatic termination proving and variants with infinite sets of labels were considered not to be suitable for automation. We show that such automation can be achieved for semantic labelling with natural numbers, in combination with <b>recursive</b> <b>path</b> ordering (RPO). In order to do so we developed algorithms to deal with <b>recursive</b> <b>path</b> ordering for these infinite labelled systems. Using these techniques TPA, a tool developed by the first author, is the only current tool that can prove termination of the SUBST system automatically. ...|$|E
40|$|Abstract. - <b>Recursive</b> <b>path</b> {{ordering}} is an ordering {{on terms}} inttodueed by Dershowitz {{to prove the}} termination of rewriting systems. A new ordering, called decomposition ordming, is dejined. It is proved to be equivalent to the path ordering and, as corollary, a simple proof of the well-foundedness of <b>recursive</b> <b>path</b> ordering is given. Rkumk. - L'ordre ricursif sur les chemins a ktk introduit par Dershowitz pour prouver la terminaison des syst 2 mes de rbicriture. On propose ici un nouvel ordre appeU ordre de &composition et Pon montre qu'il est iquivaknt d Pordre ricursifsur les chemins et comme corollaire on donne me preuve simple de la bonne fondation de ce dernier. 1...|$|E
40|$|We {{study the}} {{problems}} {{involved in the}} recursive de nition of (quasi) orders on terms, focussing {{on the question of}} establishing well-definedness, and the properties required for partial and quasi-orders: irreflexivity and transitivity, and reflexivity and transitivity, respectively. These properties are in general difficult to establish and this has in many cases come down in the literature as folklore results. Here we present a general scheme that allows us to show that relations are well-defined and represent partial or quasi-orders. Known path orders as semantic, <b>recursive</b> and lexicographic <b>path</b> order as well as Knuth-Bendix order fit into the scheme. Additionally we will also discuss how to obtain other properties commonly found in term orders (amongst which well-foundedness) as an integrated feature of the scheme...|$|R
40|$|Abstract—Calling {{contexts}} (CCs) {{are very}} important {{for a wide range}} of applications such as profiling, debugging, and event logging. Most applications perform expensive stack walking to recover contexts. The resulting contexts are often explicitly represented as a sequence of call sites and hence are bulky. We propose a technique to encode the current calling context of any point during an execution. In particular, an acyclic call path is encoded into one number through only integer additions. <b>Recursive</b> call <b>paths</b> are divided into acyclic subsequences and encoded independently. We leverage stack depth in a safe way to optimize encoding: If a calling context can be safely and uniquely identified by its stack depth, we do not perform encoding. We propose an algorithm to seamlessly fuse encoding and stack depth-based identification. The algorithm is safe because different contexts are guaranteed to have different IDs. It also ensures contexts can be faithfully decoded. Our experiments show that our technique incurs negligible overhead (0 - 6. 4 percent). For most medium-sized programs, it can encode all contexts with just one number. For large programs, we are able to encode most calling contexts to a few numbers. We also present our experience of applying context encoding to debugging crashbased failures. Index Terms—Calling context, context sensitivity, profiling, path encoding, calling context encoding, call graph Ç...|$|R
40|$|This paper {{discusses}} how {{to extend}} {{the applicability of the}} recursive cascade update command of the Xplain query language. This command guarantees termination because cycle detection is included, which is in favor of end user computing. The execution of this command is based on graph reduction; therefore it can only be applied to acyclic graphs. Because flights constitute cycles between airports, it seemed impossible to specify a query language solution for shortest flight connections between two arbitrary airports. However, on a time scale cyclic connections between successive flights cannot exist at all. Therefore we designed an appropriate semantic data model for feasible connections between successive flights. Using this extended data model, the cascade command still enables end users to specify recursive queries for the fastest series of flights between any pair of airports. KEY WORDS shortest <b>path,</b> <b>recursive</b> query, semantic model, transitive closure 1...|$|R
40|$|Semantic {{labelling}} is a transformational {{technique for}} proving termination of Term Rewriting Systems (TRSs). Only its variant with finite sets of labels was used {{so far in}} tools for automatic termination proving and variants with infinite sets of labels were considered not to be suitable for automation. We show that such automation can be achieved for semantic labelling with natural numbers, in combination with <b>recursive</b> <b>path</b> ordering (RPO). In order to do so we developed algorithms to deal with <b>recursive</b> <b>path</b> ordering for these infinite labelled systems. Using these techniques TPA, a tool developed by the first author, is the only current tool that can prove termination of the SUBST system automatically...|$|E
40|$|International audienceThe {{notion of}} computability closure has been {{introduced}} for proving the termination of higher-order rewriting with first-order matching by Jean-Pierre Jouannaud and Mitsuhiro Okada in a 1997 draft which later served {{as a basis for}} the author's PhD. In this paper, we show how this notion can also be used for dealing with beta-normalized rewriting with matching modulo beta-eta (on patterns à la Miller), rewriting with matching modulo some equational theory, and higher-order data types (types with constructors having functional recursive arguments). Finally, we show how the computability closure can easily be turned into a reduction ordering which, in the higher-order case, contains Jean-Pierre Jouannaud and Albert Rubio's higher-order <b>recursive</b> <b>path</b> ordering and, in the first-order case, is equal to the usual first-order <b>recursive</b> <b>path</b> ordering...|$|E
40|$|The tool TORPA (Termination of Rewriting Proved Automatically) {{can be used}} {{to prove}} {{termination}} of string rewriting systems (SRSs) fully automatically. The underlying techniques include semantic labelling, polynomial interpretations, <b>recursive</b> <b>path</b> order, the dependency pair method and match bounds of right hand sides of forward closures...|$|E
40|$|SummaryMedial entorhinal grid cells fire in periodic, hexagonally {{patterned}} {{locations and}} are proposed to support path-integration-based navigation. The <b>recursive</b> nature of <b>path</b> integration results in accumulating error and, without a corrective mechanism, {{a breakdown in}} the calculation of location. The observed long-term stability of grid patterns necessitates that the system either performs highly precise internal path integration or implements an external landmark-based error correction mechanism. To distinguish these possibilities, we examined grid cells in behaving rodents as they made long trajectories across an open arena. We found that error accumulates relative to time and distance traveled since the animal last encountered a boundary. This error reflects coherent drift in the grid pattern. Further, interactions with boundaries yield direction-dependent error correction, suggesting that border cells serve as a neural substrate for error correction. These observations, combined with simulations of an attractor network grid cell model, demonstrate that landmarks are crucial to grid stability...|$|R
40|$|We {{present in}} this paper a new {{procedure}} to saturate a set of clauses {{with respect to a}} well-founded ordering on ground atoms such that A < B implies Var(A) ⊆ Var(B) for every atoms A and B. This condition is satisfied by any atom ordering compatible with a lexicographic, <b>recursive,</b> or multiset <b>path</b> ordering on terms. Our saturation procedure is based on a priori ordered resolution and its main novelty is the on-the-fly construction of a finite complexity atom ordering. In contrast with the usual redundancy, we give a new redundancy notion and we prove that during the saturation a non-redundant inference by a priori ordered resolution is also an inference by a posteriori ordered resolution. We also prove that if a set S of clauses is saturated with respect to an atom ordering as described above then the problem of whether a clause C is entailed from S is decidable...|$|R
40|$|We {{show how}} to draw evenly dotted and dashed curved lines in METAFONT, using <b>recursive</b> {{refinement}} of <b>paths.</b> METAPOST provides extra primitives {{that can be used}} for this task, but the method presented here can be used for both METAFONT and METAPOST. Introduction Knuth's METAFONT has powerful facilities for manipulating and drawing curves or `paths'. These facilities are generally sufficient for METAFONT's primary intended purpose, namely drawing letters. However, METAFONT is also very well suited to producing technical diagrams; for this secondary purpose, METAFONT lacks a valuable facility [...] -that of drawing evenly dotted and dashed curves. In this paper we show how to remedy this shortcoming, using the facilities that METAFONT does have available. John Hobby's METAPOST is an adaptation of METAFONT for producing PostScript output rather than bitmaps. METAPOST was primarily intended for producing technical diagrams (Don Hosek reports Hobby as saying, `Well, you could use it for g [...] ...|$|R
