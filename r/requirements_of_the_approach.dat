11|10000|Public
40|$|This paper {{presents}} {{a new approach}} for the computation of transient measures in large continuous time Markov chains (CTMCs). The approach combines the randomization approach for transient analysis of CTMCs with a new representation of probability vectors as Kronecker products of small component vectors. This representation is an approximation that allows an extremely space- and time-efficient computation of transient vectors. Usually, the resulting approximation is very good and introduces errors that are comparable to those found with existing approximation techniques for stationary analysis. By increasing the space and time <b>requirements</b> <b>of</b> <b>the</b> <b>approach,</b> we can represent parts of the solution vector in detail and reduce the approximation error, yielding exact solutions in the limiting case...|$|E
40|$|Extracting {{information}} from unstructured text {{has become an}} emphasis in recent years due to {{the large amount of}} text now electronically available. This status report describes the findings and work done {{by the end of the}} first year of a two-year LDRD. <b>Requirements</b> <b>of</b> <b>the</b> <b>approach</b> included that it model the information in a domain independent way. This means that it would differ from current systems by not relying on previously built domain knowledge and that it would do more than keyword identification. Three areas that are discussed and expected to contribute to a solution include (1) identifying key entities through document level profiling and preprocessing, (2) identifying relationships between entities through sentence level syntax, and (3) combining the first two with semantic knowledge about the terms...|$|E
40|$|This article {{assesses the}} extent to which the book under review lives up to the {{expectations}} raised by its title. The focus is thus on whether the results of interpreting the five featured case studies justify the methodological effort. The interaction between the text and the reader is left out and this is problematic when it comes to interpreting the memories of the Jewish emigrant who is at the centre of three out of the five essays. Furthermore, it is clear that on a formal level (relating to the shared analytical subject) as well as in terms of content (relating to interconnectedness) that the methodological discussion falls short of the <b>requirements</b> <b>of</b> <b>the</b> <b>approach</b> taken. URN: urn:nbn:de: 0114 -fqs 090119...|$|E
25|$|Banks using <b>the</b> {{foundation}} <b>approach</b> use supervisory {{estimates of}} EADpreCCF and LGD. However, {{they must be}} meet <b>the</b> minimum <b>requirements</b> <b>of</b> <b>the</b> standardized <b>approach</b> for recognition of eligible collateral.|$|R
40|$|To {{differentiate}} sulfated from reduced-sulfur-containing molecules, we {{employed a}} mutant lacking <b>the</b> reductive branch <b>of</b> <b>the</b> sulfate assimilation pathway. In these sulfur auxotrophs, heavy sulfate is channeled exclusively into sulfated metabolites. The method {{was applied to}} <b>the</b> discovery <b>of</b> several new sulfated molecules in Mycobacterium tuberculosis and Mycobacterium smegmatis. Because a sulfur auxotrophic strain is <b>the</b> only <b>requirement</b> <b>of</b> <b>the</b> <b>approach,</b> many microorganisms can be studied in this manner. Such genetic engineering in combination with stable isotopic labeling {{can be applied to}} various metabolic pathways and their products...|$|R
30|$|In this paper, we {{investigate}} {{an approach that}} combines multirate frequency transformations for wideband CPM demodulation with decision feedback equalization for memory removal. This combined <b>approach</b> avoids <b>the</b> problems <b>of</b> complexity and restrictive <b>requirements</b> <b>of</b> <b>the</b> Viterbi <b>approach.</b> Simulation results are used to demonstrate <b>the</b> validity <b>of</b> <b>the</b> combined <b>approach.</b>|$|R
40|$|Pseudo-relevance {{feedback}} (PRF) improves search quality {{by expanding}} the query using terms from high-ranking documents from an initial retrieval. Although PRF can often result in large gains in effectiveness, running two queries is time consuming, limiting its applicability. We describe a PRF method that uses corpus pre-processing to achieve query-time speeds that are near {{those of the}} original queries. Specifically, Relevance Modeling, a language modeling based PRF method, can be recast to benefit substantially from finding pairwise document relationships in advance. Using the resulting Fast Relevance Model (fastRM), we substantially reduce the online retrieval time and still benefit from expansion. We further explore methods for reducing the preprocessing time and storage <b>requirements</b> <b>of</b> <b>the</b> <b>approach,</b> allowing us to achieve up to a 10 % increase in MAP over unexpanded retrieval, while only requiring 1 % {{of the time of}} standard expansion...|$|E
40|$|ABSTRACT: Object-oriented techniques, {{when applied}} seriously {{and on a}} broad scale, reflect a new culture of {{software}} engineering. which may be called the component culture. After contrasting this new culture with the more traditional project culture, this article examines some of the technical. economical and managerial implications of the new approach. The discussion explores the fundamental object-oriented processes of abstraction and extraction (recognizing inheritance structures a posteriori). and introduces a new lifecyclemodel which seems to fit best with object-oriented development of reusable software: the Cluster Model. 2. 1 OVERVIEW Object-oriented design is an old idea and a new idea. Simula introduced the basic concepts {{more than twenty years}} ago, time for a few generations when measured against the rate of evolution of the computer industry. Only recently, however, have object-oriented techniques been exposed to enough people and applied to enough projects to yield a concrete idea of the practical power, benefits and <b>requirements</b> <b>of</b> <b>the</b> <b>approach.</b> This article describes {{some of the issues that}} arise when the object-oriented approach is implemented on a significant scale. It argues that object-oriented techniques imply a ne...|$|E
40|$|Detecting and {{segmenting}} diffuse {{targets in}} laser ranging data {{is a critical}} problem for tactical reconnaissance. In this study, we pro-pose a new method that facilitates the characterization of diffuse irregularly shaped objects using “spin images, ” i. e., local 2 D histograms of laser returns oriented in 3 D space, and a clustering process. The proposed “cluster-based spin imaging ” method resolves the problem of using standard spin images for diffuse targets and it eliminates much of the computational complexity that characterizes the pro-duction of conventional spin images. The direct processing of pre-segmented laser points, including internal points that penetrate through a diffuse object’s topmost surfaces, avoids some of the <b>requirements</b> <b>of</b> <b>the</b> <b>approach</b> used at present for spin image generation, while it also greatly reduces the high computational time overheads incurred by searches to find correlated images. We employed 3 D airborne range data over forested terrain to demonstrate {{the effectiveness of this}} method in discriminating the different geometric structures of individual tree clusters. Our experiments showed that cluster-based spin images have the potential to separate classes in terms of different ages and portions of tree crowns...|$|E
40|$|Volumetric data is one <b>of</b> <b>the</b> most {{frequently}} generated {{type of data}} in modern medical imaging. Technical advances in the respective scanning technologies also increase <b>the</b> amount <b>of</b> data that is generated by a typical scanner. Since 1971 with <b>the</b> introduction <b>of</b> <b>the</b> first CT scanner, the space requirements for representing data have increased rapidly, in essence at an exponential rate. In this paper, we examine various compression methods for their applicability for volume data, focusing on <b>the</b> reduced space <b>requirements</b> <b>of</b> <b>the</b> <b>approaches.</b> We apply these methods {{to a wide range}} of 8 bit and 10 - 12 bit volume datasets, thus exposing strengths and weaknesses <b>of</b> <b>the</b> compression methods. In summary, significant differences in compression performances clearly indicate which compression techniques should be used...|$|R
40|$|A {{software}} platform able to fulfill <b>the</b> <b>requirements</b> <b>of</b> <b>the</b> new <b>approach</b> in photonic integration through <b>the</b> establishment <b>of</b> generic foundries is presented. The kernel is a circuit simulator able {{to combine the}} foundry building blocks described by accurate models to design and analyze complex circuits in the spectral domain...|$|R
30|$|Despite <b>the</b> {{low number}} <b>of</b> {{additional}} test cases required {{to cover all}} test <b>requirements</b> <b>of</b> <b>the</b> proposed <b>approaches,</b> <b>the</b> analysis <b>of</b> <b>the</b> underlying model for creating test cases is not trivial. It is essential that the model facilitates <b>the</b> understanding <b>of</b> <b>the</b> dynamic behaviour <b>of</b> a program and thus <b>the</b> generation <b>of</b> relevant test cases.|$|R
40|$|Evaluating {{the impact}} {{agricultural}} practices have on agroecosystem functions {{is essential to}} determine the sustainability of management systems. This paper presents an approach to determine the relative sustainability of agricultural practices. A simple ranking procedure using a relative scoring method is proposed to discriminate among treatments based {{on the status of}} crop and soil parameters within different agroecosystem functions. Summing scores across agroecosystem functions allows for the identification of agricultural practices that are performing optimally based on functions included in the procedure. An example, using data from a long-term cropping systems experiment in the western Corn Belt, found the indexing procedure to successfully discern differences in overall performance across four agroecosystem functions between conventional [continuous corn (Zea mays L.) cropping sequence at a fertilization rate of 180 kg N h- 1] and alternative {corn–oat (Avena sativa L.) 1 clover (Trifolium pratense L.) –grain sorghum [Sorghum bicolor (L.) Moench]–soybean [Glycine max (L.) Merr. ] cropping sequence at a fertilization rate of 90 kg N ha- 1 }management systems. The simplicity, inclusiveness, and inherent flexibility of the indexing procedure can be considered benefits and drawbacks, depending on the point of view taken. Data <b>requirements</b> <b>of</b> <b>the</b> <b>approach,</b> however, are stringent. Consequently, its most appropriate use may be with data from long-term agroecosystem experiments...|$|E
40|$|Runoff-based {{indicators}} of terrestrial water availability {{are appropriate for}} humid regions, but have tended to limit our basic hydrologic understanding of drylands – the dry-subhumid, semiarid, and arid regions which presently cover {{nearly half of the}} global land surface. In response, we introduce an indicator framework that gives equal weight to humid and dryland regions, accounting fully for both vertical (precipitation + evapotranspiration) and horizontal (groundwater + surface-water) components of the hydrologic cycle in any given location – as well as fluxes into and out of landscape storage. We apply the framework to a diverse hydroclimatic region (the conterminous USA) using a distributed water-balance model consisting of 53 400 networked landscape hydrologic units. Our model simulations indicate that about 21 % of the conterminous USA either generated no runoff or consumed runoff from upgradient sources on a mean-annual basis during the 20 th century. Vertical fluxes exceeded horizontal fluxes across 76 % of the conterminous area. Long-term-average total water availability (TWA) during the 20 th century, defined here as the total influx to a landscape hydrologic unit from precipitation, groundwater, and surface water, varied spatially by about 400 000 -fold, a range of variation ~ 100 times larger than that for mean-annual runoff across the same area. The framework includes but is not limited to classical, runoff-based approaches to water-resource assessment. It also incorporates and reinterprets the green- and blue-water perspective now gaining international acceptance. Implications of the new framework for several areas of contemporary hydrology are explored, and the data <b>requirements</b> <b>of</b> <b>the</b> <b>approach</b> are discussed in relation to the increasing availability of gridded global climate, land-surface, and hydrologic data sets...|$|E
40|$|Analysiert werden Anspruch und Wirklichkeit der im Buchtitel annoncierten Methodendiskussion. Im Zentrum steht dabei die Frage, ob der methodologische Aufwand in einem angemessenen Verhältnis zum interpretatorischen Ertrag der fünf Fallbeispiele steht. Es wird anhand von Textbelegen herausgearbeitet, dass die ausgeblendete gesellschaftshistorische Dimension und die ebenfalls ausgeblendete Text-Lesende-Interaktion problematisch für die Interpretation der lebensgeschichtlichen Erinnerungen einer jüdischen Emigrantin ist, die in drei der fünf Aufsätze im Zentrum stehen. Außerdem wird deutlich, dass sowohl formal (der gleiche Untersuchungsgegenstand) als auch inhaltlich (reflexive wechselseitige Bezugnahme) die Bedingungen für eine Diskussion nicht eingelöst wurden. This article {{assesses the}} extent to which the book under review lives up to the {{expectations}} raised by its title. The focus is thus on whether the results of interpreting the five featured case studies justify the methodological effort. The interaction between the text and the reader is left out and this is problematic when it comes to interpreting the memories of the Jewish emigrant who is at the centre of three out of the five essays. Furthermore, it is clear that on a formal level (relating to the shared analytical subject) as well as in terms of content (relating to interconnectedness) that the methodological discussion falls short of the <b>requirements</b> <b>of</b> <b>the</b> <b>approach</b> taken. En este artículo se evalúa hasta que punto el libro reseñado está a la altura de las expectativas suscitadas por el título. Por lo tanto, la atención se centra en si los resultados de la interpretación de los cinco estudios de caso descritos justifican el esfuerzo metodológico. La interacción entre el texto y el lector se deja fuera, lo que es problemático cuando se trata de interpretar la memoria de los judíos emigrantes, aspecto central en tres de los cinco ensayos. Por otra parte, es evidente que en un nivel formal (con relación al tema analítico compartido), así como en términos del contenido (con relación a la interconectividad), el debate metodológico no está a la altura de las exigencias del enfoque adoptado...|$|E
40|$|<b>The</b> purpose <b>of</b> {{this paper}} is to {{investigate}} <b>the</b> concept <b>of</b> literacy <b>of</b> population and <b>the</b> evolution <b>of</b> literacy according to <b>the</b> <b>requirements</b> <b>of</b> nowadays. <b>The</b> <b>approaches</b> <b>of</b> scientists to multifaceted literacy of population and its necessity are considered. Special attention is paid to statistical literacy of population and its necessity in <b>the</b> life <b>of</b> every modern person...|$|R
40|$|Purpose: {{to prove}} methodological <b>requirements</b> <b>of</b> <b>the</b> competetive <b>approach</b> in <b>the</b> tourist {{preparation}} <b>of</b> <b>the</b> future teachers. Material : the research work {{was made on}} <b>the</b> basis <b>of</b> studying <b>of</b> references, <b>the</b> analysis and synthesis <b>of</b> <b>the</b> received information, with <b>the</b> usage <b>of</b> <b>the</b> method <b>of</b> pedagogical designing. Results: methodological <b>requirements</b> <b>of</b> <b>the</b> competetive <b>approach</b> in tourist formation <b>of</b> <b>the</b> future teachers are considered and concretised. <b>The</b> methods <b>of</b> objective diagnosing of tourist preparation <b>of</b> <b>the</b> future teacher is opened. It is noticed that for objective diagnosing are necessary not only the subject (as it descends in traditional training), but also the system, professionally oriented criteria, allowing to measure level of forming of tourist competence <b>of</b> <b>the</b> future teacher. Conclusions: <b>the</b> universal structure <b>of</b> tourist competence <b>of</b> <b>the</b> future teachers consists of following components: motivational; cognitive; praxeological; individually-psychologic; the subjective. <b>The</b> assessment <b>of</b> these components allows to define complex level of forming of tourist competence <b>of</b> <b>the</b> future teacher...|$|R
40|$|The {{dissertation}} aims {{to evaluate}} whether <b>the</b> Pre-Intermmediate volume <b>of</b> <b>the</b> Matrix coursebook series is appropriate {{to be used in}} secondary school English language teaching, whether the selected material and the ways it is presented are sufficient and effective enough to prepare learners for language examinations, whether it meets <b>the</b> <b>requirements</b> <b>of</b> <b>the</b> recent <b>approaches</b> concerning <b>the</b> achievement <b>of</b> communicative competence. egyetemiangol nyelv és irodalo...|$|R
40|$|This article {{assesses the}} extent to which the book under review lives up to the {{expectations}} raised by its title. The focus is thus on whether the results of interpreting the five featured case studies justify the methodological effort. The interaction between the text and the reader is left out and this is problematic when it comes to interpreting the memories of the Jewish emigrant who is at the centre of three out of the five essays. Furthermore, it is clear that on a formal level (relating to the shared analytical subject) as well as in terms of content (relating to interconnectedness) that the methodological discussion falls short of the <b>requirements</b> <b>of</b> <b>the</b> <b>approach</b> taken. &# 13; URN: urn:nbn:de: 0114 -fqs 0901193 En este artículo se evalúa hasta que punto el libro reseñado está a la altura de las expectativas suscitadas por el título. Por lo tanto, la atención se centra en si los resultados de la interpretación de los cinco estudios de caso descritos justifican el esfuerzo metodológico. La interacción entre el texto y el lector se deja fuera, lo que es problemático cuando se trata de interpretar la memoria de los judíos emigrantes, aspecto central en tres de los cinco ensayos. Por otra parte, es evidente que en un nivel formal (con relación al tema analítico compartido), así como en términos del contenido (con relación a la interconectividad), el debate metodológico no está a la altura de las exigencias del enfoque adoptado. &# 13; URN: urn:nbn:de: 0114 -fqs 0901193 Analysiert werden Anspruch und Wirklichkeit der im Buchtitel annoncierten Methodendiskussion. Im Zentrum steht dabei die Frage, ob der methodologische Aufwand in einem angemessenen Verhältnis zum interpretatorischen Ertrag der fünf Fallbeispiele steht. Es wird anhand von Textbelegen herausgearbeitet, dass die ausgeblendete gesellschaftshistorische Dimension und die ebenfalls ausgeblendete Text-Lesende-Interaktion problematisch für die Interpretation der lebensgeschichtlichen Erinnerungen einer jüdischen Emigrantin ist, die in drei der fünf Aufsätze im Zentrum stehen. Außerdem wird deutlich, dass sowohl formal (der gleiche Untersuchungsgegenstand) als auch inhaltlich (reflexive wechselseitige Bezugnahme) die Bedingungen für eine Diskussion nicht eingelöst wurden. &# 13; URN: urn:nbn:de: 0114 -fqs 090119...|$|E
40|$|This {{investigation}} {{explores the}} use of an approximate energy flow approach to provide a global modelling tool capable of predicting the pattern and level of vibrational energy flow in complex structures. The modelling approach is based on a differential control volume formulation which, by virtue of its simplified nature, describes the flow of mechanical energy within a structural component in a manner analogous to the flow of thermal energy in heat conduction problems. For complex structures the approach can be implemented using existing finite element software through an analogy between the thermal and vibrational systems. Energy flow predictions along simple beam structures, obtained using the energy flow approach, are compared to "exact" analytical solutions and experimental structural intensity measurements on real structures. This provides useful insight into the capabilities and <b>requirements</b> <b>of</b> <b>the</b> <b>approach,</b> such as the quality of model predictions at lower frequencies and the accuracy requirement for modelling parameters. The task of modelling the transmission of vibrational energy in practical engineering structures is complicated by the partial reflection of incident wave energy at structural discontinuities. Methods to account for this effect are discussed and an approach is developed which can be incorporated into the finite element global modelling scheme. This is used to model a complex multiple transmission path structure which illustrates the ability of the approach to form an effective transmission path ranking tool. Finally, the approach is used to build a representative energy flow model of a ribbed bulkhead structure typical of marine applications. A wavenumber measurement technique is used to assess the wave transmission characteristics of this structure which exhibit strong directional dependence. Predictions provided by the energy flow model are in good general agreement with energy flow measurements obtained from the real structure. Throughout these modelling exercises particular attention is paid to the provision of suitable estimates of the parameters (damping, group velocity, power input and transmission efficiency) on which the accuracy of the model predictions rely. This investigation represents a significant contribution to current knowledge regarding {{the use of}} the energy flow approach and its ability to provide representative models of real structures. Although further research is still required, considerable progress has been made and the work documented here provides the framework for a global modelling tool using existing finite element software...|$|E
40|$|With {{capillary}} electrophoresis, it {{is desirable}} to have simultaneous determination of cations and anions, which avoids costs and time spent on separate analyses, so concurrent approaches to separation gained popularity in recent years. We review the different strategies employed for the simultaneous separation and determination of cations and anions, including <b>the</b> use <b>of</b> complexing agents, micelles, two injectors, dual detectors, or two capillaries. We give an overview <b>of</b> <b>the</b> methods reported to date, and their benefits and drawbacks, and we evaluate <b>the</b> instrumental <b>requirements</b> <b>of</b> <b>the</b> different <b>approaches.</b> (C) 2014 Elsevier B. V. All rights reserved...|$|R
40|$|This paper gives a {{schematic}} overview <b>of</b> <b>the</b> building <b>of</b> object-oriented function classes for <b>the</b> realisation <b>of</b> information <b>requirements</b> <b>of</b> end-users. <b>The</b> <b>approach</b> shows {{how easy it}} is to build these classes around an object-oriented model <b>of</b> <b>the</b> business logic. The specifications are illustrated by means <b>of</b> examples. <b>The</b> paper concludes with a discussion <b>of</b> <b>the</b> proposed concepts. A solution package is available as an appendix. Keywords Model-driven - Object-Oriented - Event-driven - Entity-Relationship - Systems Development - Software Development - Jackson Systems Development - Software Methodology - Business Modeling - Information Modeling - System Implementation. 0...|$|R
40|$|The {{inherent}} {{uncertainty in}} quantum mechanics offers {{a source of}} true randomness {{which can be used}} to produce unbreakable cryptographic keys. We discuss <b>the</b> development <b>of</b> a high-speed random number generator based on the quantum phase fluctuations in spontaneously initiated stimulated Raman scattering (SISRS). We utilize the tight confinement and long interaction length available in a Potassium Titanyl Phosphate waveguide to generate highly efficient SISRS using nanojoule pulse energies, reducing the high pump power <b>requirements</b> <b>of</b> <b>the</b> previous <b>approaches.</b> We measure <b>the</b> random phase <b>of</b> <b>the</b> Stokes output using a simple interferometric setup to yield quantum random numbers at 145 Mbps. Peer reviewed: YesNRC publication: Ye...|$|R
40|$|This paper evaluates a novel k-nearest {{neighbour}} (k-NN) classifier {{built from}} binary neural networks. <b>The</b> binary neural <b>approach</b> uses robust encoding to map standard ordinal, categorical and numeric data sets onto a binary neural network. The binary neural network uses high speed pattern matching to recall a candidate set of matching records, {{which are then}} processed by a conventional k-NN <b>approach</b> to determine <b>the</b> k-best matches. We compare various configurations <b>of</b> <b>the</b> binary <b>approach</b> to a conventional approach for memory overheads, training speed, retrieval speed and retrieval accuracy. We demonstrate the superior performance with respect to speed and memory <b>requirements</b> <b>of</b> <b>the</b> binary <b>approach</b> compared to <b>the</b> standard <b>approach</b> and we pinpoint the optimal configurations. (C) 2003 Elsevier Ltd. All rights reserved...|$|R
40|$|The {{internal}} ratings based approach (IRB Approach) was created {{as part of}} Basel II replacing the original Basle Accord of 1988 (Basle I) in an effort to create a better framework for regulating bank capital. This paper covers the methodology and components <b>of</b> <b>the</b> IRB <b>Approach</b> used to determine capital requirements for credit risk. Such an approach, which relies heavily upon a banks internal assessment of its counterparties and exposures, can secure two key objectives consistent with those which support <b>the</b> wider review <b>of</b> <b>The</b> New Basel Capital Accord [...] IRB approach should promote safety and soundness in the financial system and, consistent with providing incentive compatibility, that <b>the</b> structure and <b>requirements</b> <b>of</b> <b>the</b> IRB <b>approach</b> do not impinge upon or undermine banks well-established lending and credit risk management practice...|$|R
40|$|This paper {{identifies}} {{issues from}} Australian case law {{that are associated}} with <b>the</b> management <b>of</b> <b>the</b> inclusion <b>of</b> students with disabilities in Australian schools. Examples from disability discrimination case law are analysed and discussed according to <b>the</b> contexts <b>of</b> <b>the</b> student and school situation and <b>the</b> <b>requirements</b> <b>of</b> <b>the</b> law. Strategic <b>approaches</b> for <b>the</b> lawful management <b>of</b> inclusion are then suggested so that schools and principals are able to proactively manage inclusion and reduce <b>the</b> incidence <b>of</b> unlawful disability discrimination in schools...|$|R
40|$|In {{this paper}} we {{investigate}} <b>the</b> privacy dimension <b>of</b> collaborative fraud detection envisioned for outsourcing scenarios. Firstly, we investigate the privacy requirements derived from privacy law and present the resulting judicial argument for pseudonymizing audit data generated for <b>the</b> purpose <b>of</b> fraud detection. Second, we summarize {{the requirements for}} such pseudonymization derived from <b>the</b> <b>requirements</b> <b>of</b> <b>the</b> misuse detection <b>approach</b> for fraud detection. Third, we describe our approach for pseudonymization of audit data and two approaches for hiding timestamps in audit data...|$|R
40|$|International audienceThis paper {{presents}} an approach for composing event streams based on quality <b>of</b> service <b>requirements</b> <b>of</b> smart grids. <b>The</b> <b>approach</b> consists <b>of</b> an event stream model, composition strategies guided by quality <b>of</b> service <b>requirements</b> such as memory consumption, event priority and notification latency. Model and strategies are implemented by a distributed event stream processing system consisting of execution units {{that can be}} deployed across a smart grid. The paper describes implementation issues and experimental results...|$|R
40|$|This paper {{presents}} an alternative procedure for computing the steady state probability vector of an M/M/ 1 queue with randomly varying arrival and service rates. By exploiting <b>the</b> structure <b>of</b> <b>the</b> infinitesimal generator <b>of</b> <b>the</b> underlying continuous-time Markov chain, <b>the</b> <b>approach</b> re{{presents an}} efficient adaptation <b>of</b> <b>the</b> state reduction method introduced by Grassmann for solving problems involving M/M/ 1 queues under a random environment. We compare computational <b>requirements</b> <b>of</b> <b>the</b> proposed <b>approach</b> with <b>the</b> method <b>of</b> Neuts and block elimination under different rush-hour congestion patterns {{while keeping the}} overall traffic intensity constant as well as under different traffic intensities. We demonstrate that the proposed method requires minimal computing time to reach convergence and moreover the time requirement does not change much when traffic intensity increases. M/M/ 1 queues in a random environment, matrix-geometric models, computing stationary probabilities...|$|R
40|$|A major {{objection}} to top-down accounts of lexical recognition {{has been that}} they are incompatible with an account of acquisition, it being argued that bottom-up segmentation must precede lexical acquisition. We counter this objection by presenting a top-down account of lexical acquisition. This is made possible by <b>the</b> adoption <b>of</b> a flexible criterion as to what may constitute a lexical item during acquisition, this being justified by <b>the</b> extensive evidence <b>of</b> children's undersegmentation. Advantages <b>of</b> <b>the</b> top-down account offered over the bottom-up alternatives are that it presents a unified account <b>of</b> <b>the</b> acquisition <b>of</b> a lexicon and segmentation abilities, and is wholly driven by <b>the</b> <b>requirements</b> <b>of</b> comprehension. <b>The</b> <b>approach</b> described has been incorporated into an integrated model <b>of</b> acquisition processes, <b>the</b> incremental learning <b>of</b> which captures <b>the</b> gradual nature <b>of</b> child language development. ...|$|R
40|$|K-Nearest Neighbour (k-NN) is {{a widely}} used {{technique}} for classifying and clustering data. K-NN is effective but is often criticised for its polynomial run-time growth as k-NN calculates the distance to every other record in the data set for each record in turn. This paper evaluates a novel k-NN classifier with linear growth and faster run-time built from binary neural networks. <b>The</b> binary neural <b>approach</b> uses robust encoding to map standard ordinal, categorical and real-valued data sets onto a binary neural network. The binary neural network uses high speed pattern matching to recall the k-best matches. We compare various configurations <b>of</b> <b>the</b> binary <b>approach</b> to a conventional approach for memory overheads, training speed, retrieval speed and retrieval accuracy. We demonstrate the superior performance with respect to speed and memory <b>requirements</b> <b>of</b> <b>the</b> binary <b>approach</b> compared to <b>the</b> standard <b>approach</b> and we pinpoint the optimal configurations...|$|R
40|$|Purpose: to {{consider}} <b>the</b> direction <b>of</b> training handball {{team in the}} annual Ukrainian Superleague macrocycles game seasons in years 2006 - 2013. Material: in the experiment took part 125 participated highly qualified handballers. <b>The</b> analysis <b>of</b> more than 50 references on multi-year training athletes is conducted. Results: confirmed advisability <b>of</b> constructing <b>the</b> training process handball qualifications based on <b>the</b> structural components <b>of</b> <b>the</b> preparation. According to <b>the</b> <b>requirements</b> <b>of</b> <b>the</b> system <b>approach</b> presented technology of preparation are disclosed management methodology training process in terms of long-term training. Conclusions: {{it is necessary to}} compile and optimize long-term training program handball qualifications; raise <b>the</b> level <b>of</b> preparedness <b>of</b> <b>the</b> various parties in strict accordance with <b>the</b> objective laws <b>of</b> <b>the</b> formation <b>of</b> their constituents, and calendar events, {{to consider}} specific features <b>of</b> <b>the</b> occurrence <b>of</b> adaptive reactions in improving <b>the</b> various components <b>of</b> sportsmanship...|$|R
40|$|Computing {{response}} time distributions using stochastic Petri nets and matrix diagrams In this paper, we consider random variables {{expressed in terms}} <b>of</b> <b>the</b> time required for <b>the</b> state <b>of</b> a stochastic Petri net to pass from a set of starting markings {{to a set of}} stopping markings. These random variables have continuous phase-type distributions when the all transitions have exponentially-distributed firing delays. We demonstrate how to numerically compute <b>the</b> distribution <b>of</b> <b>the</b> random variable using both explicit techniques and an implicit approach based on multi-way decision diagrams and matrix diagrams. We present an efficient matrix-vector multiplication algorithm for matrix diagrams that is necessary for numerical solution. We demonstrate <b>the</b> efficiency <b>of</b> our <b>approaches</b> using several models. <b>The</b> lower storage <b>requirements</b> <b>of</b> <b>the</b> implicit <b>approach</b> effectively increases <b>the</b> size <b>of</b> models that can be analyzed by about an order of magnitude. 1...|$|R
40|$|Measurement-Based Probabilistic Timing Analysis (MBPTA) {{techniques}} simplify deriving {{tight and}} trustworthy WCET estimates for industrial-size programs running on complex processors. MBPTA poses some requirements on <b>the</b> timing behaviour <b>of</b> <b>the</b> hardware/software platform: execution times of end-to-end runs {{have to be}} independent and identically distributed (i. i. d.). Hardware and software solutions have been deployed to accomplish MBPTA requirements. The latter has achieved the i. i. d. properties running on some commercial off-the-shelf (COTS) processor designs. Unfortunately, software randomisation challenges functional verification needed for certification since it introduces indirections through pointers in the code. In this {{paper we propose a}} new approach to software randomisation able to contain its functional verification costs. Our approach performs software randomisation statically, as opposed to current dynamic approaches. We carefully review <b>the</b> <b>requirements</b> <b>of</b> <b>the</b> new <b>approach</b> and prove its feasibility. Peer ReviewedPostprint (published version...|$|R
40|$|We compare two {{classifier}} approaches, namely classifiers {{based on}} Multi Layer Perceptrons (MLPs) and Gaussian Mixture Models (GMMs), {{for use in}} a face verification system. The comparison is carried out in terms of performance, robustness and practicability. Apart from structural differences, <b>the</b> two <b>approaches</b> use different training criteria; <b>the</b> MLP <b>approach</b> uses a discriminative criterion, while <b>the</b> GMM <b>approach</b> uses a combination of Maximum Likelihood (ML) and Maximum a Posteriori (MAP) criteria. Experiments on the XM 2 VTS database show that for low resolution faces <b>the</b> MLP <b>approach</b> has slightly lower error rates than the GMM approach; however, <b>the</b> GMM <b>approach</b> easily outperforms <b>the</b> MLP <b>approach</b> for high resolution faces and is significantly more robust to imperfectly located faces. The experiments also show that <b>the</b> computational <b>requirements</b> <b>of</b> <b>the</b> GMM <b>approach</b> can be significantly smaller than <b>the</b> MLP <b>approach</b> at a cost of small loss of performance...|$|R
40|$|Abstract. Soccer meets <b>the</b> <b>requirements</b> <b>of</b> <b>the</b> Situated Agent <b>approach</b> {{and as a}} task domain is {{sufficiently}} rich to support research integrating many branches of AI. Reactive deliberation is a robot architecture that combines responsiveness to the environment with intelligent decision making. Under Reactive Deliberation, the robot controller is partitioned into a deliberator and an executor; the distinction is primarily based on the different time scales of interaction. A controller for our team entry in the Robocup 97 Simulation League, UBC Dynamo 97, has been developed using the Reactive Deliberation architecture...|$|R
