65|61|Public
5000|$|The dual-tree complex wavelet {{transform}} (ℂWT) {{is a relatively}} recent enhancement to the discrete {{wavelet transform}} (DWT), with important additional properties: It is nearly shift invariant and directionally selective in two and higher dimensions. It achieves this with a <b>redundancy</b> <b>factor</b> of only [...] substantially lower than the undecimated DWT. The multidimensional (M-D) dual-tree ℂWT is nonseparable but {{is based on a}} computationally efficient, separable filter bank (FB).|$|E
40|$|By a {{classical}} result of Gomory and Hu (1961), in every edge-weighted graph G=(V,E,w), the minimum st-cut values, when ranging over all s,t∈ V, take at most |V|- 1 distinct values. That is, these |V| 2 instances exhibit <b>redundancy</b> <b>factor</b> Ω(|V|). They further showed how to construct from G a tree (V,E',w') that stores all minimum st-cut values. Motivated by this result, we obtain tight bounds for the <b>redundancy</b> <b>factor</b> of several generalizations {{of the minimum}} st-cut problem. 1. Group-Cut: Consider the minimum (A,B) -cut, ranging over all subsets A,B⊆ V of given sizes |A|=α and |B|=β. The <b>redundancy</b> <b>factor</b> is Ω_α,β(|V|). 2. Multiway-Cut: Consider the minimum cut separating every two vertices of S⊆ V, ranging over all subsets of a given size |S|=k. The <b>redundancy</b> <b>factor</b> is Ω_k(|V|). 3. Multicut: Consider the minimum cut separating every demand-pair in D⊆ V× V, ranging over collections of |D|=k demand pairs. The <b>redundancy</b> <b>factor</b> is Ω_k(|V|^k). This result is a bit surprising, as the <b>redundancy</b> <b>factor</b> is much larger than {{in the first two}} problems. A natural application of these bounds is to construct small data structures that stores all relevant cut values, like the Gomory-Hu tree. We initiate this direction by giving some upper and lower bounds. Comment: This version contains additional references to previous work (which have some overlap with our results), see Bibliographic Update 1. ...|$|E
40|$|In {{order to}} assess the {{structural}} reliability and redundancy with respect to deterioration, it is required to select appropriate models which describe the deterioration process. The parameters associated with these models have to be estimated through statistical interference, which introduces uncertainties in parameter estimates. As the structural reliability indices which are incorporated in the reliability-based <b>redundancy</b> <b>factor</b> {{can be considered as}} random variable, this <b>redundancy</b> <b>factor</b> itself is a random variable as well. In case additional information becomes available, the distribution function can be updated by taking into account this extra information. In this contribution, a framework is developed, which allows for the incorporation of additional information in the uncertain reliability index and the associated <b>redundancy</b> <b>factor</b> through Bayesian updating. It is shown that in case additional information on a main variable is gathered, this has a significant effect on the (mean) value and uncertainty of the reliability index and the associated <b>redundancy</b> <b>factor...</b>|$|E
40|$|Previous {{work has}} shown a {{relationship}} between syllabic duration, redundancy within speech, and prosodic structure [1]. In addition, a spectral care of articulation measure of vowels in spontaneous speech has supported these duration results and suggest that care of articulation varies inversely with redundancy and conversely with prosodic prominence. However, these spectral measures remain inconclusive due to measurement difficulties. In this paper a simpler spectral measurement {{is presented as a}} metric of care of articulation and applied to three vowels from each corner of the vowel triangle. Prosodic and <b>redundancy</b> <b>factors</b> can predict up to 5 % of the variance of this new measurement, supporting the inverse redundancy result. However, in contrast to syllabic duration, whether prosodic boundaries are controlled for or not, the predictive power of prosodic <b>factors</b> and <b>redundancy</b> <b>factors</b> remain relatively independent. This suggests that 1. phrase final syllables, despite lengthening, do not show increased care of articulation if measured spectrally, and 2. unlike duration, <b>redundancy</b> <b>factors</b> affect the spectral characteristics of vowels independently of prosodic structure. 1...|$|R
40|$|Abstract. In this paper, {{we propose}} a generic hybrid oriented-transform and wavelet-based image {{representation}} for intra-band image coding. We instantiate for three popular directional transforms having similar powers of approximation but different <b>redundancy</b> <b>factors.</b> For each transform type, we design a compression scheme wherein we exploit intra-band coefficient dependencies. We show that our schemes outperform alternative approaches reported in literature. Moreover, on some images, {{we report that}} two of the proposed codec schemes outperform JPEG 2000 by over 1 dB. Finally, we investigate the tradeoff between oversampling and sparsity and show that, at low rates, hybrid coding schemes with transform <b>redundancy</b> <b>factors</b> as high as 1. 25 to 5. 8 are capable in fact of outperforming JPEG 2000 and its critically-sampled wavelets. ...|$|R
40|$|Abstract In {{this paper}} the authors {{summarize}} {{the results of}} a study devoted to assess, using nonlinear static analyses, the impact of increasing the structural redundancy in ductile moment-resisting reinforced concrete concentric braced frames structures (RC-MRCBFs). Among the studied variables were the number of stories and the number of bays. Results obtained were compared with the currently proposed values in the Manual of Civil Structures (MOC- 08), a model code of Mexico. The studied frames have 4, 8, 12 and 16 -story with a story height h= 3. 5 m. and a fixed length L= 12 m., where 1, 2, 3 or 4 bays have to be located. RC-MRCBFs were assumed to be located in soft soil conditions in Mexico City and were designed using a capacity design methodology adapted to general requirements of the seismic, reinforced concrete and steel guidelines of Mexican Codes. From the results obtained in this study it is possible to conclude that a different effect is observed in overstrength <b>redundancy</b> <b>factors</b> respect to ductility <b>redundancy</b> <b>factors</b> due to an increase of the bay number considered. Also, the structural <b>redundancy</b> <b>factors</b> obtained for this particular structural system varies respect to the currently proposed in MOC- 08...|$|R
40|$|AbstractTraditional {{theoretical}} and experimental {{investigations of the}} mechanical behavior of granular media such as sand are restricted by the limited quantitative information about what actually happens internally. The discrete element method (DEM) was developed as a technique to examine the micromechanics of granular media for this purpose. In this paper, a new microscopic parameter in terms of <b>redundancy</b> <b>factor</b> is proposed to describe liquefaction for sand, {{and the evolution of}} <b>redundancy</b> <b>factor</b> is provided using DEM simulations under undrained conventional triaxial conditions. It is demonstrated that the phase transition dividing the soild-like behavior and liquid-like behavior is associated with a <b>redundancy</b> <b>factor</b> of 1, which corresponds to an average coordination number slightly above 4...|$|E
40|$|International audienceThis paper {{analyzes}} {{the impact on}} the stability of the TCP-Reno congestion control mechanism when a network coding (NC) layer is inserted in the TCP/IP stack. A model of the dynamics of the TCP-NC protocol combined with random early detection (RED) as active queue management mechanism is considered to study the network equilibrium and stability properties. The existence and uniqueness of an equilibrium point is demonstrated and characterized in terms of average throughput, loss rate, and queue length. Global stability is proved in absence of forward delay, and the effects of the NC <b>redundancy</b> <b>factor</b> and of the delay on the local stability of TCP-NC-RED are studied around the equilibrium. The fairness of TCP-NC with respect to TCP-Reno-like protocols is also studied. A version of TCP-NC with adaptive <b>redundancy</b> <b>factor</b> (TCP-NCAR) is also introduced. Results provided by the proposed model are compared with those obtained by simulation for N sources sharing a single link. TCP-NC-RED becomes unstable when delay or capacity increases, as TCP-Reno does, but also when the <b>redundancy</b> <b>factor</b> increases. Its stability region is characterized {{as a function of the}} <b>redundancy</b> <b>factor.</b> If TCP-NC and TCP-Reno share the same links, TCP-NC is fair with TCP-Reno-like protocols when no redundancy is added. Simulations show that TCP-NCAR is able to compensate losses on the wireless parts of the network...|$|E
40|$|Our {{recently}} introduced JPEG steganographic method called Yet Another Steganographic Scheme (YASS) can resist blind steganalysis by embedding {{data in the}} discrete cosine transform (DCT) domain in randomly chosen image blocks. To maximize the embedding rate for a given image and a specified attack channel, the <b>redundancy</b> <b>factor</b> used by the repeataccumulate (RA) code based error correction framework in YASS is optimally chosen by the encoder. An efficient method is suggested for the decoder to accurately compute this <b>redundancy</b> <b>factor.</b> We also show experimentally which DCT coefficients are better suited for hiding and detection under various attacks. The effectiveness of YASS for robust steganography is demonstrated for certain attacks. Index Terms — randomized hiding, steganography, steganalysis, repeat-accumulate code, redundancy facto...|$|E
50|$|TDRSS {{is similar}} to most other space systems, whereby it is {{composed}} of three segments: the ground, space and user segments. These three segments work in conjunction to accomplish the mission. An emergency or failure in any one segment could have catastrophic impact {{on the rest of}} the system. For this reason all segments have <b>redundancy</b> <b>factored</b> in.|$|R
5000|$|According to ASCE (2010) [...] "Dan M. Frangopol is a preeminent {{authority}} in bridge safety and maintenance management, structural systems reliability, and life-cycle engineering. His contributions have defined {{much of the}} practice around design specifications, management methods, and optimization approaches. From the maintenance of deteriorated structures {{and the development of}} system <b>redundancy</b> <b>factors</b> to assessing the performance of long-span structures, Dr. Frangopol's research has not only saved time and money, but very likely also saved lives." ...|$|R
40|$|Combining {{conditional}} probabilities {{based on}} logratios is considered and {{compared with other}} integration models. Each data set is at first treated separately and merged with considering data source redundancies. Permanence of ratios and tau-model are presented {{as a way of}} merging conditional probabilities and their results are compared to those of logratio model. In logratios model, <b>redundancy</b> <b>factors</b> are iteratively optimized in order to improve the integrated estimate. Measure of goodness is used to quantitatively evaluate the models of integration and logratio model gives the best experimental results in terms of local uncertainty and closeness to true facies...|$|R
40|$|Our {{recently}} introduced JPEG steganographic method called Yet Another Steganographic Scheme (YASS) can resist blind steganalysis by embedding {{data in the}} discrete cosine transform (DCT) domain in randomly chosen image blocks. To maximize the embedding rate for a given image and a specified attack channel, the <b>redundancy</b> <b>factor</b> used by the repeat-accumulate (RA) code based error correction framework in YASS is optimally chosen by the encoder. An efficient method is suggested for the decoder to accurately compute this <b>redundancy</b> <b>factor.</b> We demonstrate the redundancy estimation for the quantization index modulation and matrix embedding based schemes through Sec. 2 - 4. The second part of this technical report (Sec. 5) discusses the steganalysis performance of YASS, using different embedding schemes, such as matrix embedding and quantization index modulation, and after {{using a variety of}} steganalysis features. Here, we shall be discussing the estimation of the RA code <b>redundancy</b> <b>factor</b> for the following 2 types of methods. For each method, the databits are RA-encoded using a suitable <b>redundancy</b> <b>factor</b> and then different embedding techniques are used to embed the code bits in the given image. • QIM-RA: use quantization index modulation (QIM) [1] to embed the RA code bits • ME-RA: use matrix embedding (ME) to embed the RA code bits We present a brief introduction into how matrix embedding operates and then also briefly describe YASS, the randomized block-based hiding framework. Matrix Embedding Example: Consider (7, 3) matrix embedding, in which 3 data bits are embedded in 7 host bits. The idea is to perturb the host bits minimally so that they fall in the coset of a linear code, whose syndrome equals the data bits to be hidden. In particular, we consider the (7, 4) Hamming code with parity check matrix H...|$|E
40|$|The shearlet {{transform}} is {{a recent}} sibling in the family of geometric image representations that provides a traditional multiresolution analysis combined with a multidirectional analysis. In this paper, we present a fast DFT-based analysis and synthesis scheme for the 2 D discrete shearlet transform. Our scheme conforms to the continuous shearlet theory to high extent, provides perfect numerical reconstruction (up to floating point rounding errors) in a non-iterative scheme and is highly suitable for parallel implementation (e. g. FPGA, GPU). We show that our discrete shearlet representation is also a tight frame and the <b>redundancy</b> <b>factor</b> of the transform is around 2. 6, independent {{of the number of}} analysis directions. Experimental denoising results indicate that the transform performs the same or even better than several related multiresolution transforms, while having a significantly lower <b>redundancy</b> <b>factor...</b>|$|E
40|$|Damage {{investigations}} {{from past}} earthquakes such as Northridge and Kobe indicate that severe structural failure occurred {{due to lack}} of redundancy, which has since become a serious concern of both researchers and practitioners. As suggested in ATC 19 and 34, buildings with a small number of lateral resisting components for a given floor area are penalized by an increase in design force to compensate for the lack of redundancy. Recently, such a reliability/redundancy factor is introduced in NEHRP 97 and UBC 97 based largely on engineering judgement. In this paper, two types of building structure, a 5 -story dual system and a 3 - story special moment resisting frame, are investigated. The <b>redundancy</b> <b>factor</b> in NEHRP 97 and a uniform risk <b>redundancy</b> <b>factor</b> based on nonlinear analyses and proper consideration of the uncertainty in the excitation are compared. The shortcomings of the former are pointed out...|$|E
3000|$|In {{order to}} reduce the number of signal values to {{eliminate}} <b>redundancy,</b> twiddle <b>factor</b> transformations are required. The push transformation of the twiddle factors can be described as shown in Fig. 4. We can push a factor of W [...]...|$|R
40|$|This paper {{presents}} {{the participation of}} the IRIT laboratory (University of Toulouse) to the Microblog Track of TREC 2015. This track consists in a real-time filtering task aiming at monitoring a stream of social media posts in accordance to a user's interest profile. In this context, our team proposes three approaches: (a) a novel selective summarization approach based on a decision of selecting/ignoring tweets without the use of external knowledge and relying on novelty and <b>redundancy</b> <b>factors,</b> (b) a processing workflow enabling to index tweets in real-time and enhanced by a notification and digests method guided by diversity and user personalization, and (c) a step by step stream selection method focusing on rapidity, and taking into account tweet similarity as well as several features including content, entities and user-related aspects. For all these approaches, we discuss the obtained results during the experimental evaluation...|$|R
40|$|Abstract. Shrinking feature {{sizes and}} energy levels coupled with high clock rates and {{decreasing}} node capacitance lead {{us into a}} regime where transient errors in logic cannot be ignored. Consequently, several recent {{studies have focused on}} feed-forward spatial redundancy techniques to combat these high transient fault rates. To complement these studies, we analyze fine-grained rollback techniques and show that they can offer lower spatial <b>redundancy</b> <b>factors</b> with no significant impact on system performance for fault rates up to one fault per device per ten million cycles of operation (Pf = 10 − 7) in systems with 1012 susceptible devices. Further, we concretely demonstrate these claims on nanowire-based Programmable Logic Arrays. Despite expensive rollback buffers and general-purpose, conservative analysis, we show the area overhead factor of our technique is roughly an order of magnitude lower than a gate-level feed-forward redundancy scheme. 1...|$|R
40|$|Abstract—This paper {{analyzes}} {{the impact on}} the TCP-Reno congestion control mechanism of a network coding (NC) layer inserted in the TCP/IP stack. A multi-source multi-link model is considered to study the equilibrium and dynamic properties of the TCP-NC protocol with RED as active queue management mechanism. The existence and uniqueness of some network equilibrium is demonstrated and characterized in terms of average throughput, loss rate, and queue length. Global stability is proved in absence of forward delay, and the effects of the NC <b>redundancy</b> <b>factor</b> and of the delay on the local stability of TCP-NC-RED is studied around the equilibrium point. Results provided by the proposed model are compared to those obtained by simulation for N sources sharing a single link. TCP-NC-RED becomes unstable when delay or capacity increases, as TCP-Reno does. Its stability region is characterized {{as a function of the}} <b>redundancy</b> <b>factor.</b> 1 Index Terms- congestion control, network coding, queue management, stability. I...|$|E
40|$|In recent years, {{there has}} been a lot of {{interest}} in multiresolution representations that also perform a multidirectional analysis. These representations often yield very sparse representation for multidimensional data. The shearlet representation, which has been derived within the framework of composite wavelets, can be extended quite trivially from 2 D to 3 D. However, the extension to 3 D is not unique and consequently there are different implementations possible for the discrete transform. In this paper, we investigate the properties of two relevant designs having different 3 D frequency tilings. We show that the first design has a <b>redundancy</b> <b>factor</b> of around 7, while in the second design the transform can attain a <b>redundancy</b> <b>factor</b> around 3. 5, independent of the number of analysis directions. Due to the low redundancy, the 3 D shearlet transform becomes a viable alternative to the 3 D curvelet transform. Experimental results are provided to support these findings...|$|E
40|$|Abstract: Precision angular {{scales are}} {{considered}} from common point of view, {{and principles of}} their construction are formulated. Methods of mutual calibration of circular scales are developed to meet these principles {{taking into account the}} <b>redundancy</b> <b>factor.</b> Multidimensional classifica-tion of the methods is proposed. The family of designs is constructed, and relations of procedure parameters of a scale carrier calibration with required accuracy of the procedure results is established...|$|E
40|$|In {{almost all}} codes of {{practice}} for seismic resistant design of buildings, a behavior factor is used to reduce design base shear. The behavior factor is affected by several parameters such as ductility, overstrength and <b>redundancy</b> reduction <b>factors.</b> There are two common approaches to assess the effects of redundancy {{on the strength of}} a structural system, which are as follows: static pushover analysis and incremental dynamic analysis. The two indices: redundancy strength coefficient and redundancy variation coefficient have been introduced to measure these effects. Simplified methods are developed and presented to calculate these parameters. In this study, the redundancy strength and the redundancy variation parameters are evaluated for the reinforced concrete plane frames with different number of stories, bays and ductility capacities. The investigations indicate that these two parameters are mainly the results of <b>redundancy</b> reduction <b>factors...</b>|$|R
40|$|Shrinking feature {{sizes and}} energy levels coupled with high clock rates and {{decreasing}} node capacitance lead {{us into a}} regime where transient errors in logic cannot be ignored. Consequently, several recent {{studies have focused on}} feed-forward spatial redundancy techniques to combat these high transient fault rates. To complement these studies, we analyze fine-grained rollback techniques and show that they can offer lower spatial <b>redundancy</b> <b>factors</b> with no significant impact on system performance for fault rates up to one fault per device per ten million cycles of operation (Pƒ = 10 - 7) in systems with 1012 susceptible devices. Further, we concretely demonstrate these claims on nanowire-based programmable logic arrays. Despite expensive rollback buffers and general-purpose, conservative analysis, we show the area overhead factor of our technique is roughly an order of magnitude lower than a gate level feed-forward redundancy scheme...|$|R
40|$|International audienceThis paper {{presents}} {{the participation of}} the IRIT laboratory (University of Toulouse) to the Microblog Track of TREC 2015. This track consists in a real-time filtering task aiming at monitoring a stream of social media posts in accordance to a user's interest profile. In this context, our team proposes three approaches: (a) a novel selective summarization approach based on a decision of selecting/ignoring tweets without the use of external knowledge and relying on novelty and <b>redundancy</b> <b>factors,</b> (b) a processing workflow enabling to index tweets in real-time and enhanced by a notification and digests method guided by diversity and user personalization, and (c) a step by step stream selection method focusing on rapidity, and taking into account tweet similarity as well as several features including content, entities and user-related aspects. For all these approaches, we discuss the obtained results during the experimental evaluation...|$|R
40|$|In 1992, Bamberger and Smith {{proposed}} the directional filter bank (DFB) for an efficient directional decomposition of two-dimensional (2 -D) signals. Due to the nonseparable {{nature of the}} system, extending the DFB to higher dimensions while still retaining its attractive features is a challenging and previously unsolved problem. This paper proposes a new family of filter banks, named 3 DDFB, that can achieve the directional decomposition of 3 -D signals with a simple and efficient tree-structured construction. The ideal passbands of the proposed 3 DDFB are rectangular-based pyramids radiating out from the origin at different orientations and tiling the whole frequency space. The proposed 3 DDFB achieves perfect reconstruction. Moreover, the angular resolution of the proposed 3 DDFB can be iteratively refined by invoking more levels of decomposition through a simple expansion rule. We also introduce a 3 -D directional multiresolution decomposition, named the surfacelet transform, by combining the proposed 3 DDFB with the Laplacian pyramid. The 3 DDFB has a <b>redundancy</b> <b>factor</b> of 3 and the surfacelet transform has a <b>redundancy</b> <b>factor</b> up to 24 / 7...|$|E
40|$|Abstract. High {{availability}} in peer-to-peer DHTs requires data redundancy. This paper takes user download behavior {{into account}} to evaluate redundancy schemes in data storage and share systems. Furthermore, we propose a hybrid redundancy scheme of replication and erasure coding. Experiment {{results show that}} replication scheme saves more bandwidth than erasure coding scheme, although it requires more storage space, when average node availability is higher than 48 %. Our hybrid scheme saves more maintenance bandwidth with acceptable <b>redundancy</b> <b>factor...</b>|$|E
40|$|A {{proof is}} {{provided}} that a logarithmic <b>redundancy</b> <b>factor</b> {{is necessary for}} the reliable computation of the parity function by means of a network with noisy gates. This result was first stated by R. L. Dobrushin and S. I. Ortyukov (1977). However, the authors believe that the analysis given by Dobrushin and Ortyukov is not entirely correct. The authors establish the result by following the same steps and by replacing the questionable part of their analysis with entirely new arguments...|$|E
40|$|Fault Tolerant Sublithographic Design with Rollback Recovery Shrinking feature {{sizes and}} energy levels coupled with high clock rates and {{decreasing}} node capacitance lead {{us into a}} regime where transient errors in logic cannot be ignored. Consequently, several recent {{studies have focused on}} feed-forward spatial redundancy techniques to combat these high transient fault rates. To complement these studies, we analyze fine-grained rollback techniques and show that they can offer lower spatial <b>redundancy</b> <b>factors</b> with no significant impact on system performance for fault rates up to one fault per device per ten million cycles of operation (Pƒ = 10 - 7) in systems with 1012 susceptible devices. Further, we concretely demonstrate these claims on nanowire-based programmable logic arrays. Despite expensive rollback buffers and general-purpose, conservative analysis, we show the area overhead factor of our technique is roughly an order of magnitude lower than a gate level feed-forward redundancy scheme...|$|R
40|$|In the {{conventional}} design and analysis methods affecting parameters loads, materials' strength, etc) are not set as probable variables. Safety {{factors in the}} current Codes and Standards are usually obtained {{on the basis of}} judgment and experience, which may be improper or uneconomical. In technical literature, a method based on nonlinear static analysis is suggested to set Reliability Index on strength of structural systems. In this paper, a method based on Nonlinear Dynamic analysis with rising acceleration (or Incremental Dynamic Analysis) is introduced, the results of which are compared with those of the previous (Static Pushover Analysis) method and two concepts namely Redundancy Strength and Redundancy Variations are proposed as an index to these impacts. The <b>Redundancy</b> Variation <b>Factor</b> and <b>Redundancy</b> Strength <b>Factor</b> indices for reinforced concrete frames with varying number of bays and stories and different ductility potentials are computed and ultimately, Reliability Index is determined using these two indices...|$|R
50|$|Blowout preventers come in {{a variety}} of styles, sizes and {{pressure}} ratings. Several individual units serving various functions are combined to compose a blowout preventer stack. Multiple blowout preventers of the same type are frequently provided for <b>redundancy,</b> an important <b>factor</b> in the effectiveness of fail-safe devices.|$|R
40|$|Abstract — This paper {{addresses}} the functional robustness and fault-tolerance capability of very-deep submicron CMOS and single-electron transistor (SET) circuits. A four-layer circuit architecture is proposed, {{and a set}} of guidelines is identified for the design of very highdensity digital systems using inherently unreliable and errorprone devices. The proposed architecture is based on the principle of graceful degradation of circuit performance allowing recovery of information, where classical circuits would fail. The integration of the proposed architecture is shown as a regular and compact PLA-style design, allowing the adaptability of the <b>redundancy</b> <b>factor...</b>|$|E
40|$|We {{determine}} the information {{capacity of the}} linear, time-varying communications channel with additive white Gaussian noise for transmission signals with support approximately restricted to closed regions {{of the time and}} frequency domains. We address the two-part problem of first, constructing appropriate transmission functions, and second, determining the mutual information. Our approach provides a signaling set that is adaptive to the time and frequency stability of the channel, and we use this set to estimate the channel’s information capacity. In the limiting regime, this approach recovers the time-invariant capacity up to a <b>redundancy</b> <b>factor...</b>|$|E
40|$|We {{introduce}} a new semi-orthogonal complex wavelet basis of L 2 (R 2). The basis functions are associated to the complex gradient-Laplace operator, which plays {{a central role in}} image processing. We define analytically a single-generator wavelet that is shifted on the coset positions of the subsampling ma-trix. Next, we propose the “wavelet Marr pyramid ” for an ex-tension of the new basis that achieves near shift-invariance and steerability (using a Gaussian-like smoothing kernel), for a mild <b>redundancy</b> <b>factor</b> only. This new wavelet pyramid de-composition closely mimicks the basic operations of Marr’s framework for early vision. The pyramid is implemented by a fast filterbank algorithm using the FFT...|$|E
40|$|Dwarf is {{a highly}} {{compressed}} structure for computing, storing, and querying data cubes. Dwarf identifies prefix and suffix structural <b>redundancies</b> and <b>factors</b> them out by coalescing their store. Prefix redundancy is high on dense areas of cubes but suffix redundancy is significantly higher for sparse areas. Putting the two together fuses the exponential sizes of high dimensional full cubes into a dramatically condensed data structure. The elimination of suffix redundancy has an equally dramatic reduction in the computation of the cube because recomputation of the redundant suffixes is avoided. This effect is multiplied {{in the presence of}} correlation amongst attributes in the cube...|$|R
30|$|The <b>redundancy</b> of <b>factors</b> and receptors {{involved}} in migration of {{cells in the}} same type of cancer poses an important question: Is it reasonable to target particular pro-migratory axes when several other pro-metastatic axes exist for a given tumor cell? Moreover, in most of the published reports demonstrating migration, “supraphysiological concentrations” of pro-metastatic factors were employed at doses not encountered in normal tissues and that may not be relevant to clinical situations. In addition, the responsiveness of primary tumor cells may change over time as a malignancy progresses and could be affected by several additional clinical problems that emerge in patients, such as infections or organ failure.|$|R
40|$|Abstract—The {{predicted}} {{deterioration of}} the component quality, due to the shrinking of components to near atomic scale, threatens the effectiveness and the applicability of conventional digital system design methodologies in the giga and tera-scale integration era. Three aggression sources support the previous statement: i) the increasing device parameter variability induced by the extreme reduction of the critical feature sizes and the intrinsic nature of new devices; ii) the intense and practically unpredictable internal noise; and iii) {{the large number of}} physical defects. This paper provides a detailed analysis of the noise and parameter variations effects on a basic processing gate. We derive formulas to calculate the expected value and the variance of the gate output under the effects of noise, threshold, and gain fluctuations. Using these expressions we also derive a cost-performance equation that evaluates the gate error probability from its parameter variability, noise, power, and area or redundance. The proposed model is generic for any computing gate in the current digital paradigm. To illustrate the model applicability we calculate the error probability curve for a 90 nm CMOS inverter showing that for this technology the noise is the main limiting factor. A tradeoff analysis of area-power-redundancy-reliability for nanogates is performed indicating that the use of nanoscale individual elements for fabricating gates in deep-nanoscale technologies may not be a viable option. The results clearly suggest that the use of redundant structures is necessary and that averaging structures with mid-high <b>redundancy</b> <b>factors</b> may constitute a reasonable solution for building reliable nanoscale gates. Index Terms—Fault tolerance, logic design, nanotechnology, nonlinear functions. I...|$|R
