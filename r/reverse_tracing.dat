7|59|Public
40|$|In mobile ad hoc-hoc Networks (MANETs), the {{important}} {{concern is the}} security as well as establishment of verbal exchange amongst nodes is that nodes have got {{to work at the}} side of each different. Averting or sensing malicious nodes initiation grayhole or collaborative black hole attacks is the fundamental undertaking. Cooperative bait detection approach mixes the benefits of each proactive and reactive defense manners. Right here it makes use of the method of transposition for implementing safety and the CBDA procedure outfits a <b>reverse</b> <b>tracing</b> procedure to aid achieve the certain goal. The demo in the existence of malicious-node assaults, the CBDA beats the DSR, chosen as performance metrics in terms of throughput, delay and energy. Within the transposition method we use the key which is the ascii worth of the personality which is encrypted at sender aspect and decrypted at receiver...|$|E
40|$|International audience“Earthquake chains” are {{clusters}} of moderate-size earthquakes which extend over large distances and are formed by statistically rare pairs {{of events that}} are close {{in space and time}} (“neighbors”). Earthquake chains are supposed to be precursors of large earthquakes with lead times of a few months. Here we substantiate this hypothesis by mass testing it using a random earthquake catalog. Also, we study stability under variation of parameters and some properties of the chains. We found two invariant parameters: they characterize the spatial and energy scales of earthquake correlation. Both parameters of the chains show good correlation with the magnitudes of the earthquakes they precede. Earthquake chains are known as the first stage of the earthquake prediction algorithm <b>reverse</b> <b>tracing</b> of precursors (RTP) now tested in forward prediction. A discussion of the complete RTP algorithm is outside the scope of this paper, but the results presented here are important to substantiate the RTP approach...|$|E
40|$|International audienceShort-term {{earthquake}} prediction, {{months in}} advance, is an elusive goal of earth sciences, {{of great importance}} for fundamental science and for disaster preparedness. Here, we describe a methodology for short-term prediction named RTP (<b>Reverse</b> <b>Tracing</b> of Precursors). Using this methodology the San Simeon earthquake in Central California (magnitude 6. 5, Dec. 22, 2003) and the Tokachi-Oki earthquake in Northern Japan (magnitude 8. 1, Sept. 25, 2003) were predicted 6 and 7 months in advance, respectively. The physical basis of RTP {{can be summed up}} as follows: An earthquake is generated by two interacting processes in a fault network: an accumulation of energy that the earthquake will release and a rise of instability triggering this release. Energy is carried by the stress field, instability is carried by the difference between the stress and strength fields. Both processes can be detected and characterized by “premonitory” patterns of seismicity or other relevant fields. Here, we consider an ensemble of premonitory seismicity patterns. RTP methodology is able to reconstruct these patterns by tracing their sequence backwards in time. The principles of RTP are not specific to earthquakes and may be applicable to critical transitions in a wide class of hierarchical non-linear systems...|$|E
40|$|Methods {{based on}} the {{stochastic}} apparatus technical diagnostics are put forward to solve problems concerning determination of the structural elements technical condition. Diagnosis is performed using probabilistic methods of recognition of technical conditions of complex technical systems. The diagnosis is conducted {{with the help of}} probabilistic methods of the complex engineering systems condition recognition {{based on the}} Bayesian analysis. The aforementioned approach and information theory methods are applied to run the multilevel diagnostics of elements and systems of floor slabs in old urban buildings. Multilevel diagnostics was done in the concepts of information entropy. During the analysis of the results of forward and <b>reverse</b> <b>traces</b> on the hierarchical diagnostics structure the next conclusion was made. The forward trace allows to determine the technical condition and category for the each element of each level in the hierarchical structure and the <b>reverse</b> <b>trace</b> gives a possibility to evaluate the contribution of each element condition to the information about the whole building condition. The last point can be an argumentative basis for the account of physical depreciation of building structures...|$|R
40|$|Magnetization {{processes}} in a sintered Nd-Fe-B permanent magnet (NEOMAX- 35) were examined {{on a small}} scale using a Hall-effect microprobe with an active area 75 μm on a side. Probes were made by evaporating bismuth through a stencil mask onto glass slides. Experiments were performed by placing a probe onto the polished pole face of a Nd-Fe-B magnet and inserting the probe-magnet assembly into an electromagnet. Barkhausen steps, indicating rapid domain wall motion, were observed (superimposed upon the blank probe signal) in the demagnetization of a fully magnetized magnet. Magnetization traces for a thermally demagnetized Nd-Fe-B magnet did not exhibit measurable Barkhausen steps until a field of approximately 1. 2 T was applied. The following observations were made for two thermally demagnetized samples which were cycled through minor hysteresis loops (maximum applied field of approximately 2 T) : (1) virgin magnetization traces did not contain measurable Barkhausen steps, however all other forward and <b>reverse</b> magnetization <b>traces</b> did; (2) the initial <b>reverse</b> magnetization <b>trace</b> exhibited more and larger Barkhausen steps than subsequent traces; and (3) some Barkhausen steps were repeatable, that is, occurring at approximately the same field on each subsequent forward or <b>reverse</b> <b>trace.</b> Hall voltage signals were on the order of millivolts for probe currents of 10 mA...|$|R
40|$|Several {{alternative}} methods for solving the group height equation are presented. Three {{of these are}} now in operation at Ames Research Center and use data contained in a single ionogram trace. From the data an electron density profile N(h) is computed. If the ionogram also exhibits other <b>traces,</b> <b>reverse</b> ionogram <b>traces</b> are computed, using the N(h) profile, for comparison with the redundant data. When agreement is poor, the initial data trace is reinterpreted, another N(h) profile computed, and the <b>reverse</b> <b>traces</b> generated once again. This process is repeated until a desired degree of consistency is achieved. To reduce the necessity for human intervention and eliminate decision making required {{in conjunction with the}} preceding methods, a method is proposed that accepts as input, all data from a single ionogram. In general, no electron density function will satisfy these data exactly, but a best N(h) profile can be computed. Finally, a method is described that eliminates the need to assume that the ionosphere is spherically stratified. Horizontal gradients in electron density are detected and accounted for by processing several ionograms from the same satellite pass simultaneously. This idea is derived as an extension of one of the basic methods...|$|R
30|$|After the March 11, 2011, Tohoku earthquake, {{several studies}} have been {{published}} relating to the seismicity before, and after, the mainshock. Ishikawa (see, [URL] provided a quick analysis of regional and global seismicity before, and after, the Tohoku earthquake. Seismicity was systematically outlined by Hirose et al. (2011). Katsumata (2011) discussed the long-term seismic quiescence which started some 20 years before the earthquake. The Tohoku earthquake also raises an unprecedented question regarding the along-dip segmentation versus the along-strike segmentation (Yomogida et al., 2011). According {{to the study of}} the rupture process (see, Lay and Kanamori, 2011, for a concise review), the earthquake rupture starts from the deeper part radiating high-frequency-predominant seismic waves, and continues by the shallower part radiating low-frequency-predominant seismic waves and generating tsunami-generic displacements. This along-dip segmentation characteristic is different from previous great earthquakes, such as the Sumatra-Andaman earthquake in 2004. In this study, therefore, we have investigated the cumulative moment release within several specific regions, as shown in Fig. 1. With regard to methodology, this idea is somehow similar to the <b>Reverse</b> <b>Tracing</b> of Precursors (RTP, see: Keilis-Borok et al., 2004), with the difference that the RTP considers long-term anomalies within the areas of short-term precursory anomalies, but the present approach investigates AMR within the specific areas related to the earthquake preparation and rupture processes.|$|E
40|$|In 2003, the <b>Reverse</b> <b>Tracing</b> of Precursors (RTP) {{algorithm}} {{attracted the}} attention of seismologists and international news agencies when researchers claimed two successful predictions of large earthquakes. These researchers had begun applying RTP to seismicity in Japan, California, the eastern Mediterranean and Italy; they have since applied it to seismicity in the northern Pacific, Oregon and Nevada. RTP is a pattern recognition algorithm that uses earthquake catalogue data to declare alarms, and these alarms indicate that RTP expects a moderate to large earthquake in the following months. The spatial extent of alarms is highly variable and each alarm typically lasts 9 months, although the algorithm may extend alarms in time and space. We examined the record of alarms and outcomes since the prospective application of RTP began, and in this paper we report on the performance of RTP to date. To analyse these predictions, we used a recently developed approach based on a gambling score, and we used a simple reference model to estimate the prior probability of target earthquakes for each alarm. Formally, we believe that RTP investigators did not rigorously specify the first two ‘successful' predictions in advance of the relevant earthquakes; because this issue is contentious, we consider analyses with and without these alarms. When we included contentious alarms, RTP predictions demonstrate statistically significant skill. Under a stricter interpretation, the predictions are marginally unsuccessfu...|$|E
40|$|In {{world wide}} web, a {{document}} is usually {{made up of}} multiple pages, each one of which has a unique URL address and links to each other by hyperlink pointers. Related documents are also connected together through hyperlinks. Thus, {{it is important for}} web information discovery to know the referral parent(s) of a given web page. However, {{due to the lack of}} back-pointers, such information is usually not available to web surfers. This reduces the effectiveness of web surfing and information discovery significantly. Major search engines such as AltaVista and HotBot try to solve this problem from the server side by maintaining the hyperlink structure of each web site registered with them. Although effective, the drawbacks of this approach are the huge effort to store and maintain this link database and the limitation to their registered members only. In this paper, we propose an alternative mechanism to locate the referral parent(s) for a given fragment of a web document (in terms of an URL address) from the client side. The basic idea is to explore the hierarchical hyperlink structure of a web document fragment from its storage path directory information that is embedded in its URL. Two mechanisms were proposed: exhaustibility first search (EFS) and generaliz ation first search (GFS). Results showed that through direct mapping of the storage hierarchy path to URL address and then performing <b>reverse</b> <b>tracing</b> along the hyperlink structure, the chance to discover a referral parent ranged from 41 % to 51 %. Compared to EFS, GFS was found to reduce the average search space from 26 pages to 4 pages. This result is important to web information discovery because no link database needs to be maintained and the overhead of finding referral page is very low...|$|E
40|$|Trace {{distance}} (between two quantum states) can {{be viewed}} as quantum generalization of statistical difference (between two probability distributions). On input a pair of quantum states (represented by quantum circuits), how to construct another pair, such that their trace distance is large (resp. small) if the original trace distance is small (resp. large) ? That is, how to <b>reverse</b> <b>trace</b> distance? This problem originally arose in the study of statistical zero-knowledge quantum interactive proof. We discover a surprisingly simple way to do this job. In particular, our construction has two interesting features: first, entanglement plays a key role underlying our construction; second, strictly speaking, our construction is non-black-box. © 2012 Springer-Verlag. State Key Laboratory of Computer Science; Chinese Academy of Sciences, Institute of Software; Chinese Academy of SciencesTrace distance (between two quantum states) {{can be viewed}} as quantum generalization of statistical difference (between two probability distributions). On input a pair of quantum states (represented by quantum circuits), how to construct another pair, such that their trace distance is large (resp. small) if the original trace distance is small (resp. large) ? That is, how to <b>reverse</b> <b>trace</b> distance? This problem originally arose in the study of statistical zero-knowledge quantum interactive proof. We discover a surprisingly simple way to do this job. In particular, our construction has two interesting features: first, entanglement plays a key role underlying our construction; second, strictly speaking, our construction is non-black-box. © 2012 Springer-Verlag...|$|R
50|$|Days later a damning {{report from}} Britain's Information Commissioner {{found that the}} Irish Daily Mail was {{involved}} in the illegal trade of obtaining personal information on driving licences, criminal records, vehicle registration searches, <b>reverse</b> telephone <b>traces</b> and mobile-phone conversations.|$|R
2500|$|<b>Reversing</b> the <b>trace</b> {{again would}} restore the {{original}} EFE. The trace-reversed form {{may be more}} convenient in some cases (for example, when one is interested in weak-field limit and can replace [...] in the expression on the right with the Minkowski metric without significant loss of accuracy).|$|R
40|$|UnrestrictedEarthquake {{prediction}} {{is one of}} the most important unsolved problems in the geosciences. Over the past decade, earthquake prediction research has been revitalized, and predictability experiments are currently active worldwide. In considering these experiments, a number of issues related to prediction evaluation are vital: a detailed experiment specification, the measure of success to be used, and a choice of appropriate reference model(s). Here, we address each of these, with an emphasis on testing prospective earthquake predictions.; We consider a general class of earthquake forecasts for which the forecast format allows a binary interpretation; that is, for any given interval of space and time, we can infer whether or not an earthquake of a given size is expected. This generalization allows us to test deterministic and probabilistic forecasts and compare the results; furthermore, the tests are easily understood because they are essentially the sum of many yes/no questions. As an introduction to binary performance measures and their wide applicability, we considered <b>Reverse</b> <b>Tracing</b> of Precursors (RTP), a recent earthquake prediction algorithm intended to forecast damaging earthquakes. We introduce and analyze several methods for measuring predictive performance but concede that the RTP experiment results are likely unstable due to the small number of earthquakes occurringto date.; In the context of an experiment with three 10 year seismicity forecasts [...] Relative Intensity, Pattern Informatics, and National Seismic Hazard Map [...] we introduce the area skill score, a measure of success derived from the Molchan diagram. Using this experiment and applying approaches from statistical hypothesis testing, we illustrate the importance of choosing an appropriate reference model, and show that added model complexity does not necessarily yield a significant improvement in predictive skill.; Having demonstrated the use of the area skill score as a performance metric, we explore its statistical properties and the related computational procedures in some detail. Based on this work and the previous experiment results, we used the area skill score to explore the evolution of regional seismicity and optimize simple forecast models...|$|E
50|$|The Water Wheel: The {{process of}} {{enlightenment}} is a <b>reverse</b> process of <b>tracing</b> {{our way back}} to the stages of creation and beyond.|$|R
40|$|The {{use of a}} ray file {{to model}} the optical {{characteristics}} of a light source is a well-known and popular method to achieve accurate results when simulating luminous intensity distributions of luminaires, especially if the source is interacting with optical components at a close distance. However, lighting industry {{becomes more and more}} interested in the spatial luminance distribution of the luminaire itself. Luminance maps offer a tool to predict the degree of discomfort glare early in the design process, especially when developing fixtures using small and intense LED light sources. The generation of luminance maps is commonly based on the <b>reverse</b> ray <b>tracing</b> technique, requiring one or more surfaces to be defined as light sources. However, ray files can not be considered as surface sources, but as a collection of ray data that model the near field of a light source. Despite the fact that ray files are constructed from experimental data they do not explicitly contain the geometry of the light source. This excludes the use of <b>reverse</b> ray <b>tracing.</b> For this reason the implementation of brute force forward ray tracing to obtain luminance maps was investigated. To be able to compare the results of both techniques an inhomogeneous surface source was defined. Luminance maps were then generated using both the brute force ray tracing approach and the conventional <b>reverse</b> ray <b>tracing</b> approach. A good agreement was obtained. A reduction in simulation time was achieved by parallel ray tracing computation and digital enhancement techniques. status: publishe...|$|R
40|$|We {{describe}} URCHIN, a <b>reverse</b> ray <b>tracing</b> {{radiative transfer}} scheme optimised to model self-shielding from the post-reionisation ultraviolet (UV) background in cosmological simulations. The <b>reverse</b> ray <b>tracing</b> strategy provides several benefits over {{forward ray tracing}} codes including: (1) the preservation of adaptive density field resolution (2) completely uniform sampling of gas elements by rays; (3) the preservation of galilean invariance; (4) the ability to sample the UV background spectrum with hundreds of frequency bins; and (5) exact preservation of the input UV background spectrum and amplitude in optically thin gas. The implementation described here focuses on Smoothed Particle Hydrodynamics (SPH). However, the method {{can be applied to}} any density field representation in which resolution elements admit ray intersection tests and can be associated with optical depths. We characterise the errors in our implementation in stages beginning with comparison to known analytic solutions and ending with a realistic model of the z = 3 cosmological UV background incident onto a suite of spherically symmetric models of gaseous galactic halos. Comment: 17 pages, updated to match version published in MNRAS; 2013 MNRAS. tmp. 1731...|$|R
50|$|In a {{crossover}} {{with the}} early Superman mythos, Lex Luthor helps the Martians, although he eventually betrays them. Scarlet <b>Traces</b> <b>reverses</b> this, with a Martian survivor helping the British prepare for a counter-invasion of Mars.|$|R
40|$|The {{refraction}} convolution section (RCS) is {{a simple}} and efficient method for full trace processing of shallow seismic refraction data. It facilitates improved interpretation of shallow seismic refraction data through the convenient use of amplitudes as well as traveltimes. The RCS is generated by the convolution of forward and reverse shot records. The convolution operation effectively adds the first arrival traveltimes of each pair of forward and <b>reverse</b> <b>traces</b> and produces {{a measure of the}} depth to the refracting interface in units of time which is equivalent to the time-depth function of the generalized reciprocal method (GRM). The convolution operation also multiplies the amplitudes of first arrival signals. This operation compensates for the large effects of geometric spreading to a very good first approximation, with the result that the convolved amplitude is essentially proportional to the square of the head coefficient. The head coefficient is approximately proportional to the ratio of the specific acoustic impedances in the upper layer and in the refractor, where there is a reasonable contrast between the specific acoustic impedances in the layers. The RCS can also include a separation between each pair of forward and <b>reverse</b> <b>traces</b> in order to accommodate the offset distance {{in a manner similar to}} the XY spacing of the GRM. Lateral variations in the near-surface soil layers can effect amplitudes thereby causing 'amplitude statics'. Increases in the thickness of the surface soil layer correlate with increases in refraction amplitudes. These increases are adequately described and corrected with the transmission coefficients of the Zoeppritz equations. The minimum amplitudes, rather than an average, should be used where it is not possible to map the near surface layers. The use of amplitudes with 3 D data effectively improves the spatial resolution by almost an order of magnitude. Amplitudes provide a measure of refractor wavespeeds at each detector, whereas the analysis of traveltimes provides a measure over several detectors, commonly a minimum of six. The ratio of amplitudes obtained with different shot azimuths provides a detailed qualitative measure of azimuthal anisotropy. Dip filtering of the RCS removes 'cross-convolution' artifacts and provides a convenient approach to the study of later events. The RCS facilitates the stacking of refraction data in a manner similar to the CMP methods of reflection seismology. It can improve signal-to-noise ratios...|$|R
40|$|AbstractRecently Tsallis {{relative}} operator entropy Tp(A∣B) and Tsallis {{relative entropy}} Dp(A∥B) are discussed by Furuichi–Yanagi–Kuriyama. We shall show two reverse inequalities involving Tsallis relative operator entropy Tp(A∣B) via generalized Kantorovich constant K(p). As some applications of two reverse inequalities, we shall show two <b>trace</b> <b>reverse</b> inequalities involving −Tr[Tp(A∣B) ] and Dp(A∥B) {{and also a}} known <b>reverse</b> <b>trace</b> inequality involving the relative operator entropy S^(A|B) by Fujii–Kamei and the Umegaki relative entropy S(A,B) is shown as a simple corollary. We show the following result: Let A and B be strictly positive operators on a Hilbert space H such that M 1 I⩾A⩾m 1 I> 0 and M 2 I⩾B⩾m 2 I> 0. Put m=m 2 M 1, M=M 2 m 1, h=Mm=M 1 M 2 m 1 m 2 > 1 and p∈(0, 1]. Let Φ be normalized positive linear map on B(H). Then the following inequalities hold:(i) 1 -K(p) pΦ(A) ♯pΦ(B) +Φ(Tp(A|B)) ⩾Tp(Φ(A) |Φ(B)) ⩾Φ(Tp(A|B)) and (ii) F(p) Φ(A) +Φ(Tp(A|B)) ⩾Tp(Φ(A) |Φ(B)) ⩾Φ(Tp(A|B)),where K(p) is the generalized Kantorovich constant defined byK(p) =(hp-h) (p- 1) (h- 1) (p- 1) p(hp- 1) (hp-h) pand K(p) ∈(0, 1] and F(p) =mpphp-hh- 11 -K(p) 1 p- 1 ⩾ 0. In addition, let A and B be strictly positive definite matrices, (iii) 1 -K(p) p(Tr[A]) 1 -p(Tr[B]) p+Dp(A‖B) ⩾-Tr[Tp(A|B) ]⩾Dp(A‖B) and (iv) F(p) Tr[A]+Dp(A‖B) ⩾-Tr[Tp(A|B) ]⩾Dp(A‖B). In particular, both (iii) and (iv) yield the following known result:logS(1) Tr[A]+S(A,B) ⩾-Tr[S^(A|B) ]⩾S(A,B),where S(1) =h 1 h- 1 elogh 1 h- 1 {{is said to be}} the Specht ratio and S(1) > 1...|$|R
40|$|Atmospheric acoustic-gravity waves {{associated}} with severe thunderstorms, tornadoes, typhoons (hurricanes) and tsunamis {{can be studied}} through the coupling between the ionosphere and the troposphere. <b>Reverse</b> ray <b>tracing</b> computations of acoustic-gravity waves observed by an ionospheric Doppler sounder array show that wave sources are in the nearby storm systems and that the waves are excited prior to the storms. Results show that ionospheric observations, together with satellite observations, {{can contribute to the}} understanding of the dynamical behavior of typhoons, severe storms and tsunamis...|$|R
5000|$|It is a {{mathematical}} {{fact that the}} Einstein tensor vanishes {{if and only if}} the Ricci tensor vanishes. This follows from the fact that these two second rank tensors stand in a kind of dual relationship; they are the <b>trace</b> <b>reverse</b> of each other: ...|$|R
5000|$|In {{computer}} graphics, relief mapping is a {{texture mapping}} technique used {{to render the}} surface details of three-dimensional objects accurately and efficiently. It can produce accurate depictions of self-occlusion, self-shadowing, and parallax. [...] It {{is a form of}} short-distance raytrace done in a pixel shader. Relief mapping is highly comparable in both function and approach to another displacement texture mapping technique, Parallax occlusion mapping, considering that they both rely on raytraces, though the two are {{not to be confused with}} each other, as parallax occlusion mapping uses <b>reverse</b> heightmap <b>tracing.</b>|$|R
5000|$|In general relativity, the {{quadrupole}} formula describes rate {{at which}} gravitational waves are emitted from a system of masses based on the change of the (mass) quadrupole moment. The formula readswhere [...] is the (spatial part of) the <b>trace</b> <b>reversed</b> perturbation of the metric (i.e. the gravitational wave), and [...] is the mass quadrupole moment.|$|R
40|$|We {{conducted}} {{gravity wave}} ray-tracing experiments within an atmospheric region centered near the ARCLITE lidar system at Sondrestrom, Greenland (67 N, 310 deg E), {{in efforts to}} understand lidar observations of both upper stratospheric gravity wave activity and mesospheric clouds during August 1996 and the summer of 2001. The ray model was used to trace gravity waves through realistic three-dimensional daily-varying background atmospheres in the region, based on forecasts and analyses in the troposphere and stratosphere and climatologies higher up. <b>Reverse</b> ray <b>tracing</b> based on upper stratospheric lidar observations at Sondrestrom was also {{used to try to}} objectively identify wave source regions in the troposphere. A source spectrum specified by <b>reverse</b> ray <b>tracing</b> experiments in early August 1996 (when atmospheric flow patterns produced enhanced transmission of waves into the upper stratosphere) yielded model results throughout the remainder of August 1996 that agreed best with the lidar observations. The model also simulated increased vertical group propagation of waves between 40 km and 80 km due to intensifying mean easterlies, which allowed many of the gravity waves observed at 40 km over Sondrestrom to propagate quasi-vertically from 40 - 80 km and then interact with any mesospheric clouds at 80 km near Sondrestrom, supporting earlier experimentally-inferred correlations between upper stratospheric gravity wave activity and mesospheric cloud backscatter from Sondrestrom lidar observations. A pilot experiment of real-time runs with the model in 2001 using weather forecast data as a low-level background produced less agreement with lidar observations. We believe this is due to limitations in our specified tropospheric source spectrum, the use of climatological winds and temperatures in the upper stratosphere and mesosphere, and missing lidar data from important time periods...|$|R
40|$|A {{scanning}} radiometer deployed at Davis Station, Antarctica (68 °S, 78 °E), has been recording infrared (1. 10 – 1. 65 μm) {{images of a}} small region (24 km × 24 km) of the zenith night sky once per minute each austral winter night since February 1999. These images have been processed to extract information on the passage of gravity waves (GWs) (horizontal wavelength, λh > 15 km) and ripples (λh ≤ 15 km) over the observing station. Phase speeds, periods, horizontal wavelengths, and predominant propagation directions have been deduced. Observed speeds {{were found to be}} highly correlated with horizontal wavelengths as has been reported in previous studies. <b>Reverse</b> ray <b>tracing</b> of the detected GWs only enabled us to identify four distinct groups. On average, only 15...|$|R
40|$|A {{continuous}} wave-spectrum high-frequency radiowave Doppler sounder array {{was used}} to observe upper-atmospheric disturbances during an extreme tornado outbreak. The observations indicated that gravity waves with two harmonic wave periods were detected at the F-region ionospheric height. Using a group ray path computational technique, the observed gravity waves were traced in order to locate potential sources. The signals were apparently excited 1 - 3 hours before tornado touchdown. <b>Reverse</b> ray <b>tracing</b> indicated that the wave source was located at the aurora zone with a Kp index of 6 {{at the time of}} wave excitation. The summation of the 24 -hour Kp index for the day was 36. The results agree with existing theories (Testud, 1970; Titheridge, 1971; Kato, 1976) for the excitation of large-scale traveling ionospheric disturbances associated with geomagnetic activity in the aurora zone...|$|R
40|$|One of the {{problems}} appearing in the virtual reality (VR) application is the image distortion and blending correction for curved screens with single or multiple projectors. There are ways {{to solve this problem}} via a special circuit implementation within the image projectors or via special image correction PC based boxes. In this study we proposed own algorithm for the image correction based on the back ray tracing approach. The algorithm is using <b>reverse</b> ray <b>tracing</b> and it was tested on the Cybersphere(1) setup. We propose the software implementation of the algorithm which allows using it for any programs not limited by a certain technology such as OpenGL for instance as in other image correction algorithms. The algorithm can be used for distributed image rendering and projection such as Chromium based sets. ...|$|R
40|$|The paper {{investigates the}} {{hypothesis}} that financial development is the leading channel through which the foreign direct investment (FDI) positive spillovers accelerate growth rate. A simultaneous equations model (SEM) was specified using quarterly data within period (1993 - 2005). The estimated model evidenced a unidirectional causality from economic growth towards FDI. However, the <b>reverse</b> equations <b>traced</b> the indirect impact of the FDI on economic growth through its dualistic influence on both the financial sector as well as domestic investment. Therefore, further financial liberalization is highly recommended {{if and only if}} the planned institutional and regulatory reforms are politically supported. Then, financial derivatives were proposed {{as a part of the}} liberalization scenario from one side and as a tool towards managing risks in the Egyptian financial market from the other side. Financial development, foreign direct investment, financial integration, financial instruments...|$|R
40|$|Penetrative convection, thunderstorms, squall lines, etc., all {{generate}} atmospheric {{gravity waves}} {{which can be}} observed by a ground-based ionospheric Doppler sounder array. Sources of these waves can be determined from <b>reverse</b> ray <b>tracing</b> computations. Case studies of gravity waves associated with isolated tornadic storms on January 13, 1976 were summarized to establish the minimum data sampling time required for correct spectral analysis and ray tracing computations. It was concluded that the data sampling time {{can be reduced to}} two to three times the wave period while still obtaining a reasonably good power spectral density. It was also demonstrated that the data sampling time can be reduced to two to three times the time delay of the wave arrival between two station pairs while still obtaining a justifiably good cross-spectral analysis. Computed source locations of the observed gravity waves are compared with conventional and satellite meteorological data...|$|R
40|$|We {{would like}} to propose two {{critical}} dimensions for strategy: "Industry Scope Shift" and "Reverse Strategy Trace. " Recent changes in the progress of information technology and economic globalization raised {{the importance of these}} dimensions. Rapid progress in information technology requires firms to respond to the changes of scope including market and product. The execution speed is increasingly becoming critical to keep uniqueness of product and service offerings. Industry Scope Shift helps the capturing of these changes into strategy. Economic globalization demands the organizational challenge to manage conflicts between local market responsiveness and global operation efficiency. <b>Reverse</b> Strategy <b>Trace</b> gives a clear perspective to analyze emergent strategy to accumulate organizational learning from business operations. We will examine the importance of these two dimensions and provides answers when and why these are critical in the strategy planning process. by Yasuhiko Kiuchi. Thesis (S. M. M. O. T.) [...] Massachusetts Institute of Technology, Sloan School of Management, Management of Technology Program, 2004. Includes bibliographical references (leaves 80 - 83) ...|$|R
40|$|Gravity wave {{observations}} using all-sky CCD imager {{to measure}} the airglow OH, O 2, and OI emissions were made at Cachoeira Paulista (22. 7 °S, 45 °W) (CP), at the low-middle latitude in Brazil, from October 1998 to September 1999. Near the equator, at Tanjungsari observatory (6. 9 °S, 107. 9 °E) (TJS), Indonesia, another wide angle CCD imager measuring the OH airglow emission layer has been operated from September 2000 to September 2001. With these data sets, a <b>reverse</b> ray <b>tracing</b> method was used to study propagation of gravity waves through the middle atmosphere and to estimate the source region. The CIRA- 86 reference zonal wind and temperature models and the GSWM- 02 tidal wind model {{were used in the}} present analysis. Both observation sites showed apparently similar wave characteristics, except for the horizontal phase speed, which was much faster in the equatorial region. From the inverse ray tracing calculations, it was found that at CP, only about 15...|$|R
40|$|We study {{short period}} gravity waves (20 – 120 min) in the {{equatorial}} Mesosphere and Lower Thermosphere (MLT) using a Medium Frequency (MF) radar at Pameungpeuk (7. 4 ° S, 107. 4 ° E), Indonesia. In particular, we study local time and seasonal {{variation of the}} gravity wave variance {{and its relation to}} tropical convection. The gravity wave variance at 88 km enhances between 20 : 00 LT and 07 : 00 LT, with a peak at 02 : 00 – 03 : 00 LT. The enhancement is mainly observed during February–April and September–October and shows inter-annual variability. Convective activity over the same location persists from 16 : 00 – 21 : 00 LT with a peak activity ~ 18 : 00 LT and enhances between November–April. Time delay between the peak of convection and that of gravity wave activity ranges 1 – 15 h, which is consistent with theoretical calculations and previous reports based on <b>reverse</b> ray <b>tracing</b> analysis...|$|R
40|$|On 23 March 2012, our all-sky imager {{recorded}} a concentric, ring-like gravity wave pattern. The wave arose within the area covered by images of both OH and O(1 S) nightglow emissions {{taken at the}} Andes Lidar Observatory (ALO), Chile (30. 3 ÁS, 70. 7 ÁW). We have estimated the observed and intrinsic parameters of the event and located the wave source within the lower mesosphere altitude range using a <b>reverse</b> ray <b>tracing</b> method. By the analysis of GOES and LIS satellite images, we have not found evidence of neither convective nor lightning activity nearby ALO, indicating {{that the source of}} the ring-like wave was not directly in the troposphere. The absence of tropospheric activity and the height of the source of the event suggest that a secondary wave generation mechanism might be the cause of the ring-like wave. The secondary wave mechanism was likely triggered by a breaking, larger-scale primary wave excited by deep convection _ 1400 ækm northeast of ALO over Bolivia, as determined by a forward ray tracing scheme. © 2016. American Geophysical Union. All Rights Reserved...|$|R
40|$|RadBall{trademark} {{is a novel}} {{technology}} that can locate and quantify unknown radioactive hazards within contaminated areas, hot cells, and gloveboxes. The device consists of a colander-like outer tungsten collimator that houses a radiation-sensitive polymer semi-sphere. The collimator {{has a number of}} small holes with tungsten inserts; as a result, specific areas of the polymer are exposed to radiation becoming increasingly more opaque in proportion to the absorbed dose. The polymer semi-sphere is imaged in an optical computed tomography scanner that produces a high resolution 3 D map of optical attenuation coefficients. A subsequent analysis of the optical attenuation data using a <b>reverse</b> ray <b>tracing</b> or backprojection technique provides information on the spatial distribution of gamma-ray sources in a given area forming a 3 D characterization of the area of interest. RadBall{trademark} was originally designed for dry deployments and several tests, completed at Savannah River National Laboratory and Oak Ridge National Laboratory, substantiate its modeled capabilities. This study involves the investigation of the RadBall{trademark} technology during four submerged deployments in two water filled cells at the DOE Hanford Site's Waste Encapsulation Storage Facility...|$|R
5000|$|During {{the course}} of many schemes, scammers ask victims to supply bank account {{information}}. Usually this is a [...] "test" [...] devised by the scammer to gauge the victim's gullibility; the bank account information isn't used directly by the scammer, because a fraudulent withdrawal from the account is more easily detected, <b>reversed,</b> and <b>traced.</b> Scammers instead usually request that payments be made using a wire transfer service like Western Union and MoneyGram. The reason given by the scammer usually relates to {{the speed at which}} the payment can be received and processed, allowing quick release of the supposed payoff. The real reason is that wire transfers and similar methods of payment are irreversible, untraceable and, because identification beyond knowledge of the details of the transaction is often not required, completely anonymous. However, bank account information obtained by scammers is sometimes sold in bulk to other fraudsters, who wait a few months for the victim to repair the damage caused by the initial scam, before raiding any accounts which the victim didn't close.|$|R
40|$|ObjectiveTo {{explore a}} new method to treat brachial plexus root {{avulsion}} experimentally by reimplantation combined with transplantation of neural stem cells (NSCs) modified by neurotrophin- 3 gene (NT- 3). MethodsThe total RNA was extracted from neonatal rat striatum and the NT- 3 cDNA {{was obtained by}} reverse transcription and amplified by polymerase chain reaction. The NT- 3 gene was transferred into NSCs via the pLEGFP-C 1, an expression plasmid vectors. The untransfected NSCs, the pLEGFP-C 1 treated NSCs, and the pLEGFP-C 1 -NT- 3 treated NSCs were transplanted into corresponding spinal cord segment with brachial plexus root avulsion. The survival, differentiation, and migration of the transplanted cells were determined under confocal laser scanning microscope or by immunohistochemistry method. The nerve regeneration was evaluated by gross observation, electrophysiological examination and <b>reverse</b> horseradish peroxidase <b>tracing.</b> ResultsThe NT- 3 gene was successfully amplified and transferred into neural stem cells via the plasmid vectors. The transplanted cells survived, differentiated, and migrated and NT- 3 was expressed within the spinal cord. The animals regained some muscle strength which was less than 3 -degree muscular strength according to the British Medical Research Council (BMRC) evaluating system. The results of electrophysiological examination and <b>reverse</b> horseradish peroxidase <b>tracing</b> were superior in the pLEGFP-C 1 -NT- 3 group to the NSCs untransfected group or the pLEGFP-C 1 group. ConclusionTransplantation of NSCs modified by NT- 3 gene combined with reimplantation is a relatively effective way to treat brachial plexus root avulsion experimentally. It still need further study to improve the results...|$|R
