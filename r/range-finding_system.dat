8|5|Public
50|$|In his mid-twenties he {{designed}} a <b>range-finding</b> <b>system</b> which allowed guns to {{home in on}} enemy ships beyond the horizon with accuracy and to fire a salvo the instant they were detected.|$|E
5000|$|Quantapoint {{was founded}} as K2T, Inc (or K2T) in Pittsburgh, Pennsylvania in 1991 by Eric Hoffman, Pradeep Khosla, Takeo Kanade and other Carnegie Mellon University faculty members. K2T focused on {{creating}} custom robotics and 3D range-finding imaging systems {{to help them}} navigate complex environments. The most notable are the laser <b>range-finding</b> <b>system</b> created in 1992 for the DANTE walking robot that explored Mount Erebus in Antarctica {{as part of a}} NASA sponsored competition [...] and the 360-degree phase-based 3D laser scanner named SceneModeler created in 1997.|$|E
5000|$|The Porsche Prototype II was {{eventually}} {{selected as the}} winner of the contest in 1963; this did not come as a surprise: it had already been decided in 1961 to build a pre-series of 50 vehicles based on this design; production of these was started that very year. This [...] "0-series" [...] was modified with a new cast turret and several hull changes to raise the rear deck to provide more room in the engine compartment, and move some of the radiators to the upper sides of the hull. Before mass production of the standard version started, it was also decided to add an optical <b>range-finding</b> <b>system</b> for better long-range gunnery, which required the turret to be somewhat taller, and added [...] "bumps" [...] {{on either side of the}} turret to mount the optics for triangulation. In 1963, France and Germany had both decided to build their own tanks, with Germany continuing to work on the Leopard while France designed and built the similar AMX-30.|$|E
5000|$|Precision {{depends upon}} sensor precision, data {{granularity}} and calculation speed. Range-finding lasers may have +/-1 cm accuracy while digital stereo camera accuracy {{is limited to}} [...]25 pixel and thus is range-dependent. Vision-based systems require more computational resources than simple <b>range-finding</b> <b>systems</b> such as lasers, but may employ a digital signal processor embedded with the camera. Cost/precision trade-offs led to less expensive vision-based systems on consumer robots while commercial and industrial robots and automated guided vehicles (AGVs) tend to use laser-based systems.|$|R
40|$|A laser {{satellite}} ranging {{system that}} is mounted upon and integrated with a microwave tracking radar is reported. The 1 -pulse/sec ruby laser transmitter is attached directly to the radar's elevation axis and radiates through a new opening in the radar's parabolic dish. The laser photomultiplier tube receiver utilizes the radar's existing 20 -cm diam f/ 11 boresight telescope and observes through a similar symmetrically located opening in the dish. The laser system possesses separate ranging system electronics but shares the radar's timing, computer, and data handling/recording systems. The basic concept of the laser/radar is outlined together with a listing of the numerous advantages over present singular laser <b>range-finding</b> <b>systems.</b> The developmental laser hardware is described along with preliminary range-finding results and expectations...|$|R
40|$|The Er 3 + fibre laser {{operates}} at a wavelength between 1. 5 and 1. 6 microns {{and is thus}} of interest for both telecommunication purposes and, since it can be Q-switched to give high pulse powers, in eye-safe <b>range-finding</b> <b>systems.</b> To date, ~ 810 nm has been the preferred pump wavelength owing to the ready availability of laser diodes. However, the 810 nm pump band of Er 3 + suffers from the serious disadvantage of pump excited-state absorption (ESA). As a result much of the pump light is wasted in exciting ions from the metastable level to a still higher energy level, rather than producing stimulated emission. This {{is reflected in the}} best reported slope efficiency of 17 %, obtained for Er 3 + sensitized with Yb 3 +...|$|R
40|$|We {{present a}} {{high-speed}} range-imaging {{system based on}} a VLSI computational sensor developed in the CMU Computer Science Department. The VLSI range sensor is a custom chip consisting of an array of cells which combine photo-sensing and computation. Unlike conventional "step-and-repeat" lightstripe range finders, our sensor gathers range images in parallel as a scene is swept by a continuously moving plane of light. A prototype <b>range-finding</b> <b>system</b> has been built using a second-generation sensor and is capable of acquiring a 32 32 point frame of 3 -D measurements in a millisecond [...] - two orders of magnitude faster than currently available range-finding systems. The accuracy and the repeatability of the acquired range data has been measured {{to be less than}} 0. 2 %. In this paper, we discuss the <b>range-finding</b> <b>system</b> and present experimental results that measure its performance. CMU Very Fast Range-Imaging System Shigeyuki Tada, Andrew Gruss and Takeo Kanade 10 October 1993 CMU-CS- 93 - 179 T [...] ...|$|E
40|$|Recent {{advances}} in nonlinear fiber optics and compact pulsed lasers {{have resulted in}} creation of broadband directional light sources. These supercontinuum laser sources produce directional broadband light using cascaded nonlinear optical interactions in an optical fibre framework. This system is used to simultaneously measure distance and reflectance to demonstrate a technique capable of distinguishing between a vegetation target and inorganic material using the Normalized Difference Vegetation Index (NDVI) parameters, while the range {{can be obtained from}} the waveform of the echoes. A two-channel, spectral <b>range-finding</b> <b>system</b> based on a supercontinuum laser source was used to determine its potential application of distinguishing the NDVI for Norway spruce, a coniferous tree, and its three-dimensional parameters at 600 nm and 800 nm. A prototype system was built using commercial components...|$|E
40|$|Introduction: For {{determining}} range via triangulation, {{the baseline}} distance between source and sensor {{as well as}} sensor and source angles are used in theory. Figure 1 shows the configuration for triangulation ranging [Everett 1995]: Figure 1 P 1 and P 2 represent two reference points (e. g., camera and laser source), while P 3 is a target point. The range B can be determined from {{the knowledge of the}} baseline separation A and the angles q and f using the Law of Sines: In practice this is difficult to achieve because the baseline separation and angles are difficult to measure accurately. We have demonstrated a technique for obtaining range information via laser triangulation without the need to know A, f and q. This technique was successfully implemented on a laser <b>range-finding</b> <b>system</b> on the NR...|$|E
40|$|Previously, we {{demonstrated}} a novel heterodyne based solid-state full-field <b>range-finding</b> imaging <b>system.</b> This system {{is comprised of}} modulated LED illumination, a modulated image intensifier, and a digital video camera. A 10 MHz drive is provided with 1 Hz difference between the LEDs and image intensifier. A sequence of images of the resulting beating intensifier output are captured and processed to determine phase and hence distance to the object for each pixel. In a previous publication, we detailed results showing a one-sigma precision of 15 mm to 30 mm (depending on signal strength). Furthermore, we identified {{the limitations of the}} system and potential improvements that were expected to result in a range precision in the order of 1 mm. These primarily include increasing the operating frequency and improving optical coupling and sensitivity. In this paper, we report on the implementation of these improvements and the new system characteristics. We also comment on the factors that are important for high precision image ranging and present configuration strategies for best performance. Ranging with sub-millimeter precision is demonstrated by imaging a planar surface and calculating the deviations from a planar fit. The results are also illustrated graphically by imaging a garden gnome...|$|R
40|$|Problem statement. The radar {{monitoring}} systems are used broadly for the moving object coordinates determination. Errors of the radar navigation systems are random in nature. The optimal estimation methods and algorithms {{of the aircraft}} (AC) flight trajectory parameters are used along with application of the statistical estimation theory for the data processing of such monitoring systems. Object of the work. This article deals with AC flight trajectory estimation using the data of a twoposition monitoring system with two rangefinding radar navigation stations located at the distance of d between them, each of which measures the distances to the aircraft. The influence of the different linearization methods on the trajectory estimation accuracy at the algorithms synthesis of optimal onestep data processing of twopositioned distance-measuring radionavigation system is investigated. The expressions for error statistical characteristics are defined as well as initial values for trajectory estimation algorithms offering an opportunity to provide the correctness of algorithms functioning. Conclusions. Three methods for linearized algorithms synthesis of onestep optimal estimation the aircraft movement trajectory parameters are shown in the work using the meas-uring results of a twoposition <b>range-finding</b> monitoring <b>system.</b> Finally, results of computer modeling are presented and comparative analysis of the accuracy using three different approaches to the trajectory estimation system synthesis is performed. Simple application {{of each of the}} synthesized algorithms considered here considerably increases the trajectory evaluation accuracy as compared with the accuracy of the coordinate's calculation without using of optimal methods. ??????????? ??????? ?? ???????? ??????????? ?????? ?????? ???????? ???????????? ??? ??????? ?????????? ??????????? ??????????? ????????? ?????? ????????? ??????????????? ??????? ???????????? ?????????????????? ???????. ?????????? ????????? ??? ?????????????? ????????????? ????????????, ?????????? ????????? ???????? ??? ?????????? ??????????? ??????; ??? ???? ??????????? ?????????? ???????????? ???????????????? ??????????. ????????? ?????????? ????????????? ?????????????, ?????? ????????????? ?????? ???????? ??? ????????????? ???? ?????? ???????? ??????? ??????? ??????????? ??????...|$|R
40|$|This article {{describes}} and tests a photography rig {{that has been}} built at the University of Melbourne, Australia, specifically {{for the purpose of}} taking rapid and highly standardized craniofacial photographs, in simultaneous views of front and profile. The rig uses a novel projected light <b>range-finding</b> <b>system</b> that has been designed for easy and accurate positioning of subjects, in the natural head position, at precise distances from the frontal camera. Results of experiments examining the intraobserver error of multiple photographs taken on the rig indicate that high-quality, repeatable photographs can be taken after a reasonably large amount of time has lapsed between photography sessions (e. g., 30 days). This study also indicates that some variability remains between photographs even when highly standardized protocols are followed. Consequently, it is expected that the variation between photographs with limited standardization is much larger and more likely to cause significant errors in any comparisons...|$|E
40|$|We have {{developed}} a new real-time <b>range-finding</b> <b>system</b> based on vertical stereo vision for measuring the distance to vehicles in front. In the system, stereo images are inputted from vertical cameras which are placed in {{the periphery of the}} windshield. However, the placement causes to the difference of vehicle's size in upper and lower images and missing stereo matching. To solve the problem, we proposed the powerful stereo matching algorithm that increases the missing. The method has two processes; the first process is to select particular characteristics of vehicles as matching candidates. The second process is to correspondence the same characteristic of the vehicles in the candidates using size invariant measure. To evaluate the accuracy of our algorithm, we compared measured values with actual distance. The result that the measured value is close to the actual one is indicated to few missing matching. Moreover, we implemented the algorithm on our high-speed generalpurpose video image processing system, ISHTAR, and processed video data in expressway scenes. We confirmed robustness of the algorithm under environmental changes, such as various vehicles in front, sunlight changes and shadows. 1...|$|E

