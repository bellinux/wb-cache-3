21|2194|Public
40|$|We {{suggest a}} method of fitting of a zero-range model of a tectonic plate under a {{boundary}} stress {{on the basis of}} comparison of the theoretical formulae for the corresponding eigenfunctions/eigenvalues with the <b>results</b> <b>extraction</b> under monitoring, in the remote zone, of non-random (regular) oscillations of the Earth with periods 0. 2 - 6 hours, on the background seismic process, in case of low seismic activity. Observations of changes of the characteristics of the oscillations (frequency, amplitude and polarization) in course of time, together with the theoretical analysis of the fitted model, would enable us to localize the stressed zone on the boundary of the plate and estimate the risk of a powerful earthquake at the zone. Comment: 24 pages, 4 figure...|$|E
40|$|Introduction. This {{protocol}} aims at preparing total RNA for {{gene expression}} analysis by Northern blots, RT-PCR and real-time quantitative PCR; cDNA isolation by RTPCR; and cDNA library construction. The principle, key advantages, starting plant material, time required for obtaining total RNA and expected results are presented. Materials and methods. This part describes the required materials and the 27 steps necessary for preparing RNA from peel and pulp fruit tissue: preparation of plant tissue powder, preparation of the complete RNA extraction buffer and isolation of RNA from ground banana fruit tissue. <b>Results.</b> <b>Extraction</b> of total RNA by the method described {{makes it possible to}} achieve electrophoresis under denatured conditions and in vitro reverse transcription. An example for Northern blot analysis is illustrated...|$|E
40|$|Cell {{migration}} {{is central to}} the development and maintenance of multicellular organisms. Fundamental understanding of cell migration can, for example, direct novel therapeutic strategies to control invasive tumor cells. However, the study of cell migration yields an overabundance of experimental data that require demanding processing and analysis for <b>results</b> <b>extraction.</b> Computational methods and tools have therefore become essential in the quantification and modeling of cell migration data. We review computational approaches for the key tasks in the quantification of in vitro cell migration: image pre-processing, motion estimation and feature extraction. Moreover, we summarize the current state-of-the-art for in silico modeling of cell migration. Finally, we provide a list of available software tools for cell migration to assist researchers in choosing the most appropriate solution for their needs...|$|E
40|$|Distributed {{objects and}} remote {{services}} adhere to various standards for data delivery and <b>result</b> <b>extraction.</b> There are multiple means of requesting results and multiple ways of delivering those results. By examining several popular and idiosyncratic methods, {{we have developed}} a comprehensive model that combines the functionality of all component models. This model for arbitrary <b>result</b> <b>extraction</b> from distributed objects provides increased flexibility for object users, and an increased audience for module providers. Keywords Distributed objects, remote services, <b>result</b> <b>extraction,</b> autonomy, partial extraction, progressive extraction. 1. INTRODUCTION 1. 1 Traditional RPCs and asynchronous extraction We {{address the problem of}} obtaining results from any of multiple computational servers in response to requests made by a client program. The simplest form of <b>result</b> <b>extraction</b> is the traditional synchronous remote procedure call (RPC). Parameters are passed in, the client waits patiently [...] ...|$|R
40|$|The {{study was}} carried out to {{determine}} the response of PGF 2 ? <b>result</b> <b>extraction</b> of Bali cattle seminal vesicle fluid {{on the level of}} progesterone. The seminal vesicle fluid was aspirated and then were. extracted with methanol. This reseach was conducted by devided the mare in the luteal phase into two groups. The first group were treated with PGF 2 ? <b>result</b> <b>extraction</b> of Bali cattle seminal vesicle fluid and the second group were treated with dinoprost as a patent product of PGF 2 ? were administered intra uterine. The level of progesterone was measured before (0 hours) treatment and at 24, 48, 72 hours after treatment. The level of Progesterone were determined by radioimmunoassay (RIA) technique. The result showed that PGF 2 ? <b>result</b> <b>extraction</b> of Bali cattle seminal vesicle liquid decreased the progesterone level 73. 03 % at 24 hours and 92. 79 % at 48 Hours. However, there was no significant different between PGF 2 ? <b>result</b> <b>extraction</b> of Bali cattle seminal vesicle liquid with PGF 2 ? of paten product on the progesterone level decreased. In conclusion, PGF 2 ? extraction of Bali cattle seminal vesicle liquid can decreas the level of progesterone in the mare with luteal phase. </div...|$|R
40|$|Within {{the realms}} of {{workflow}} management and grid computing, scheduling of distributed services is a central issue. Most schedulers balance time and cost to fit within a client's budget, while accepting explicit data dependencies between services as the best resolution for scheduling. Results are extracted from one service in total, and then simply forwarded to the next service. However, distributed objects and remote services adhere to various standards for data delivery and <b>result</b> <b>extraction.</b> There are multiple means of requesting results and multiple ways of delivering those results. By examining several popular and idiosyncratic methods, we have developed a comprehensive model that combines the functionality of all component models. This model for arbitrary <b>result</b> <b>extraction</b> from distributed objects provides increased flexibility for object users, and an increased audience for module providers. In turn, intelligent schedulers may leverage these <b>result</b> <b>extraction</b> features...|$|R
40|$|An {{assessment}} of structural reliability requires multiple {{evaluations of the}} limit state function for various realizations of random parameters of the structural sys-tem. In the majority of industrial applications the limit state functions cannot be expressed explicitly {{in terms of the}} random parameters but they are specified using selected outcomes of the FE analysis. In consequence, in order to be useful in prac-tice, a structural reliability analysis program should be closely integrated with a FE module or it should be interfaced with an advanced external FE program. When the FE source code is not available, which is usually the case, the only option is to establish a communication between the reliability analysis program and an external FE software through the batch mechanism of data modification, job submission and <b>results</b> <b>extraction.</b> The main subject {{of this article is to}} present the reliability analysis capabili-ties of STAND software, which is being developed in the Institute of Fundamental Technological Research of Polish Academy of Sciences. A special emphasis is pu...|$|E
40|$|Semi-thin and ultrathin {{sections}} of locust testes have been incubated in 3 H-actinomycin D solution and submitted to radioautography. The improved technical conditions described allow the reproducible obtainment of cell radioautographs with a moderate nuclear labelling {{and a very}} low nonspecific background which are usable for semi-quantitative <b>results.</b> <b>Extraction</b> with enzymes (DNase, RNase, pronase) or concentrated salt solution {{have been carried out}} before 3 H-actinomycin D treatment in order to characterize the reaction. The semi-quantitative results obtained at the light microscope level suggest that, in relation to the structural and chemical changes which occur in chromatin during spermiogenesis, some proteins may be easily hydrolysed in early spermatids. In ultrathin {{sections of}} spermatocytes the X chromosome is heavily 'stained' with 3 H-actinomycin D, while 3 H-uridine is not incorporated into the sex chromatin. These results are discussed {{in the light of the}} current ideas on the constitution of active chromatin. SCOPUS: NotDefined. jinfo:eu-repo/semantics/publishe...|$|E
40|$|Abstract Background Significant {{differences}} in G+C content between different isochore types {{suggest that the}} nucleosome positioning patterns in DNA of the isochores should be different as well. <b>Results</b> <b>Extraction</b> of the patterns from the isochore DNA sequences by Shannon N-gram extension reveals that while the general motif YRRRRRYYYYYR is characteristic for all isochore types, the dominant positioning patterns of the isochores vary between TAAAAATTTTTA and CGGGGGCCCCCG due to the large {{differences in}} G+C composition. This is observed in human, mouse and chicken isochores, demonstrating that the variations of the positioning patterns are largely G+C dependent rather than species-specific. The species-specificity of nucleosome positioning patterns is revealed by dinucleotide periodicity analyses in isochore sequences. While human sequences are showing CG periodicity, chicken isochores display AG (CT) periodicity. Mouse isochores show very weak CG periodicity only. Conclusions Nucleosome positioning pattern as revealed by Shannon N-gram extension {{is strongly dependent on}} G+C content and different in different isochores. Species-specificity of the pattern is subtle. It is reflected in the choice of preferentially periodical dinucleotides. </p...|$|E
30|$|The FTIR-ATR {{spectra of}} the samples {{extracted}} in different conditions showed {{significant differences in the}} secondary structure of the BMSS products <b>resulted</b> from <b>extraction</b> in mild conditions (Anderlini method) and those <b>resulting</b> from <b>extraction</b> in degradative conditions (alkaline, autoclave).|$|R
40|$|A {{metasearch}} engine supports unified access to multiple component search engines. To build a very large-scale {{metasearch engine}} that can access up {{to hundreds of}} thousands of component search engines, one major challenge is to incorporate large numbers of autonomous search engines in a highly effective manner. To solve this problem, we propose automatic search engine discovery, automatic search engine connection, and automatic search engine <b>result</b> <b>extraction</b> techniques. Experiments indicate that these techniques are highly effective and efficient...|$|R
40|$|Objective The aim of {{this study}} is to explore the {{analysis}} methods of data from citizens' personal information infringement cases. Methods We distinguish various types of case data according to inspection methods, and proposes three kinds of inspection methods including the methods of data conversion extraction, inspection of file size property and forensics tools. <b>Result</b> <b>Extraction</b> technologies can realize mass data inspection in different degrees. Conclusion The inspection methods is effective and need to develop software further...|$|R
40|$|Reprocessing of used {{nuclear fuel}} and {{treatment}} of nuclear waste are important issues for the sustainable development of nuclear energy. It is necessary to develop novel nuclear waste treatment technologies to meet the goal of minimizing the secondary liquid waste. Supercritical fluids are considered green solvents in chemical engineering process. It gains growing interest to treat nuclear waste using supercritical fluid extraction recently, because it can greatly decrease the secondary liquid waste with high radioactivity. During the past two decades, extraction of actinides and lanthanides by supercritical fluid has been intensively studied in some countries, and many important progresses have been made. However, the prospect of industrial application of supercritical fluid extraction technology in reprocessing of used nuclear fuel {{and treatment of}} nuclear waste is still unclear. In this paper, extraction of actinides and lanthanides from various matrixes or from their oxides by supercritical fluid including the experimental <b>results,</b> <b>extraction</b> mechanism and kinetic process was reviewed. The engineering demonstration projects were introduced. The trend of industrial application of supercritical fluid extraction technology in nuclear waste management was also discussed...|$|E
40|$|Stevioside can be {{obtained}} in Stevia rebaudiana leaves, which originated from Paraguay. It has been planted across Asia, Europe and Canada. It {{is the source of}} the highly sweet ent-kaurenoid diterpene glycosides, rebaudiana A, stevioside and other several sweet analogs. Stevioside is 300 times sweeter than sucrose and has lately gained importance as a natural non-caloric sweetener. The commercial exploration of S. rebaudiana has become stronger since 70 ’s due to the Japanese researchers developed extraction and purification process of sweetener. In S. rebaudiana, the ratio of stevioside to rebaudiaoside-A is 2 : 1. For its dominance, stevioside imparts a bitter after-taste characteristic to the crude extracts. The main purpose of this to study the effect of solvent concentration, extraction time and the ratio leaves to volume of solvent on the stevioside extraction. The soxhlet extractor was used in this study. Analysis of stevioside was carried out by anthrone reaction. From the <b>results,</b> <b>extraction</b> using 70 % ethanol resulted in the highest stevioside yield at 12 mg/mL. Meanwhile, the highest stevioside at 16. 5 mg/mL yield can {{be obtained}} during 24 hours extraction time. For the mass leaves to volume of solvent, 0. 09 g/mL of the mass of the leaves gave the highest stevioside yield at 32. 5 mg/mL...|$|E
40|$|Abstract Background Mefloquine-artesunate is a {{formulation}} of artemisinin based combination therapy (ACT) {{recommended by the}} World Health Organization and historically the first ACT used clinically. The use of ACT demands constant monitoring of therapeutic efficacies and drug levels, {{in order to ensure}} that optimum drug exposure is achieved and detect reduced susceptibility to these drugs. Quantification of anti-malarial drugs in biological fluids other than blood would provide a more readily applicable method of therapeutic drug monitoring in developing endemic countries. Efforts in this study were devoted to the development of a simple, field applicable, non-invasive method for assay of mefloquine in saliva. Methods A high performance liquid chromatographic method with UV detection at 220 nm for assaying mefloquine in saliva was developed and validated by comparing mefloquine concentrations in saliva and plasma samples from four healthy volunteers who received single oral dose of mefloquine. Verapamil was used as internal standard. Chromatographic separation was achieved using a Hypersil ODS column. <b>Results</b> <b>Extraction</b> recoveries of mefloquine in plasma or saliva were 76 - 86 % or 83 - 93 % respectively. Limit of quantification of mefloquine was 20 ng/ml. Agreement between salivary and plasma mefloquine concentrations was satisfactory (r = 0. 88, p Conclusion Disposition of mefloquine in saliva paralleled that in plasma, making salivary quantification of mefloquine potentially useful in therapeutic drug monitoring. </p...|$|E
30|$|The TBA value used {{to express}} the <b>result</b> of <b>extraction</b> method was {{calculated}} by multiplying the absorbance by the ‘K’ value (5.2) for extraction.|$|R
30|$|Figure 4 {{shows the}} <b>extraction</b> <b>results</b> of the 1 st and 3 rd frames of video {{sequence}} “Table”. As shown in Figure 4, the existing of shadows seriously affects {{the accuracy of}} extraction, though the moving object keeps itself integrated. Therefore, the shadows must be eliminated to ensure the accuracy of <b>extraction</b> <b>results.</b>|$|R
40|$|Compression wave {{analysis}} started nearly 50 {{years ago}} with Fowles. [1] Coperthwaite and Williams [2] gave a method that helps identify simple and steady waves. We have been developing a method that gives describes the non-isentropic character of compression waves, in general. [3] One result of that work is a simple analysis tool. Our method helps clearly identify when a compression wave is a simple wave, a steady wave (shock), and when the compression wave is in transition. This affects the analysis of compression wave experiments and the <b>resulting</b> <b>extraction</b> of the high-pressure equation of state...|$|R
40|$|International audienceActual {{industrial}} maintenance activities are mainly driven by traditional strategies where events are normally time-based. Tough {{it has been}} pointed that more advanced, condition-based strategies can provide clear savings in many maintenance activities, their application is normally prevented by different causes, such as the need to manage, both physically and logically, an increasing volume of data and information. This paper presents {{the development of a}} flexible architecture concept to provide flexible data and information management. On the one hand, a platform of web services to provide intelligent processing capabilities has been designed. This platform is logically structured according to OSA-CBM decision layers, from Condition Monitoring to Decision Support, and will provide automated <b>results</b> <b>extraction</b> for maintenance staff out of the existing data sources, with a flexible configuration that allows the system to be used ‘on-demand' and to grow according to the needs (new sensors and functionality). On the other hand, this software platform is supported by a flexible communications infrastructure, where a generic wireless ‘gateway' device is being developed, in order to complement existing communications options (wired or wireless) between sensors and company decision areas when other communication options are not available (such as SCADA, PDAs, etc.). This development, nicknamed DYNAWeb, is still ongoing and takes part of the DYNAMITE project, where additionally other technologies are being develope...|$|E
40|$|This PhD {{research}} investigated treatment {{effects of}} extraction {{of one and}} two maxillary first molars in Class II subdivision and Class II/ 1 malocclusion cases respectively from a longer time perspective. Private practice records were scrutinized to evaluate aspects of a treatment technique combining maxillary first molar extraction(s) and Begg brackets; outcome stability, influence on the position of maxillary third molars, interference of adjacent anatomical structures in closing extraction spaces, and effectiveness of fixed retainers in preventing vertical movement of mandibular second molars without contacts with maxillary teeth. Based on our <b>results,</b> <b>extraction</b> of a maxillary first molar and orthodontics led to favourable and stable results regarding aesthetics and occlusion. In patients treated with one and two extractions, the position of maxillary third molars improved by 3 to 4 times more compared to nonextraction maxillary halves and subjects. When applying this technique, clinicians {{should be aware of}} the possible interference of a large maxillary sinus in achieving upright position of maxillary second molars, and the capacity of retention wires to inhibit displacement of mandibular posterior teeth lacking occlusal contacts. Overall, there is evidence that maxillary first molar extraction(s) followed by orthodontic treatment, when carried out properly, and in selected cases, may be rewarding in clinical terms, and therefore may be preferred instead of extraction of premolars...|$|E
40|$|In analog design, {{there are}} so many design {{considerations}} that the modeling and simulation required to guide decisions from design conception to fabrication becomes staggering. In [18], Murphy and Bibyk estimate that there are 14 million different amplifier types corresponding to 3 levels of performance in 15 basic analog performance categories (3 15 ≈ 14 million). The variation in amplifier design underscores the complexity of analog design decisions and hints at the massive amount of simulation and modeling that these decisions require. In addition to the design complexity, the design flow adds several hurdles as the different platforms (Matlab, Cadence, ADS, Spice) used to model and simulate at various levels of abstraction are poorly integrated. We seek to reduce this massive simulation burden by using platform independent Verilog AMS along with C Shell scripting to automate {{a great deal of the}} simulation and <b>results</b> <b>extraction.</b> Furthermore, using Verilog AMS and C Shell can also bridge gaps between system-level design often done in Matlab and component-level design done in Cadence. Using Verilog AMS and scripting will not only reduce time spent doing simulations, but will also allow the designer to achieve a better understanding of the design. ii This thesis will outline attempts to create better design flows, communication of design intent, simulation time, and design reuse through the use of Verilog AMS testbenches and C Shell scripts. iii This is dedicated to my great-grandmother, Marie Koenig, who supported me in my education for so many years. i...|$|E
40|$|International audienceThis paper {{proposes a}} feature {{extraction}} method for online handwritten characters for a penmanship learning support system. This system has {{a database of}} model characters. It evaluates the characters a learner writes by comparing them with the model characters. However, if we prepare feature information for every character, information must be input every time a model character is added. Therefore, we propose a method of automatically extracting features from handwritten characters. In this paper, we examine whether it correctly identifies the turns in strokes as features. The <b>resulting</b> <b>extraction</b> rate is 80 % and in the remaining 20 % of cases, it extracted an area near a turn...|$|R
50|$|The SSSI {{is close}} to another in Berkshire <b>resulting</b> from gravel <b>extractions</b> at Wraysbury.|$|R
50|$|Summarization {{of media}} content (feature <b>extraction).</b> The <b>result</b> of feature <b>extraction</b> is a description.|$|R
40|$|Mobile {{technology}} has been increased in demand in vanous applications, such as consumer and business environment. Mobile devices communications are employed in many applications, e. g. mobile payment, and mobile tickets. Such mobile-based applications need secure environment, {{so that it could}} establish confidential and secure to provide authentication to access. Biometrics authentication becomes one of the possible secure solutions in mobile devices. Face recognition is one of secure and reliable methods for identification and verification. The project concentrates on the practical experiment to identify the solutions for improving the performance and security level, so that make the usability of the face recognition enhanced. The proposed experiment contains two parts: control experiment and test experiment. Both two categories of the experiment provide fully details involving experiment design, procedures, as well as the <b>results</b> <b>extraction</b> and analysis. Control experiment focuses on the users' acceptance, i. e. False Rejection Rate (FRR), which is the proportion of the number of rejected user patterns divided {{by the total number of}} user patterns. While the test experiment, i. e. False Acceptance Rate (FAR) pays an attention to the security. FAR indicates a fraction which is depended by the threshold of falsely accepted user patterns divided by the number of all impostor patterns (BioID Technology 2006). User acceptance for the experiment task requires the face images could be identified for a person. In real scenario, to increase the security along with the user acceptance, the usability of face recognition technology must be developed to be enhanced along with performance evaluation rates. School of Computing, Communications and Electronic...|$|E
40|$|Background. Increase of {{molecular}} tests performed on DNA extracted from various biological materials {{should not be}} carried out without an adequate standardization of the pre-analytical and post-analytical phase. Materials and Methods. Aim {{of this study was}} to evaluate the role of internal control (IC) to standardize pre-analytical phase and the role of cellularity control (CC) in the suitability evaluation of biological matrices, and their influence on false negative results. 120 cervical swabs (CS) were pre-treated and extracted following 3 different protocols. Extraction performance was evaluated by amplification of: IC, added in each mix extraction; human gene HPRT 1 (CC) with RT-PCR to quantify sample cellularity; L 1 region of HPV with SPF 10 primers. 135 urine, 135 urethral swabs, 553 CS and 332 ThinPrep swabs (TP) were tested for C. trachomatis (CT) and U. parvum (UP) with RT-PCR and for HPV by endpoint-PCR. Samples were also tested for cellularity. <b>Results.</b> <b>Extraction</b> protocol with highest average cellularity (Ac) /sample showed lowest number of samples with inhibitors; highest HPV positivity was achieved by protocol with greatest Ac/PCR. CS and TP under 300. 000 cells/sample showed a significant decrease of UP (P< 0. 01) and HPV (P< 0. 005) positivity. Female urine under 40. 000 cells/mL were inadequate to detect UP (P< 0. 05). Conclusions. Our data show that IC and CC allow optimization of pre-analytical phase, with an increase of analytical quality. Cellularity/sample allows better sample adequacy evaluation, crucial to avoid false negative results, while cellularity/PCR allows better optimization of PCR amplification. Further data are required to define the optimal cut-off for result normalization. </p...|$|E
40|$|Environmental chemists {{have been}} {{challenged}} for over 30 years to analyse complex mixtures of halogenated organic pollutants like polychlorinated biphenyls (PCBs), polychlorinated alkanes (PCAs), polybrominated diphenyl ethers (PBDEs) and polychlorinated dibenzo-p-dioxins and polychlorinated furans (PCDD/Fs). Gas chromatography (GC) often {{proved to be}} the method of choice because of its high resolution. The recent developments in the field of comprehensive two-dimensional GC (GC × GC) show that this technique can provide much more information than conventional (single-column) GC. Large volume injection (e. g. by programmed temperature vaporiser, or on-column injection) can be employed for the injection of tens of microliters of sample extract, in that way substantially improving the detection limits. Electron-capture detection (ECD) is a sensitive detection method but unambiguous identification is not possible and misidentification easily occurs. Mass spectrometric (MS) detection substantially improves the identification and the better the resolution (as with MS/MS, time-of-flight (TOF) MS and high-resolution (HR) MS), the lower the chances of misidentification are. Unfortunately, this comes only with substantially higher investments and maintenance costs. Co-extracted lipids, sulphur and other interferences can disturb the GC separation and detection leading to unreliable <b>results.</b> <b>Extraction,</b> and more so, sample clean-up and fractionation, are crucial steps prior to the GC analysis of these pollutants. Recent developments in sample extraction and clean-up show that selective pressurised liquid extraction (PLE) is an effective and efficient extraction and clean-up technique that enables processing of multiple samples in less than 1 h. Quality assurance tools such as interlaboratory studies and reference materials are very well established for PCDD/Fs and PCBs but the improvement of that infrastructure is needed for brominated flame retardants, PCAs and toxaphene. © 2008 Elsevier B. V. All rights reserved...|$|E
40|$|ABSTRACT Chemical {{reaction}} of small silicon cluster ions (Si n+: 20 ≤ n ≤ 29) with nitric oxide was studied {{by using the}} FT-ICR (Fourier Transform Ion Cyclotron Resonance) mass spectrometer. Silicon clusters were generated by a pulsed laser-vaporization supersonic-expansion cluster beam source directly connected to the FT-ICR mass spectrometer. Injected and size selected clusters were thermalized to the room temperature through collisions with argon, and {{were exposed to the}} reactant gas in the ICR cell. As a <b>result,</b> <b>extraction</b> {{reaction of}} a silicon atom was observed. When SiO was removed from Si n+ cluster, resulting Si n- 1 N+ clusters occasionally fragmented into smaller pieces. For a comparison, laser induced fragmentation patterns of size-selected clusters were performed. The reaction induced fragmentation was explained that after the Si atom <b>extraction,</b> <b>resulting</b> Si n- 1 N+ fragmented {{in the same manner as}} pure Si n- 1 + clusters when the released heat of the initial reaction was not absorbed in the Si n- 1 N+ clusters...|$|R
30|$|Fresh {{leaves of}} henna were dried in the {{sunlight}} for 1  day and again dried at 80  °C for 1  h in a hot air oven following washing and cleaning with distilled water. Dried leaves were grinded to powder form for getting proper <b>extraction</b> <b>result.</b> The <b>extraction</b> of dye was obtained after immersing 20  g henna powder in 100  mL water–ethanol mixture (90 : 10 v/v) for 24  h. This dye extract solution {{was used for the}} dyeing of both chitosan-treated and untreated jute fabric samples.|$|R
5000|$|Methods for the {{summarization}} {{of media}} content (feature <b>extraction).</b> The <b>result</b> of feature <b>extraction</b> is a description.|$|R
40|$|To {{ensure the}} {{mechanical}} quality of mobile devices, their behaviour is verified by drop tests {{in which they}} are dropped onto a hard surface. FEM simulations of these tests are carried out to predict failures and to provide a basis for decisions on design improvements. The results are not only varying due to material, assembly and geometric tolerances – they depend strongly on the drop orientation. Drop tests are carried out as random free fall tests with randomly varying drop orientation. Being part of boundary and initial conditions, the varying drop orientation has a much stronger influence on the results than the scattering of geometric dimensions and material parameters. Therefore a two-step approach is proposed for the sensitivity analysis. In the first step the design is investigated by simulation-based sensitivity studies with the drop orientation angles as input parameters. In the second step, sensitivity to material and geometry variation is analysed with fixed orientation angles. These angles are selected {{based on the results of}} step 1. Those orientations which produce the highest stress- the „worst case orientations“ are analysed. By application of the Metamodel of Optimal Prognosis (MOP) in optiSLang, Coefficients of Prognosis (CoP) are calculated, which can be used as a quality measure for the model. It was found that the CoP value depends strongly on the method of <b>results</b> <b>extraction.</b> In particular, CoP is sensitive to the location of stress evaluation. Typically, stress or strain maxima over a certain area and time are calculated and applied as output parameters for sensitivity studies in mechanics. Search of maxima over too large areas or over long time durations can mean that physically different events are used as the basis for the Metamodel. The proposed Local Maximum Method aims to take into account the physical background of the results and leads to significantly increased CoP values...|$|E
40|$|This {{research}} {{focus on}} the isolation of lignin component from lignocellulosic biomass of oil palm empty fruit bunch (OPEFB) using the organosolv method. Lignin has a unique structure where it consist of varies aromatic compound in their polymeric chain lignin that capable to copolymerize alternative units that derive from incomplete monolignol biosynthesis in plants. Nowadays, trending in lignin research was to focus the integration into lignin polymer and also improve the lignin degradation. Among the pretreatment methods to isolate lignin from its lignocellulosic biomass, the organosolv method process is the promising pretreatment method for biorefinery approach. Common organosolv methods consist of cooking lignocellulosic biomass in aqueous ethanol solvent at high temperature and carry out in a pressurized reactor. However, in this study, modification on organosolv method has been made where this reaction was carry out by refluxing at ambient pressure and lower temperature. Two parameters have been studied during the process: i) Extraction times (4 - 8 hour) ii) Ethanol concentrations (65 - 75 % vol.). From the <b>results,</b> <b>extraction</b> time and ethanol concentration gives large effects to delignification. While delignification is decreased by lower extraction time and higher solvent concentration, pulp yield increased and thus decreased the yield of lignin. Extension of time leads to a decrease of the pulp yield and increase the lignin yield. For overall ethanol concentration, it can be shown {{that there is no}} significant effect in their trend. Mostly, the highest lignin yield was recorded at extraction time of 8 hour with 6. 73 % lignin yield (65 % ethanol vol.), 8. 91 % lignin yield (70 % ethanol vol.). However, for 75 % ethanol vol., the highest was at 6 hour with 5. 44 % lignin yield. For solvent concentration effect, overall maximum lignin yield was observed at 70 % ethanol. The highest lignin yield isolated at maximum extraction time (8 hour) was at 70 % ethanol concentration with 8. 91 % lignin yield followed by 65 % with 6. 73 % and 75 % at 4. 66 % only. From this trend, it can be shown that a further increase ethanol concentration at 70 % vol. reduces the lignin yield. Solvent concentration and extraction time gives an intense impact to this process as these parameters able to lead to much economical process condition to isolate high yield of lignin...|$|E
40|$|During {{the course}} of this master project, the {{candidates}} have worked with FEA of local vibrations occurring in bracers on offshore windturbine jacket. These vibrations arise as a dynamic response from wind-, wave-, and windturbine- loads. The predicted vibrations can vary depending on which analysis method is being used. The methods in question are fully coupled- and sequentially coupled analysis. The given task provided by TDA included a literature study, a study of the phenomenon in question and a recommendation of how to handle the problem. It was necessary to be able to run both fully coupled analysis and sequentially coupled analysis to be able to study the phenomenon. The FEA codes USFOS and FEDEM was chosen for the analyses in the project. The fully coupled analysis were performed in FEDEM, while the sequentially coupled analysis were performed using a combination of both FEDEM and USFOS. To be able to run a sequentially coupled analysis, using a combination of FEDEM and USFOS, the general properties of the jacket structure had to be defined in FEDEM without including the actual jacket structure in the FEA. This was solved by replacing the jacket structure by a full spring connected to ground. The properties of the spring included the full stiffness matrix, the diagonal damping matrix and the diagonal mass matrix. These matrices were extracted analytically from analyses made in USFOS that captured the response of the jacket structure from static and dynamic load cases. Generating these matrices was a complex and time consuming task, and created a need for scripts that could run and extract information from a large number of analyses. Once the fully coupled- and sequential analyses were done, comparisons could be made. Prior to viewing the results, the assumption was that the sequentially coupled analysis would predict more damage than the fully coupled analysis. The results showed that the sequentially coupled analysis predicted more damage than fully coupled analysis, but the differences were extreme, and the explanation to this had to be found. After debugging input files, output files, and scripts involved in the <b>results</b> <b>extraction</b> without finding any errors, the cause would have to lie within the FEM analysis. It was reasonable to believe that the error was within the sequentially coupled analysis due to the prediction of very short lifetime. The debugging was done to find which factors contributed to the error in question. The factor contributing most to the errors was found likely to be values in the K, C and M matrixes affecting the rotational degree of freedom in z-direction. This results in severe twisting of the offshore wind turbine, contributing to higher axial forces in the bracers, again affecting the accumulated damage. This report shows how important and {{how difficult it is to}} get all parameters right when doing a sequentially coupled analysis, indicating that it is a vulnerable method when generating the needed K, C and M matrixes analytically...|$|E
40|$|We {{propose a}} {{molecular}} modeling strategy which {{is capable of}} mod-eling the mechanical properties on nano-scale low-dielectric (low-k) materials. Such modeling strategy has been also validated by the bulking force of carbon nano tube (CNT). This modeling framework consists of model generation method, boundary condition setting and <b>result</b> <b>extraction</b> method. For the amorphous silicon-based low-dielectric (low-k) material, {{the impact of the}} porosity and pore size upon the elastic modulus are modeled. Due to the electronic requirement of advanced electronic devices, low-k materials are in demand for the IC backend structure. However, due to the amorphous nature and porosity of this material, it exhibits low mechanical stiffness and low interfacial strength, as well as inducing numerous reliability issues. The mechanical impact of the nano-scaled pore...|$|R
40|$|We propose an {{iterative}} {{scheme of}} spatio-temporal local color transformation of background and graphcut segmentation for silhouette extraction. Given an initial background subtraction, spatio-temporal background color transformation is processed for fitting modeled background colors to input background ones {{under a different}} illumination condition. After foreground colors are modeled based on the fit background, spatio-temporal graph-cut algorithm is applied to acquire a foreground/background segmentation result. Because these two processes need well-segmented background and well-fit background each other, they are iterated in turn to obtain better silhouette <b>extraction</b> <b>results.</b> Silhouette <b>extraction</b> experiments for a walking human on a treadmill show {{the effectiveness of the}} proposed method...|$|R
40|$|Standard signal <b>extraction</b> <b>results</b> {{for both}} {{stationary}} and nonstationary time series are expressed as linear filters {{applied to the}} observed series. Computation of the filter weights, and of the corresponding filter transfer function, is relevant for studying properties of the filter and of the <b>resulting</b> signal <b>extraction</b> estimates. Methods for doing such computations for symmetric, doubly infinite filters are well-established. This paper develops an algorithm for computing filter weights for asymmetric, semi-infinite signal extraction filters, including the important case of the concurrent filter (for signal extraction at the current time point.) The setting is where the time series components being estimated follow ARIMA (autoregressive-integrated-moving average) models...|$|R
