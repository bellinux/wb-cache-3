1686|3401|Public
5|$|Measurements of the {{distance}} have elicited much controversy. Results prior to {{the launch of the}} Hipparcos satellite generally found that the Pleiades were about 135 parsecs away from Earth. Data from Hipparcos yielded a surprising result, namely a distance of only 118 parsecs by measuring the parallax of stars in the cluster—a technique that should yield the most direct and accurate results. Later work consistently argued that the Hipparcos distance measurement for the Pleiades was erroneous. In particular, distances derived to the cluster via the Hubble Space Telescope and infrared color-magnitude diagram fitting favor a distance between 135 and 140 pc; a dynamical distance from optical interferometric observations of the Pleiad double Atlas favors a distance of 133–137 pc. However, the author of the 2007–2009 catalog of revised Hipparcos parallaxes reasserted that {{the distance}} to the Pleiades is ~120 pc and challenged the dissenting evidence. Recently, Francis and Anderson proposed that a systematic effect on Hipparcos parallax errors for stars in clusters biases calculation using the weighted mean and gave a Hipparcos parallax distance of 126 pc and photometric distance 132 pc based on stars in the AB Doradus, Tucana-Horologium, and Beta Pictoris moving groups, which are all similar in age and composition to the Pleiades. Those authors note that the difference between these results can be attributed to <b>random</b> <b>error.</b>|$|E
25|$|<b>Random</b> <b>error</b> is {{the result}} of {{fluctuations}} around a true value because of sampling variability. <b>Random</b> <b>error</b> is just that: random. It can occur during data collection, coding, transfer, or analysis. Examples of <b>random</b> <b>error</b> include: poorly worded questions, a misunderstanding in interpreting an individual answer from a particular respondent, or a typographical error during coding. <b>Random</b> <b>error</b> affects measurement in a transient, inconsistent manner and it is impossible to correct for <b>random</b> <b>error.</b>|$|E
25|$|Precision in {{epidemiological}} variables is {{a measure}} of <b>random</b> <b>error.</b> Precision is also inversely related to <b>random</b> <b>error,</b> so that to reduce <b>random</b> <b>error</b> is to increase precision. Confidence intervals are computed to demonstrate the precision of relative risk estimates. The narrower the confidence interval, the more precise the relative risk estimate.|$|E
40|$|Multi-particle {{simulations}} {{are performed}} to study emittance {{growth in the}} Fermilab Booster. Analysis shows {{that the source of}} vertical emittance growth comes mostly from <b>random</b> <b>errors</b> in skew quadrupoles {{in the presence of a}} strong transverse space-charge force. [1] <b>Random</b> <b>errors</b> in dipole rolls and the Montague resonance do contribute but to lesser extent. The effect of <b>random</b> <b>errors</b> in the quadrupoles is small because the betatron envelope tunes are reasonably far away from the half-integer stopband...|$|R
40|$|Describes {{the design}} and {{realization}} of an error-correcting codec. For error protection of TV lines the realized codec utilizes a shortened (2196, 2136) BCH-code with 60 bits (2. 7 %) redundancy. The codec provides correction of 4 <b>random</b> <b>errors</b> or correction of one error burst up to 26 bits alternatively; 5 or 6 <b>random</b> <b>errors</b> can be detected. In the case of <b>random</b> <b>errors</b> the residual error rate after error correction is less than 10 - 8 even at 10 - 4 channel error rate...|$|R
40|$|The {{problem of}} {{estimating}} the <b>random</b> <b>errors</b> in the LHC dipole is considered. The main contributions to <b>random</b> <b>errors</b> {{are due to}} random displacements of the coil position with respect to nominal design and to the variation of the magnetization of the superconducting cable. Coil displacements can be induced either by mechanical tolerances or by the manufacturing process. Analytical and numerical scaling laws that provide the dependence of the <b>random</b> <b>errors</b> due to <b>random</b> displacements on the multipolar order are worked out. Both simplified and more realistic models of the coil structure are analysed. The obtained scaling laws are used to extract from experimental field shape data the amplitude of the coil displacements in the magnet prototypes. Finally, <b>random</b> <b>errors</b> due to interstrand resistance variation during the ramp are estimate...|$|R
25|$|There is <b>random</b> <b>error</b> in all {{sampling}} procedures. This {{is called}} sampling error.|$|E
25|$|These {{confidence}} intervals reflect <b>random</b> <b>error,</b> {{but do not}} compensate for systematic error, {{which in this case}} can arise from, for example, the reference group not having fasted long enough before blood sampling.|$|E
25|$|There are {{two basic}} ways to reduce <b>random</b> <b>error</b> in an {{epidemiological}} study. The first {{is to increase the}} sample size of the study. In other words, add more subjects to your study. The second is to reduce the variability in measurement in the study. This might be accomplished by using a more precise measuring device or by increasing the number of measurements.|$|E
30|$|This {{parameter}} represents {{influence of}} <b>random</b> <b>errors</b> on measured value.|$|R
5000|$|... The <b>errors</b> are <b>random,</b> {{thus the}} mean of the errors is zero: [...] * The <b>random</b> <b>errors</b> are {{uncorrelated}} with each other: [...] * The <b>random</b> <b>errors</b> are uncorrelated with the independent variables: , [...] and [...] * The method factors are assumed to be uncorrelated with one another and with the trait factors: ...|$|R
40|$|A {{class of}} linear {{convolutional}} codes for compound channels (i. e., channels on which burst and <b>random</b> <b>errors</b> occur) is given. It is shown that for any rate and burst length {{there exists a}} linear convolutional code of that rate that can correct almost all bursts of errors of that length and that requires a much smaller guard space than any code that can correct all possible bursts of errors {{less than or equal}} to that length. Protection against <b>random</b> <b>errors</b> can be obtained at the expense of the burst-error-correction capability. Explicit formulas are given for the number of bursts and <b>random</b> <b>errors</b> that can be corrected. A particular scheme to construct some codes is given. It is noted that these codes exhibit limited error propagation. A technique for constructing codes that can correct <b>random</b> <b>errors</b> within the guard space is also given...|$|R
25|$|The Off-line {{strategy}} {{determines the}} best patient position through accumulated data gathered during treatment sessions, almost always initial treatments. Physicians and staff measure {{the accuracy of}} treatment and devise treatment guidelines during using information from the images. The strategy requires greater coordination than on-line strategies. However, the use of off-line strategies does {{reduce the risk of}} systematic error. The risk of <b>random</b> <b>error</b> may still persist, however.|$|E
25|$|Interleaving is used {{to convert}} {{convolutional}} codes from <b>random</b> <b>error</b> correctors to burst error correctors. The basic idea behind the use of interleaved codes is to jumble symbols at the receiver. This leads to randomization of bursts of received errors which are closely located and we can then apply the analysis for random channel. Thus, the main function performed by the interleaver at transmitter is to alter the input symbol sequence. At the receiver, the deinterleaver will alter the received sequence to get back the original unaltered sequence at the transmitter.|$|E
500|$|Among the {{explanations}} advanced for the hard-easy effect are [...] "systematic cognitive mechanisms, experimenter bias, <b>random</b> <b>error,</b> and statistical artifact".|$|E
30|$|In this study, we presume both {{normally}} distributed <b>random</b> <b>errors</b> {{and systematic}} errors and propose {{the use of}} the weighted likelihood method (WLL) (Hu and Zidek, 2002; Wang and Zidek, 2005) to address this problem. First, we demonstrate that WLSQ and WLL provide the same solution; however, the variance of <b>random</b> <b>errors</b> estimated by WLL exceeds that estimated by WLSQ. In order to clarify which method estimates more reasonable errors, both methods are applied to data contaminated with systematic errors in order to simulate hypocenter determination with an unsuitable velocity model. The solutions with both methods could be analytically obtained for the simulated data. This paper compares the variance of <b>random</b> <b>errors</b> estimated by the maximum likelihood method with the assumed ones. This comparison indicates that WLSQ underestimates the variance of the <b>random</b> <b>errors</b> and is unreliable as an approach to this problem.|$|R
30|$|The {{literature}} on measurement error suggests {{a wide variety}} of issues that might contribute to measurement errors in both current (contemporaneous panel) and recalled (retrospective) data. The implications of measurement error depend substantially {{on the nature of the}} problems. Truly <b>random</b> <b>errors</b> in continuous variables will not bias estimates of key statistics such as means or estimates of linear regression models when serving as the dependent variable (Bound et al. 2001). <b>Random</b> <b>errors</b> in an explanatory variable, x, will downward-bias or attenuate the estimated coefficient. <b>Random</b> <b>errors</b> in categorical or binary variables are more problematic as they bias model estimates and descriptive statistics.|$|R
40|$|Data input for the AVE-SESAME I {{experiment}} are {{utilized to}} describe the effects of <b>random</b> <b>errors</b> in rawinsonde data on the computation of ageostrophic winds. Computer-generated <b>random</b> <b>errors</b> for wind direction and speed and temperature are introduced into the station soundings at 25 mb intervals from which isentropic data sets are created. Except for the isallobaric and the local wind tendency, all winds are computed for Apr. 10, 1979 at 2000 GMT. Divergence fields reveal that the isallobaric and inertial-geostrophic-advective divergences are less affected by rawinsonde <b>random</b> <b>errors</b> than the divergence of the local wind tendency or inertial-advective winds...|$|R
500|$|In {{testing on}} the bomb range, the Mk. XIV {{demonstrated}} an average accuracy of [...] from [...] altitude. In service, however, the average systematic error was , while the <b>random</b> <b>error</b> was [...] In comparison, units using {{the much more}} complex Stabilized Automatic Bomb Sight (SABS) improved this to [...] under the same operational conditions and altitude.|$|E
2500|$|... where [...] is the {{response}} variable, [...] is the explanatory variable, εi is a <b>random</b> <b>error</b> term, and [...] and [...] are parameters.|$|E
2500|$|... where [...] is the {{rational}} expectation and [...] is the <b>random</b> <b>error</b> term, {{which has an}} expected value of zero, and is independent of [...]|$|E
30|$|<b>Random</b> <b>errors</b> of radar {{distance}} and the position: 200 and 0.3.|$|R
50|$|Random: <b>Random</b> <b>errors</b> {{are small}} {{unavoidable}} fluctuations. They {{are caused by}} imperfections in measuring equipment, eyesight, and conditions. They can be minimized by redundancy of measurement and avoiding unstable conditions. <b>Random</b> <b>errors</b> tend to cancel each other out, but checks {{must be made to}} ensure they are not propagating from one measurement to the next.|$|R
50|$|Precision is a {{description}} of <b>random</b> <b>errors,</b> a measure of statistical variability.|$|R
2500|$|In a {{wide range}} of situations, maximum {{likelihood}} parameter estimates exhibit asymptotic normality – that is, they are equal to the true parameters plus a <b>random</b> <b>error</b> that is approximately normal (given sufficient data), and the error's variance decays as 1/n. For this property to hold, it is necessary that the estimator does not suffer from the following issues: ...|$|E
2500|$|An {{important}} difference between CTT and IRT is {{the treatment of}} measurement error, indexed by the standard error of measurement. [...] All tests, questionnaires, and inventories are imprecise tools; we can never know a person's true score, but rather only have an estimate, the observed score. There is some amount of <b>random</b> <b>error</b> which may push the observed score higher or lower than the true score. [...] CTT assumes {{that the amount of}} error is the same for each examinee, but IRT allows it to vary.|$|E
2500|$|In {{addition}} to expressing {{the variability of}} a population, the standard deviation is commonly used to measure confidence in statistical conclusions. [...] For example, {{the margin of error}} in polling data is determined by calculating the expected standard deviation in the results if the same poll were to be conducted multiple times. [...] This derivation of a standard deviation is often called the [...] "standard error" [...] of the estimate or [...] "standard error of the mean" [...] when referring to a mean. [...] It is computed as the standard deviation of all the means that would be computed from that population if an infinite number of samples were drawn and a mean for each sample were computed. [...] It is very {{important to note that the}} standard deviation of a population and the standard error of a statistic derived from that population (such as the mean) are quite different but related (related by the inverse of the square root of the number of observations). The reported margin of error of a poll is computed from the standard error of the mean (or alternatively from the product of the standard deviation of the population and the inverse of the square root of the sample size, which is the same thing) and is typically about twice the standard deviation—the half-width of a 95 percent confidence interval. [...] In science, many researchers report the standard deviation of experimental data, and only effects that fall much farther than two standard deviations away from what would have been expected are considered statistically significant—normal <b>random</b> <b>error</b> or variation in the measurements is in this way distinguished from likely genuine effects or associations. [...] The standard deviation is also important in finance, where the standard deviation on the rate of return on an investment is a measure of the volatility of the investment.|$|E
50|$|There are {{two types}} of {{measurement}} error: systematic <b>errors</b> and <b>random</b> <b>errors.</b>|$|R
5000|$|Multidimensional scaling (a {{statistical}} {{technique used}} when distances are measured with <b>random</b> <b>errors)</b> ...|$|R
5000|$|... #Subtitle level 3: Measuring or {{approximating}} {{the statistical}} variance of the <b>random</b> <b>errors</b> ...|$|R
50|$|<b>Random</b> <b>error</b> is {{the result}} of {{fluctuations}} around a true value because of sampling variability. <b>Random</b> <b>error</b> is just that: random. It can occur during data collection, coding, transfer, or analysis. Examples of <b>random</b> <b>error</b> include: poorly worded questions, a misunderstanding in interpreting an individual answer from a particular respondent, or a typographical error during coding. <b>Random</b> <b>error</b> affects measurement in a transient, inconsistent manner and it is impossible to correct for <b>random</b> <b>error.</b>|$|E
50|$|Precision in {{epidemiological}} variables is {{a measure}} of <b>random</b> <b>error.</b> Precision is also inversely related to <b>random</b> <b>error,</b> so that to reduce <b>random</b> <b>error</b> is to increase precision. Confidence intervals are computed to demonstrate the precision of relative risk estimates. The narrower the confidence interval, the more precise the relative risk estimate.|$|E
5000|$|Random error: Error {{that occurs}} due to natural {{variation}} in the process. <b>Random</b> <b>error</b> is typically assumed to be normally distributed with zero mean and a constant variance. <b>Random</b> <b>error</b> is also called experimental error.|$|E
40|$|This {{paper is}} {{concerned}} with a semiparametric partially linear regression model with unknown regression coefficients, an unknown nonparametric function for the non-linear component, and unobservable serially correlated <b>random</b> <b>errors.</b> The <b>random</b> <b>errors</b> are modeled by an autoregressive time series. We show that the distributions of the feasible semiparametric generalized least squares estimator of the parametric component, and the estimator of the autoregressive coefficients of the error process, admit bootstrap approximation. Simulation {{results show that the}} bootstrap substantially outperforms the normal approximation not only for small to medium sample sizes, but also for highly correlated <b>random</b> <b>errors.</b> A data example is provided to illustrate the method. Department of Applied Mathematic...|$|R
50|$|<b>Random</b> <b>errors,</b> {{in which}} the word has no {{relation}} to the target, also occur.|$|R
5000|$|Do <b>Random</b> <b>Errors</b> Explain Newsvendor Behavior?, Manufacturing and Services Operations Management Vol. 12, N°4, October 2010 ...|$|R
