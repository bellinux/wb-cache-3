5|16|Public
50|$|In computing, {{incremental}} search, incremental find or <b>real-time</b> <b>suggestions</b> is a {{user interface}} interaction method to progressively search for and filter through text. As the user types text, {{one or more}} possible matches for the text are found and immediately presented to the user. This immediate feedback often allows the user to stop short of typing the entire word or phrase they were looking for. The user may also choose a closely related option from the presented list.|$|E
40|$|Users {{presented}} with a system equipped with many advanced features and vast collections of searchable documents often have problems getting to the information they seek. Our studies with intelligence analysts using the Rosetta Web-based information access system revealed inefficiencies {{in the way they}} used the tool. Motivated by that observation, we implemented a prototype of an intelligent software agent that monitors the behavior of users with a goal of generating <b>real-time</b> <b>suggestions</b> to improve their performance. To evaluate the agent’s ability to predict the changes in the analysts’ performance, we compared it to the judgment of human domain experts. The results revealed evidence of substantial disagreement among human judges. We found the level of agreement among the judges and the agent to be much higher. The agent’s predictions were similar to those of an average judge. © 2011 - IOS Press and the authors...|$|E
40|$|Two {{branches}} of the trend towards "agents" that are gaining currency are interface agents, software that actively assists a user in operating an interactive interface, and autonomous agents, software that takes action without user intervention and operates concurrently, either while the user is idle or taking other actions. These two branches are related, but not identical, and are often lumped together under the single term "agent". Much agent work can be classified as either being an interface agent, but not autonomous, or as an autonomous agent, but not operating directly in the interface. We show why {{it is important to}} have agents that are both interface agents and autonomous agents. We explore some design principles for such agents, and illustrate these principles with a description of Letizia, an autonomous interface agent that makes <b>real-time</b> <b>suggestions</b> for Web pages that a user might be interested in browsing. Keywords Agents, interface agents, autonomous agents, Web, browsi [...] ...|$|E
50|$|In October 2007, Yahoo! Search was {{updated with}} a more modern {{appearance}} {{in line with the}} redesigned Yahoo! home page. In addition, Search Assist was added; which provides <b>real-time</b> query <b>suggestions</b> and related concepts as they are typed.|$|R
40|$|International audienceThis paper {{describes}} {{a study to}} develop an intelligent air traffic ground control operation system that is able to integrate initiatives from both controllers andautonomous vehicles. We use a multi-agent approach to optimize dynamically a routing and scheduling task while taking into account <b>real-time</b> human <b>suggestions.</b> Weexpect that such mixed-initiative systems combined with autonomous vehicles will permit reduction of congestion and fuel consumption in large airports...|$|R
5000|$|Google Suggest {{marked the}} {{addition}} of <b>real-time</b> query <b>suggestion.</b> As users began to enter a query, a list of possible query matches would dynamically appear beneath the search bar, allowing for quicker and more accurate searches. [...] According to Google, only about 2% of all user queries were tracked and monitored, {{in an effort to}} better improve the service, quelling concerns over privacy. The addition of instant suggestions added yet another dynamic to SEO, as webmasters now vied to associate their site with high ranking instant suggestion queries.|$|R
40|$|Crowdsourcing {{and machine}} {{learning}} are both useful tech-niques for solving difficult problems (e. g., computer vision and natural language processing). In this paper, we propose a novel method that harnesses and combines {{the strength of}} these two techniques to better analyze the features and the sentiments toward them in user reviews. To strike a good balance between reducing information overload and provid-ing the original context expressed by review writers, the pro-posed system (1) allows users to interactively rank the enti-ties based on feature-rating, (2) automatically highlights sen-tences {{that are related to}} relevant features, and (3) utilizes im-plicit crowdsourcing by encouraging users to provide correct labels of their own reviews to improve the feature-sentiment classifier. The proposed system not only helps users to save time and effort to digest the often massive amount of user re-views, but also provides <b>real-time</b> <b>suggestions</b> on relevant fea-tures and ratings as users generate their own reviews. Results from a simulation experiment show that leveraging on the crowd can significantly improve the feature-sentiment anal-ysis of user reviews. Furthermore, results from a user study show that the proposed interface was preferred by more par-ticipants than interfaces that use traditional noun-adjective pair summarization, as the current interface allows users to view feature-related information in the original context. Author Keywords Human computation; crowdsourcing; interactive machin...|$|E
40|$|In biomedicine, good {{metadata}} {{is crucial}} to finding experimental datasets, to understand how experiments were performed, and to reuse data to conduct new analyses. Despite {{the growing number of}} efforts to define guidelines and standards to describe biomedical experiments, the impediments to creating accurate, complete, and consistent metadata are still considerable. Authoring good metadata is a tedious and time-consuming task that biomedical scientists tend to avoid. The Center for Expanded Data Annotation and Retrieval (CEDAR) is developing novel methods and tools to simplify the process by which investigators annotate their experimental data with metadata. The CEDAR Workbench ([URL] is a set of Web-based tools for the acquisition, storage, search, and reuse of metadata templates. As a step towards decreasing authoring time while increasing metadata quality, we have enhanced the CEDAR Workbench with value recommendation capabilities. Our system identifies common patterns in the CEDAR metadata repository, and generates <b>real-time</b> <b>suggestions</b> for filling out metadata acquisition forms. These suggestions are context-sensitive, meaning that the values predicted for a particular field are generated and ranked based on previously entered values. Our value recommendation approach supports both free-text values and terms from ontologies and controlled terminologies. We demonstrate CEDAR's intelligent authoring capabilities, and show how the technology that we are developing leverages existing metadata to make the authoring of high-quality metadata a manageable task...|$|E
40|$|Page ii Context-aware media {{annotation}} utilizing Social Networks In {{this thesis}} {{the design and}} implementation of a novel photo annotation system is presented. ContextTag is an application specifically designed to take advantage over user and social context available in social networks. The aim of the application is to support the user in the photo annotation process by providing <b>real-time</b> tag <b>suggestions</b> {{with the use of}} an algorithm. To archive this, ContextTag automatically extracts user and social context from various sources and utilizes it for its tag predictions. ContextTag also incorporates collaborative tagging, face detection and tag classification using WordNet 1. Photos are tagged at the instance they are captured and can be shared immediately from the camera phone to the user’s social network. To easily locate already shared photos a custom Facebook application has been implemented which includes enhanced browsing features. The approach was evaluated with a user test including N= 5 participants, that carried a camera phone using ContextTag for a duration of four weeks. All phone activities were recorded and an individual user interview completed the user test. Further, simple Decision Tree modeling was applied in order to determine which contexts define the breakpoints. The tag suggestion algorithm has then been optimized accordingly. Results have indicated that generation of <b>real-time</b> tag <b>suggestion</b> from user and social context is possible by following the proposed methodology...|$|R
40|$|As part of {{an effort}} to improve user {{interactions}} with authority data in its online catalog, the UNC Chapel Hill Libraries have developed and implemented a system for providing <b>real-time</b> query <b>suggestions</b> from records found within its catalog. The system takes user input as it is typed to predict likely title, author, or subject matches in a manner functionally similar to the systems found on commercial websites such as google. com or amazon. com. This paper discusses the technologies, decisions and methodologies that went into the implementation of this feature, as well as analysis of its impact on user search behaviors...|$|R
40|$|Automotive {{navigation}} {{systems are}} widely used by drivers to help them reach a particular destination. Mostly, such systems are designed to suggest routes which will help the driver to reach destination by covering less distance or consuming less time. This paper presents a technique that will select least congested path by using a vehicular traffic prediction technique that utilizes Global positioning data paired with Speed and Accelerometer Telemetry provided by a GPS unit, mounted on a vehicle, to improve the results of existing graph search methodologies currently being implemented to provide navigation data to users. Clustering of vehicles is done, based on similar positional and directional behavior. These clusters will have similar congestion levels. Traffic data identified through clustering is used to manipulate the path cost of the corresponding road, on an existing road network graph. It tries to improve <b>real-time</b> route <b>suggestions</b> by selecting less congested routes dynamically...|$|R
40|$|The Scalable Coherent Interface (SCI) is a {{recently}} developed IEEE standard that defines a scalable high performance multiprocessor network. The SCI concept offers enormous potential improvement in both performance and life-cycle-cost {{with regard to}} the future of multiprocessor computing. Unfortunately, the high potential offered by SCI, as it is currently specified, cannot be directly exploited for <b>real-time</b> systems. <b>Suggestions</b> have been made by various SCI working group members on how to best extend/modify SCI to support real-time applications (SCI/RT). However, because of some limitations of each of the proposed candidate SCI/RT schemes, progress in developing a universal agreed upon SCI/RT standard has been slow. In this paper, we propose an efficient and low cost alternative SCI/RT scheme, called the job packing scheme. The scheme is based upon solid theoretical foundation of generalized rate monotonic scheduling theory and bin-packing methodology. It is flexible and lo [...] ...|$|R
40|$|Existing pattern {{recognition}} and classification algorithms in computer vision require {{vast amounts of}} computations on input data. As a result, memory access time is a critical parameter in system performance. Tremendous parallelism in structure and algorithm {{is required for the}} system to operate in real-time. A preprocessing structure for qualitative feature extraction which meets these system requirements is presented. In general, the structure architecture consists of a cellular array of pixel-processors each containing an inherently parallel associative memory element. As such, memory access time is minimal and parallelism is maximized. By varying this basic structure with regard to interconnection and additional logic, specific structures result which are capable of extracting measures of specific qualitative features. Two specific structures are described which extract, respectively, the qualitative features of texture regularity and line trend. Applications of these structures are presented. Low-level simulation and performance estimates indicate these applications are viable and amenable to <b>real-time</b> operation. <b>Suggestions</b> for the development of structures which extract other features or multiple features are described...|$|R
40|$|The IMOTION {{system is}} a {{content-based}} video search engine that provides fast and intuitive known item search in large video collections. User interaction consists mainly of sketching, which the system recognizes in <b>real-time</b> and makes <b>suggestions</b> based on both visual appearance of the sketch (what does the sketch look like in terms of colors, edge distribution, etc.) and semantic content (what object is the user sketching). The latter is enabled by a predictive sketch-based UI that identifies likely candidates for the sketched object via state-of-the-art sketch recognition techniques and offers on-screen completion suggestions. In this demo, we show how the sketch-based video retrieval of the IMOTION system is used {{in a collection of}} roughly 30, 000 video shots. The system indexes collection data with over 30 visual features describing color, edge, motion, and semantic information. Resulting feature data is stored in ADAM, an efficient database system optimized for fast retrieval...|$|R
40|$|Color theme {{or color}} palette can deeply {{influence}} {{the quality and}} {{the feeling of a}} photograph or a graphical design. Although color palettes may come from different sources such as online crowd-sourcing, photographs and graphical designs, in this paper, we consider color palettes extracted from fine art collections, which we believe to be an abundant source of stylistic and unique color themes. We aim to capture color styles embedded in these collections by means of statistical models and to build practical applications upon these models. As artists often use their personal color themes in their paintings, making these palettes appear frequently in the dataset, we employed density estimation to capture the characteristics of palette data. Via density estimation, we carried out various predictions and interpolations on palettes, which led to promising applications such as photo-style exploration, <b>real-time</b> color <b>suggestion,</b> and enriched photo recolorization. It was, however, challenging to apply density estimation to palette data as palettes often come as unordered sets of colors, which make it difficult to use conventional metrics on them. To this end, we developed a divide-and-conquer sorting algorithm to rearrange the colors in the palettes in a coherent order, which allows meaningful interpolation between color palettes. To confirm the performance of our model, we also conducted quantitative experiments on datasets of digitized paintings collected from the Internet and received favorable results. Comment: IEEE Transactions on Visualization and Computer Graphic...|$|R
40|$|We {{present the}} {{architecture}} behind Twitter’s <b>real-time</b> re-lated query <b>suggestion</b> and spelling correction service. Al-though these tasks have received much {{attention in the}} web search literature, the Twitter context introduces a real-time “twist”: after significant breaking news events, we aim to pro-vide relevant results within minutes. This paper provides a case study illustrating the challenges of real-time data pro-cessing {{in the era of}} “big data”. We tell the story of how our system was built twice: our first implementation was built on a typical Hadoop-based analytics stack, but was later re-placed because it did not meet the latency requirements nec-essary to generate meaningful real-time results. The second implementation, which is the system deployed in produc-tion, is a custom in-memory processing engine specifically designed for the task. This experience taught us that the current typical usage of Hadoop as a “big data ” platform, while great for experimentation, is not well suited to low-latency processing, and points the way to future work on data analytics platforms that can handle “big ” as well as “fast ” data. 1...|$|R
30|$|The second {{vision is}} of a techno-optimistic outlook {{on the impact}} of new mobile {{technologies}} which will radically transform travel behaviour by offering immediate <b>real-time</b> information and <b>suggestions</b> for optimal travel routes based on former behaviour. Concerns about privacy issues {{do not seem to be}} of high importance in this scenario owing to the advantages of individualized information and control. Information technology will play an active role through travel apps and other technologies to coordinate shared transport resources in the inner city. Active use of travel time on public transport through a combination of communication, work and play forms part of this vision. Moreover, increased flexibility in work, along with congestion charging schemes, will make peak hour traffic less problematic in the future. In many ways this vision reflects what the future scenario ecologist Peter Sale has labelled “Technopolis”, characterized by a growing technology addiction but also progressively more fragmented and distanced communities [7]. Efficiency given priority over individual privacy is an indication that this vison may be close to “Controlled mobility”, although with a more techno-optimistic accentuation.|$|R
40|$|The {{application}} of the Reticon RO- 64 annular photo-diode array {{to the task of}} optical tracking of special targets, direct optical focusing, and automatic printed circuit board inspection were studied. In order to facilitate this work, a digital camera unit incorporating the array was designed and constructed. Of the three applications investigated, the tracking task proved to be the most successful, since multiple targets were tracked in real time using the array. In the focusing application, the digital approach was found to be too slow for <b>real-time</b> use, and <b>suggestions</b> were made for the analog implementation of a focusing algorithm using the array. The printed circuit board inspection algorithm detected errors successfully, but the inefficiency of image acquisition with the array is a serious drawback, leading to the conclusion that linear arrays of similar design would provide faster and less expensive inspection. Thus the annular geometry is best suited to the onetime sampling of points on a circle in an image, {{as in the case of}} the tracking and focusing tasks. The focusing task suffers mainly from the amount of computation required to achieve focus, and from its competition with more established indirect focusing techniques. Submitted to the Department of Electrical Engineering and Computer Science on January 18, 1980 in partial fulfillment of the requirements for the Degree Master of Science in Electrical Engineering and Computer ScienceMIT Artificial Intelligence Laborator...|$|R
40|$|REASON: An {{intelligent}} user {{assistant for}} interactive environments The provision of intelligent user assistance {{has been an}} ongoing problem in designing computer interfaces. Interactive computing environments must support expert as well as novice users when providing advice for error correction and answers to questions directed to a system. To address these issues, we have investigated the application of fairly well-understood artificial intelligence techniques in novel ways to provide intelligent help. This paper describes the design methodology used to build REASON (<b>Real-time</b> Explanation And <b>SuggestiON),</b> an intelligent user-assistant prototype for a windowed, multitasking environment. REASON'S central component is an inference engine that solves problems arising from a user's activity. When the user makes one of several different kinds of errors, the inference engine offers dynamically generated suggestions about what the user might have intended. The user can also query REASON using natural language. In addition to providing suggestions of corrected input or answers to questions, REASON can provide two complementary types of explanations of these responses, derived from the inferences that led to them. uch of the recent work in designing help M systems for computer users has {{been influenced by the}} difficulties that people have in learning how to interact with c~mputers. &quot; ~ However, one of the most common, yet arguably least successful, computer applications is on-line user assistance. In studying new user interface technology, there is a considerable base of work in the areas of contextual assistance, user modeling, planning and proble...|$|R
40|$|The {{automotive}} industry {{has already taken}} a big step towards fully autonomous vehicles. This trend is now spreading to the maritime industry with development of autonomous surface vessels (ASVs). A reliable collision avoidance (COLAV) system is essential in this context. In order to avoid collision with other vessels, one must predict the future trajectories of nearby vessels. The constant velocity model (CVM) is the prevailing approach for trajectory prediction in today s COLAV systems. The main purpose of this thesis is to investigate to what extent {{it is possible to}} predict future vessel trajectories based on historical automatic identification system (AIS) data for prediction horizons up to about 15 minutes. A survey of other relevant prediction methods are also presented. Two new, AIS based methods for vessel trajectory prediction are developed and tested: the single point neighbor search (SPNS) method and the neighbor course distribution method (NCDM). Three speed prediction methods are also tested: the straightforward constant speed method, a method using the median speed of the predicted state s close neighbors (CNs) and lastly a linear transition in predicted time between the two former methods. The SPNS method is compared to a CVM approach and yields significantly better results on curved trajectories, in terms of lower average and median path and trajectory errors. However, a major part of vessels transit time is spent on straight line trajectories. The SPNS algorithm shows also good path predicting capabilities on close to straight line trajectories, although the CVM method yields the lowest errors in such environments. The SPNS algorithm outputs a single predicted trajectory which tends to follow the most AIS-dense sea lane ahead. Hence, it does neither facilitate any uncertainty measure nor the possibility to suggest multiple possible route choices. The more computational demanding NCDM algorithm, which outputs multiple predicted trajectories, does better facilitate prediction uncertainty and it is also capable of dividing the predicted trajectories into multiple branching sea lanes. Its predicted positions at certain time instants are clustered with the density-based spatial clustering of applications with noise (DBSCAN) algorithm. The predictions are further statistically evaluated with respect to the distances to the nearest cluster centers. Lastly, a computation time analysis is presented. The computational time is reduced from an earlier version of the algorithm by storing data in a k-d tree. However, the NCDM algorithm with the tested decision parameters is not practically feasible in <b>real-time.</b> Several <b>suggestions</b> to reduce the computation time are given...|$|R

