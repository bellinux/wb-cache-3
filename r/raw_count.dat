67|255|Public
5000|$|In {{the case}} of the term {{frequency}} , the simplest choice is to use the <b>raw</b> <b>count</b> of a term in a document, i.e. the number of times that term [...] occurs in document [...] If we denote the <b>raw</b> <b>count</b> by , then the simplest tf scheme is [...] Other possibilities include ...|$|E
5000|$|... where JDTCG is the TCG time {{expressed}} as a Julian date (JD). This is just a transformation of the <b>raw</b> <b>count</b> of seconds represented by the variable TCG, so this form of the equation is needlessly complex. The use of a Julian Date specifies the epoch fully. The above equation is often given with the Julian Date [...] for the epoch, but that is inexact (though inappreciably so, {{because of the small}} size of the multiplier LG). The value [...] is exactly in accord with the definition.|$|E
50|$|The law did {{not come}} without {{controversy}} and criticism though. Anti-LGBT {{groups such as the}} National Organization for Marriage, SaveCalifornia.com, and The Pacific Justice Institute have all supported a petition to have a ballot initiative to overturn the law. The petition was circulated by the Privacy for All Students Coalition which has worked with the aforementioned groups. By <b>raw</b> <b>count</b> 620,000 signatures were signed while only 505,000 are required to put a referendum on the ballot. If all signatures are deemed valid the initiative will go up on the ballot for the 2014 California Elections. However, the law is still in effect.|$|E
30|$|Formulate the {{real-time}} occupant count estimation problem using past corrections {{and their}} corresponding erroneous <b>raw</b> <b>counts.</b>|$|R
3000|$|The whole dataset, {{including}} the <b>raw</b> <b>counting</b> of HW ads, the HW Index and Job Vacancy Rate and adjusted data, is available online at: [URL] [...]...|$|R
30|$|In this section, {{we propose}} the PreCount {{algorithm}} for accurately correcting <b>raw</b> <b>counts</b> in real-time. One approach to achieving real-time error correction from <b>raw</b> <b>counts</b> is to continuously learn the patterns and trends of count errors using machine learning approaches. We introduce the following definitions and notations {{to distinguish the}} types of datasets used in this work: Transitions (ΔC) represents {{the difference between the}} entries and exits for each time-step in a dataset. Occupant Count (CC) is the cumulative sum of ΔC from the first time-step of a given day to the last time-step of that day.|$|R
50|$|It {{requires}} an observer to move along a fixed path and to count occurrences {{along the path}} and, {{at the same time}} (in some procedures), obtain the distance of the object from the path. This results in an estimate of the area covered and an estimate {{of the way in which}} detectability increases from probability 0 (far from the path) towards 1 (near the path). Using the <b>raw</b> <b>count</b> and this probability function, one can arrive at an estimate of the actual density of objects.The estimation of the abundance of populations (such as terrestrial mammal species) can be achieved using a number of different types of transect methods, such as strip transects, line transects, belt transects, point transects and curved line transects.|$|E
5000|$|Each {{entry of}} the lists refers to {{count of the}} {{corresponding}} entry in the list (this is also the histogram representation). For example, in the first list (which represents document 1), the first two entries are [...] "1,2". The first entry corresponds to the word [...] "John" [...] {{which is the first}} word in the list, and its value is [...] "1" [...] because [...] "John" [...] appears in the first document 1 time. Similarly, the second entry corresponds to the word [...] "likes" [...] which is the second word in the list, and its value is [...] "2" [...] because [...] "likes" [...] appears in the first document 2 times. This list (or vector) representation does not preserve the order of the words in the original sentences, which is just the main feature of the Bag-of-words model. This kind of representation has several successful applications, for example email filtering. However, term frequencies are not necessarily the best representation for the text. Common words like [...] "the", [...] "a", [...] "to" [...] are almost always the terms with highest frequency in the text. Thus, having a high <b>raw</b> <b>count</b> {{does not necessarily mean that}} the corresponding word is more important. To address this problem, one of the most popular ways to [...] "normalize" [...] the term frequencies is to weight a term by the inverse of document frequency, or tf-idf. Additionally, for the specific purpose of classification, supervised alternatives have been developed that take into account the class label of a document. Lastly, binary (presence/absence or 1/0) weighting is used in place of frequencies for some problems. (For instance, this option is implemented in the WEKA machine learning software system.) ...|$|E
3000|$|At the {{beginning}} of the measurement, the total <b>raw</b> <b>count</b> rate and the background count rate are ∼ 6 × 10 ^ 4  c/spin and 3 × 10 ^ 3  c/spin, respectively, and the background count occupies approximately 5 [...]...|$|E
30|$|Through this experiment, analyzer’s {{response}} to UV photons is compiled {{as a function}} of both elevation and azimuth angles for each channel. Hence, photon counts can be subtracted from the <b>raw</b> <b>counts</b> during data processing.|$|R
5000|$|... #Caption: The figure shows 15-second {{samples of}} the <b>raw</b> <b>counts</b> (per 20.48 ms) {{observed}} in a 1973 sounding-rocket-borne exposure to three of the X-ray brightest binary sources in the Milky Way galaxy: Her X-1 (1.7 days), Cyg X-3 (0.2 day), and Cyg X-1 (5.6 days).|$|R
40|$|Abstract: A {{procedure}} for monitoring discrete multivariate counts is proposed. The procedure {{is based on}} two schemes: the first scheme detects a shift {{in one or two}} of the p variables; the second procedure detects a shift in all the variables. The first scheme is based on an unbiased estimator for the shift in a particular Poisson count when input variables are not measurable. Run length results show that for most shift conditions this estimator is more effective in detecting a shift in one or two variables than using multiple C charts on the <b>raw</b> <b>counts.</b> The second scheme is based on the average of the p variables. Run length results show that its performance is equal to or better than the performance of multiple C charts on the <b>raw</b> <b>counts.</b> Together the two schemes provide efficient detection of virtually all shift situations...|$|R
3000|$|Given this formulation, {{the input}} feature set is {{comprised}} of all the aforementioned features and, <b>raw</b> <b>count</b> data [...] ({CC_r_d_j,s_ 0, [...]..., CC_r_d_j,s_k}or{CC_rt_d_j,s_ 0, [...]..., [...] CC_rt_d_j,s_k}). Where sk is the current time slot, and s 0 is the time slot {{at the beginning of}} the day.|$|E
30|$|Variability in {{detection}} rates {{can potentially}} bias {{the results of}} bird point count surveys and, therefore, other researchers recommend applying correction factors to the <b>raw</b> <b>count</b> data to compensate for this bias (Rosenstock et al. 2002, MacKenzie and Kendall 2002, Ellingson and Lukas 2003). However, {{we were not able}} to apply these methods due to data set limitations such as a lack of distance estimates for each individual in the pre-fire bird point counts. For our analyses, we used the <b>raw</b> <b>count</b> data, which we did not adjust for detection rate variability due to different bird species characteristics or vegetation types or complexity. Just as Hutto and Young (2003) stated, we felt that, despite the suspected biases that may exist, our point count results were sufficient to detect large-scale changes should they occur.|$|E
30|$|Different heart {{sizes were}} {{represented}} by syringes of various column heights mimicking {{a range of}} cardiac diameters. Syringes with fixed activity were scanned at five different volumes by successively adding non-radioactive water to the syringes. This procedure was repeated five times {{on each of the}} three cameras. <b>Raw</b> <b>count</b> rates were recorded for each scan to determine whether count rates changed with syringe column height.|$|E
40|$|The unique {{yield of}} {{collecting}} observational data on human movement has received increasing attention {{in a number}} of domains, including the study of decision-making style. As such, interest has grown in the nuances of core methodological issues, including the best ways of assessing inter-rater reliability. In this paper we focus on one key topic – the distinction between establishing reliability for the patterning of behaviors as opposed to the computation of <b>raw</b> <b>counts</b> – and suggest that reliability for each be compared empirically rather than determined a priori. We illustrate by assessing inter-rater reliability for key outcome measures derived from Movement Pattern Analysis (MPA), an observational methodology that records body movements as indicators of decision-making style with demonstrated predictive validity. While reliability ranged from moderate to good for <b>raw</b> <b>counts</b> of behaviors reflecting each of two Overall Factors generated within MPA (Assertion and Perspective), inter-rater reliability for patterning (proportional indicators of each factor) was significantly higher and excellent (ICC =. 89). Furthermore, patterning, as compared to <b>raw</b> <b>counts,</b> provided better prediction of observable decision-making process assessed in the laboratory. These analyses support the utility of using an empirical approach to inform the consideration of measuring discrete behavioral counts versus patterning of behaviors when determining inter-rater reliability of observable behavior. They also speak to the substantial reliability that may be achieved via application of theoretically grounded observational systems such as MPA that reveal thinking and action motivations via visible movement patterns...|$|R
50|$|Locally bounded loss rates can be {{measured}} using species richness and its variation over time. <b>Raw</b> <b>counts</b> {{may not be as}} ecologically relevant as relative or absolute abundances. Taking into account the relative frequencies, a considerable number of biodiversity indexes has been developed. Besides richness, evenness and heterogeneity are considered to be the main dimensions along which diversity can {{be measured}}.|$|R
30|$|An energy-time {{diagram of}} the {{observation}} on February 27  is shown in Fig.  10. Electron energy fluxes in the diagram are calculated by subtracting the background counts from the electron counts. It {{must be noted that}} absolute calibration of the MCP sensitivities has not yet been completed. The bottom panel shows channel-averaged <b>raw</b> <b>counts</b> per spin (shown in orange) and background counts per spin (in blue).|$|R
40|$|Aim A <b>raw</b> <b>count</b> of {{the species}} {{encountered}} across surveys usually underestimates species richness. Statistical estimators are often less biased. Nonparametric estimators of species richness are widely considered the least biased, but no particular estimator has consistently performed best. This is partly a function of estimators responding differently to assemblage-level factors and survey design parameters. Our objective was to evaluate the performance of raw counts and nonparametric estimators of species richness across various assemblages and with different survey designs. Location We used both simulated and published field data. Methods We evaluated the bias, precision and accuracy of raw counts and 13 nonparametric estimators using simulations that systematically varied assemblage characteristics (number of species, species abundance distribution, total number of individuals, spatial configuration of individuals and species detection probability), sampling effort and survey design. Results informed {{the development of an}} estimator selection framework that we evaluated with field data. Results When averaged across assemblages, most nonparametric estimators were less negatively biased than a <b>raw</b> <b>count.</b> Estimators based on the similarity of repeated subsets of surveys were most accurate and their accumulation curves appeared to reach asymptotes fastest. Number of species, species abundance distribution and effort had the largest effects on performance, ultimately by affecting the proportion {{of the species}} pool contained in a sample. Our estimator selection framework showed promising results when applied to field data. Main conclusions A <b>raw</b> <b>count</b> of the number of species in an area is far from the best estimate of true species richness. Nonparametric estimators are less biased. Newer largely unused, estimators perform better than more well known and longer established counterparts under certain conditions. Given that there is generally a trade-off between bias and precision, we believe that estimator variance, which is often not reported when presenting species richness estimates, should always be included...|$|E
30|$|The <b>raw</b> <b>count</b> {{data of the}} {{photographs}} were mapped to their tangential points in geographical coordinates using the calibrated imaging parameters. The peak heights for the F-region airglow, e.g., the 630 and 557.7 -nm OI emissions, and the mesospheric airglow, such as OI, NaD, and OH emissions, had a good agreement with those of previous studies. The EIA structures of the 630 -nm OI emission obtained from the red channel of {{the photographs}} and IMAP/VISI data also had good agreement. These agreements support {{the validity of the}} calibration method.|$|E
30|$|The OFFICE is a 2500 m 2 {{building}} that records {{an average of}} 70 to 80 occupants on normal weekdays. The building is primarily an office {{building that}} hosts a number of university researchers. Thus it is mainly comprised of offices, laboratories, meeting rooms and restrooms. To obtain the <b>raw</b> <b>count</b> of occupants in this building, 4 Stereo-vision cameras are installed to cover all transitions between all entrances and exits in the building. Also, the cameras installed in this building are manufactured by Xovis. All the datasets from OFFICE are obtained at a temporal granularity of 1 min.|$|E
30|$|The MALL is a 36, 000 m 2 {{building}} containing 80 commercial spaces or shops. To {{obtain the}} <b>raw</b> <b>counts</b> of occupants in this building, 22 Xovis Stereo-vision cameras are installed {{to cover all}} transitions between the entrances and exits of the building. This building records an average of 4500 to 5000 occupants on weekends and 3500 to 4500 occupants on weekdays. All the datasets from the MALL are obtained at a temporal granularity of 15 min.|$|R
5000|$|Input {{the data}} into a {{statistical}} software program and analyse. The software will produce utility functions {{for each of}} the features. In addition to utility scores, you can also request <b>raw</b> <b>counts</b> which will simply sum the total number of times a product was selected as best and worst. These utility functions indicate the perceived value of the product on an individual level and how sensitive consumer perceptions and preferences are to changes in product features.|$|R
30|$|In this section, we utilize {{datasets}} {{from the}} first three building cases to present our investigation of the error pattern in <b>raw</b> <b>counts.</b> As stated earlier, if there exists a consistent and repeatable error pattern, this will {{provide the basis for}} adopting a machine learning approach to accurately estimate count errors in real-time. To investigate the assumption that an error pattern exists, we reiterate the following proposition from Ihler et al. (2006); Hutchins et al. (2007); Sangoboye and Kjærgaard (2016).|$|R
30|$|The UNIVERSITY is an 8000 m 2 {{building}} that records {{an average of}} 800 to 900 occupants on normal weekdays. The building is primarily a teaching building with some office spaces. The types of room in this building are comprised mainly of classrooms, study zones, offices, and restrooms. To obtain the <b>raw</b> <b>count</b> of occupants in this building, 17 Stereo-vision cameras are installed to cover all transitions between all entrances and exits. The cameras installed in this building are manufactured by Xovis. All the datasets from the UNIVERSITY are obtained at a temporal granularity of 1 min.|$|E
30|$|The data {{processing}} time is 13.175  µs. (The PH window time[*]=[*] 3  µs, the A/D conversion time[*]=[*] 3.675  µs, the PH discharge time[*]=[*] 4.5  µs {{and the dead}} time for self-transmission[*]=[*] 2  µs.) When the XEP does not perform the A/D conversion process in an event, its processing time is 9.5  µs (with PH window time of 3  µs, PH discharge time of 4.5  µs and dead time for self-transmission of 2  µs). The XEP counts the dead time in units of 25  ns. This dead time information is necessary for converting <b>raw</b> <b>count</b> data to the physical quantities.|$|E
40|$|Soft X-ray {{spectra of}} Scorpius X- 1 {{obtained}} with the low-energy detectors of the A- 2 experiment on HEAO 1 are presented. The <b>raw</b> <b>count</b> spectra are deconvolved using the Kahn and Blissett technique {{to reveal the}} presence of oxygen absorption in the range 0. 5 - 0. 7 keV. The strength of this feature is shown to vary on a time scale of order hours. These results are interpreted as evidence for variable X-ray photoionization of circumsource material in the system. An alternative model, involving variable Compton broadening of an oxygen edge, is also discussed...|$|E
40|$|This paper {{presents}} an analytic framework for comparing data flow diagrams based on five dimensions: control points, process automation, data aggregation, resource usage, and <b>raw</b> <b>counts.</b> Our {{goal was to}} develop some simple quantitative metrics that are appropriate for computer-aided system development tools. In addition, we argue for computer-aided tools that support the tandem development of alternative system diagrams. Simultaneous development of competing system descriptions may allow for more accurate contrasts and insightful analysis. Finally, we use two case studies to illustrate the comparison techniques. ...|$|R
30|$|Sensing {{the number}} of people occupying a {{building}} in real-time facilitates a number of pervasive applications within the area of building energy optimization and adaptive control. To ascertain occupant counts, the adoption of camera-based sensors i.e. 3 D stereo-vision and thermal cameras have grown significantly. However, camera-based sensors can only produce occupant counts with accumulating errors. Existing methods for correcting such errors can only correct erroneous count data {{at the end of the}} day and not in real-time. However, many applications depend on real-time corrected counts. In this paper, we present an algorithm named PreCount for accurately correcting <b>raw</b> <b>counts</b> in real-time. The core idea of PreCount is to learn error estimates from the past. We evaluated the accuracy of the PreCount algorithm using datasets from four buildings. Also, the Normalized Root Mean Squared Error was used to evaluate the performance of PreCount. Our evaluation results show that in real-time PreCount achieved a significantly lower Normalized Root Mean Squared Error compared to <b>raw</b> <b>counts</b> and other correction approach with a maximum error reduction of 68 % when benchmarked with ground truth data. By presenting a more accurate algorithm for estimating occupant counts in real-time, we hope to enable buildings to better serve the actual number of people to improve both occupant comfort and energy efficiency.|$|R
30|$|To {{determine}} {{differences in}} gender within the model, I conducted a {{content analysis of}} the categories within the emergent themes. Specifically, I used Atlas.ti to tag quotes with a male or female identifier based on their source document. Because there were more female participants than male participants, I converted <b>raw</b> <b>counts</b> in each category to proportions by dividing by the total quotations for either male or female participants. Then, I calculated the percent difference between those proportions to represent whether male or female statements were more representative of a particular category.|$|R
40|$|Wikipedia is a {{very large}} and {{successful}} Web 2. 0 example. As the number of Wikipedia articles and contributors grows at a very fast pace, there are also increasing disputes occurring among the contributors. As a result of disputes, many articles in Wikipedia are controversial. In this project, I propose a supervised learning model using Support Vector Machines (SVMs) to identify controversial articles in Wikipedia. The idea is to represent each article by a bag-of-word feature vector. Each value in this vector is a <b>raw</b> <b>count</b> of a word type appearing in the article. Experiments on real articles from Wikipedia show that the proposed approach can effectively identify controversial articles...|$|E
30|$|The LIBRARY is a 60, 000 m 2 {{building}} that accommodates a library and business spaces. It records {{an average of}} 800 to 1000 occupants on weekdays and 400 to 600 occupants on weekends. To obtain the <b>raw</b> <b>count</b> of occupants in this building, 7 network cameras are installed to cover all transitions between the entrances and exits of the building. The cameras installed in this building are manufactured by AXIS communications and are coupled with a software module namely Cognimatics TrueView People Counter to dynamically recognize people entering and exiting the building. All raw counts are publicly available in Jensen (2016), and the datasets from this building are obtained at a temporal granularity of 1 h.|$|E
30|$|From the {{categorization}} in Table  1, it can {{be observed}} that the naive approach is insensitive to overestimation in buildings. This problem was highlighted {{in one of the}} building cases presented in Sangoboye and Kjærgaard (2016), where the past count estimates obtained through the naive approach {{is the same as the}} erroneous <b>raw</b> <b>count.</b> The probabilistic approach, on the other hand, achieved high fidelity count estimates compared to ground truth data for all building cases presented in Sangoboye and Kjærgaard (2016). Secondly, unlike the probabilistic approach which is non-adaptable for real-time correction, the naive approach can be easily adapted for correcting count estimates in real-time, but it does not provide high accuracy.|$|E
40|$|Abst rac t This paper {{presents}} an analytic framework for comparing data flow diagrams based on five dimensions: control points, process automa-tion, data aggregation, resource usage, and <b>raw</b> <b>counts.</b> Our {{goal was to}} develop some simple quantitative metrics that are appropriate for computer-aided system development tools. In addition, we argue for computer-aided tools that support the tandem development of alter-native system diagrams. Simultaneous development of competing s y s tem descriptions may allow for more accurate contrasts and insightful analysis. Finally, we use two case studies to illustrate the comparison techniques...|$|R
40|$|Abstract—This demo {{focuses on}} the online {{classification}} of traffic generated by P 2 P-TV applications, live video delivering services used by an ever increasing number of users worldwide. We designed a novel behavioural technique, which is able to reliably identify P 2 P-TV traffic simply based on <b>raw</b> <b>counts</b> of packets and bytes exchanged by the application during small-time windows. The demo software aims at showing the classification process and results, allowing users to interact on a simple active testbed with different live running P 2 P-TV applications. I...|$|R
40|$|This article {{examines}} the relationship between Research & Development (R&D) funding {{and the production of}} knowledge by academic chemists. Using articles published, either <b>raw</b> <b>counts</b> or adjusted for quality, we find a strong, positive causal effect of funding on knowledge production. This effect is similar across subsets of universities, suggesting a relatively efficient allocation of R&D funds. Finally, we document a rapid acceleration in the rate at which chemical knowledge was produced in the late 1990 s and early 2000 s relative to the financial and human resources devoted to its production...|$|R
