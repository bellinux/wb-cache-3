12|12|Public
3000|$|Defining Qorig, Qorig 1, and Qorig 2 as the {{original}} unmodified receiver signature sequence matrices of Q, Q 1, and Q 2 with its order is equivalent to S, <b>reordering</b> <b>procedure</b> is carried out by setting [...]...|$|E
40|$|We propose an {{adaptive}} reordered method {{to deal with}} the PageRank problem. It has been shown that one can reorder the hyperlink matrix of PageRank problem to calculate a reduced system and get the full PageRank vector through forward substitutions. This method can provide a speedup for calculating the PageRank vector. We observe that in the existing reordered method, the cost of the recursively <b>reordering</b> <b>procedure</b> could offset the computational reduction brought by minimizing the dimension of linear system. With this observation, we introduce {{an adaptive}} reordered method to accelerate the total calculation, in which we terminate the <b>reordering</b> <b>procedure</b> appropriately instead of reordering to the end. Numerical experiments show the effectiveness of this adaptive reordered method...|$|E
40|$|The authors {{develop an}} {{efficient}} particle labeling procedure {{based on a}} linked cell algorithm which is shown to reduce the computing time for a molecular dynamics simulation {{by a factor of}} 3. They prove that the improvement of performance is due to the efficient fulfillment of both spatial and temporal locality principles, as implemented by the contiguity of labels corresponding to interacting atoms. Finally, they show that the present label <b>reordering</b> <b>procedure</b> can be used to devise an efficient parallel one-dimensional domain decomposition molecular dynamics scheme...|$|E
40|$|The cost {{of testing}} {{is a major}} factor in the cost of digital system design. In order to reduce the test {{application}} time, it is required to order the test vectors in such a way that it reduces the time a defective chip spends on a tester until the defect is detected. In this paper, we propose an efficient test vector reordering technique that significantly reduces both the time and memory complexities of <b>reordering</b> <b>procedures</b> based on fault simulation without dropping. Experimental results demonstrate both the efficiency and effectiveness of our proposed technique...|$|R
40|$|In a direct-mapped {{instruction}} cache, all {{instructions that}} have the same memory address modulo the cache size, share a common and unique cache slot. Instruction cache conflicts can be partially handled at linked time by procedure placement. Pettis and Hansen give in [1] an algorithm that <b>reorders</b> <b>procedures</b> in memory by aggregating them in a greedy fashion. The Gloy and Smith algorithm [2] greatly decreases the number of conflict-misses but increases the code size by allowing gaps between procedures. The latter contains two main stages: the cache-placement phase assigns modulo addresses to minimizes cache-conflicts; the memoryplacement phase assigns final memory addresses under the modulo placement constraints, and minimizes the code size expansion. In this paper: (1) we state the NP-completenes...|$|R
40|$|The {{objective}} {{of this paper is}} to develop a reorder policy for a two-echelon supply chain with one central stock and multiple stores. The products under concern are high value imported watches, which exhibit high intermittent demand on the points of sale. The manager has centralized stock information over the entire chain and each store employs a base stock ordering policy. In spite of the lumpy demand on the stores, the monthly aggregate demand on the supply chain is significant and so, can be modeled using the continuous normal distribution approximation. The proposed model consists of an exponential smoothing forecasting model for the aggregate demand, a simple disaggregating method to derive the single items forecasts and a periodic <b>reorder</b> <b>procedure.</b> The order quantities of each item are determined according to the Poisson distribution and a desired service level. The purchased items are kept in the central stock and are shipped to stores on demand. The results achieved so far are very encouraging and should be extended to a wider range of brands and products...|$|R
40|$|We {{describe}} a <b>reordering</b> <b>procedure</b> {{that changes the}} order of test vectors in a test sequence for a synchronous sequential circuit without reducing the fault coverage. We use this procedure to investigate the effects of reordering {{on the ability to}} compact the test sequence. Reordering is shown to have two effects on compaction. (1) The reordering process itself allows us to reduce the test sequence length. (2) Reordering can improve the effectiveness of an existing static compaction procedure. Reordering also provides an insight into the detection by test generation procedures of faults that are detected by relatively long subsequences. 1...|$|E
40|$|In this work, {{we present}} a POS-based {{preordering}} approach that tackles both long- and short-distance reordering phenomena. Syntactic unlexicalized reordering rules are automatically extracted from a parallel corpus using only word alignment and a source-side language tagging. The reordering rules are used in a deterministic manner; this prevents the decoding speed from being bottlenecked in the <b>reordering</b> <b>procedure.</b> A new approach for both rule filtering and rule application is used to ensure a fast and efficient reordering. The tests performed on the IWSLT 2016 English-to-Arabic evaluation benchmark show a noticeable increase in the overall Blue Score for our system over the baseline PSMT system...|$|E
30|$|In this section, the {{proposed}} BRJPDA is evaluated and {{compared with the}} existing methods, namely JPDA, ENNJPDA, SetJPDA, and JPDA*. Moreover, the filtering method with perfect data association, denoted by CorrectAsso, is also considered in the simulation for comparison. The implementation of SetJPDA retains only at most ten hypotheses with the largest a posteriori probabilities to do the <b>reordering</b> <b>procedure</b> by the brute force method. The fast and suboptimal method of SetJPDA is not applied because {{the starting point for}} this algorithm is important but may be scenario dependent and only is given for a special scenario through empirical studies [22]. The aim of the hypotheses pruning for SetJPDA is reducing the computational complexity to a general case. Thus, the implementation of the SetJPDA could be possible.|$|E
40|$|We prove theorems {{that show}} {{that if we can}} reorder a program's memory refer-ence stream such that the reordered memory {{reference}} stream satises a disjointness property, then the transformed program corresponding to the reordered stream is guar-anteed to have fewer misses for any cache with arbitrary size or organization so long as the cache uses the LRU replacement policy. We can apply these results to reorder instructions within a basic block, to transform loops, to reorder blocks within a pro-cedure, or to <b>reorder</b> <b>procedures</b> within a program so as to improve hit rate for any cache that uses LRU replacement. Based on these theorems, we develop algorithmic methods for program transforma-tion to improve cache performance. While {{there has been a lot}} of work in improving cache performance using program transformations, our work diers from previous work in that it can be applied at many dierent levels, from the basic block to procedural levels, and does not require xing the size or organization of a cache prior to program transformation. We present preliminary experimental results {{that show that}} reordering based on our methods can result in signicant improvements in hit rate and program performance. ...|$|R
40|$|In a direct-mapped {{instruction}} cache, all {{instructions that}} have the same memory address modulo the cache size, share a common and unique cache slot. Instruction cache conflicts can be partially handled at linked time by procedure placement. Pettis and Hansen give in [1] an algorithm that <b>reorders</b> <b>procedures</b> in memory by aggregating them in a greedy fashion. The Gloy and Smith algorithm [2] greatly decreases the number of conflict-misses but increases the code size by allowing gaps between procedures. The latter contains two main stages: the cache-placement phase assigns modulo addresses to minimizes cache-conflicts; the memory-placement phase assigns final memory addresses under the modulo placement constraints, and minimizes the code size expansion. In this paper: (1) we prove the NP-completeness of the cache-placement problem; (2) we provide an optimal algorithm to the memory-placement problem with complexity O(n min(n, L) α(n)) (n {{is the number of}} procedures, L the cache size, α is the inverse Ackermann’s function that is lower than 4 in practice); (3) we take final program size into consideration during the cache-placement phase. Our modifications to the Gloy and Smith algorithm gives on average a code size expansion of 8 % over the original program size, while the initial algorithm gave an expansion of 177 %. The cache miss reduction is nearly the same as the Gloy and Smith solution with 35 % cache miss reduction...|$|R
40|$|Abstract. The Vehicle Routing Problems (VRPs) {{has been}} {{extensively}} studied and applied in many fields. Variations of VRPs have been proposed and appeared in research for many decades. Dynamic Vehicle Routing Problem with Multiple Depots (D-MDVRP) extends the variation of VRPs to dynamism of customers by knowing the information of customers (both locations and due dates) at diverse times. An application of this problem {{can be found in}} food delivery services which have many service stores. The customer delivery orders are fulfilled by a group of scattered service stores which can be analogous to depots in D-MDVRP. In this example the information of all customer orders are not known at the same time depending on arrivals of customers. Thus the objective of this operation is to determine vehicle routing from service stores as well as dispatching time. This paper aims to develop a heuristic approach for D-MDVRP. The proposed heuristic method comprises of two phases: route construction and vehicle dispatch. Routes are constructed by applying the Nearest Neighbor Procedure (NNP) to cluster customers and select a proper depot, Sweeping and <b>Reordering</b> <b>Procedures</b> (SRP) to generate initial feasible routes, and Insertion Procedure (IP) to improve routing. Then the determination of dispatch is followed in the next phase. In order to deal with the dynamism, the dispatch time of each vehicle is determined by maximizing the waiting time to provide the opportunity to add more arriving customers in the future. A...|$|R
40|$|In {{this paper}} we {{describe}} a procedure for optimizing the MPI communication of an unstructured CFD code {{in a parallel}} multi-core environment. By reordering the MPI ranks, a mapping of MPI processes to CPU cores is established, such that the main communication takes place within the compute nodes. The motivation {{of this approach is}} based on the observation that the communication between CPU cores on the same compute node is usually much faster than the communication between CPU cores on different nodes. The generic nature of our approach provides an out-of-the-box optimization tool, which can be easily used with other CFD codes due to the external MPI rank <b>reordering</b> <b>procedure.</b> The optimization tool was successfully tested with the DLR TAU code and the results of the optimization are demonstrated by benchmark computations for different geometries of aircraft configurations...|$|E
40|$|To {{facilitate}} interactive design, {{the solutions}} to configuration problems can be compiled into a decision diagram. We develop three heuristics for reducing the time and space required to do this. These heuristics {{are based on the}} distinctive clustered and hierarchical structure of the constraint graphs of configuration problems. The first heuristic attempts to limit the growth {{in the size of the}} decision diagram by providing an order in which constraints are added to the decision diagram. The second heuristic provides an initial order for the variables within the decision diagram. Finally, the third heuristic groups variables together so that they can be reordered by a dynamic variable <b>reordering</b> <b>procedure</b> used during the construction of the decision diagram. These heuristics provide one to two orders magnitude improvement in the time to compile a wide range of configuration. ...|$|E
40|$|Identifiable parametrizations {{for direct}} {{adaptive}} control of linear multivariable plants, which assume exact {{knowledge of the}} systems observability indices and the full interactor, {{have been reported in}} the literature recently. The observability indices have no clear physical meaning, hence it is not obvious how they can be obtained in practical applications. Also, assuming the interactor is known is not very reasonable, since it, roughly speaking, describes the "high frequency" behaviour of the plant. In this brief note we present an output <b>reordering</b> <b>procedure,</b> based on plant prior knowledge and data from simple experiments, which allows us to [...] generically [...] obtain a unique parametrization for the interactor. A further contribution of our work is to show how, using practically sensible prior knowledge, one can restrict the controller parameters to insure uniqueness of the solution of the Diophantine equation. Keywords: Adaptive Control, Multivariable Systems, Systems Identification [...] . ...|$|E
50|$|Interprocedural {{optimization}} {{works on}} the entire program, across procedure and file boundaries. It works tightly with intraprocedural counterparts, carried out {{with the cooperation of}} a local part and global part. Typical interprocedural optimizations are: procedure inlining, interprocedural dead code elimination, interprocedural constant propagation, and <b>procedure</b> <b>reordering.</b> As usual, the compiler needs to perform interprocedural analysis before its actual optimizations. Interprocedural analyses include alias analysis, array access analysis, and the construction of a call graph.|$|R
50|$|Aspects of the {{language}} were still being designed as PL/I F was implemented, so some were omitted until later releases. PL/I RECORD I/O was shipped with PL/I F Release 2. The list processing functions Based Variables, Pointers, Areas and Offsets and LOCATE-mode I/O were first shipped in Release 4. In a major attempt to speed up PL/I code to compete with Fortran object code, PL/I F Release 5 does substantial program optimization of DO-loops facilitated by the <b>REORDER</b> option on <b>procedures.</b>|$|R
40|$|Program {{reference}} patterns {{can have}} a more profound effect on paging performance in a virtual memory system than page re-placement algorithms. This paper describes experimental techniques that can sign$-cantly reduce paging exceptions in existing, frequently executed programs. Automated <b>procedures</b> <b>reorder</b> relocatable program sectors, and computer displays of memory usage facilitate fur-ther optimization qf program structure. Program restructuring for virtual memory by D. J. Hatfield and J. Gerald Experimental techniques {{have been developed for}} improving the performance of programs in virtual memory Systems'J by rearranging, or by duplicating and rearranging, relocatable sectors of code. Experimental results were obtained from finished programs, rather than from programs in the design stage. Improvements i...|$|R
40|$|We {{present a}} novel 3 -D {{scalable}} compression method for medical images with optimized volume of interest (VOI) coding. The method is presented {{within the framework}} of interactive telemedicine applications, where different remote clients may access the compressed 3 -D medical imaging data stored on a central server and request the transmission of different VOIs from an initial lossy to a final lossless representation. The method employs the 3 -D integer wavelet transform and a modified EBCOT with 3 -D contexts to create a scalable bit-stream. Optimized VOI coding is attained by an optimization technique that reorders the output bit-stream after encoding, so that those bits belonging to a VOI are decoded at the highest quality possible at any bit-rate, while allowing for the decoding of background information with peripherally increasing quality around the VOI. The bit-stream <b>reordering</b> <b>procedure</b> is based on a weighting model that incorporates the position of the VOI and the mean energy of the wavelet coefficients. The background information with peripherally increasing quality around the VOI allows for placement of the VOI into the context of the 3 -D image. Performance evaluations based on real 3 -D medical imaging data showed that the proposed method achieves a higher reconstruction quality, in terms of the peak signal-to-noise ratio, than that achieved by 3 D-JPEG 2000 with VOI coding, when using the MAXSHIFT and general scaling-based methods...|$|E
40|$|Abstract—We {{present a}} novel 3 -D {{scalable}} compression method for medical images with optimized volume of interest (VOI) coding. The method is presented {{within the framework}} of interactive telemedicine applications, where different remote clients may access the compressed 3 -D medical imaging data stored on a central server and request the transmission of different VOIs from an initial lossy to a final lossless representation. The method employs the 3 -D integer wavelet transform and a modified EBCOT with 3 -D contexts to create a scalable bit-stream. Optimized VOI coding is attained by an optimization technique that reorders the output bit-stream after encoding, so that those bits belonging to a VOI are decoded at the highest quality possible at any bit-rate, while allowing for the decoding of background information with peripherally increasing quality around the VOI. The bit-stream <b>reordering</b> <b>procedure</b> is based on a weighting model that incorporates the position of the VOI and the mean energy of the wavelet coefficients. The background information with peripherally increasing quality around the VOI allows for placement of the VOI into the context of the 3 -D image. Performance evaluations based on real 3 -D medical imaging data showed that the proposed method achieves a higher reconstruction quality, in terms of the peak signal-to-noise ratio, than that achieved by 3 D-JPEG 2000 with VOI coding, when using the MAXSHIFT and general scaling-based methods. Index Terms—Embedded block coding with optimized truncation (EBCOT), medical image compression, scalable compression, volume of interest coding, 3 D-JPEG 2000. I...|$|E
40|$|AbstractCoarse grain {{parallel}} {{codes for}} solving sparse systems of linear algebraic equations {{can be developed}} in several different ways. The following procedure is suitable for some parallel computers. A preliminary reordering of the matrix is first applied to move as many zero elements {{as possible to the}} lower left corner. After that the matrix is partitioned into large blocks and the blocks in the lower left corner contain only zero elements. An attempt to obtain a good load-balance is carried out by allowing the diagonal blocks to be rectangular. While the algorithm based on the above ideas has good parallel properties, some stability problems may arise during the factorization because the pivotal search is restricted to the diagonal blocks. A simple a priori procedure has been used in a previous version in an attempt to stabilize the algorithm. In this paper it is shown that three enhanced stability devices can successfully be incorporated in the algorithm so that it is further stabilized and, moreover, the parallel properties of the original algorithm are preserved. The first device is based on a dynamic check of the stability. In the second device a slightly modified reordering is used in an attempt to get more nonzero elements in the diagonal blocks (the number of candidates for pivots tends to increase in this situation and, therefore, there is a better chance to select more stable pivots). The third device applies a P 5 -like ordering as a secondary criterion in the basic <b>reordering</b> <b>procedure.</b> This tends to improve the reordering and the performance of the solver. Moreover, the device is stable, while the original P 5 ordering is often unstable. Numerical results obtained by using the three new devices are presented. The well-known sparse matrices from the Harwell-Boeing set are used in the experiments...|$|E
40|$|The Property and Equipment Department has {{a central}} supply of {{automotive}} parts, tools, and maintenance supplies. This central supply {{is used to}} supply the repair shop and also to supply parts to the various field garages and all departments of the Commission. The old procedure involved keeping track manually {{of all of the}} parts, which involved some 22, 000 items. All records, billings, arid re-order points were kept manually. Mani times the re-order points were located by reaching into a bin and finding nothing there. Desiring to improve this situation, an inventory control system was established for use on the computer. A complete record of the supplies that are stored in the central warehouse was prepared and this information was used to make a catalog. Each time an item is issued or received, it is processed through the inventory program. When the re-order point is reached, a notice is given to <b>reorder.</b> The <b>procedure</b> for taking inventory has been improved. A voucher invoice is now prepared by the computer for all issues to departments. These are some of the many benefits that have been de rived from this system...|$|R
40|$|The {{performance}} of most embedded systems is critically {{dependent on the}} memory hierarchy performance. In particular, higher cache hit rate can provide significant performance boost to an embedded application. Procedure placement is a popular technique that aims to improve instruction cache hit rate by reducing conflicts in the cache through compile/link time <b>reordering</b> of <b>procedures.</b> However, existing procedure placement techniques make reordering decisions based on imprecise conflict information. This imprecision leads to limited and sometimes negative performance gain, specially for set-associative caches. In this paper, we introduce intermediate blocks profile (IBP) to accurately but compactly model cost-benefit of procedure placement for both direct mapped and set associative caches. We propose an efficient algorithm that exploits IBP to place procedures in memory such that cache conflicts are minimized. Experimental results demonstrate that our approach provides substantial improvement in cache performance over existing procedure placement techniques. Furthermore, we observe that the code layout for a specific cache configuration is not portable across different cache configurations. To solve this problem, we propose an algorithm that exploits IBP to place procedures in memory such that the average cache miss rate across a set of cache configurations is minimized...|$|R
40|$|As the {{gap between}} memory and {{processor}} performance continues to grow, it becomes increasingly important to exploit cache memory e ectively. One technique used bycompiler and linkers to improve the performance ofthecache is code reordering. Code reordering optimizations rearrange a program so that sections of the program with temporal locality will be placed {{next to each other}} in the nal program layout. A number of software approaches to code reordering have been proposed. Their goal is to reduce the number of cache line con icts. Most of these schemes use pro le data in order to reposition the code in the address space. In this paper we present a link-time procedure mapping algorithm which uses a call graph constructed without the use of pro le data. We will refer to this scheme as static call graph estimation. In this approach we use program-based heuristics to statically estimate the behavior of the call graph. Then once the estimated weighted call graph is formed, we can employ various procedure remapping algorithms. Our results show that we were able to reduce instruction cache miss rates by 20 % on average when using our estimated static call graph with modern <b>procedure</b> <b>reordering</b> algorithms. ...|$|R

