8|55|Public
30|$|Spatial reuse is the reuse of a {{timeslot}} by simultaneously activated links, {{with sufficient}} SINR, in the spatial domain. Likewise, temporal reuse is defined {{here as the}} reuse of a timeslot {{by a group of}} links in the time domain. A temporal <b>reuse</b> <b>group</b> is the set of outgoing links from a particular node, which may transmit in a certain timeslot. Since a transmission schedule is composed of a T-length frame that is repeated in time, every timeslot in the frame is repeated at frequency 1 /T. This means that the links in a temporal <b>reuse</b> <b>group</b> will share the capacity of a timeslot over all the repetitions of the timeslot in which the temporal <b>reuse</b> <b>group</b> appears. The reuse of a timeslot in the time domain thus refers to a timeslot, at a particular location in the scheduling frame, that is reused by a group of links as the specific timeslot reoccurs with the repetition of the frame in time.|$|E
30|$|In {{the case}} of node-assigned scheduling, each node forms its own {{temporal}} <b>reuse</b> <b>group</b> and secondary scheduling must be executed at each node to service each of the outgoing links of a node. However, temporal reuse groups are prioritised in link-assigned scheduling with extended transmission rights, which makes the schedule completely defined since the secondary scheduling is implied. In addition, by extending a link assignment to a prioritised group of links, the schedule allows {{for the implementation of}} opportunistic network coding, which further improves performance, as in {{the case of}} node-assigned scheduling.|$|E
30|$|The {{purpose of}} a {{transmission}} schedule is to control link transmission powers and rates, regulate medium access and provide adequate capacity for all network traffic. Transmission schedules are predetermined for {{a limited number of}} timeslots, with the frame being repeated in time. The capacity provided during a specific timeslot is defined by the associated link rate vector, which gives the transmission rate for each active link in the spatial <b>reuse</b> <b>group,</b> or clique. The cross-layer optimisation framework in [9] is partly reviewed in this section to make the paper self-contained.|$|E
30|$|The {{number of}} spatial <b>reuse</b> <b>groups</b> is limited for size-constrained fixed-topology networks, and the {{resulting}} link rate vectors are all determined. The accurate temporal reuse-aware link rate vectors are also determinable, {{and the number of}} vectors remains the same. The column generation must therefore end, since the number of link rate vectors is limited. Due to Carathéodory's theorem, there is a high probability that the master problem will converge before all the link rate vectors have been generated. The moment no new link rate vector can increase the capacity supply, the column generation converges.|$|R
3000|$|... {{values in}} the optimal schedule. The exact number of {{utilised}} link rate vectors depends on the specific optimal solution for a particular network. The greater the number of links, the more numerous the possible spatial <b>reuse</b> <b>groups,</b> which increases the number of used link rate vectors. For a proper TDMA (time-division multiple access) schedule, {{it can be seen}} that L link rate vectors would be needed for a feasible solution. When spatial reuse comes into play, less link rate vectors can describe the same capacity of TDMA, so the limit of the number of involved link rate vectors is not exceeded. The delivery route of each data flow is established in the network layer as represented by R, and the flow rates s are regulated in the transport layer.|$|R
40|$|Abstract — Natural organisms {{have to deal}} ef£ciently with {{changing}} environments and are thus {{a great source of}} inspiration to solve dynamic problems in arti£cial domains. Dynamic optimisation has gained a lot of interest lately as many real world problems are indeed dynamic. In this paper, we look at post-transcriptional processes and alternative splicing in particular: Although these biochemical processes are gaining increasing attention from the genetics community, they remain relatively unexplored in evolutionary computation. We suggest a simple abstract encoding that allows one to construct multiple expressions from the same template supporting quick adaptation to changes in the cost surface. This encoding enables the system to £nd, control and <b>reuse</b> <b>groups</b> of building blocks that are being shared by different environments. Tests on a modi£ed version of the dynamic knapsack problem show that it signi£cantly outperforms the canonical genetic algorithm as well as simple implementations of random immigrants and hypermutations. I...|$|R
40|$|ABSTRACT The goal of {{our study}} is to {{evaluate}} the effect on program comprehension of three factors that have not previously been studied in a single experiment. These factors are programmer expertise (expert vs. novice), programming task (documentation vs. reuse), {{and the development of}} understanding over time (phase 1 vs. phase 2). This study is carried out {{in the context of the}} mental model approach to comprehension based on van Dijk and Kintsch's model (1983). One key aspect of this model is the distinction between two kinds of representation the reader might construct from a text: 1) the textbase, which refers to what is said in the text and how it is said, and 2) the situation model, which represents the situation referred to by the text. We have evaluated the effect of the three factors mentioned above on the development of both the textbase (or program model) and the situation model in object-oriented program comprehension. We found a four-way interaction of expertise, phase, task and type of model. For the documentation group we found that experts and novices differ in the elaboration of their situation model but not their program model. There was no interaction of expertise with phase and type of model in the documentation group. For the <b>reuse</b> <b>group,</b> there was a three-way interaction between phase, expertise and type of model. For the novice <b>reuse</b> <b>group,</b> the effect o...|$|E
40|$|Abstract. The goal of {{our study}} is to {{evaluate}} the effect on program comprehension of three factors that have not previously been studied in a single experiment. These factors are programmer expertise (expert versus novice), programming task (documentation versus reuse), {{and the development of}} understanding over time (phase 1 versus phase 2). This study is carried out {{in the context of the}} mental model approach to comprehension based on van Dijk and Kintsch’s model [(1983) Strategies of Discourse Comprehension. New York: Academic]. One key aspect of this model is the distinction between two kinds of representation the reader might construct from a text: (1) the textbase, which refers to what is said in the text and how it is said, and (2) the situation model, which represents the situation referred to by the text. We have evaluated the effect of the three factors mentioned above on the development of both the textbase (or program model) and the situation model in object-oriented program comprehension. We found a four-way interaction of expertise, phase, task and type of model. For the documentation group we found that experts and novices differ in the elaboration of their situation model but not their program model. There was no interaction of expertise with phase and type of model in the documentation group. For the <b>reuse</b> <b>group,</b> there was a three-way interaction between phase, expertise and type of model. For the novice <b>reuse</b> <b>group,</b> the effect of the phase was to increase the construction of the situation model but not the program model...|$|E
40|$|The goal of {{our study}} is to {{evaluate}} the effect on program comprehension of three factors that have not previously been studied in a single experiment. These factors are programmer expertise (expert vs. novice), programming task (documentation vs. reuse), {{and the development of}} understanding over time (phase 1 vs. phase 2). This study is carried out {{in the context of the}} mental model approach to comprehension based on van Dijk and Kintsch's model (1983). One key aspect of this model is the distinction between two kinds of representation the reader might construct from a text: 1) the textbase, which refers to what is said in the text and how it is said, and 2) the situation model, which represents the situation referred to by the text. We have evaluated the effect of the three factors mentioned above on the development of both the textbase (or program model) and the situation model in object-oriented program comprehension. We found a four-way interaction of expertise, phase, task and type of model. For the documentation group we found that experts and novices differ in the elaboration of their situation model but not their program model. There was no interaction of expertise with phase and type of model in the documentation group. For the <b>reuse</b> <b>group,</b> there was a three-way interaction between phase, expertise and type of model. For the novice <b>reuse</b> <b>group,</b> the effect of the phase was to increase the construction of the situation model but not the program model. With respect to the task, our results show that novices do not spontaneously construct a strong situation model but are able to do so if the task demands it...|$|E
40|$|Compiler transformations can {{significantly}} improve data locality of scientific programs. In this paper, {{we examine the}} impact of multi-level caches on data locality optimizations. We find nearly all the benefits can be achieved by simply targeting the L 1 (primary) cache. Most locality transformations are unaffected because they improve reuse for all levels of the cache; however, some optimizations can be enhanced. Inter-variable padding can take advantage of modular arithmetic to eliminate conflict misses and preserve <b>group</b> <b>reuse</b> on multiple cache levels. Loop fusion can balance increasing <b>group</b> <b>reuse</b> for the L 2 (secondary) cache at the expense of losing <b>group</b> <b>reuse</b> at the smaller L 1 cache. Tiling for the L 1 cache also exploits locality available in the L 2 cache. Experiments show enhanced algorithms are able to reduce cache misses, but performance improvements are rarely significant. Our results indicate existing compiler optimizations are usually sufficient to achieve good performance [...] ...|$|R
40|$|A Reuse Enablement System (RES) allows {{developers}} of Earth science software to contribute software for reuse by others and. for users to find, select, and obtain software for reuse {{in their own}} systems. This paper describes work that the X 4 S, 4 Earth Science Data Systems (ESDS) Software <b>Reuse</b> Working <b>Group</b> has completed to date {{in the development of}} an RES for NASA...|$|R
50|$|DLR Group is an {{integrated}} design firm delivering architecture, engineering, interiors, planning, and building optimization for new construction, renovation, and adaptive <b>reuse.</b> DLR <b>Group</b> is a 100 percent employee-owned firm. More than 1,000 employees serve for {{public and private}} sector clients from 27 offices around the world. Core areas of design expertise include Civic, Courts, Detention, Energy Services, Healthcare, Higher Education, Hospitality, K-12 Education, Museums, Performing Arts, Retail/Mixed-Use, Sports, and Workplace.|$|R
40|$|AbstractThere {{is growing}} {{interest}} in the potential of grassroots innovations {{to play a role}} in the transition to sustainable production and consumption systems. However, the role of values has been little considered in relation to the development and diffusion of grassroots innovations. We develop a conceptual model of how citizens' values are mobilised by grassroots innovations, drawing on the value theory of Schwartz et al. (2012) and the theory of collective enactment of values of Chen et al. (2013). Using the results of a large scale survey of free reuse groups (e. g. Freecycle and Freegle), which enable collaborative forms of consumption, we apply the conceptual model to explore how participants' values are mobilised and expressed. We show that while the majority of free <b>reuse</b> <b>group</b> participants do hold significantly stronger self-transcendence (i. e. pro-social) values than the wider UK population, they also hold other values in common with that population and a minority actually place less emphasis on self-transcendence values. We conclude that diffusion of this particular grassroots innovation is unlikely to be simply value limited and that structural features may be more significant...|$|E
50|$|The {{motor and}} battery, {{together}} with comprehensive instructions are included. Only basic hand tools {{are required to}} assemble the kit, which can be dismantled {{at the end of}} the season and <b>reused</b> by another <b>group.</b>|$|R
40|$|Abstract A {{concern is}} {{a unit of}} <b>reuse</b> that <b>groups</b> {{together}} software artifacts describing properties and behaviour related to any domain of interest to a software engineer {{at different levels of}} abstraction. This demonstration illustrates how to specify, design, and reuse concerns with two integrated tools: jUCMNav for feature modelling, goal modelling, and scenario modelling, and TouchRAM for design modelling with class, sequence, and state diagrams, and for code generation. For a demo video see...|$|R
40|$|The present paper reviews {{literature}} on textile wastewater treatment and reuse published {{during the year}} 2004. Particularly, after a general introduction, different alternative technologies employed for textile wastewater treatment and/or <b>reuse</b> are presented <b>grouped</b> into physico-chemical, biological and combined processes...|$|R
40|$|Abstract—This paper {{analyzes}} the carrier-to-interference {{ratio of the}} so-called shotgun cellular system (SCS). In the SCS, basestations are placed randomly according to a two-dimensional Poisson point process. Such a system can model a dense cellular or wireless data network deployment, where the base station locations end up being close to random due to constraints other than optimal coverage. The SCS is a simple cellular system where we can introduce several variations and design scenarios such as shadow fading, power control features, and multiple channel <b>reuse</b> <b>groups,</b> and assess {{their impact on the}} performance. We first derive an analytical expression for the characteristic function of the inverse of the carrier-to-interference ratio. Using this result, we show that the carrier-to-interference ratio is independent of the base station density and further, we derive a semi-analytical expression for the tail-probability. These results enable a complete characterization of the cellular performance of the SCS. Next, we incorporate shadow fading into the SCS and demonstrate that it merely scales the base station density by a constant. Hence, the cellular performance of the SCS is independent of shadow fading. These results are further used to analyze dense cellular scenarios...|$|R
40|$|In this paper, we {{analyze the}} signal-to-interference-plus-noise ratio (SINR) {{performance}} at a mobile station (MS) {{in a random}} cellular network. The cellular network is formed by base-stations (BSs) placed in a one, two or three dimensional space according to a possibly non-homogeneous Poisson point process, which is a generalization of the so-called shotgun cellular system. We develop a sequence of equivalence relations for the SCSs {{and use them to}} derive semi-analytical expressions for the coverage probability at the MS when the transmissions from each BS may be affected by random fading with arbitrary distributions as well as attenuation following arbitrary path-loss models. For homogeneous Poisson point processes in the interference-limited case with power-law path-loss model, we show that the SINR distribution is the same for all fading distributions and is not a function of the base station density. In addition, the influence of random transmission powers, power control, multiple channel <b>reuse</b> <b>groups</b> on the downlink performance are also discussed. The techniques developed for the analysis of SINR have applications beyond cellular networks and can be used in similar studies for cognitive radio networks, femtocell networks and other heterogeneous and multi-tier networks. Comment: 30 pages, 8 figures, re-submitted to Transactions on Communications on Sep- 12 2012, initial submission to Transactions on Communications on 26 -Apr 201...|$|R
40|$|This paper reviews a {{selection}} {{of the literature on}} textile wastewater treatment processes published during the year 2007. After some experiences on quantification of different dyes and toxicity, alternative technologies employed for textile wastewater treatment and/or <b>reuse</b> are presented <b>grouped</b> into physico-chemical, biological and combined processes...|$|R
50|$|The {{building}} design makes it environmentally friendly, using {{technologies such as}} floor-to-ceiling insulated glazing to contain heat and maximize natural light, and an automatic daylight dimming system. The tower also features a greywater system, which captures rainwater for <b>reuse.</b> Kohinoor <b>Group</b> Pvt Ltd. states that the building is made largely of recycled and recyclable materials. Air entering the building is filtered, as is common, but the air exhausted is cleaned as well. The Kohinoor Square Building {{is one of the}} first Skyscraper building in India to achieve a Gold (LEED) Certification from Green Building Council.|$|R
40|$|A {{review of}} the {{literature}} published in 2005 on textiles wastewater treatment and reuse is presented. This review starts with the characterization of some commercial dyes for their contamination and ecotoxicological effects. Then, different alternative technologies employed for textile wastewater treatment and/or <b>reuse</b> are presented <b>grouped</b> into physico-chemical, biological and combined processes...|$|R
40|$|Many cache misses in {{scientific}} programs {{are due to}} conflicts caused by limited set associativity. Two data-layout transformations, inter- and intra-variable padding, can eliminate many conflict misses at compile time. We present GroupPad, an inter-variable padding heuristic to preserve <b>group</b> <b>reuse</b> in stencil computations frequently found {{in scientific}} computations. We show padding can also improve performance in parallel programs. Our optimizations have been implemented and tested on a collection of kernels and programs for different cache and data sizes. Preliminary results demonstrate GroupPad is able to consistently preserve <b>group</b> <b>reuse</b> among the programs evaluated, though execution time improvements are small for actual problem and cache sizes tested. Padding improves performance of parallel versions of programs approximately the same magnitude as sequential {{versions of the same}} program. 1 Introduction Effectively exploiting caches is widely regarded as the key to achieving good [...] ...|$|R
40|$|The present paper reviews a {{selection}} {{of the literature on}} textile wastewater treatment and reuse published during the year 2006. Firstly, a case study of the textile industry is synthetically described, followed by some experiences on dye characterization. Then, different alternative technologies employed for textile wastewater treatment and/or <b>reuse</b> are presented <b>grouped</b> into physico-chemical, biological and combined processes...|$|R
40|$|The {{purpose of}} the study was to {{investigate}} the effect of recasting Ti- 6 Al- 4 V on the marginal accuracy and internal fit of complete cast crowns. Ti- 6 Al- 4 V was used to cast 18 single crowns, six of each group. Three groups of Ti- 6 Al- 4 V ingots were tested. The first group was as received from manufacturer, second group was a mixture (1 : 1 ratio) of as received and the alloy that was once used and the last group was an alloy used once (recast). A travelling microscope was used to measure the marginal and internal gaps between the metal die and the casting. The fitting discrepancies were analyzed with a 1 -way ANOVA and Tukey’s multiple range (α=. 05). The lowest mean marginal gap was recorded for the as-received (36. 87 im) and the highest was for the 100 % reused (39. 24 im). However, these differences were not statistically significant (P= 0. 192). For the internal fitting, no significant difference was shown between as-received and 50 % <b>reused</b> <b>groups</b> (P> 0. 91). Yet, the alloys in both the groups showed gaps that were significantly smaller than the 100 % reused alloy (P< 0. 002). Used Ti- 6 Al- 4 V metals could be melted and utilized again for casting single crowns. As-received and 50 % reused metals demonstrated better internal fit than the 100 % reused metals. King Saud Universit...|$|R
40|$|Abstract. Hierarchical state {{machines}} {{is a popular}} visual formalism for software specifications. To apply automated analysis to such specifications, the traditional approach is to compile them to existing model checkers. Aimed at exploiting the modular structure more effectively, our approach is to develop algorithms that work directly on the hierarchical structure. First, we report on an implementation of a visual hierarchical language with modular features such as nested modes, variable scoping, mode <b>reuse,</b> exceptions, <b>group</b> transitions, and history. Then, we identify a variety of heuristics to exploit these modular features during reachability analysis. We report on an enumerative {{as well as a}} symbolic checker, and case studies. ...|$|R
3000|$|Another {{interesting}} {{observation is}} that malicious content is also extensively shared across different Bars. To understand such content <b>reuse,</b> we <b>grouped</b> the malicious programs retrieved from different Bars {{based on the}} similarity of their code in terms of edit distance. Specifically, we removed the spaces within the pro- grams and ran the Python library scipy.cluster.hierarchy.linkage (Scipy 2015) to hierarchically cluster them (now {{in the form of}} strings) according to their Jaro scores (Cohen et al. 2003). In this way, we were able to discover three types of content sharing: intra-bucket sharing, cross-bucket sharing, and cross-platform sharing. Specifically, within the Amazon bucket akamaihd.net_asrv-a, we found that many of its cloud URLs are in the form of [...]...|$|R
40|$|The NASA Earth Science Data Systems (ESDS) Software <b>Reuse</b> Working <b>Group</b> (SRWG) is {{chartered}} {{with the}} investigation, production, {{and dissemination of}} information related to the reuse of NASA Earth science software assets. One major current objective is to engage the NASA decadal missions in areas relevant to software reuse. In this paper {{we report on the}} current status of these activities. First, we provide some background on the SRWG in general and then discuss the group s flagship recommendation, the NASA Reuse Readiness Levels (RRLs). We continue by describing areas in which mission software may be reused in the context of NASA decadal missions. We conclude the paper with pointers to future directions...|$|R
40|$|Background: Endobronchial {{ultrasound}} (EBUS) -guided transbronchial needle aspiration (TBNA) {{requires a}} dedicated needle for aspiration of mediastinal lesions. There is no data on reuse of these needles. Methods: This is a retrospective study {{of patients who}} underwent EBUS-TBNA with either new or reused EBUS-TBNA needles. The needles were reused after thorough cleaning with filtered water and organic cleaning solution, disinfection with 2. 4 % glutaraldehyde solution followed by ethylene oxide sterilization. The yield of EBUS-TBNA was compared between the two groups. Results: A total of 500 EBUS-TBNA procedures (351 new, 149 reused needles) were performed. The baseline characteristics were different {{in the two groups}} with suspected granulomatous disorders (sarcoidosis or tuberculosis) being significantly more common in the new compared to the <b>reused</b> needle <b>group.</b> Similarly, the median, interquartile range number of lymph node stations sampled, and the total number of passes were significantly higher in the new versus the <b>reused</b> needle <b>group.</b> The diagnostic yield was significantly higher with new needle as compared to reused needle (65. 2 % vs. 53. 7 %, P = 0. 02). On multivariate logistic regression analysis, clinical suspicion of granulomatous disorders (odds ratio 1. 86 [95 % confidence interval, 1. 20 - 2. 87], P = 0. 005) was the only predictor of diagnostic yield, after adjusting for the type of needle (new or reused), total number of passes and the number of lymph node stations sampled. No case of mediastinitis was encountered in either group. Conclusions: The yield of EBUS-TBNA might be similar with single reuse of needles as compared to new needles. However, reuse of needle should be performed only when absolutely necessary...|$|R
40|$|Roost {{availability}} {{may limit}} some bat populations, implying {{that there may}} be a selective advantage associated with the ability to reuse sites on an annual basis. We monitored aspen tree use by Eptesicus fuscus during multi-year studies (spanning up to 10 years) at the same site in Saskatchewan, Canada. We found that reuse of live trees over the medium-term (three years) was common and that, in some instances, reuse over the long-term (nine and 10 years) can occur. Our data also suggest that, over the medium-term, aspen roosts are <b>reused</b> by <b>groups</b> of bats more often than by solitary individuals. Our findings support the hypothesis that cavity roosting bats exhibit between year loyalty, not just to patches of forest but also to specific trees...|$|R
30|$|This paper {{presents}} a deep-dive {{examination of the}} cross-boundary data practices {{of natural resources and}} environmental scientists in the context of Virginia Tech’s institutional visioning and strategic development efforts. The goal is to understand scientists’ actual data information behaviors, their communication and exchange dynamics, and their knowledge discovery mechanisms for effective and productive data sharing and <b>reuse.</b> A focus <b>group</b> and multiple individual interviews were conducted using critical incident, story telling, and scenario building techniques.|$|R
40|$|AbstractÐThis paper aims at {{identifying}} {{some of the}} {{key factors}} in adopting or running a company-wide software reuse program. Key factors are derived from empirical evidence of reuse practices, as emerged from a survey of projects for the introduction of reuse in European companies: 24 such projects performed from 1994 to 1997 were analyzed using structured interviews. The projects were undertaken in both large and small companies, working in a variety of business domains, and using both object-oriented and procedural development approaches. Most of them produce software with high commonality between applications, and have at least reasonably mature processes. Despite that apparent potential for success, around one-third of the projects failed. Three main causes of failure were not introducing reuse-specific processes, not modifying nonreuse processes, and not considering human factors. The root cause was a lack of commitment by top management, or nonawareness of the importance of those factors, often coupled with the belief that using the object-oriented approach or setting up a repository seamlessly is all that is necessary to achieve success in reuse. Conversely, successes were achieved when, given a potential for reuse because of commonality among applications, management committed to introducing reuse processes, modifying nonreuse processes, and addressing human factors. While addressing those three issues turned out to be essential, the lower-level details of how to address them varied greatly: for instance, companies produced large-grained or small-grained reusable assets, did or did not perform domain analysis, did or did not use dedicated <b>reuse</b> <b>groups,</b> used specific tools for the repository or no tools. As far as these choices are concerned, the key point seems to be the sustainability of the approach and its suitability to the context of the company. Index TermsÐSurvey, software reuse, empirical study. ...|$|R
40|$|To meet {{a variety}} of needs in {{information}} modeling, software development and integration as well as knowledge management and <b>reuse,</b> various <b>groups</b> within industry, academia, and government have been developing and deploying sharable and reusable models known as ontologies. Ontologies {{play an important role}} in knowledge representation. In this paper, we address the problem of capturing knowledge needed for indexing and retrieving art resources. We describe a case study in which we attempt to construct an ontology for a subset of art. The aim of the present ontology is to build an extensible repository of knowledge and information about artists, their works and materials used in artistic creations. Influenced by the recent interest in colours and colouring materials, mainly shared by French researchers and linguists, an ontology prototype has been developed using Protégé. It allows to organize and catalogue information about artists, art works, colouring materials and related colours. 1...|$|R
40|$|Scalable formal {{analysis}} of reactive programs demands integration of modular reasoning techniques with existing analysis tools. Modular reasoning principles such as abstraction, compositional refinement, and assume-guarantee reasoning are well understood for architectural hierarchy {{that describes the}} communication structure between component processes, and {{have been shown to}} be useful. In this paper, we develop the theory of modular reasoning for behavior hierarchy that describes control structure using hierarchic modes. From Statecharts to UML, behavior hierarchy has been an integral component of many software design languages, but only syntactically. Wepresentthehierarchic reactive modules language that retains powerful features such as nested modes, mode <b>reuse,</b> exceptions, <b>group</b> transitions, history, and conjunctive modes, and yet has a semantic notion of mode hierarchy. We present an observational trace semantics for modes that provides the basis for mode refinement. We show the refinement to be compositional with respect to the mode constructors, and develop an assume-guarantee reasoning principle...|$|R
40|$|The Space Station Freedom Program (SSFP) Level 2 Software <b>Reuse</b> Study <b>group</b> {{was formed}} by Bob Nelson (NASA SSFP) {{from members of the}} Information Systems Program Support Contract (PSC) team. The {{objectives}} of the study were to identify existing software reuse libraries, to identify existing reusability processes and experiences, to identify reusability analysis tools and users, and to provide recommendations for a software reusability process for the SSFP. To date the following have been delivered: (1) definitions of commonality and reuse, (2) a report on existing software reuse libraries and library management systems, (3) a report on reuse process and methodology gleaned from software reuse experts, and (4) a report on software attributes for measuring commonality and reusability. Three implementation alternatives for a repository of reusable components were identified: centralized at the SSE Development Facility (SSEDF), a distributed approach across the network of Software Production Facilities, and a directory approach. A number of findings from the reuse study and several reuse strategy considerations were presented...|$|R
40|$|Reusable {{learning}} objects {{can play an}} important part in enhancing interprofessional learning. They provide flexible support to students of health care and provide an opportunity during the creation process, for interprofessional educators to share knowledge and understand more about each other’s roles. When creating {{learning objects}}, a development and evaluation framework including technical expertise and quality control at critical stages is important, however it is the interprofessional community brought together at workshops {{at the start of the}} development cycle and the underlying pedagogical design principles that ensure the materials are fit for purpose and guarantee <b>reuse</b> across professional <b>groups...</b>|$|R
30|$|The most {{influential}} complication in distributed trust management {{is how to}} collaborate the observations from multiple sources to calculate the trust of any node. The primary intention of the proposed work is to adapt the dynamic topology with a hybrid trust management mechanism. The trust establishment maintains the self-organizing property with no trust agent involved in trust calculation. This is attained by incorporating the direct trust measurements and the recommendations obtained from the cluster members. The direct trust is evaluated and verified using Bayesian theory, whereas the indirect trust is calculated by the Dempster-Shafer (DS) evidence theory which combines recommendations obtained from various neighbouring nodes. The observations in the proposed scheme are taken as evidences on the node behaviour. We {{make use of the}} well-established mathematical structure called Voronoi diagram to overwhelm the neighbour-searching problem and to reduce the distance computation complexities. Unlike the traditional circular clusters, a regular hexagonal shape is constructed with improved spatial <b>reuse</b> to <b>group</b> the MANET area into adjacent, non-overlapping clusters of nodes. The proposed trust-based clusters guarantees improved performance with dynamic re-configurability, scalability and security.|$|R
