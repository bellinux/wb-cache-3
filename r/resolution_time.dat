471|9668|Public
50|$|Problem Management works {{together}} with Incident Management and Change Management {{to ensure that}} IT service availability and quality are increased. When incidents are resolved, information about the resolution is recorded. Over time, this information is used {{to speed up the}} <b>resolution</b> <b>time</b> and identify permanent solutions, reducing the number and <b>resolution</b> <b>time</b> of incidents. This results in less downtime and less disruption to business critical systems.|$|E
5000|$|To {{review the}} {{existing}} mechanism of dispute <b>resolution,</b> <b>time</b> involved for resolution, and compliance cost and recommend measures for strengthening the process. This includes {{domestic and international}} taxation.|$|E
50|$|As a time-frequency representation, the {{spectrogram}} hasrelatively poor <b>resolution.</b> <b>Time</b> {{and frequency}} resolutionare {{governed by the}} choice of analysis window and greaterconcentration in one domain is accompanied by greatersmearing in the other.|$|E
50|$|One of {{the pitfalls}} of the STFT {{is that it has}} a fixed resolution. The width of the {{windowing}} function relates to how the signal is represented—it determines whether there is good frequency resolution (frequency components close together can be separated) or good <b>time</b> <b>resolution</b> (the <b>time</b> at which frequencies change). A wide window gives better frequency <b>resolution</b> but poor <b>time</b> <b>resolution.</b> A narrower window gives good <b>time</b> <b>resolution</b> but poor frequency resolution. These are called narrowband and wideband transforms, respectively.|$|R
30|$|The {{time delays}} for an indoor {{environment}} are extremely small (few milliseconds), where {{the source and}} the microphones lie close to each other. In this case, accurate TDE requires high <b>time</b> <b>resolution</b> (low sampling <b>time).</b> The proposed method reconstructs a sparse RIR signal using signal statistics, sparsity information, and the problem structure. Although decreasing the number of measurements (sampling rate) makes the RIR estimation less accurate, this does not decrease the <b>time</b> <b>resolution.</b> In contrast, CC-based TDE method depends largely on the sampling rate. At low sampling rates, the <b>time</b> <b>resolution</b> (large sampling <b>time)</b> becomes poor which {{makes it hard to}} find the correlation peak close to the true time delay.|$|R
50|$|Adaptive Gabor {{representation}} (AGR) is a Gabor {{representation of}} a signal where its variance is adjustable. There's always a trade-off between <b>time</b> <b>resolution</b> and frequency resolution in traditional short-time Fourier transform (STFT). A long window leads to high frequency <b>resolution</b> and low <b>time</b> <b>resolution.</b> On the other hand, high <b>time</b> <b>resolution</b> requires shorter window, with the expense of low frequency resolution. By choosing the proper elementary function for signal with different spectrum structure, adaptive Gabor representation is able to accommodate both narrowband and wideband signal.|$|R
50|$|In {{addition}} to these, KE has also introduced Mobile IBCs especially in under-privileged areas for on-spot bill-payment facilities {{and distribution of}} low-cost meters among people. It has ensured a quick <b>resolution</b> <b>time</b> and received great response from consumers.|$|E
50|$|When two auto MDI-X ports are {{connected}} together, which is normal for modern products, the algorithm <b>resolution</b> <b>time</b> is typically < 500 ms. However, a ~1.4 second asynchronous timer {{is used to}} resolve the extremely rare case (with a probability of less than 1 in 5×1021) of a loop where each end keeps switching.|$|E
50|$|Total Problem Resolution: {{percentage}} of time {{the problem has been}} completely resolved from the customer point of view. This KPI is mostly used for: Operational Excellence. This keeps troubleshooting time to a minimum, which, according to industry averages, currently accounts for as much as 80 percent of total problem <b>resolution</b> <b>time,</b> and gets the problem fixed.|$|E
40|$|Abstract—This paper {{deals with}} the {{analysis}} of PQ abnormalities using Hilbert–Huang Transform (HHT). HHT {{can be applied to}} both non-stationary as well as non-linear signals and it provides the energy-frequency-time representation of the signal. HHT is a time–frequency analysis method having low order of complexity and does not include the frequency <b>resolution</b> and <b>time</b> <b>resolution</b> fundamentals. So, {{it has the potential to}} outperform the frequency <b>resolution</b> and <b>time</b> <b>resolution</b> based methods. Several cases have been considered to present the efficiency of HHT. For the case study, various PQ abnormalities like voltage sag, swell and harmonics with sag are considered. These PQ abnormalities are subjected to HHT and the results are shown in the form of IMFs, instantaneous frequency, absolute value, phase and Hilbert Huang Spectrum. The results shows that the HHT performs better than the any other <b>time</b> <b>resolution</b> and frequency resolution based methods...|$|R
40|$|Phase transitions, {{ubiquitous}} in condensedmatter physics, are encounteredin computer science too. The existence of critical phenomena has deep consequences on computational complexity, {{that is the}} <b>resolution</b> <b>times</b> of various optimization or decision problems. Concepts and methods borrowedfrom the statistical physics of disorderedandout-of-equilibrium systems shed {{new light on the}} dynamical operation of solving algorithms. c # 20 T Publishedby Elsevier Science B. V...|$|R
50|$|Among the {{advantages}} of Fourier ptychography {{is the ability to}} use imaging optics with a lower numerical aperture, hence improving the depth of focus, the working distance, {{and the size of the}} field of view. It also allows for the numerical correction of lens aberrations, leading to a very large effective space-bandwidth product (the <b>resolution</b> <b>times</b> exploitable size of an image).|$|R
5000|$|In older {{versions}} of POSIX.1 standard, the time-related fields {{were defined as}} , [...] and , and were of type [...] Since the 2008 version of the standard, these fields were renamed to , [...] and , respectively, of type struct , since this structure provides a higher <b>resolution</b> <b>time</b> unit. For the sake of compatibility, implementations can define the old names {{in terms of the}} [...] member of [...] For example, [...] can be defined as [...]|$|E
5000|$|A cut in {{the segment}} 4 of South East Asia-Middle East-Western Europe 4 (SEA-ME-WE 4) {{submarine}} optical fiber cable on Wednesday morning (27 March 2013) has been reported leading to a degradation of internet speed by 60% in several countries including Pakistan and Egypt. A consortium of SEA-ME-WE-4 Cable System {{is working on the}} fault but they have not come up with a <b>resolution</b> <b>time</b> for this problem and confirmed nature of fault is yet to be determined ...|$|E
50|$|Just as a TDC may use {{interpolation}} to get finer {{than one}} clock period resolution, a delay generator may use similar techniques. The Hewlett-Packard 5359A High <b>Resolution</b> <b>Time</b> Synthesizer provides delays of 0 to 160 ms, has an accuracy of 1 ns, and achieves a typical jitter of 100 ps. The design uses a triggered phase-locked oscillator that runs at 200 MHz. Interpolation {{is done with}} a ramp, an 8-bit digital-to-analog converter, and a comparator. The resolution is about 45 ps.|$|E
40|$|We derive {{expressions}} for the <b>time</b> <b>resolution</b> {{of silicon}} detectors, using the Landau theory and a PAI model for describing the charge deposit of high energy particles. First {{we use the}} centroid time of the induced signal and derive analytic expressions for the three components contributing to the <b>time</b> <b>resolution,</b> namely charge deposit fluctuations, noise and fluctuations of the signal shape due to weighting field variations. Then we derive expressions for the <b>time</b> <b>resolution</b> using leading edge discrimination of the signal for various electronics shaping <b>times.</b> <b>Time</b> <b>resolution</b> of silicon detectors with internal gain is discussed as well...|$|R
40|$|In this paper, {{we present}} the {{comparison}} of note events extraction using Nonnegative Matrix Factorization (NMF) with input from a classic Fourier Transform (FT) and with input from an improved <b>time</b> <b>resolution</b> FT. In order to improve <b>time</b> <b>resolution,</b> FT sample window length must be increased. As the window length increases, the <b>time</b> <b>resolution</b> is sacrificed for a better frequency <b>resolution.</b> Hence, good <b>time</b> and frequency <b>resolutions</b> are required in our polyphonic music transcription task. Here, we first apply Zero padding algorithm to classic FT to help maintain the <b>time</b> and frequency <b>resolution.</b> Then, we apply the hanning window. Finally we use NW to decompose the note events. The experiment shows that NW performs the decomposition of multivariate nonnegative data matrix well after applying the improved <b>time</b> <b>resolution</b> FT...|$|R
25|$|In signal {{processing}} terms, a function (of time) is {{a representation of}} a signal with perfect <b>time</b> <b>resolution,</b> but no frequency information, while the Fourier transform has perfect frequency <b>resolution,</b> but no <b>time</b> information.|$|R
5000|$|Most {{general-purpose}} computing systems {{rely heavily}} upon interrupts. A pure interrupt {{system may be}} possible, though usually some component of polling is also required, as it is very common for multiple potential sources of interrupts to share a common interrupt signal line, in which case polling is used within the device driver to resolve the actual source. (This <b>resolution</b> <b>time</b> also contributes to an interrupt system's performance penalty. Over the years {{a great deal of}} work has been done to try to minimize the overhead associated with servicing an interrupt. Current interrupt systems are rather lackadaisical when compared to some highly tuned earlier ones, but the general increase in hardware performance has greatly mitigated this.) ...|$|E
50|$|One of {{the major}} criticisms {{levelled}} at NIE during the Boxing Day Storm, was the inability of customers to obtain up-to-date and accurate information on the expected <b>resolution</b> <b>time</b> of faults, {{and in many cases}} customers simply could not contact the company at all. To prevent this from happening again, NIE have retained Eckoh plc to provide the High Availability Call Answering system (HVCA) from Twenty First Century Communications. This system automatically directs callers to an automated IVR system when all of the company's call handlers are unavailable. This system captures information from the caller to identify their premises, and automatically links them to a known fault if possible. Once tagged to a fault, the customer is provided up-to-date status information by the automated system.|$|E
50|$|Each {{nanolithography}} {{technique has}} varying factors of <b>resolution,</b> <b>time</b> consumption, and cost. There are three basic methods used by nanolithography. One involves using a resist material which {{acts as a}} “mask” to cover and protect {{the areas of the}} surface that are intended to be smooth. The uncovered portions can now be etched away, with the protective material acting as a stencil. The second method involves directly carving the desired pattern. Etching may involve using a beam of quantum particles, such as electrons or light, or chemical methods such as oxidation or SAM’s (self-assembled monolayers). The third method places the desired pattern directly on the surface, producing a final product that is ultimately a few nanometers thicker than the original surface. In order to visualize the surface to be fabricated, the surface must be visualized by a nano-resolution microscope, which include the scanning probe microscope (SPM) and the atomic force microscope (AFM). Both microscopes can also be engaged in processing the final product.|$|E
30|$|In general, satellite-derived {{databases}} {{are characterized}} by several criteria, e.g., [18, 19] input and output data, spatial and <b>time</b> <b>resolution,</b> period of <b>time,</b> methods for the computation, and the algorithm used for the simulation.|$|R
50|$|In signal {{processing}} terms, a function (of time) is {{a representation of}} a signal with perfect <b>time</b> <b>resolution,</b> but no frequency information, while the Fourier transform has perfect frequency <b>resolution,</b> but no <b>time</b> information.|$|R
40|$|Let $X$ be {{a smooth}} scheme with an action of a reductive {{algebraic}} group $G$ over an algebraically closed field $k$ of characteristic zero. We construct an {{action of the}} extended affine Braid group on the $G$-equivariant absolute derived category of matrix factorizations on the Grothendieck variety times $T^*X$ with potential given by the Grothendieck-Springer <b>resolution</b> <b>times</b> the moment map composed with the natural pairing. Comment: 25 page...|$|R
5000|$|In {{terms of}} {{standards}} and other timing or network access protocols such as NTP or CDMA2000, the quality and enforcement of NITZ is weak. This standard allows the network to [...] "transfer its current identity, universal time, DST and LTZ" [...] but each is optional, and support across RAN vendor and operator varies. This presents a problem for device manufacturers, who are required to maintain a complex timezone database, rather than rely on the network operator. Additionally, unlike 3GPP2, which transmits GPS-sourced, millisecond <b>resolution</b> <b>time</b> via the sync channel, for NITZ, the [...] "accuracy of the time information is {{in the order of}} minutes". [...] The optional nature of the delivery mechanism results in issues for users in regions that don't practice daylight savings but which share a time zone with a region that does.Most modern handsets have their own internal time zone software and will automatically perform a daylight savings advance.Because the NITZ delivery is not usually periodic but dependent on the handset crossing radio network boundaries, these handsets can be displaying incorrect time for many hours or even days before a NITZ update arrives and corrects them.|$|E
50|$|REXIS is a coded {{aperture}} soft X-ray (0.3-7.5 keV) telescope that images X-ray fluorescence line emission {{produced by}} the interaction of solar X-rays and the solar wind with the regolith of Bennu. Images are formed with 21 arcminute resolution (4.3 m spatial resolution {{at a distance of}} 700 m). Imaging is achieved by correlating the detected X-ray image with a 64 x 64 element random mask (1.536 mm pixels). REXIS will store each X-ray event data in order to maximize the data storage usage and to minimize the risk. The pixels will be addressed in 64 x 64 bins and the 0.3-7.5 keV range will be covered by five broad bands and 11 narrow line bands. A 24 s <b>resolution</b> <b>time</b> tag will be interleaved with the event data to account for Bennu rotation. Images will be reconstructed on the ground after downlink of the event list. Images are formed simultaneously in 16 energy bands centered on the dominant lines of abundant surface elements from O-K (0.5 keV) to Fe-Kß (7 keV) as well the representative continuum. During orbital phase 5B, a 21-day orbit 700 m from the surface of Bennu, a total of at least 133 events/asteroid pixel/energy band are expected under 2 keV; enough to obtain significant constraints on element abundances at scales larger than 10 m.|$|E
40|$|This thesis {{explores the}} {{importance}} of affectiveness in predicting issue <b>resolution</b> <b>time</b> and analyses the contribution of subsets of all the features earlier suggested to predict the same. We find that, unlike prior studies, affectiveness is not usually {{a significant factor in}} predicting issue <b>resolution</b> <b>time...</b>|$|E
40|$|Responses {{from one}} manual and four {{automatic}} gamma counters for assaying 125 I were compared. The <b>resolution</b> <b>times</b> quoted by manufacturers when applied in a standardized correction formula to obtain true counts from observed counting rates above 104 counts per second {{appeared to be}} inadequate. The need to investigate the errors associated with high counting rates for all instruments and electronic settings employed to determine 125 I in radioimmunoassays is emphasized...|$|R
40|$|Cherenkov {{radiators}} {{based on}} Silica aerogel {{are used to}} measure the electron bunch length at the photo injector test facility at DESY Zeuthen (PITZ). The energy range of those electrons is 4 - 5 MeV. In this paper the <b>time</b> <b>resolution</b> defined by the usage of aerogel is calculated analytically and Monte Carlo simulations are performed. It is shown that Silica aerogel gives the possibility to reach a <b>time</b> <b>resolution</b> of about 0. 1 ps for high photon intensities and a <b>time</b> <b>resolution</b> of about 0. 02 ps can be obtained for thin Silica aerogel radiators. Key words: silica aerogel, bunch length, <b>time</b> <b>resolution,</b> PITZ...|$|R
30|$|Fine <b>time</b> <b>resolution</b> of the OFA {{is another}} {{feature of the}} PWE. We {{nominally}} operate the OFA with a <b>time</b> <b>resolution</b> of 1  s. This <b>time</b> <b>resolution</b> is sufficient to distinguish the chorus emission from the other plasma waves, even though the time variation of OFA spectra data does not correspond to each chorus element. This feature is also very important in the data selection process described in “Onboard data processing and data reduction” section.|$|R
40|$|An {{automatic}} {{decade scaler}} which operates for a fixed number of counts {{has been developed}} for use with a Geiger tube. The elapsed counting time is read by a 115 V AC clock to 0. 01 minute. Manual operation is provided to allow the scaler to be run for a fixed time interval in which case every 10, 000 counts are recorded by a Cyclotron recording meter. The instrument has a two pulse <b>resolution</b> <b>time</b> of 25 microseconds. Four decades in cascade {{are used in the}} scaler, one of which has a <b>resolution</b> <b>time</b> of 8 microseconds; the other three, a <b>resolution</b> <b>time</b> of 30 microseconds. Ten neon bulbs are used in each decade to indicate the count. An automatic decade scaler which operates for a fixed number of counts has been developed for use with a Geiger tube. The elapsed counting time is read by a 115 V AC clock to 0. 01 minute. Manual operation is provided to allow the scaler to be run for a fixed time interval in which case every 10, 000 counts are recorded by a Cyclotron recording meter. The instrument has a two pulse <b>resolution</b> <b>time</b> of 25 microseconds. Four decades in cascade are used in the scaler, one of which has a <b>resolution</b> <b>time</b> of 8 microseconds; the other three, a <b>resolution</b> <b>time</b> of 30 microseconds. Ten neon bulbs are used in each decade to indicate the count. Mode of access: Internet...|$|E
40|$|Abstract: Domain name system (DNS) is {{a primary}} {{identification}} mechanism for Internet applications. However, DNS resolutions often take an unbearably long time, and this could seriously im-pair {{the consistency of the}} service quality of Internet applications based on DNS such as World Wide Web. Several approaches re-duce DNS <b>resolution</b> <b>time</b> by proactively refreshing expired cached records or prefetching available records beforehand, but these ap-proaches have an inherent problem in that they cause additional DNS traffic. In this paper, we propose a DNS <b>resolution</b> <b>time</b> re-duction scheme, named renewal using piggyback (RUP), which re-freshes expired cached records by piggybacking them onto solicited DNS queries instead of by issuing additional DNS queries. This method decreases both DNS <b>resolution</b> <b>time</b> and DNS traffic since it reduces the number of queries generated to handle a given DNS resolution without generating additional DNS messages. Simula-tion results based on two large independent DNS traces show that our proposed approach much reduces not only the DNS <b>resolution</b> <b>time</b> but also the DNS traffic...|$|E
30|$|In the 2013 <b>Resolution</b> <b>time</b> spent {{travelling}} to {{and from}} work is excluded from both employment and OUP activities.|$|E
40|$|We {{present results}} of {{simulations}} on {{the influence of}} photon propagation and the Cherenkov effect on the <b>time</b> <b>resolution</b> of LSO:Ce scintillators. The influence of the scintillator length on the coincidence <b>time</b> <b>resolution</b> is shown. Furthermore, the impact of the depth of interaction on the <b>time</b> <b>resolution,</b> the light output and the arrival time distribution at the photon detector is simulated and it is shown how these information can be used for time walk correction...|$|R
40|$|In this paper, {{we propose}} near {{admissible}} multiobjective search algorithms to approximate, with performance guarantee, {{the set of}} Pareto optimal solution paths in a state space graph. Approximation of Pareto optimality relies {{on the use of}} an epsilon-dominance relation between vectors, significantly narrowing the set of nondominated solutions. We establish correctness of the proposed algorithms, and discuss computational complexity issues. We present numerical experimentations, showing that approximation significantly improves <b>resolution</b> <b>times</b> in multiobjective search problems...|$|R
40|$|We {{address the}} issue whether Single-Photon Avalanche Diodes (SPADs) can be {{suitably}} designed to achieve a trade-off between quantum efficiency and <b>time</b> <b>resolution</b> performance. We briefly recall the physical mechanisms setting the <b>time</b> <b>resolution</b> of avalanche photodiodes operated in single-photon counting, and we give some criteria {{for the design of}} SPADs with a quantum efficiency better than l 0 percent at 1064 nm together with a <b>time</b> <b>resolution</b> below 50 ps rms...|$|R
