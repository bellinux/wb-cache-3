234|1111|Public
2500|$|A more {{quantitative}} analysis of LEED experimental {{data can be}} achieved by analysis of so-called I-V curves, which are measurements of the intensity versus incident electron energy. The I-V curves can be recorded by using a camera connected to computer controlled data handling or by direct measurement with a movable Faraday cup. The experimental curves are then compared to computer calculations based on the assumption of a particular model system. The model is changed in an iterative process until a satisfactory agreement between experimental and theoretical curves is achieved. A quantitative measure for this agreement is the so-called reliability- or R-factor. A commonly used <b>reliability</b> <b>factor</b> is the one proposed by Pendry. It is expressed in terms of the logarithmic derivative of the intensity: ...|$|E
5000|$|In crystallography, the R-factor (sometimes called {{residual}} factor or <b>reliability</b> <b>factor</b> or the R-value or RWork) is {{a measure}} of the agreement between the crystallographic model and the experimental X-ray diffraction data. In other words, it {{is a measure}} of how well the refined structure predicts the observed data. The value is also sometimes called the discrepancy index, as it mathematically describes the difference between the experimental observations and the ideal calculated values. It is defined by the following equation: ...|$|E
5000|$|A more {{quantitative}} analysis of LEED experimental {{data can be}} achieved by analysis of so-called I-V curves, which are measurements of the intensity versus incident electron energy. The I-V curves can be recorded by using a camera connected to computer controlled data handling or by direct measurement with a movable Faraday cup. The experimental curves are then compared to computer calculations based on the assumption of a particular model system. The model is changed in an iterative process until a satisfactory agreement between experimental and theoretical curves is achieved. A quantitative measure for this agreement is the so-called reliability- or R-factor. A commonly used <b>reliability</b> <b>factor</b> is the one proposed by Pendry. It is expressed in terms of the logarithmic derivative of the intensity: ...|$|E
40|$|This paper {{evaluates the}} {{accuracy}} of Bayesian classifiers using <b>reliability</b> <b>factors</b> estimated by the entropy of image inter-class Bhattacharyya distance. The {{results show that the}} use of <b>reliability</b> <b>factors</b> improves {{the accuracy of}} the classifier in comparison with a standard Bayesian classifier (the Cascade Classifier in this case). When compared to exhaustive evaluation, the entropy estimated <b>reliability</b> <b>factors</b> lies within 3 % from the best results. Pages: 5965 - 597...|$|R
40|$|Abstract. According to {{the status}} of the lack of {{reliability}} data for MEMS fuze, this paper mainly studied the <b>reliability</b> <b>factors</b> of MEMS Safety and Arming System by using Dynamic simulation method. Through simulation analysis, the mainly <b>reliability</b> <b>factors,</b> weakness and potential failure modes of MEMS Safety and Arming System can be obtained, which can provide theory reference and data support for the design and application of the MEMS Safety and Arming System...|$|R
40|$|This {{article is}} one of few {{attempts}} to get insights into business robustness metrics with a systemic approach based on improved corporate structure of construction companies. With a systemic out look, this article sets out a concept of “reliability system” as unbiased description of the system’s organizational structure, highlights organizational, process flow, financial and economic, {{as well as social}} and HR systemic (internal) <b>reliability</b> <b>factors</b> of corporate structure functioning. The article also offers a technique focused on the practical use of the laid down principles of business reliability metrics {{based on the assumption that}} an absolutely robust company in a sample is the one with <b>reliability</b> <b>factors</b> not lower than the average for this sample. In order to apply the described technique, this article summarizes indicators divided into groups of <b>reliability</b> <b>factors...</b>|$|R
50|$|Hermes was envisaged to be {{launched}} using the Ariane 5, replacing the upper stage of the latter during such missions, and would have detached from the launcher towards {{the latter part of}} the ascent. Hermes consisted of two separate sections: the vehicle itself and a cone-shaped Resource Module, the latter was to have been attached to the vehicle's rear and would have been detached and discarded prior to re-entry. Only the manned vehicle would re-enter Earth's atmosphere and be re-used, both the Resource Module and the launcher would be expended. When operated in conjunction with Hermes, the Ariane 5 would have had its upper stage entirely replaced to accommodate both the space plane and an adaptor to mate the vehicle with the main cryogenic stage, the equipment bay of the launcher would also be absent while the space plane itself would perform all guidance and control functions. The development and configuration of the Ariane 5 was strongly influenced by the requirements of Hermes, such as the extra aerodynamic loads that it would have imposed along with the elevated <b>reliability</b> <b>factor</b> of 0.9999, while retaining minimal impact on the launcher's commercial competitiveness on non-Hermes missions.|$|E
40|$|The turbo {{detection}} of turbo coded symbols over correlated Rayleigh flat fading channels generatedaccording to Jakes’ model is considered in this paper. We propose {{a method to}} estimate the channelsignal-to-noise ratio (SNR) and the maximum Doppler frequency. These statistics are required bythe linear minimum mean squared error (LMMSE) channel estimator. To improve the system convergence,we redefine the channel <b>reliability</b> <b>factor</b> by {{taking into account the}} channel estimationerror statistics. Simulation results for rate 1 = 3 turbo code and two different normalized fading ratesshow that the use of the new <b>reliability</b> <b>factor</b> greatly improves the performance. The improvementis more substantial when channel statistics are unknown...|$|E
30|$|The <b>reliability</b> <b>factor</b> {{is adapted}} {{to the purpose of}} the {{application}}. This application can be a post-production with a high ITF value and a lower realism or the opposite situation, for real-time video stabilization used in tele-operation systems.|$|E
40|$|Component Based Software Engineering {{is based}} on {{reusability}} of code. It is an approach which let customer to have quality product by paying less amount of money and spending less time to produce. In this paper {{we will find out}} the factors which greatly effects reliability of component based system by conducting literature survey. The focus {{of this paper is to}} provide an overview of estimation of <b>reliability</b> <b>factors</b> from literature survey. We will prioritized <b>reliability</b> <b>factors</b> by applying soft computing techniques which in turn result factor which greatly effects reliability of component based system...|$|R
40|$|In {{order to}} {{maintain}} and enhance the operational reliability of a robotic manipulator deployed in space, an operational reliability system control method is presented in this paper. First, a method to divide factors affecting the operational reliability is proposed, which divides the operational <b>reliability</b> <b>factors</b> into task-related factors and cost-related factors. Then the models describing {{the relationships between the}} two kinds of factors and control variables are established. Based on this, a multivariable and multiconstraint optimization model is constructed. Second, a hierarchical system control model which incorporates the operational <b>reliability</b> <b>factors</b> is constructed. The control process of the space manipulator is divided into three layers: task planning, path planning, and motion control. Operational reliability related performance parameters are measured and used as the system’s feedback. Taking the factors affecting the operational reliability into consideration, the system can autonomously decide which control layer of the system should be optimized and how to optimize it using a control level adjustment decision module. The operational <b>reliability</b> <b>factors</b> affect these three control levels in the form of control variable constraints. Simulation results demonstrate that the proposed method can achieve a greater probability of meeting the task accuracy requirements, while extending the expected lifetime of the space manipulator...|$|R
40|$|AbstractThe authors {{conducted}} {{a set of}} studies concerning the development of methodological support of multivariate predictive control reliability system {{for oil and gas}} industry. The algorithms, the innovative methods of calculation and the mathematical models of <b>reliability</b> <b>factors,</b> compatible with the modern production technological maintenance system, the system of dispatcher data registration, non-destructive testing diagnostics, and automated process control systems are developed. The mathematical software is designed to meet the technological features of the specific facilities, with applying the theory of process analysis, theory of reliability and fluctuation analysis elements. The developed models of <b>reliability</b> <b>factors</b> provide the possibility of predicting the parameters of technical facilities in a real time mode or for a fixed period, the structural and factor analysis function of the system in order to plan its optimal maintenance...|$|R
30|$|As {{mentioned}} in the previous section, the proposed soft-input arithmetic decoder does not use a finite-state machine to model the AC. Thus, BCJR [23] or SOVA [22] algorithms are not applicable. The main idea is not to generate bits a posteriori LLRs exact estimation but to define bits <b>reliability</b> <b>factor.</b>|$|E
40|$|This {{project will}} analyze raw {{photovoltaic}} (PV) solar panel performance data {{in order to}} determine a <b>reliability</b> <b>factor</b> for solar panels in San Luis Obispo. This project is a subset of a larger project being performed by SLO RESCO, which is funded {{by a grant from the}} California Energy Commission. Their project will explore the use of solar, wind, geothermal, and biomass renewable resources. The scope of this project is limited to a small section of RESCO 2 ̆ 7 s analysis of solar panel technology and implementation in which a <b>reliability</b> <b>factor</b> will be generated. The objective is to determine a <b>reliability</b> <b>factor</b> for solar panels for each month of the year while creating an Excel tool to assist with the calculations and organization of information. The analysis of this report involved obtaining one year 2 ̆ 7 s worth of PV performance data, manipulating and interpreting an entire year 2 ̆ 7 s worth of PV performance data, designing and generating an Excel tool to perform the calculations, and finally making conclusions and recommendations. In order to perform the analysis many variables had to be defined, as well as ways to interpret the results such that the desired outputs could be obtained. From the data and results San Luis Obispo had a capacity factor of 80. 94...|$|E
40|$|Abstract- The present {{research}} aims to study {{relationship between the}} spiritual leadership of principals and work life quality of teachers in high schools of Izeh county. Its method is descriptive-correlative and research sample includes principals (80 people) and teachers (452 people) in high schools of Izehcounty. Sample size calculated by Karjis-Morgan table (1970) for 66 principals and 207 teachers. But returned questionnaire was 63 for principals and 188 for teachers. To select teacher's simple random sampling method and for teacher's classification random sampling used in proportion to statistical sample {{of men and women}} teachers. Measurement tools include a 16 items questionnaire made by the researcher of spiritual leadership due to Rio (2005),Fry (2003) by a <b>reliability</b> <b>factor</b> of / 85 and a 30 items questionnaire of work life quality of valton(1973) by <b>reliability</b> <b>factor</b> of / 88. To analyze data...|$|E
40|$|This {{paper is}} devoted to obtain the {{two-dimensional}} <b>reliability</b> modeling equivalence <b>factors</b> of n independent and identical components parallel system. Bivariate Weibull model {{has been used by}} considering the failure behavior of components. We discuss two-dimensional failure modeling for a system where degradation is due to age and usage. Three different methods are used to improve the given system. The mean times to failures of the original and improved systems are obtained. Numerical studies are presented to compare the different <b>reliability</b> <b>factors</b> obtained...|$|R
40|$|The <b>reliability</b> {{equivalence}} <b>factors</b> of {{a parallel}} system with n independent and identical components are obtained. The failure {{rates of the}} system's components {{are assumed to be}} constant. Three different methods are used to improve the given system. The mean times to failures of the original and improved systems are obtained. A comparison between the mean time to failures of the improved systems obtained via different methods used is presented. Numerical studies are presented to compare the different <b>reliability</b> <b>factors</b> obtained. The results obtained here generalize the results given in the literature by setting n= 1, 2...|$|R
40|$|The article {{deals with}} methods for {{determining}} the <b>reliability</b> of the <b>factors</b> of oil production equipment, a study of reliability characteristics of the system "well - setting electric centrifugal pumps", shows the <b>factors</b> of <b>reliability</b> in terms of production complications. The preliminary generalizations on the classification of oil drilling equipment <b>reliability</b> <b>factors</b> leading to such practically relevant provisions of durability, forecasting and optimization of accident repairs. The principles of classification of the <b>factors</b> of <b>reliability</b> of equipment in the aspect of the efficiency of oil productio...|$|R
30|$|The {{economic}} and social costs of disposal increase as landfill gets filled up and environmental protection groups protest against dumping in third world countries. Increasing production knowledge decreases unit production cost, whereas lower values of product <b>reliability</b> <b>factor</b> increase development cost. Therefore, productivity and quality knowledge can be developed through induced and autonomous learning to strengthen company position.|$|E
40|$|This TABLE {{lists the}} {{measurement}} <b>reliability</b> <b>factor,</b> r, the maximum power density, Pmax, dissipated in the transistor channel, {{as well as}} the maximum current density, jSDmax, in the channel of (organic) field-effect transistors (FETs) calculated from the data shown in recent literature reports. For the exact definitions of these parameters see Nature Mater. DOI: 10. 1038 /nmat 5035...|$|E
40|$|Abstract. Wireless sensor and ad hoc {{networks}} are gaining {{a lot of}} attention in research lately due to their importance in enabling mobile wireless nodes to com-municate without any predetermined infrastructure. Routing protocol in wireless sensor and ad hoc networks discover a multi-hop route between source and des-tination nodes. This paper presents RAS: a Reliable routing protocol for wire-less Ad hoc and Sensor networks. In the RAS protocol, increased reliability is achieved by the maintenance of a <b>reliability</b> <b>factor</b> by the nodes. The value of this factor is increased when nodes participate successfully in data transmissions. This is determined through the use of positive and passive acknowledgements. During the path discovery process, an intermediate node only extends the request message to nodes that have a minimal <b>reliability</b> <b>factor</b> which is specified by the source. Additional optimizations are included in order to increase the efficiency and performance of the network...|$|E
40|$|The {{purpose of}} the study is to provide a better {{understanding}} of how organizations utilize e-logistics within their supply chain. Two questions will be examined, (1) How can the e-Logistics system be described and (2) What the factors that influence the e-logistics system. The e-Logistics system can be described as a process and as an information system. <b>Factors</b> then include <b>reliability</b> <b>factors,</b> maintainability factors, supply support factors, test and support equipment factors, organizational factors, facility, transportation, and handling factors, software factors, availability factors, and economic and effectiveness factors. These factors, however, deserves further research...|$|R
40|$|By {{means of}} {{analytical}} uncertainty computations and model simulations the reliability is assessed for the NH 3 -emission computations of 1992, on local (5 x 5 km grids), regional (acidification regions) {{as well as}} national scale (the Netherlands). Results are presented in terms of confidence intervals and <b>reliability</b> <b>factors.</b> It is studied how the various error sources affect the reliability...|$|R
40|$|Abstract. This paper {{gives the}} <b>reliability</b> {{equivalence}} <b>factors</b> of a parallel system with n independent and non-identical components. It is assumed here that, the failure {{rates of the}} system’s components are constants. We used three different methods to improve the system given. Two reliability characteristics (the {{mean time to failure}} and the reliability function) are used to perform the system improvement. For this purpose, the reliability functions and the mean times to failures of the original and improved systems are obtained. The results given in this paper generalize the results given in the literatures by setting n = 1, 2. An illustrative numerical example is presented to compare the different <b>reliability</b> <b>factors</b> obtained...|$|R
40|$|The {{investigation}} {{is concerned with}} the conditions of operation of a thermal power station generating equipment. The purpose of the work is to develop procedures for selection of the optimal composition of operating conditions of the generating equipment at passing the dips of electric load curves with due regard for efficiency and reliability. The author has developed the methods of optimal selection of the composition of the generating equipment at passing load dips with subsequent loading with due regard for low-cycle <b>reliability</b> <b>factor.</b> The author has proposed a new scheme of the unit starting from the hot state. The author has developed the algorithm and the program of selection of the optimal composition of a thermoelectric power plant generating equipment with due regard for the <b>reliability</b> <b>factor</b> at passing load curve dipsAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|E
40|$|This paper {{considers}} blind {{chip rate}} estimation of DS-SS signals in multi-rate and multi-user DS-CDMA systems over channels having slow flat Rayleigh fading plus additive white Gaussian noise. Channel impulse response is estimated by a subspace method, {{and then the}} chip rate of each signal is estimated using zero crossing of estimated differential channel impulse response. For chip rate estimation of each user, an algorithm which uses weighted zero-crossing ratio is proposed. Maximum value of the weighted zero crossing ratio {{takes place in the}} Nyquist rate sampling frequency, which equals to the twice of the chip rate. Furthermore, bit time of each user is estimated using fluctuations of autocorrelation estimators. Since code length of each user can be obtained using bit time and chip time ratio. Fading channels reduce <b>reliability</b> <b>factor</b> of the proposed algo-rithm. To overcome this problem, a receiver with multiple antennas is proposed, and the <b>reliability</b> <b>factor</b> of the proposed algorithm is analyzed over both spatially correlated and independent fading channels...|$|E
40|$|Scheduling of jobs {{is one of}} {{the crucial}} tasks in grid environment. We {{consider}} non-preemptive scheduling of independent tasks in a computational grid. Recently, a general distributed scalable grid scheduler (GDS) was proposed, which prioritizes mission-critical tasks while maximizing the number of tasks meeting deadlines. However, the GDS scheduler did not consider the <b>reliability</b> <b>factor,</b> which may result in low successful schedule rates. In this paper, we propose a novel distributed grid scheduler which takes <b>reliability</b> <b>factor</b> (RDGS) into consideration with respect to the failure of grid nodes. The proposed scheduler invokes the tasks allocated to deficient grid nodes and maintains them in a queue. Further the queued tasks are rescheduled to the other nodes of the grid. It is observed that RDGS scheduler shows a significant improvement in terms of successfully scheduled tasks as compared to a variation of GDS without priority and deadlines (GDS-PD). The results of our exhaustive simulation experiments demonstrate the superiority of RDGS over the GDS-PD scheduler...|$|E
40|$|This thesis investigates {{methods for}} {{assessing}} <b>reliability</b> equivalence <b>factors</b> for several common systems that comprise independent components or subsystems. We consider improving {{the reliability of}} the systems by (a) a reduction method and (b) several duplication methods: (i) hot duplication; (ii) cold duplication with perfect switching; (iii) cold duplication with imperfect switching. Two measures for comparing system improvements are considered in this study, survival <b>reliability</b> equivalence <b>factors</b> and mean <b>reliability</b> equivalence <b>factors.</b> We apply our study to: (1) some simple systems including parallel-series and series-parallel systems, with flexible lifetime distributions including generalized quadratic failure rate and exponentiated Weibull lifetime distributions; (2) networks and complex systems with multiple types of components. We choose the exponentiated Weibull and generalized quadratic failure rate distributions because they are flexible and enable comparisons with other reliability equivalence studies. We use the concept of survival signature to derive the <b>reliability</b> equivalence <b>factors</b> for any coherent system with any structure and with different lifetime distributions. In order to implement this approach, we use the ReliabilityTheory R package to derive survival <b>reliability</b> equivalence <b>factors</b> and mean <b>reliability</b> equivalence <b>factors</b> for networks and complex systems with multiple types of components. Numerical examples for simple and complex systems are presented, to illustrate how to apply the theoretical results and demonstrate the relative benefits of various system improvements. We explain and discuss the results obtained by presenting summary tables and figures, before presenting conclusions and recommendations that arise from this study. In particular, we deduce that considerable advances in reliability equivalence testing are made possible by specifying and analysing the survival signature, especially for the increasingly common context and practice of modelling networks and complex systems...|$|R
40|$|The {{long life}} of Pioneer interplanetary {{spacecraft}} is considered {{along with a}} general accelerated methodology for long-life mechanical components, dependable long-lived household appliances, and the design and development philosophy to achieve reliability and long life in large turbine generators. Other topics discussed include an integrated management approach to long life in space, artificial heart <b>reliability</b> <b>factors,</b> and architectural concepts and redundancy techniques in fault-tolerant computers. Individual items are announced in this issue...|$|R
40|$|Integrated {{injection}} logic (1, 2) {{technology for}} reliable operation under a - 55 C to + 300 C, temperature range is discussed. Experimental measurements indicate that an 80 mv signal swing {{is available at}} 300 C with 100 micro A injection current per gate. In addition, modeling results predict how large gate fan-ins can decrease the maximum thermal operational limits. These operational limits and the longterm <b>reliability</b> <b>factors</b> associated with device metallization are evaluated via specialized test mask...|$|R
40|$|The {{chemical}} stability tests currently used for propellants suffer from some drawback. In this paper an attempt {{has been made}} to recast the existing system of stability testing in order to improve the <b>reliability</b> <b>factor.</b> A new stability concept has also been brought out based on the action of the stabilizer and its derivatives with the decomposed products of the nitric esters, the chief constituents of the propellants...|$|E
40|$|Multipath routing {{protocols}} for Mobile Ad hoc NETwork (MANET) addresses {{the problem of}} load balancing, scalability, security and life time of networks. In this paper, we propose a new multipath protocol, Stability and Energy Aware Multipath Ad hoc On-demand Distance Vector (SEAM-AODV) protocol which is an enhancement of Ad hoc On-demand Distance Vector (AODV) protocol. It designs a bi-objective optimization formulation to compute the <b>reliability</b> <b>factor</b> based on the stability and residual energy of nodes, through cross layer approach. The reliability of the multiple paths is increased through node disjointness. The path with the highest <b>reliability</b> <b>factor</b> value is selected as the primary path for data transmission. It also employs effective route maintenance mechanism to reduce the frequency of route recovery. This protocol is compared with other similar routing protocol: AOMDV. We use ns- 2 for simulation. Our simulation results show that, the proposed protocol reduces the packet loss by up to 25 – 35 % and routing overhead by about 32 - 40 %. It also accomplishes 10 - 13 % higher packet delivery ratio...|$|E
40|$|Phishing is {{a common}} online weapon, used against users, by Phishers for {{acquiring}} a confidential information through deception. Since the inception of internet, nearly everything, ranging from money transaction to sharing information, is done online {{in most parts of}} the world. This has also given rise to malicious activities such as Phishing. Detecting Phishing is an intricate process due to complexity, ambiguity and copious amount of possibilities of factors responsible for phishing. Rough sets can be a powerful tool, when working on such kind of Applications containing vague or imprecise data. This paper proposes an approach towards Phishing Detection Using Rough Set Theory. The Thirteen basic factors, directly responsible towards Phishing, are grouped into four Strata. <b>Reliability</b> <b>Factor</b> is determined on the basis of the outcome of these strata, using Rough Set Theory. <b>Reliability</b> <b>Factor</b> determines the possibility of a suspected site to be Valid or Fake. Using Rough set Theory most and the least influential factors towards Phishing are also determined. Comment: The International Conference on Machine Intelligence Research and Advancement, ICMIRA- 201...|$|E
30|$|In {{comparison}} with previous studies, by calculating reliability measurement metrics in {{different levels of}} the supply chain and identifying the impact value {{of each of these}} metrics on variances of reliability criterion in different periods, this research has been able to offer a new method for prioritizing decreasing <b>reliability</b> <b>factors</b> in a supply chain in order to reduce their effects. In addition, this research is a case study in Iran which is suitable for computing reliability of supply chain for Iranian organizations.|$|R
40|$|In {{the crystal}} {{structure}} of the title compound, [Ni(C 2 N 3) 2 (C 5 H 5 N) 4], the NiII cations are coordinated by four pyridine ligands and two dicyanamide anions into discrete complexes. The shortest Ni [...] . Ni separation is 8. 1068 &# 8197;(10) &# 8197;&# 197;. The structure is pseudo-centrosymmetric and can also be refined in the space group C 2 /c in which both anionic ligands are strongly disordered and the refinement leads to significantly poorer <b>reliability</b> <b>factors...</b>|$|R
30|$|SOMS- 5 {{does have}} {{sufficient}} <b>reliability</b> and <b>factor</b> validity. Because of its frequent usage in recent years, its Japanese version {{can be used}} without difficulty.|$|R
