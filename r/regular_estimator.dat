24|48|Public
50|$|Hodges’ {{estimator}} improves upon a <b>regular</b> <b>estimator</b> at {{a single}} point. In general, any superefficient estimator may surpass a <b>regular</b> <b>estimator</b> at most {{on a set of}} Lebesgue measure zero.|$|E
50|$|In statistics, the Hájek-Le Cam {{convolution}} theorem {{states that}} any <b>regular</b> <b>estimator</b> in a parametric model is asymptotically {{equivalent to a}} sum of two independent random variables, {{one of which is}} normal with asymptotic variance equal to the inverse of Fisher information, and the other having arbitrary distribution.|$|E
5000|$|The {{mean square}} error (scaled by n) {{associated}} with the <b>regular</b> <b>estimator</b> x is constant and equal to 1 for all θ’s. At {{the same time the}} {{mean square error}} of the Hodges’ estimator [...] behaves erratically in the vicinity of zero, and even becomes unbounded as n → ∞. This demonstrates that the Hodges’ estimator is not regular, and its asymptotic properties are not adequately described by limits of the form (θ fixed, n → ∞).|$|E
5000|$|In statistics, Hodges’ {{estimator}} (or the Hodges-Le Cam estimator), {{named for}} Joseph Hodges, is a famous counter {{example of an}} estimator which is [...] "superefficient", i.e. it attains smaller asymptotic variance than <b>regular</b> efficient <b>estimators.</b> The existence of such a counterexample {{is the reason for}} the introduction of the notion of <b>regular</b> <b>estimators.</b>|$|R
40|$|We examine {{challenges}} to estimation and inference when {{the objects of}} interest are nondifferentiable functionals of the underlying data distribution. This situation arises {{in a number of}} applications of bounds analysis and moment inequality models, and in recent work on estimating optimal dynamic treatment regimes. Drawing on earlier work relating differentiability to the existence of unbiased and <b>regular</b> <b>estimators,</b> we show that if the target object is not continuously differentiable in the parameters of the data distribution, there exist no locally asymptotically unbiased <b>estimators</b> and no <b>regular</b> <b>estimators.</b> This places strong limits on estimators, bias correction methods, and inference procedures. ...|$|R
50|$|The obvious {{corollary}} {{from this}} theorem {{is that the}} “best” among <b>regular</b> <b>estimators</b> are those with the second component identically equal to zero. Such estimators are called efficient and are known to always exist for regular parametric models.|$|R
40|$|This paper {{considers}} a two-sample regression model with nonparametric regression curves that differ by a parametric {{transformation in the}} horizontal axis and constructs an efficient estimate of the parameter of the transformation. Semiparametric regression Efficient influence function Least dispersed <b>regular</b> <b>estimator</b> Least squares spline estimators...|$|E
40|$|In {{this paper}} we {{consider}} the semiparametric additive regression model whose regression function {{is the sum of}} a linear parametric component and several smooth nonparametric components. We construct root-n-consistent and then efficient estimators of the finite dimensional parameter. Least dispersed <b>regular</b> <b>estimator</b> Least squares spline estimator...|$|E
40|$|De Haan and Pereira (2006) [6] {{provided}} {{models for}} spatial extremes {{in the case}} of stationarity, which depend on just one parameter [beta]> 0 measuring tail dependence, and they proposed different estimators for this parameter. We supplement this framework by establishing local asymptotic normality (LAN) of a corresponding point process of exceedances above a high multivariate threshold. Standard arguments from LAN theory then provide the asymptotic minimum variance within the class of regular estimators of [beta]. It turns out that the relative frequency of exceedances is a <b>regular</b> <b>estimator</b> sequence with asymptotic minimum variance, if the underlying observations follow a multivariate extreme value distribution or a multivariate generalized Pareto distribution. Extreme value analysis Spatial extremes Multivariate exceedances Multivariate extreme value distribution Multivariate generalized Pareto distribution Local asymptotic normality LAN <b>Regular</b> <b>estimator</b> sequence Asymptotic efficiency...|$|E
40|$|AbstractRelative {{efficiencies}} are studied through invariance in multiparameter estimation. Scalar efficiency indices, {{together with}} lower and upper bounds, are generated via invariant monotone functions, and are augmented to include tripartite efficiency numbers. Bounds on directed Fisher efficiencies emerge through generalized Rayleigh quotients. Applications are noted in improving estimators through conditioning, in comparing <b>regular</b> <b>estimators</b> with efficient estimators achieving their minimal dispersion bounds, and in comparing two second-order experimental designs...|$|R
3000|$|... 1. Monte Carlo {{simulations}} will {{be performed}} to confirm the better efficiency of the new direct QR estimator relative to the <b>regular</b> QR <b>estimator</b> and a nonparametric LPQR.|$|R
25|$|This {{assumption}} {{is not needed}} for {{the validity of the}} OLS method, although certain additional finite-sample properties can be established in case when it does (especially in the area of hypotheses testing). Also when the errors are normal, the OLS estimator is equivalent to the maximum likelihood estimator (MLE), and therefore it is asymptotically efficient in the class of all <b>regular</b> <b>estimators.</b> Importantly, the normality assumption applies only to the error terms; contrary to a popular misconception, the response (dependent) variable is not required to be normally distributed.|$|R
40|$|We give a {{characterization}} of asymptotically linear estimator sequences {{which leads to}} a concept of asymptotic linearity in arbitrary locally asymptotically normal models, and to a generalization of asymptotic linearity in i. i. d. models, retaining the properties of classical sense asymptotically linear estimator sequences. Asymptotically linear estimator <b>regular</b> <b>estimator...</b>|$|E
40|$|Suppose {{we observe}} an ergodic Markov chain {{and know that}} the {{stationary}} law {{of one or two}} successive observations fulfills a linear constraint. We show how to improve the given estimators exploiting this knowledge, and prove that the best of these estimators is efficient. Empirical estimator Asymptotically linear estimator Influence function <b>Regular</b> <b>estimator</b> Markov chain model Reversible chain Symmetric chain Linear autoregression...|$|E
40|$|We use a Bayesian {{version of}} the Cramer-Rao lower bound due to van Trees to give an {{elementary}} proof that the limiting distibution of any <b>regular</b> <b>estimator</b> cannot have a variance less than the classical information bound, under minimal regularity conditions. We also show how minimax convergence rates can be derived in various non- and semi-parametric problems from the van Trees inequality. Finally we develop multivariate versions of the inequality and give applications...|$|E
40|$|The P. O. T. (Peaks-Over-Threshold) {{approach}} {{consists of}} using the generalized Pareto distribution (GPD) to approximate the distribution of excesses over thresholds. We use the maximum likelihood estimators, or some other ones satisfying regularity conditions, to estimate {{the parameters of the}} approximating distribution. We study the asymptotic bias of these estimators and also the functional bias of the estimated GPD. Key-Words: • Extreme values; domain of attraction; excesses; generalized Pareto distribution; maximum likelihood estimators. AMS Subject Classification: • 60 G 70, 62 G 20. 20 Jean Diebolt and Armelle GuillouAsymptotic Behaviour of <b>Regular</b> <b>Estimators</b> 2...|$|R
40|$|Summary: The present paper {{establishes}} convolution theorems for <b>regular</b> <b>estimators</b> {{when the}} limit experiment is non-Gaussian or of infinite dimension with sparse parameter space. Applications are given for Gaussian shift experiments of infinite dimension, the Brownian motion signal plus noise model, Lévy processes which are observed at discrete times and estimators of the endpoints of densities with jumps. The {{method of proof}} is also of interest for the classical convolution theorem of Hájek and Le Cam. As technical tool we present an elementary approach for the comparison of limit experiments on standard Borel spaces. ...|$|R
50|$|This {{assumption}} {{is not needed}} for {{the validity of the}} OLS method, although certain additional finite-sample properties can be established in case when it does (especially in the area of hypotheses testing). Also when the errors are normal, the OLS estimator is equivalent to the maximum likelihood estimator (MLE), and therefore it is asymptotically efficient in the class of all <b>regular</b> <b>estimators.</b> Importantly, the normality assumption applies only to the error terms; contrary to a popular misconception, the response (dependent) variable is not required to be normally distributed.|$|R
40|$|It is {{well known}} that the sample {{covariance}} is not an efficient estimator of the covariance of a bivariate normal vector. We extend this result to elliptical distributions and we propose a simple explicit estimator, which is efficient in the normal case and which outperforms the sample covariance in general. Necessary and sufficient conditions are established under which this estimator is in general efficient for an elliptical distribution. elliptical distribution spherically symmetric distribution local asymptotic normality (LAN) <b>regular</b> <b>estimator</b> efficient estimator...|$|E
40|$|In {{this paper}} we {{construct}} efficient estimators for linear functionals of a bivariate distribution with known marginals. Previously, Bickel et al. (Ann. Statist. 19 (1991) 1316) constructed such estimators using the modified minimum chi-square principle. Our estimators utilize the least-squares principle and orthonormal bases for the Hilbert spaces of square integrable functions under the known marginal distributions and {{are easy to}} compute. Simulations indicate that in the moderate sample sizes considered our estimator compares favorably with the one proposed by Bickel et al. Least dispersed <b>regular</b> <b>estimator</b> Least-squares estimators Efficient influence function Orthonormal basis...|$|E
40|$|Suppose {{we observe}} a time series that {{alternates}} between different nonlinear autoregressive processes. We give {{conditions under which}} the model is locally asymptotically normal, derive a characterization of efficient estimators for differentiable functionals of the model, {{and use it to}} construct efficient estimators for the autoregression parameters and the innovation distributions. Surprisingly, the estimators for the autoregression parameters can be improved if we know that the innovation densities are equal. 62 G 20 62 M 05 Convolution theorem <b>Regular</b> <b>estimator</b> Asymptotically linear estimator Newton-Raphson procedure Weighted least squares estimator Linear autoregression...|$|E
40|$|We {{investigate}} a semiparametric regression model where one gets noisy non linear non invertible {{functions of the}} observations. We focus on the application to bearings-only tracking. We first investigate the least squares estimator and prove its consistency and asymptotic normality under mild assumptions. We study the semiparametric likelihood process and prove local asymptotic normality of the model. This allows to define the efficient Fisher information as a lower bound for the asymptotic variance of <b>regular</b> <b>estimators,</b> and {{to prove that the}} parametric likelihood <b>estimator</b> is <b>regular</b> and asymptotically efficient. Simulations are presented to illustrate our results...|$|R
40|$|If {{we have a}} {{parametric}} {{model for}} the invariant distribution of a Markov chain but cannot or {{do not want to}} use any information about the transition distribution (except, perhaps, that the chain is reversible) — what, then, is the best use we can make of the observations? We determine a lower bound for the asymptotic variance of <b>regular</b> <b>estimators</b> and show constructively that the bound is attainable. The results apply to discretely observed diffusions. AMS 1991 subject classifications. Primary 62 G 20, 62 M 05; secondary 62 F 12. Key words and Phrases. Efficient estimator, ergodic Markov chain, discretel...|$|R
40|$|The present paper {{establishes}} convolution theorems for <b>regular</b> <b>estimators</b> {{when the}} limit experiment is non-Gaussian or of infnite dimension with sparse parameter space. Applications are given for Gaussian shift experiments of infnite dimension, the Brownian motion signal plus noise model, Levy processes which are observed at discrete times and estimators of the endpoints of densities with jumps. The {{method of proof}} is also of interest for the classical convolution theorem of Hajek and Le Cam. As technical tool we present an elementary approach for the comparison of limit experiments on standard Borel spaces. Comment: 21 page...|$|R
40|$|This {{article is}} {{concerned}} with the estimation of the integral of a squared regression function using Latin hypercube sampling. A class of generalized nearest-neighbour estimators is proposed and their properties are investigated with respect to various smoothness classes of regression functions. In particular, mild conditions are established which ensure that achieves a root-n convergence rate. It is further shown that has an asymptotic mean squared error smaller than that of any <b>regular</b> <b>estimator</b> based on an i. i. d. sample of the same size. Integrated squared regression function Latin hypercube sampling Nearest neighbour estimator Nonparametric information bound Rate of convergence...|$|E
40|$|It {{is already}} {{known that the}} {{convolution}} of a bounded density with itself can be estimated at the root-n rate using the two asymptotically equivalent kernel estimators: (i) Frees estimator (Frees (1994)) and (ii) Saavedra and Cao estimator (Saavedra and Cao (2000)). In this work, we investigate the efficiency of these estimators of the convolution of a bounded density. The efficiency criterion used in this work {{is that of a}} least dispersed <b>regular</b> <b>estimator</b> described in Begun et al. (1983). This concept is based on the Hájek-Le Cam convolution theorem for locally asymptotically normal (LAN) families...|$|E
40|$|Abstract: In this paper, we derive the {{generalized}} maximum likelihood estimator (GMLE) and Nelson- Aalen (NA) type's estimator of the survival function for censored data under the partial Koziol-Green model. The small sample properties of these estimators are {{compared with those}} of Kaplan- Meier (KM) and partial Abdushukurov- Cheng- Lin (PACL) estimators. The simulation result has shown that the GMLE and NA estimators perform competitively with the PACL estimator, and all three estimators are more ecient than the KM estimator. The large sample analysis indicates that the GMLE, PACL, and NA estimators are asymptotically equivalent, and they are asymptotically ecient in the sense of being the least dispersed <b>regular</b> <b>estimator...</b>|$|E
40|$|Consider the {{unconditional}} moment restriction E[m(y, υ, w; π 0) / fnull (υ |w) − s (w; π 0) ] = 0, where m (·) and s (·) {{are known}} vector-valued functions of data (y┬, υ, w ┬) ┬. The smallest asymptotic variance that null -consistent <b>regular</b> <b>estimators</b> of null 0 can have is calculated when f null (·) is only {{known to be}} a bounded, continuous, nonzero conditional density function. Our results show that “plug-in” kernel-based estimators of null 0 constructed from this type of moment restriction, such as Lewbel (1998, Econometrica 66, 105 – 121) and Lewbel (2007, Journal of Econometrics 141, 777 – 806), are semiparametric efficient. ...|$|R
40|$|Bivariate {{generalized}} Pareto distributions (GPs) with uniform {{margins are}} introduced and elementary properties such as peaks-over-threshold (POT) stability are discussed. A unified parameterization with parameter [theta][set membership, variant][0, 1] of the GPs {{is provided by}} their canonical parameterization. We derive efficient estimators of [theta] and of the dependence function of the GP in various models and establish local asymptotic normality (LAN) of the loglikelihood function of a 2 x 2 table sorting of the observations. From this result we can deduce that the estimator of [theta] suggested by Falk and Reiss (2001, Statist. Probab. Lett. 52, 233 - 242) is not efficient, whereas a modification actually is. Bivariate max-stable distribution Bivariate generalized Pareto distribution Dependence function Canonical parameterization Peaks-over-threshold stability BLUE LAN Hajek-LeCam convolution theorem <b>Regular</b> <b>estimators...</b>|$|R
40|$|This paper {{extends the}} {{conditional}} logit approach (Rasch, Andersen, Chamberlain) used in panel data models of binary variables with correlated fixed effects and strictly exogenous regressors. In a two-period two-state model, necessary and sufficient {{conditions on the}} joint distribution function of the individual-and-period specific shocks are given such that the sum of individual binary variables across time is a sufficient statistic for the individual effect. By extending a result of Chamberlain, it is shown that root-n consistent <b>regular</b> <b>estimators</b> can be constructed in panel binary models {{if and only if}} the property of sufficiency holds. In applied work, the estimation method amounts to quasi-differencing the binary variables as if they were continuous variables and transforming a panel data model into a cross-section model. Semiparametric approaches can then be readily applied. Copyright The Econometric Society 2004. ...|$|R
40|$|AbstractDe Haan and Pereira (2006) [6] {{provided}} {{models for}} spatial extremes {{in the case}} of stationarity, which depend on just one parameter β> 0 measuring tail dependence, and they proposed different estimators for this parameter. We supplement this framework by establishing local asymptotic normality (LAN) of a corresponding point process of exceedances above a high multivariate threshold. Standard arguments from LAN theory then provide the asymptotic minimum variance within the class of regular estimators of β. It turns out that the relative frequency of exceedances is a <b>regular</b> <b>estimator</b> sequence with asymptotic minimum variance, if the underlying observations follow a multivariate extreme value distribution or a multivariate generalized Pareto distribution...|$|E
40|$|In this paper, we {{characterize}} {{and construct}} efficient estimators of linear functionals of a bivariate distribution with equal marginals. An efficient estimator equals the empirical estimator minus a correction term and provides significant improvements over the empirical estimator. We construct an efficient estimator by estimating the correction term. For this {{we use the}} least-squares principle and an estimated orthonormal basis for the Hilbert space of square-integrable functions under the unknown equal marginal distribution. Simulations confirm the asymptotic behavior of this estimator in moderate sample sizes and the considerable theoretical gains over the empirical estimator. Least dispersed <b>regular</b> <b>estimator</b> Least-squares estimators Efficient influence function Empirical estimator Local asymptotic normality...|$|E
40|$|This paper {{deals with}} root-n {{consistent}} {{estimation of the}} parameter [beta] in the partly linear regression model Y = [beta]T U + [gamma](X) + [var epsilon], where, [gamma] is a function on [0, 1]q, the error variable [var epsilon] satisfies E([var epsilon] / U, X) = 0 and E([var epsilon] 2 / U, X) is bounded, and the random vector (UT, XT) T is. Under an identifiability condition, least squares type estimates of [beta] are shown to be root-n consistent under mild smoothness assumptions on [gamma], h or both, where h(X) = E(U X). No assumption {{on the distribution of}} X are imposed. This result improves on a result of Chen (1988). Least dispersed <b>regular</b> <b>estimator</b> Least squares spline estimator...|$|E
40|$|This paper {{studies the}} {{asymptotic}} efficiency of estimates in nonlinear panel data models with fixed effects when both the cross-sectional {{sample size and}} the length of time series tend to infinity. The efficiency bounds for <b>regular</b> <b>estimators</b> are derived using the infinite-dimensional convolution theorem by van der Varrt and Wellner (1996). It {{should be noted that the}} number of fixed effects increases with the sample size, so they constitute an infinite-dimensional nuisance parameter. The presence of fixed efFects makes our derivation of the efficiency bounds non-trivial, and the techniques to overcome the difficulties caused by fixed effects will be discussed indetail. Our results include the efficiency bounds for models containing unknown functions (for instance, a distribution function of error terms). We apply our results to show that the bias-corrected fixed effects estimator of Hahn and Newey (2004) is asymptotically efficient...|$|R
40|$|We {{consider}} the linear regression model with censored dependent variable, where the disturbance terms are restricted {{only to have}} zero conditional median (or other prespecified quantile) given the regressors and the censoring point. Thus, the functional form of the conditional distribution of the disturbances is unrestricted, permitting heteroskedasticity of unknown form. For this model, a lower bound for the asymptotic covariance matrix for <b>regular</b> <b>estimators</b> of the regression coefficients is derived. This lower bound corresponds to the covariance matrix of an optimally weighted censored least absolute deviations estimator, where the optimal weight is the conditional density at zero of the disturbance. We also show how an estimator that attains this lower bound can be constructed, via nonparametric estimation of the conditional density at zero of the disturbance. As a special case our results apply to the (uncensored) linear model under a conditional median restriction. ...|$|R
40|$|Using {{different}} random normings, {{the paper}} {{shows that the}} distributions of the normalized maximum likelihood <b>estimator</b> and normalized <b>regular</b> Bayes <b>estimators</b> of the drift parameter in the Ornstein-Uhlenbeck process observed continuously over [0,T] converge to the standard normal distribution with an error rate O(T- 1 / 2). Ito stochastic differential equation Ornstein-Uhlenbeck process Maximum likelihood estimator Bayes estimators Rate of weak convergence Random normings...|$|R
