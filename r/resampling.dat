5902|1530|Public
5|$|An {{approximation}} to {{the curve}}-shortening flow can be computed numerically, by approximating the curve as a polygon {{and using the}} finite difference method to calculate the motion of each polygon vertex. Alternative methods include computing a convolution of polygon vertices and then <b>resampling</b> vertices on the resulting curve, or repeatedly applying a median filter to a digital image whose black and white pixels represent the {{inside and outside of}} the curve.|$|E
25|$|Boxee {{features}} are on-the-fly audio frequency <b>resampling,</b> gapless playback, crossfading, ReplayGain, cue sheet and Ogg Chapter support.|$|E
25|$|Comprehensive set {{of image}} {{processing}} and remote sensing tools like extensive set of filters, <b>resampling,</b> aggregation, classifications. etc...|$|E
40|$|Figure 1 - Curve {{selection}} of four characters. A the red curve (Curve 1) is {{the outline of}} pronotum, which <b>resampled</b> into 50 semi-landmarks (SLM); the two green curves (Curve 2, 3) are outline of the carinae, which <b>resampled</b> into 15 SLM; two blue curves (Curve 4, 5) are the outline of lateral carinae, which <b>resampled</b> into 10 SLM B the curve is the outline of elytra, which <b>resampled</b> into 50 SLM C the curve is the outline of protibia, which <b>resampled</b> into 50 SLM D the curve is {{the outline of the}} left paramere, which <b>resampled</b> into 50 SLM...|$|R
3000|$|... c {{represents}} the FFT {{result of the}} covariance signal of a <b>resampled</b> image with the CSS process. The result shows a clear peak when the CSS process is applied. The CSS process makes peak clearer only with <b>resampled</b> image. It makes accurate classification of a non-resampled image and a <b>resampled</b> image possible.|$|R
40|$|This paper {{proposes a}} {{hierarchical}} framework that <b>resamples</b> 3 D reconstructed points to reduce computation cost {{on time and}} memory for very large-scale Structure from Motion. The goal is to maintain accuracy and stability similar for different <b>resample</b> rates. We consider this problem in a level-of-detail perspective, from a very large scale global and sparse bundle adjustment to a very detailed and local dense optimization. The dense matching are <b>resampled</b> by exploring the redundancy using local invariant properties, while 3 D points are <b>resampled</b> by exploring the redundancy using their covariance and their distribution in both 3 D and image space. Detailed experiments on our <b>resample</b> framework are provided. We also demonstrate the proposed framework on large-scale examples. The {{results show that the}} proposed <b>resample</b> scheme can produce a 3 D reconstruction with the stability similar to quasi dense methods, while the problem size is as neat as sparse methods. © 2010 Springer-Verlag...|$|R
25|$|<b>Resampling</b> methods, {{which include}} the {{bootstrap}} and the jackknife, {{may be used to}} test the equality of variances.|$|E
25|$|When {{the sample}} {{is not a simple}} random sample from a large population, the {{standard}} error and the confidence interval must be estimated through more advanced calculations. Linearization and <b>resampling</b> are widely used techniques for data from complex sample designs.|$|E
25|$|Gaussian {{blurring}} {{is commonly}} used when reducing {{the size of an}} image. When downsampling an image, it is common to apply a low-pass filter to the image prior to <b>resampling.</b> This is to ensure that spurious high-frequency information does not appear in the downsampled image (aliasing). Gaussian blurs have nice properties, such as having no sharp edges, and thus do not introduce ringing into the filtered image.|$|E
5000|$|The {{bootstrap}} {{can be used}} {{to construct}} confidence intervals for Pearson's correlation coefficient. In the [...] "non-parametric" [...] bootstrap, n pairs (xi, yi) are <b>resampled</b> [...] "with replacement" [...] from the observed set of n pairs, and the correlation coefficient r is calculated based on the <b>resampled</b> data. This process is repeated a large number of times, and the empirical distribution of the <b>resampled</b> r values are used to approximate the sampling distribution of the statistic. A 95% confidence interval for ρ can be defined as the interval spanning from the 2.5th to the 97.5th percentile of the <b>resampled</b> r values.|$|R
40|$|We {{examined}} the out-of-sample performance of using <b>resampled</b> portfolio efficiency, an approach proposed in 1998, in international asset allocation {{strategies for the}} period January 1983 to May 2000. For most models we used to estimate expected returns, using strategies based on <b>resampled</b> portfolio efficiency provided some benefits, in terms of improved Sharpe ratios and abnormal returns, over using traditional mean-variance strategies. We found little evidence, however, that active mean-variance strategies or <b>resampled</b> efficiency strategies would have generated significantly positive abnormal returns for the time period we considered...|$|R
5000|$|... resamp <b>Resample</b> the 1st {{dimension}} of a 2-dimensional function f(x1,x2) ...|$|R
2500|$|Increased {{computing}} power has {{also led to}} {{the growing popularity of}} computationally intensive methods based on <b>resampling,</b> such as permutation tests and the bootstrap, while techniques such as Gibbs sampling have made use of Bayesian models more feasible. The computer revolution has implications for the future of statistics with new emphasis on [...] "experimental" [...] and [...] "empirical" [...] statistics. A large number of both general and special purpose statistical software are now available.|$|E
2500|$|For {{the general}} field of human speech reproduction, a {{bandwidth}} of 5512Hz {{is sufficient to}} produce excellent results (for voice) using the sampling rate of 11025 and VBR encoding from 44100 (standard) wave files.. This is easily accomplished using LAME version 3.99.5 and the command line [...] "lame -V 9.6 lecture.WAV" [...] English speakers average 41–42kbit/s with -V 9.6 setting but this may vary with amount of silence recorded or the rate of delivery (wpm). <b>Resampling</b> to 12000 (6K bandwidth) is selected by the LAME parameter -V 9.4 Likewise -V 9.2 selects 16000 sample rate and a resultant 8K lowpass filtering. For more info see Nyquist – Shannon. [...] Older versions of LAME and FFmpeg only support integer arguments for variable bit rate quality selection parameter. [...] The n.nnn quality parameter (-V) is documented at lame.sourceforge.net but is only supported in LAME with the new style VBR variable bit rate quality selector—not average bit rate (ABR).|$|E
2500|$|The use of Sequential Monte Carlo in {{advanced}} signal processing and Bayesian inference is more recent. It was in 1993, that Gordon et al., published in their seminal work the first {{application of a}} Monte Carlo <b>resampling</b> algorithm in Bayesian statistical inference. The authors named their algorithm 'the bootstrap filter', and demonstrated that compared to other filtering methods, their bootstrap algorithm does not require any assumption about that state-space or {{the noise of the}} system. We also quote another pioneering article in this field of Genshiro Kitagawa on a related [...] "Monte Carlo filter", and the ones by Pierre Del Moral and Himilcon Carvalho, Pierre Del Moral, André Monin and Gérard Salut on particle filters published in the mid-1990s. Particle filters were also developed in signal processing in the early 1989-1992 by P. Del Moral, J.C. Noyer, G. Rigal, and G. Salut in the LAAS-CNRS in a series of restricted and classified research reports with STCAN (Service Technique des Constructions et Armes Navales), the IT company DIGILOG, and the [...] (the Laboratory for Analysis and Architecture of Systems) on RADAR/SONAR and GPS signal processing problems. These Sequential Monte Carlo methodologies can be interpreted as an acceptance-rejection sampler equipped with an interacting recycling mechanism.|$|E
30|$|We {{confirmed}} that the distribution of <b>resampled</b> distances was close to a normal distribution. Over many <b>resampled</b> pairs, the frequency of instances when this inequality was true gave us {{the probability that the}} difference in word usage between the two communities could have happened by chance if words were randomly distributed amongst communities.|$|R
30|$|With the CSS process, {{there is}} an amplifying effect for the {{intensity}} of the peak signal. In a later part, the peak in the Fourier transformed signal is amplified if the stereoscopic images have been <b>resampled.</b> On the other hand, the peak of signals are weakened if the stereoscopic images are not <b>resampled.</b>|$|R
5|$|Because of the <b>resampled</b> {{convolution}} method that they describe for computing a numerical approximation of the curve-shortening flow, they call their method the <b>resampled</b> curvature scale space. They observe that this scale space is invariant under Euclidean transformations of the given shape, and assert that it uniquely determines {{the shape and}} is robust against small variations in the shape. They compare it experimentally against several related alternative definitions of a scale space for shapes, and find that the <b>resampled</b> curvature scale space is less computationally intensive, more robust against nonuniform noise, and less strongly influenced by small-scale shape differences.|$|R
50|$|Sinc <b>resampling</b> {{in theory}} {{provides}} the best possible reconstruction for a perfectly bandlimited signal. In practice, the assumptions behind sinc <b>resampling</b> are not completely met by real-world digital images. Lanczos <b>resampling,</b> an approximation to the sinc method, yields better results. Bicubic interpolation {{can be regarded as}} a computationally efficient approximation to Lanczos <b>resampling.</b>|$|E
5000|$|Is {{the same}} as {{sequential}} importance <b>resampling,</b> but without the <b>resampling</b> stage.|$|E
50|$|Lanczos <b>resampling</b> {{is based}} on a windowed sinc {{function}} as a practical upsampling filter approximating the ideal sinc function. Lanczos <b>resampling</b> is widely used in video up-sampling for digital zoom applications.|$|E
3000|$|Judge if {{it needs}} to <b>resample</b> through {{effective}} sampling scale N_eff and the default threshold N_th, if it does, replace small weight of particles with high weight of particles according to normalized weight ω̃ ̃_̃k̃(x_ 0 :k^i) from (x_k^i)_i= 1 ^N [...]. If it {{does not need to}} <b>resample,</b> continuing to the next step.|$|R
5000|$|... #Subtitle level 3: <b>Resampled</b> {{layers of}} sounds {{generated}} by a music workstation ...|$|R
5000|$|Moreover, the {{randomized}} algorithm {{described above}} <b>resamples</b> an event [...] at most an expected ...|$|R
50|$|See also bitmap <b>resampling.</b>|$|E
50|$|Low-pass {{filtering}} and <b>resampling</b> often cause overshoot, {{which increases}} acutance, {{but can also}} reduce absolute gradient, which reduces acutance. Filtering and <b>resampling</b> can also cause clipping and ringing artifacts. An example is bicubic interpolation, widely used in image processing for resizing images.|$|E
50|$|For {{more details}} see {{bootstrap}} <b>resampling.</b>|$|E
30|$|The {{points are}} <b>resampled</b> to 61 and 131 for {{skeleton}} and boundary pixel images drawing order, respectively. We have experimented to <b>resample</b> from 41 to 91 for skeleton and 91 to 181 for boundary pixels images drawing order. The selection of 61 and 131 points for skeleton and boundary pixels images drawing order {{are made on}} the basis of lowest error rate achieved.|$|R
50|$|Another {{approach}} to bootstrapping in regression problems is to <b>resample</b> residuals. The method proceeds as follows.|$|R
40|$|Infinite order V-statistics (IOVSs), an {{extension}} of V-statistics, are studied. Their L 1 consistency and asymptotic normality are proved. A class of <b>resampled</b> V-statistics, a good proxy of the corresponding IOVSs when orders of kernels are large, is introduced to alleviate computational difficulties. Asymptotic properties of <b>resampled</b> V-statistics are also proved. Applicability of IOVSs are demonstrated by two examples. U-statistics Asymptotic normality Renewal function...|$|R
50|$|In {{regression}} problems, case <b>resampling</b> {{refers to}} the simple scheme of <b>resampling</b> individual cases - often rows of a data set. For regression problems, {{so long as the}} data set is fairly large, this simple scheme is often acceptable. However, the method is open to criticism.|$|E
5000|$|<b>Resampling</b> Methods, Birkhauser, Boston, 1999 (3rd edition, 2005).|$|E
5000|$|... libavresample : A library {{containing}} audio <b>resampling</b> routines.|$|E
40|$|Mean for Large r Median for Small r Fig. 1. Flow {{chart for}} the {{ensemble}} approach to gene prioritization after missing value imputation: <b>resample</b> imputed data vectors are first generated in a bootstrap manner for each sample; <b>resample</b> imputed data matrices are then generated by randomly selecting one <b>resample</b> vector for each sample; <b>resample</b> prioritization vectors are finally calculated {{based on these}} <b>resample</b> matrices and their average is considered as the estimated vector for gene prioritization. data, gene prioritization is equivalent to detecting differentially expressed genes. When missing value imputation and gene prioritization are sequentially conducted, {{it is necessary to}} consider the distribution space of prioritization scores due to the existence of missing values. However, this issue has not been addressed since all the aforementioned missing value imputation methods only provide one estimate for each missing observation. Ensemble methods, such as boosting (Freund and Schapire, 1997) and random forest (Breiman, 2001), have been widely used in the field of machine learning. When the number of predictor variables is relatively large, these methods can usually achieve satisfactory classification performance through combining a group of weak classifiers. In this study, we propose an ensemble approach {{to address the issue of}} microarray data based gene prioritization after missing value imputation. We first describe some preliminaries. Then, we detail a bootstrap based procedure. A two-sample microarray data set is used to illustrate our approach. ...|$|R
50|$|More formally, the {{bootstrap}} {{works by}} treating inference {{of the true}} probability distribution J, given the original data, as being analogous to inference of the empirical distribution of Ĵ, given the <b>resampled</b> data. The accuracy of inferences regarding Ĵ using the <b>resampled</b> data can be assessed because we know Ĵ. If Ĵ is a reasonable approximation to J, then the quality of inference on J can in turn be inferred.|$|R
5|$|<b>Resample</b> {{the current}} curve by placing new sample points at a uniform spacing, as {{measured}} by normalized arc length.|$|R
