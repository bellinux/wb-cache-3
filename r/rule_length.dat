19|221|Public
30|$|Many other indexes and methodologies {{have been}} {{developed}} for assessing the interpretability, which are considered in this paper. These are (1) number of rules (NOR), (2) total <b>rule</b> <b>length</b> (TRL) - the sum of the number of premises in all the rules, and (3) average <b>rule</b> <b>length</b> (ARL) - calculated by TRL/NOR.|$|E
40|$|AbstractKnowledge {{representation}} and extraction {{are very important}} tasks in data mining. In this work, we proposed a variety of rule-based greedy algorithms that able to obtain knowledge contained in a given dataset {{as a series of}} inhibitory rules containing an expression “attribute ≠ value” on the right-hand side. The main goal {{of this paper is to}} determine based on rule characteristics, <b>rule</b> <b>length</b> and coverage, whether the proposed rule heuristics are statistically significantly different or not; if so, we aim to identify the best performing rule heuristics for minimization of <b>rule</b> <b>length</b> and maximization of rule coverage. Friedman test with Nemenyi post-hoc are used to compare the greedy algorithms statistically against each other for length and coverage. The experiments are carried out on real datasets from UCI Machine Learning Repository. For leading heuristics, the constructed rules are compared with optimal ones obtained based on dynamic programming approach. The results seem to be promising for the best heuristics: the average relative difference between length (coverage) of constructed and optimal rules is at most 2. 27 % (7 %, respectively). Furthermore, the quality of classifiers based on sets of inhibitory rules constructed by the considered heuristics are compared against each other, and the results show that the three best heuristics from the point of view classification accuracy coincides with the three well-performed heuristics from the point of view of <b>rule</b> <b>length</b> minimization...|$|E
40|$|Knowledge {{representation}} and extraction {{are very important}} tasks in data mining. In this work, we proposed a variety of rule-based greedy algorithms that able to obtain knowledge contained in a given dataset {{as a series of}} inhibitory rules containing an expression “attribute ≠ value” on the right-hand side. The main goal {{of this paper is to}} determine based on rule characteristics, <b>rule</b> <b>length</b> and coverage, whether the proposed rule heuristics are statistically significantly different or not; if so, we aim to identify the best performing rule heuristics for minimization of <b>rule</b> <b>length</b> and maximization of rule coverage. Friedman test with Nemenyi post-hoc are used to compare the greedy algorithms statistically against each other for length and coverage. The experiments are carried out on real datasets from UCI Machine Learning Repository. For leading heuristics, the constructed rules are compared with optimal ones obtained based on dynamic programming approach. The results seem to be promising for the best heuristics: the average relative difference between length (coverage) of constructed and optimal rules is at most 2. 27...|$|E
30|$|Kavosh is not {{suitable}} for high-dimensional data because creating all the input field combinations requires many nodes in the data generation layer. However, Kavosh is completely usable for normal data (not high-dimensional data) and can generate rules of a predefined <b>length</b> if other <b>rule</b> <b>lengths</b> are not required.|$|R
40|$|Summary. Cell fission process {{consists}} {{of the division of}} a cell into two new cells such that the contents of the initial cell is distributed between the newly created cells. This process is modelled by a new kind of cell separation rules in the framework of Membrane Computing. Specifically, in tissue-like membrane systems, cell separation rules have been considered joint with communication rules of the form symport/antiport. These models are able to create an exponential workspace, expressed {{in terms of the number}} of cells, in linear time. On the one hand, an efficient and uniform solution to the SAT problem by using cell separation and communication <b>rules</b> with <b>length</b> at most 8 has been recently given. On the other hand, only tractable problems can be efficiently solved by using cell separation and communication <b>rules</b> with <b>length</b> at most 1. Thus, in the framework of tissue P systems with cell separation, and assuming that P ̸ = NP, a first frontier between efficiency and non-efficiency is obtained when passing from communication <b>rules</b> with <b>length</b> 1 to communication <b>rules</b> with <b>length</b> at most 8. In this paper we improve the previous result by showing that the SAT problem can be solved by a family of tissue P systems with cell separation in linear time, by using com-munication <b>rules</b> with <b>length</b> at most 3. Hence, we provide a new tractability borderline: passing from 1 to 3 amounts to passing from non–efficiency to efficiency, assuming that P ̸ = NP. ...|$|R
40|$|Cell fission process {{consists}} {{of the division of}} a cell into two new cells such that the contents of the initial cell is distributed between the newly created cells. This process is modelled by a new kind of cell separation rules in the framework of Membrane Computing. Specifically, in tissue-like membrane systems, cell separation rules have been considered joint with communication rules of the form symport/antiport. These models are able to create an exponential workspace, expressed {{in terms of the number}} of cells, in linear time. On the one hand, an efficient and uniform solution to the SAT problem by using cell separation and communication <b>rules</b> with <b>length</b> at most 8 has been recently given. On the other hand, only tractable problems can be efficiently solved by using cell separation and communication <b>rules</b> with <b>length</b> at most 1. Thus, in the framework of tissue P systems with cell separation, and assuming that P ̸= NP, a first frontier between efficiency and non-efficiency is obtained when passing from communication <b>rules</b> with <b>length</b> 1 to communication <b>rules</b> with <b>length</b> at most 8. In this paper we improve the previous result by showing that the SAT problem can be solved by a family of tissue P systems with cell separation in linear time, by using communication <b>rules</b> with <b>length</b> at most 3. Hence, we provide a new tractability borderline: passing from 1 to 3 amounts to passing from non–efficiency to efficiency, assuming that P ̸= NP. Ministerio de Ciencia e Innovación TIN 2009 - 13192 Junta de Andalucía P 08 – TIC 0420...|$|R
40|$|We {{relate the}} problem of finding the best {{application}} of a Synchronous Context-Free Grammar (SCFG) rule during parsing to a Markov Random Field. This representation allows us to use the theory of expander graphs {{to show that the}} complexity of SCFG parsing of an input sentence of length N is Ω(Ncn), for a grammar with maximum <b>rule</b> <b>length</b> n and some constant c. This improves on the previous best result of Ω(N c √ n...|$|E
40|$|We generalize Uno and Yagiura’s {{algorithm}} {{for finding}} all common intervals of two permutations to {{the setting of}} two sequences with many-to-many alignment links across the two sides. We show how to maximally decompose a word-aligned sentence pair in linear time, {{which can be used}} to generate all possible phrase pairs or a Synchronous Context-Free Grammar (SCFG) with the simplest rules possible. We also use the algorithm to precisely analyze the maximum SCFG <b>rule</b> <b>length</b> needed to cover hand-aligned data from various language pairs. ...|$|E
30|$|In this section, we {{applied the}} {{proposed}} approach {{on a real}} dataset commonly used {{in the field of}} KDD [36], which identifies the characteristics of a set of customers who filed a credit application file, as a case study to illustrate the performance of our proposed approach. In addition, according to decision makers preferences we used a threshold minimum support = 0.33, confidence = 0.75, max <b>rule</b> <b>length</b> = 3 and lift = 1, for extracting frequent itemsets, then we obtain 27 extracted rules given in Table   2.|$|E
40|$|Summary. In the {{framework}} of tissue P systems with cell division, the <b>length</b> of communication <b>rules</b> provides a frontier for the tractability of decision problems. On the one hand, the limitation on the efficiency of tissue P systems with cell division and communication <b>rules</b> of <b>length</b> 1 has been established. On the other hand, polynomial time solutions to NP–complete problems by using families of tissue P systems with cell division and communication <b>rules</b> of <b>length</b> at most 3 has been provided. In this paper, we improve the previous result by showing that the HAM-CYCLE problem can be solved in polynomial time by a family of tissue P systems with cell division by using communication <b>rules</b> with <b>length</b> at most 2. Hence, a new tractability boundary is given: passing from 1 to 2 amounts to passing from non–efficiency to efficiency, assuming that P ̸ = NP. ...|$|R
40|$|Abstract Assigning bond orders is a {{necessary}} and essential step for characterizing a chemical structure correctly in force field based simulations. Several methods {{have been developed to}} do this. They all have advantages but with limitations too. Here, an automatic algorithm for assigning chemical connectivity and bond order regardless of hydrogen for organic molecules is provided, and only three dimensional coordinates and element identities are needed for our algorithm. The algorithm uses hard <b>rules,</b> <b>length</b> <b>rules</b> and conjugation rules to fix the structures. The hard rules determine bond orders based on the basic chemical rules; the <b>length</b> <b>rules</b> determine bond order by the length between two atoms based on a set of predefined values for different bond types; the conjugation rules determine bond orders by using the length information derived from the previous rule, the bond angles and some small structural patterns. The algorithm is extensively evaluated in three datasets, and achieves good accuracy of predictions for all the datasets. Finally, the limitation and future improvement of the algorithm are discussed. </p...|$|R
40|$|In the {{framework}} of tissue P systems with cell division, the <b>length</b> of communication <b>rules</b> provides a frontier for the tractability of decision problems. On the one hand, the limitation on the efficiency of tissue P systems with cell division and communication <b>rules</b> of <b>length</b> 1 has been established. On the other hand, polynomial time solutions to NP–complete problems by using families of tissue P systems with cell division and communication <b>rules</b> of <b>length</b> at most 3 has been provided. In this paper, we improve the previous result by showing that the HAM-CYCLE problem can be solved in polynomial time by a family of tissue P systems with cell division by using communication <b>rules</b> with <b>length</b> at most 2. Hence, a new tractability boundary is given: passing from 1 to 2 amounts to passing from non–efficiency to efficiency, assuming that P ̸= NP. Ministerio de Ciencia e Innovación TIN 2009 - 13192 Junta de Andalucía P 08 – TIC 0420...|$|R
40|$|In the paper, authors {{presents}} a greedy algorithm {{for construction of}} exact and partial decision rules for decision tables with many-valued decisions. Exact decision rules can be 'over-fitted', so instead of exact decision rules with many attributes, it is more appropriate to work with partial decision rules with smaller number of attributes. Based on results for set cover problem authors study bounds on accuracy of greedy algorithm for exact and partial decision rule construction, {{and complexity of the}} problem of minimization of decision <b>rule</b> <b>length.</b> © 2011 Springer-Verlag...|$|E
40|$|This {{paper is}} devoted to the study of {{approximate}} algorithms for minimization of partial association <b>rule</b> <b>length.</b> It is shown that under some natural assumptions on the class NP, a greedy algorithm is close to the best polynomial approximate algorithms for solving of this NP-hard problem. The paper contains various bounds on precision of the greedy algorithm, bounds on minimal length of rules based on an information obtained during greedy algorithm work, and results of the study of association rules for the most part of binary information systems. © 2009 Springer Berlin Heidelberg...|$|E
40|$|The aim of {{the paper}} is to study efficeient of {{inference}} process using clustered partial decision rules. Partial decision rules are constructed by greedy algorithm. They are clustered with Agglomerative Hierarchical Clustering (AHC) algorithm. We study how exact and partial decision rules clustered by AHC algorithm in-fluence on inference process in knowledge base. Clusters of rules are a way of modularization of knowledge bases in Decision Support Systems. Results of ex-periemnts present how different facors (e. g. <b>rule</b> <b>length,</b> number of facts given as an input knowledge) can influence on the efficiency of inference process...|$|E
50|$|There {{are a few}} {{exceptions}} to the ultima <b>length</b> <b>rule.</b>|$|R
50|$|Vowel {{length is}} usually {{conditioned}} by the Scottish Vowel <b>Length</b> <b>Rule.</b>|$|R
40|$|We {{address the}} problem of {{learning}} maximal <b>length</b> <b>rules.</b> Roughly speaking, a rule is called maximal length if the addition of any condition into the rule will make it cover less positive examples, In contrast, a rule is called minimal length if the deletion of any condition from the rule will make it cover more negative examples (minimal <b>length</b> <b>rule</b> corresponds to minimal attribute set, i. e., reduct or value reduct). We introduce a notion of positive-negative matrix, as an extended version of discernibility matrix, used to represent the discernibility of attribute-value of an example against other examples. An algorithm based on positive-negative matrix, called MinMax, is presented to learn minimal and maximal <b>length</b> <b>rules.</b> Experimental results and comparison on several datasets from UCI repository demonstrate that on most datasets the maximal <b>length</b> <b>rule</b> induction approach performs prediction better than the minimal. keywords: roughset, rule induction, experimental comparison 1 Intr [...] ...|$|R
40|$|Factoring a Synchronous Context-Free Grammar into an {{equivalent}} grammar {{with a smaller}} number of nonterminals in each rule enables synchronous parsing algorithms of lower complexity. The problem can be formalized as searching for the tree-decomposition of a given permutation with the minimal branching factor. In this paper, by modifying the algorithm of Uno and Yagiura (2000) for the closely related problem of finding all common intervals of two permutations, we achieve a linear time algorithm for the permutation factorization problem. We also use the algorithm to analyze the maximum SCFG <b>rule</b> <b>length</b> needed to cover hand-aligned data from various language pairs. ...|$|E
40|$|In {{the area}} of machine {{translation}} (MT) system combination, previous work on generating input hypotheses has focused on varying a core aspect of the MT system, such as the decoding algorithm or alignment algorithm. In this paper, we propose a new method for generating diverse hypotheses from a single MT system using traits. These traits are simple properties of the MT output such as “average output length ” and “average <b>rule</b> <b>length.</b> ” Our method is designed to select hypotheses which vary in trait value but do not significantly degrade in BLEU score. These hypotheses can be combined using standard system combination techniques to produce a 1. 2 - 1. 5 BLEU gain on the Arabic-English NIST MT 06 /MT 08 translation task. ...|$|E
40|$|This paper {{shows how}} {{a small number}} of fuzzy rules can be {{selected}} for designing interpretable fuzzy rule-based classification systems. Our approach consists of two phases: candidate rule generation by data mining criteria and rule selection by genetic algorithms. First a large number of candidate rules are generated and prescreened using two rule evaluation criteria in data mining. Next {{a small number of}} fuzzy rules are selected from candidate rules using genetic algorithms. Rule selection is formulated as an optimization problem with three objectives: to maximize the classification accuracy, to minimize the number of selected rules, and to minimize the total <b>rule</b> <b>length.</b> Thus the task of genetic algorithms is to find non-dominated rule sets with respect to the three objectives. 1...|$|E
40|$|Summary. The most {{investigated}} {{variants of}} P {{systems in the}} last years are cell-like models, especially in terms of efficiency. Recently, different new models of tissue-like (symport/antiport) P systems have received important attention. This paper presents a new class of tissue P systems with cell separation, where cell separation can generate new workspace. Its efficiency is investigated, specifically, (a) only tractable problem can be efficiently solved by using cell separation and communication <b>rules</b> with <b>length</b> at most 1, and (b) an efficient (uniform) solution to SAT problem by using cell separation and communication <b>rules</b> with <b>length</b> at most 6 is presented. Further research topics and open problems are discussed, too. ...|$|R
50|$|Identifier <b>length</b> <b>rules</b> are {{routinely}} contested in practice, {{and subject to}} much debate academically.|$|R
40|$|The most {{investigated}} {{variants of}} P {{systems in the}} last years are cell-like models, especially in terms of efficiency. Recently, different new models of tissue-like (symport/antiport) P systems have received important attention. This paper presents a new class of tissue P systems with cell separation, where cell separation can generate new workspace. Its efficiency is investigated, specifically, (a) only tractable problem can be efficiently solved by using cell separation and communication <b>rules</b> with <b>length</b> at most 1, and (b) an efficient (uniform) solution to SAT problem by using cell separation and communication <b>rules</b> with <b>length</b> at most 6 is presented. Further research topics and open problems are discussed, too. Ministerio de Educación y Ciencia TIN 2006 - 13452 Junta de Andalucía P 08 – TIC 0420...|$|R
40|$|Intrusion Detection Systems (IDSs) {{are used}} to {{establish}} if someone has made an intrusion into the network or {{is trying to make}} one. Many techniques are available to construct IDS using genetic algorithm, but all are based on a fixed length rule. In this paper, we propose to improve the IDSs by using dynamic length rule with an automatic feature selection. The proposed improvement accounts for the complexity of the data by using two of the most popular methods of soft computing, namely Fuzzy Logic and Genetic Algorithm. For a proper determination of the <b>rule</b> <b>length</b> we apply iterative rule learning based on a fuzzy rule-based genetic classifier. We distinguish five main classes, viz. Normal, User-to-Root (U 2 R), Probe, Remote-to-Local (R 2 L), and Denial-of-Service (DoS). The first aim of the paper is to suggest an automatic method for producing rules (chromosomes) of dynamic length. The chromosome length represents number of features involved in the corresponding rule. The second aim is to evolve comprehensible rules that improve the classification rate for each of the five classes. In the paper the performance of the evolved rules is given per class. The obtained results provide the detection rate with regard...|$|E
40|$|Multi-relation classifications can {{be widely}} used in many disciplines, such as {{financial}} decision making, medical research, and geographical applications, and information stored in multiple relations needs {{to be used in}} decision making. Crossmine is an efficient and scalable approach for multi-relation classification. Crossmine algorithm has three step, first is find-rules, the rule has been gotten from find a rule process than remove all positive tuples satisfying rule while there are more than ten percent positif tuple left. The second is find a rule, this step has input from the result of find best predicate process, that is the complex predicate with most foilgain. If foilgain value is more than mingain, the predicate is added with rule, and max <b>rule</b> <b>length</b> less than six. Third is find best predicate, in this step we find the best predicate with definition, if the foilgain value more than the max gain value, the predicate will be saved and the bigger gain value will replace the last gain value for next comparative process. In other side, the accuracy is computed from each rule that produce in find rules process. The test for this application use the sum tuple of 200, 500, 1000, 5000 for measuring the level of accuracy from rule which is produced by crossmine algorithm...|$|E
40|$|Knowledge mined from {{clinical}} {{data can}} be used for medical diagnosis and prognosis. By improving the quality of knowledge base, the efficiency of prediction of a knowledge-based system can be enhanced. Designing accurate and precise clinical decision support systems, which use the mined knowledge, is still a broad area of research. This work analyses the variation in classification accuracy for such knowledge-based systems using different rule lists. The purpose of this work is not to improve the prediction accuracy of a decision support system, but analyze the factors that influence the efficiency and design of the knowledge base in a rule-based decision support system. Three benchmark medical datasets are used. Rules are extracted using a supervised machine learning algorithm (PART). Each rule in the ruleset is validated using nine frequently used rule interestingness measures. After calculating the measure values, the rule lists are used for performance evaluation. Experimental results show variation in classification accuracy for different rule lists. Confidence and Laplace measures yield relatively superior accuracy: 81. 188 % for heart disease dataset and 78. 255 % for diabetes dataset. The accuracy of the knowledge-based prediction system is predominantly dependent on the organization of the ruleset. <b>Rule</b> <b>length</b> needs to be considered when deciding the rule ordering. Subset of a rule, or combination of rule elements, may form new rules and sometimes {{be a member of the}} rule list. Redundant rules should be eliminated. Prior knowledge about the domain will enable knowledge engineers to design a better knowledge base...|$|E
50|$|Vowel {{length is}} {{by and large}} {{determined}} by the Scottish Vowel <b>Length</b> <b>Rule,</b> although {{there are a few}} exceptions.|$|R
25|$|For some speakers, vowel length {{alternates}} with vowel {{quality in}} a very similar way to the Scottish vowel <b>length</b> <b>rule.</b>|$|R
5000|$|However, the Chronicle continues, [...] "Peada <b>ruled</b> no <b>length</b> of time, {{because he}} was betrayed by his own queen at Eastertide"; Bede also reports that Peada was [...] "very wickedly killed" [...] through his wife's treachery [...] "during the very time of celebrating Easter" [...] in 656.|$|R
40|$|A {{two-stage}} {{hybrid model}} for data classification and rule extraction is proposed. The first stage uses a Fuzzy ARTMAP (FAM) classifier with Q-learning (known as QFAM) for incremental learning of data samples, {{while the second}} stage uses a Genetic Algorithm (GA) for rule extraction from QFAM. Given a new data sample, the resulting hybrid model, known as QFAM-GA, is able to provide prediction pertaining to the target class of the data sample {{as well as to}} give a fuzzy if-then rule to explain the prediction. To reduce the network complexity, a pruning scheme using Q-values is applied {{to reduce the number of}} prototypes generated by QFAM. A 2 ̆ 7 don 2 ̆ 7 t care 2 ̆ 7 technique is employed to minimize the number of input features using the GA. A number of benchmark problems are used to evaluate the effectiveness of QFAM-GA in terms of test accuracy, noise tolerance, model complexity (number of rules and total <b>rule</b> <b>length).</b> The results are comparable, if not better, than many other models reported in the literature. The main significance of this research is a usable and useful intelligent model (i. e., QFAM-GA) for data classification in noisy conditions with the capability of yielding a set of explanatory rules with minimum antecedents. In addition, QFAM-GA is able to maximize accuracy and minimize model complexity simultaneously. The empirical outcome positively demonstrate the potential impact of QFAM-GA in the practical environment, i. e., providing an accurate prediction with a concise justification pertaining to the prediction to the domain users, therefore allowing domain users to adopt QFAM-GA as a useful decision support tool in assisting their decision-making processes...|$|E
40|$|This paper {{shows how}} {{a small number}} of simple fuzzy if-then rules can be {{selected}} for pattern classification problems with many continuous attributes. Our approach consists of two phases: Candidate rule generation by rule evaluation measures in data mining and rule selection by multi-objective evolutionary algorithms. In our approach, first candidate fuzzy if-then rules are generated from numerical data and prescreened using two rule evaluation measures (i. e., confidence and support) in data mining. Then {{a small number of}} fuzzy if-then rules are selected from the prescreened candidate rules using multiobjective evolutionary algorithms. In rule selection, we use three objectives: maximization of the classification accuracy, minimization of the number of selected rules, and minimization of the total <b>rule</b> <b>length.</b> Thus the task of multi-objective evolutionary algorithms is to find a number of non-dominated rule sets with respect to these three objectives. The main contribution {{of this paper is to}} propose an idea of utilizing the two rule evaluation measures as prescreening criteria of candidate rules for fuzzy rule selection. An arbitrarily specified number of candidate rules can be generated from numerical data for high-dimensional pattern classification problems. Through computer simulations, we demonstrate that such a prescreening procedure improves the efficiency of our approach to fuzzy rule selection. We also extend a multi-objective genetic algorithm (MOGA) in our former studies to a multi-objective genetic local search (MOGLS) algorithm where a local search procedure adjusts the selection (i. e., inclusion or exclusion) of each candidate rule. Furthermore, a learning algorithm of rule weights (i. e., certainty factors) is combined with our MOGLS algorithm. Such extensions to our MOGA for fuzzy rule selection are another contribution of this paper...|$|E
40|$|Rule-based {{classification}} system (RBC) {{has been widely}} used in many real world applications because of the easy interpretability of rules. RBC mines a collection of rule via knowledge which is hidden in dataset in order to accurately map new cases to the decision class. In the real world, the number of attribute of dataset could be very large due the capability of database technology to store much information. Following that, the large dataset may contain thousands of relationship and it will likely provide more knowledge since the interrelationship between data will give more description. Furthermore, it is also have the possibility to have most number of rules that contain unnecessary rule or redundancies in the model. Theoretically, a good set of knowledge should provide good accuracy when dealing with new cases. Besides accuracy, a good rule set must also has a minimum number of rules and each rule should be short as possible. It is often that a rule set contains smaller quantity of rules but they usually have more conditions. An ideal model {{should be able to}} produces fewer, shorter rule and classify new data with good accuracy. Consequently, the quality and compact knowledge will contribute manager with a good decision model. Because of that, the search for appropriate data mining approach which can provide quality knowledge is important. Rough classifier (RC) and decision tree classifier (DTC) are categorized as RBC. The {{purpose of this study is}} to investigate the capability of RC and DTC in generating quality knowledge which leads to the good accuracy. To achieve that, both classifiers are compared based on four measurements that are accuracy of the classification, the number of rule, the length of rule, and the coverage of rule. Five dataset from UCI Machine Learning namely United States Congressional Voting Records, Credit Approval, Wisconsin Diagnostic Breast Cancer, Pima Indians Diabetes Database, and Vehicle Silhouettes are chosen as data experiment. All datasets were mined using RC toolkit namely ROSETTA while C 4. 5 algorithm in WEKA application was chosen as DTC rule generator. The experimental results indicated that both classifiers produced good classification result and had generated quality rule in different types of model – higher accuracy, fewer rule, shorter rule, and higher coverage. In term of accuracy, RC obtained higher accuracy in average while DTC significantly generated lower number of rule than RC. In term of <b>rule</b> <b>length,</b> RC produced compact and shorter rule than DTC and the length is not significantly different. Meanwhile, RC has better coverage than DTC. Final conclusion can be decided as follows “If the user interested at a variety of rule pattern with a good accuracy and the number of rule is not important, RC is the best solution whereas if the user looks for fewer nr, DTC might be the best choice...|$|E
5000|$|While the House of Representatives has {{exclusive}} power to originate revenue bills, such legislation can be amended and/or substituted by the Senate. Moreover, because the Senate {{is considered to}} be the [...] "deliberative body", <b>rules</b> concerning <b>length</b> of debate are more liberal than those of the House of Representatives.|$|R
3000|$|... [...]. Namely, the <b>rule</b> for the <b>lengths</b> of {{negative}} and positive semi-cycles to occur successively can be periodically expressed as follows: [...]...|$|R
50|$|Contract {{benefits}} for members include minimum wages, work <b>rules</b> such as <b>length</b> of work day, health insurance, pension, and workers' compensation insurance.|$|R
