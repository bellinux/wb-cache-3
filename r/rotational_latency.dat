57|3|Public
25|$|<b>Rotational</b> <b>latency</b> is {{incurred}} {{because the}} desired disk sector {{may not be}} directly under the head when data transfer is requested. Average <b>rotational</b> <b>latency</b> {{is shown in the}} table, based on the statistical relation that the average latency is one-half the rotational period.|$|E
50|$|<b>Rotational</b> <b>latency</b> (sometimes called {{rotational}} delay or just latency) is the delay {{waiting for the}} rotation of the disk to bring the required disk sector under the read-write head. It depends on the rotational speed of a disk (or spindle motor), measured in revolutions per minute (RPM). For most magnetic media-based drives, the average <b>rotational</b> <b>latency</b> is typically based on the empirical relation that the average latency in milliseconds for such a drive is one-half the rotational period. Maximum <b>rotational</b> <b>latency</b> is {{the time it takes to}} do a full rotation excluding any spin-up time (as the relevant part of the disk may have just passed the head when the request arrived). Therefore, the <b>rotational</b> <b>latency</b> and resulting access time can be improved (decreased) by increasing the rotational speed of the disks. This also has the benefit of improving (increasing) the throughput (discussed later in this article).|$|E
50|$|The {{performance}} of a storage device can be quantified {{as the number of}} Input/Output operations Per Second (IOPS) it achieves. HDD IOPS is proportional to RPM. When a system requests to read/write data randomly from/to a HDD, seek time and <b>rotational</b> <b>latency</b> are two HDD activities that significantly reduce HDD IOPS. Seek time is {{the time it takes to}} move the HDD head to the correct cylinder to begin to receive data. <b>Rotational</b> <b>latency</b> is the time it takes to rotate the HDD platter beneath the head so that the data can be read/written. <b>Rotational</b> <b>latency</b> varies based on the RPM of the HDD.|$|E
50|$|High {{performance}} of distributed file systems requires efficient communication between computing nodes and fast {{access to the}} storage systems. Operations such as open, close, read, write, send, and receive need to be fast, to ensure that performance. For example, each read or write request accesses disk storage, which introduces seek, <b>rotational,</b> and network <b>latencies.</b>|$|R
40|$|Since {{the time}} movable head disk came into existence, the I/O {{performance}} has been improved by proper scheduling of disk accesses. Disk scheduling involves a careful examination of pending requests {{to determine the}} most efficient way to service the requests. The two most common types of scheduling are seek optimization and <b>rotational</b> (or <b>latency)</b> optimization. Most of the scheduling algorithms concentrate on reducing seek times for a set of requests, because seek times tend to be an order of magnitude greater than latency times. Some of the most important scheduling algorithms are First-Come-First-Served (FCFS), Shortest Seek Time First (SSTF), SCAN, Circular Scan (C-SCAN) and LOOK. FCFS is the simplest form of disk scheduling algorithm. This algorithm is simple to implement, but it generally does not provide the fastest service. This paper describes an improvement in FCFS. A simulator program has been designed and tested the improved FCFS. After improvement in FCFS it has been found that the service is fast and seek time has been reduced drastically...|$|R
40|$|This reseach {{project is}} a {{theoretical}} and experimental investigation of scheduling strategies that can improve the performance of Interactive Video-On-Demand (IVOD) servers. Examples of IVOD {{can be found in}} digital libraries, hypermedia, distance learning, entertainment and telemarketing applications. In contrast to the delivery of movies, interactive video programmes are seldom linear. IVOD programmes usually consist of short video branches separated by user interactions. IVOD users will not be satisfied with long latency for start-up and restart of video branches. Further, interactive media may be accompanied by other forms of data such as voice, audio, image, text or graphics. For that reason, an IVOD server also needs to provide adequate residual bandwidth to support sporadic data requests arising from user interactions. Therefore, an IVOD scheduler needs to address performance issues such as startup latencies, queuing time, admission probabilities, and data throughput. As the length of video branches in IVOD are typically short, departures and startup of requests are frequent. The adverse effects of these frequent transients on throughput and robustness must also be treated explicitly. The user-driven interactivity in IVOD service poses scheduling problems that have not been fully addressed by the admission control and static disk-scheduling techniques previously proposed for VOD servers. In this research, we identify IVOD performance issues and present solutions to address some of these performance issues. Our philosophy is to dynamically schedule request admissions and disk accesses in an IVOD server, by exploiting the use of run-time information. At the disk scheduling level, we introduce two disk scheduling strategies. To minimize start-up latency and achieve good tolerance against variable-bit-rate, we introduce the GS_EDF scheduler. To reduce the long start-up latency inherent to seek-reducing disk schedulers, we introduce the GSCS scheduler which can significantly reduce start-up latency while preserving a high stream throughput. At the admission level, we introduce admission prioritizing strategies which can improve queuing time and total throughput of a busy IVOD server without causing undesirable throughput degradation and bandwidth fragmentation. To improve sporadic service throughput without losing streaming throughput, we introduce an optimum readsize control technique to maximize the disk efficiency dynamically. The readsize control technique is also novel in removing disk <b>rotational</b> <b>latencies.</b> All the techniques introduced in this thesis are verified by comprehensive performance evaluations. The results confirm that these proposed strategies can improve IVOD service in various dimensions of performance...|$|R
5000|$|<b>Rotational</b> <b>latency</b> - Average time, {{once the}} arm {{is on the}} right track, before a head is over a desired sector.|$|E
5000|$|While {{sequential}} access memory is read in sequence, arbitrary locations can still be accessed by [...] "seeking" [...] to the requested location. This operation, however, is often relatively inefficient (see seek time, <b>rotational</b> <b>latency).</b>|$|E
5000|$|Mainframe {{computers}} {{frequently used}} head-per-track disk drives or drums for page and swap storage to eliminate seek time, and several technologies to have multiple concurrent requests {{to the same}} device {{in order to reduce}} <b>rotational</b> <b>latency.</b>|$|E
5000|$|The {{performance}} of a drum with one head per track is determined almost entirely by the <b>rotational</b> <b>latency,</b> whereas in an HDD its performance includes a <b>rotational</b> <b>latency</b> delay plus the time to position the head over the desired track (seek time). In the era when drums were used as main working memory, programmers often did optimum programming—the programmer positioned code on the drum {{in such a way}} as to reduce the amount of time needed for the next instruction to rotate into place under the head. They did this by timing how long it would take after loading an instruction for the computer to be ready to read the next one, then placing that instruction on the drum so that it would arrive under a head just in time. This method of timing-compensation, called the [...] "skip factor" [...] or [...] "interleaving" [...] (interleaving in disk storage), was used for many years in storage memory controllers.|$|E
50|$|The {{absence of}} moving parts in USB flash devices allows true random access {{avoiding}} the <b>rotational</b> <b>latency</b> and seek time (see mechanical latency) of hard drives or optical media, meaning small programs will start faster from a USB flash drive {{than from a}} local hard disk or live CD. However, as USB devices typically achieve lower data transfer rates than internal hard drives, booting from older computers that lack USB 2.0 or newer can be very slow.|$|E
50|$|Latency is {{the delay}} for the {{rotation}} of the disk to bring the required disk sector under the read-write mechanism. It depends on rotational speed of a disk, measured in revolutions per minute (rpm). Average <b>rotational</b> <b>latency</b> is shown in the table on the right, based on the statistical relation that the average latency in milliseconds for such a drive is one-half the rotational period. Average latency (in milliseconds) is computed as 30,000 divided by rotational speed (in rpm).|$|E
50|$|Major page faults on {{conventional}} computers (which use hard disk drives for storage) {{can have a}} significant impact on performance. An average hard disk drive has an average <b>rotational</b> <b>latency</b> of 3 ms, a seek time of 5 ms, and a transfer time of 0.05 ms/page. Therefore, the total time for paging is near 8 ms (= 8,000 μs). If the memory access time is 0.2 μs, then the page fault would make the operation about 40,000 times slower.|$|E
50|$|Several {{tools and}} {{techniques}} that were {{implemented in the}} past to reduce the impact of the <b>rotational</b> <b>latency</b> of traditional HDDs, most notably disk defragmentation, SuperFetch, ReadyBoost, and application launch prefetching, involve reorganizing (rewriting) the data on the platters. Since SSDs have no moving platters, this reorganization has no advantages, and may instead shorten the life of the solid state memory. Therefore, these tools are by default disabled on SSDs in Windows 7, except for some early generation SSDs that might still benefit.|$|E
5000|$|Many 1 in {{hard drives}} (often {{referred}} to by the trademarked name [...] "Microdrive") typically spin at 3600 RPM, so <b>rotational</b> <b>latency</b> is a consideration, as is spin-up from standby or idle. Seagate's 8 GB ST68022CF drive spins up fully within a few revolutions but current drawn can reach up to 350 milliamps and runs at 40-50 mA mean current. Its average seek time is 8 ms and can sustain 9 MByte/s read and write, and has an interface speed of 33 MByte/s. Hitachi's 4 GB Microdrive is 12 ms seek, sustained 6 MByte/s.|$|E
50|$|Any {{mechanical}} process encounters limitations modeled by Newtonian physics. The {{behavior of}} disk drives {{provides an example}} of mechanical latency. Here, it is the time needed for the data encoded on a platter to rotate from its current position to a position adjacent to the read-write head as well as the seek time required for the actuator arm for the read-write head to be positioned above the appropriate track. This is also known as <b>rotational</b> <b>latency</b> and seek time since the basic term latency is also applied to the time required by a computer's electronics and software to perform polling, interrupts, and direct memory access.|$|E
50|$|Making a {{comparison}} between SSDs and ordinary (spinning) HDDs is difficult. Traditional SSD benchmarks {{tend to focus on}} the performance characteristics that are poor with HDDs, such as <b>rotational</b> <b>latency</b> and seek time. As SSDs do not need to spin or seek to locate data, they may prove vastly superior to HDDs in such tests. However, SSDs have challenges with mixed reads and writes, and their performance may degrade over time. SSD testing must start from the (in use) full disk, as the new and empty (fresh, out-of-the-box) disk may have much better write performance than it would show after only weeks of use.|$|E
50|$|In addition, no ATA {{hard drives}} existed in 2005 that {{were capable of}} {{measured}} sustained transfer rates of above 80 MB/s. Furthermore, sustained transfer rate tests do not give realistic throughput expectations for most workloads: They use I/O loads specifically designed to encounter almost no delays from seek time or <b>rotational</b> <b>latency.</b> Hard drive performance under most workloads is limited first and second by those two factors; the transfer rate on the bus is a distant third in importance. Therefore, transfer speed limits above 66 MB/s really affect performance only when the hard drive can satisfy all I/O requests by reading from its internal cache—a very unusual situation, especially considering that such data is usually already buffered by the operating system.|$|E
50|$|For example, {{files in}} a file system are usually managed in units called blocks or clusters. When a file system is created, there is free space to store file blocks {{together}} contiguously. This allows for rapid sequential file reads and writes. However, as files are added, removed, and changed in size, the free space becomes externally fragmented, leaving only small holes {{in which to}} place new data. When a new file is written, or when an existing file is extended, the operating system puts the new data in new non-contiguous data blocks {{to fit into the}} available holes. The new data blocks are necessarily scattered, slowing access due to seek time and <b>rotational</b> <b>latency</b> of the read/write head, and incurring additional overhead to manage additional locations. This is called file system fragmentation.|$|E
50|$|File system {{fragmentation}} is {{more problematic}} with consumer-grade hard disk drives {{because of the}} increasing disparity between sequential access speed and <b>rotational</b> <b>latency</b> (and {{to a lesser extent}} seek time) on which file systems are usually placed. Thus, fragmentation is an important problem in file system research and design. The containment of fragmentation not only depends on the on-disk format of the file system, but also heavily on its implementation. File system fragmentation has less performance impact upon solid-state drives, as there is no mechanical seek time involved. However, the file system needs to store one additional piece of metadata for the corresponding file. Each piece of metadata itself occupies space and requires processing power and processor time. If the maximum fragmentation limit is reached, write requests fail.|$|E
50|$|A drum memory {{contained}} a large metal cylinder, coated {{on the outside}} surface with a ferromagnetic recording material. It {{could be considered the}} precursor to the hard disk drive (HDD), but {{in the form of a}} drum rather than a flat disk. In most designs, one or more rows of fixed read-write heads ran along the long axis of the drum, one for each track. The drum's controller simply selected the proper head and waited for the data to appear under it as the drum turned (<b>rotational</b> <b>latency).</b> Not all drum units were designed with each track having its own head. Some, such as the English Electric DEUCE drum and the Univac FASTRAND had multiple heads moving a short distance on the drum in contrast to modern HDDs, which have one head per platter surface.|$|E
50|$|The {{factors that}} limit {{the time to}} access the data on an HDD are mostly related to the {{mechanical}} nature of the rotating disks and moving heads. Seek time {{is a measure of}} how long it takes the head assembly to travel to the track of the disk that contains data. <b>Rotational</b> <b>latency</b> is incurred because the desired disk sector may not be directly under the head when data transfer is requested. These two delays are on the order of milliseconds each. The bit rate or data transfer rate (once the head is in the right position) creates delay which {{is a function of the}} number of blocks transferred; typically relatively small, but can be quite long with the transfer of large contiguous files. Delay may also occur if the drive disks are stopped to save energy.|$|E
5000|$|RAID 1 {{consists}} of data mirroring, without parity or striping. Data is written identically to two drives, thereby producing a [...] "mirrored set" [...] of drives. Thus, any read request can be serviced by any {{drive in the}} set. If a request is broadcast to every drive in the set, it can be serviced by the drive that accesses the data first (depending on its seek time and <b>rotational</b> <b>latency),</b> improving performance. Sustained read throughput, if the controller or software is optimized for it, approaches the sum of throughputs of every drive in the set, just as for RAID 0. Actual read throughput of most RAID 1 implementations is slower than the fastest drive. Write throughput is always slower because every drive must be updated, and the slowest drive limits the write performance. The array continues to operate as long as at least one drive is functioning.|$|E
50|$|Fractal Tree indexes {{also have}} several {{performance}} optimizations. First, buffers are themselves indexed {{in order to}} speed up searches. Second, leaves are much larger than in B-trees, which allows for greater compression. In fact, the leaves are chosen to be large enough that their access time {{is dominated by the}} bandwidth time, and therefore amortizes away the seek and <b>rotational</b> <b>latency.</b> Large leaves are an advantage with large range queries but slow down point queries, which require accessing {{a small portion of the}} leaf. The solution implemented in Fractal Tree indexes is to have large leaves that can be fetched as a whole for fast range queries but are broken into smaller pieces call basement nodes which can be fetched individually. Accessing a basement node is faster than accessing a leaf, because of the reduced bandwidth time. Thus the substructure of leaves in Fractal Tree indexes, as compared to Bε trees allows both range and point queries to be fast.|$|E
50|$|In modern computers, {{hard disk}} drives are usually used as {{secondary}} storage. The time taken to access a given byte of information stored {{on a hard}} disk is typically a few thousandths of a second, or milliseconds. By contrast, the time taken to access a given byte of information stored in random-access memory is measured in billionths of a second, or nanoseconds. This illustrates the significant access-time difference which distinguishes solid-state memory from rotating magnetic storage devices: hard disks are typically about a million times slower than memory. Rotating optical storage devices, such as CD and DVD drives, have even longer access times. With disk drives, once the disk read/write head reaches the proper placement and the data of interest rotates under it, subsequent data on the track are very fast to access. To reduce the seek time and <b>rotational</b> <b>latency,</b> data are transferred to and from disks in large contiguous blocks.|$|E
50|$|Power {{consumption}} {{has become}} increasingly important, not only in mobile devices such as laptops but also in server and desktop markets. Increasing data center machine density has led to problems delivering sufficient power to devices (especially for spin up), and {{getting rid of the}} waste heat subsequently produced, as well as environmental and electrical cost concerns (see green computing). Heat dissipation is tied directly to power consumption, and as drives age, disk failure rates increase at higher drive temperatures. Similar issues exist for large companies with thousands of desktop PCs. Smaller form factor drives often use less power than larger drives. One interesting development in this area is actively controlling the seek speed so that the head arrives at its destination only just in time to read the sector, rather than arriving as quickly as possible and then having to wait for the sector to come around (i.e. the <b>rotational</b> <b>latency).</b> Many of the hard drive companies are now producing Green Drives that require much less power and cooling. Many of these Green Drives spin slower (<5,400 rpm compared to 7,200, 10,000 or 15,000 rpm) thereby generating less heat. Power consumption can also be reduced by parking the drive heads when the disk is not in use reducing friction, adjusting spin speeds, and disabling internal components when not in use.|$|E
40|$|Reducing access {{times to}} {{secondary}} I/O devices {{has long been}} the focus of many systems researchers. With traditional disk drives, access time is the composition of seek time and <b>rotational</b> <b>latency,</b> and so many techniques to order I/O requests or place data to minimize these factors have been developed. MEMS-based storage devices are seen by many as a replacement or an augmentation for modern disk drives, but algorithms for reducing access time for MEMS-based devices are still poorly understood. These devices, based on MicroElectroMechanical systems (MEMS), use thousands of active read/write heads working in parallel on a two-dimensional non-rotating magnetic substrate, eliminating <b>rotational</b> <b>latency</b> variable from the access time equation. This leaves seek time as the dominant variable. Therefore, new data layout techniques based on minimizing the unique seek time characteristics of a MEMS-based storage device must be developed. This paper examines the qualities of a MEMS-based storage device, and based on experimental simulation, develops an understanding of the seek time characteristics on such a device. These characteristics then allow us to identify equivalent regions in which to place data for improved access. ...|$|E
40|$|Many {{computer}} applications require moving data from/to disk devices. Since the throughput of disk devices is extremely {{sensitive to the}} locality of accesses, the disk schedulers proposed in the literature typically assume {{the knowledge of the}} disks' physical parameters (e. g. seek and <b>rotational</b> <b>latency)</b> to meet the different Quality of Service requirements. Unfortunately, the unavoidable discrepancies between the estimated and actual values of such parameters affect the service guarantees, both in terms of response time and disk bandwidth distribution...|$|E
40|$|Due to the {{widening}} performance gap between RAM and disk drives, {{a large number}} of I/O optimization methods have been proposed and designed to alleviate the impact of this gap. One of the most effective approaches of improving disk access performance is enhancing data locality. This is because the method could increase the hit ratio of disk cache and reduce the seek time and <b>rotational</b> <b>latency.</b> Disk drives have experienced dramatic development since the first disk drive was announced in 1956. This paper investigates some important characteristics of modern disk drives. Based on the characteristics and the observation that data access on disk drives is highly skewed, the frequently accessed data blocks and the correlated data blocks are clustered into objects and moved to the outer zones of a modern disk drive. The idea attempts to enhance spatial locality, improve the efficiency of aggressive sequential prefetch, and take advantage of Zoned Bit Recording (ZBR). An experimental simulation is employed to investigate the performance gains generated by the enhanced data locality. The performance gains are analyzed by breaking down the disk access time into seek time, <b>rotational</b> <b>latency,</b> data transfer time, and hit ratio of the disk cache. Experimental results provide useful insights into the performance behaviours of a modern disk drive with enhanced data locality...|$|E
30|$|Storage Simulator This module {{takes the}} I/O {{requests}} from the dispatch queue of the OS Block Simulator {{and based on}} the device type (HDD or SSD), return performance metrics like completion time depending on {{the current state of the}} block device. The module takes block device configuration parameters as inputs (device driver) such as drive capacity, block device type (HDD or SSD), etc. For HDDs, drive parameters include geometry, no. of disk heads, no. of tracks (cylinders), sectors/track, rotations per minute (RPM), command processing time, settle time, average seek time, <b>rotational</b> <b>latency,</b> cylinder switch time, track-to-adjacent switch time, and head switch time. For SCMs (SSDs), the drive parameters include the no. of pages per block, size of each page, seek time (read, writes, erase) etc. The Storage Simulator is CHS compliant for 48 -bit LBA. The Storage simulator calculates the I/O access time (per I/O request) by HDDs considering the current location of the disk arm and time needed to reach the desired new location and access data size. The access time also takes into account minute details such as command processing time, settle time, <b>rotational</b> <b>latency,</b> cylinder (track) switch time, head switch time and average seek time [17, 40, 41]. For SSDs, the access time depends on the SSD properties provided by the manufacturer. The configurable features gives us the ability to test the schemes with different devices as well as drive architectures.|$|E
40|$|Streaming media servers {{and digital}} {{continuous}} media recorders require the scheduling of I/O requests to disk drives in real time. There are two accepted paradigms to achieve this: deterministic or statistical. The deterministic approach must assume larger bounds on such disk parameters as the seek time, the <b>rotational</b> <b>latency</b> and the transfer rate, {{to guarantee the}} timely service of I/O requests. The statistical approach generally allows higher utilization of resources, {{in exchange for a}} residual probability of missed I/O request deadlines. We propose a novel statistical admission control algorithm called TRAC based on a comprehensive three random variable (3 RV) model to support both reading and writing of multiple variable bit rate media streams on current generation disk drives. Its major distinctions from previous work include (1) a very realistic disk model which considers multi-zoning of disks, seek and <b>rotational</b> <b>latency</b> profiles, and unequal reading and writing data rate limits, (2) a dynamic bandwidth sharing mechanism between reading and writing, and (3) support for random placement of data blocks. We evaluate the TRAC algorithm through an extensive numerical analysis and real device measurements. The results show that it achieves a much more realistic resource utilization (up to 38 % higher) as compared with the best, previously proposed algorithm based on a single random variable (1 RV) model. Most impressive, in all the experiments the difference between the results generated by TRAC and the actual disk device measurements match closely...|$|E
40|$|Abstract. In this paper, {{we propose}} a RAID-disk {{placement}} algorithm of coded video data and an efficient disk prefetching method {{to increase the}} number of clients who can be serviced interactive operations in the media server. Our placement policy is incorporated with a special bit count control method that is based on repeated tuning of quantization parameters to adjust the actual bit count to the target bit count. The encoder using this method can generate coded frames whose sizes are synchronized with the RAID stripe size, so that when various fast-forward levels are accessed we can reduce the seek and <b>rotational</b> <b>latency</b> and enhance the disk throughput. ...|$|E
30|$|A fully {{directional}} and centralized three-way sectored antenna neighbor discovery (SAND) {{algorithm is}} proposed in [13], where a token is passed among network nodes sequentially to discover their surrounding neighbors. However, for token management, it requires a central node, which is not only often infeasible for many DSN applications but also limited by scalability. Furthermore, the <b>rotational</b> <b>latency</b> of a token affects the neighbor discovery accuracy and increases the overall neighbor discovery latency. The SAND mechanism also has not considered the directional synchronization issue among the nodes, causing deafness problem, and as a central controller controls the whole mechanism, the discovery latency sharply increases.|$|E
30|$|The data in HDDs is {{organized}} as 512 byte (or 4  kB emulated for newer drive technology) blocks in circular disk tracks {{and the data}} access time depends on both the <b>rotational</b> <b>latency</b> of disk platters and movement of read/write head mounted on disk arm. Therefore, sequential accesses (adjacent I/O blocks in the physical media) are fast as they depend on the rotation of disk platter (RPM of the disk) [17]. While random accesses are slow as they require the disk head {{to move from the}} current location to another track, i.e. involves disk arm movement which in turn is time consuming. Hence, the order in which the requests are sent to the device is important.|$|E
40|$|We propose an {{efficient}} placement algorithm and per-disk prefetching method to effectively support interactive {{operations in the}} media server. Our placement policy is incorporated with an encoder having a special bitcount control scheme that repeatedly tunes quantization parameters to adjust the bitcounts of video frames. This encoder can generate coded frames whose sizes are synchronized with the RAID stripe size, so that when various fast-forward levels are accessed we can reduce the seek and <b>rotational</b> <b>latency</b> and enhance the disk throughput of each disk in the RAID system. In the experimental results, the proposed placement policy and bitrate control scheme can significantly improve the average service time, which can enlarge {{the capacity of the}} interactive media server...|$|E
40|$|Abstract Freeblock {{scheduling}} is a {{new approach}} to utilizing more of a disk's potential media bandwidth. By filling <b>rotational</b> <b>latency</b> periods with useful media transfers, 20 - 50 % of a never-idle disk's bandwidth can often be provided to background applications with no effect on foreground response times. This paper describes freeblock scheduling and demonstrates its value with simulation studies of two concrete applications: segment cleaning and data mining. Free segment cleaning often allows an LFS file system to maintain its ideal write performance when cleaning overheads would otherwise reduce performance by up to a factor of three. Free data mining can achieve over 47 full disk scans per day on an active transaction processing system, with no effect on its disk performance...|$|E
