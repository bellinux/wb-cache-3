0|103|Public
30|$|All {{the above}} feature {{diagrams}} are internally represented using XML notation {{as can be}} shown in Listings Listing 5 XML Feature diagram of a <b>renderer</b> <b>filter</b> designed File and Listing 6 Filter graph XML Feature diagram for {{the description of the}} File <b>renderer</b> <b>filter</b> and filter graph, respectively.|$|R
40|$|This thesis {{demonstrates}} {{the way in}} which various methods for controlling detail and creating effects in computer graphics may be unified under the general theme of the <b>rendering</b> <b>filter.</b> Generally stated, such a filter is a passive, stateless operator that acts upon a decomposition of terms in the rendering equation. In the first Part, we present background that motivates this concept, and provides an understanding of {{the way in which}} the <b>rendering</b> <b>filter</b> follows logically from existing use in other domains. First, in Chapter 1, we discuss the general and historical use of the term “filter, ” especially as a useful metaphor that encapsulates various similar operations. We present examples of filters in photography, electronics, imaging and geometry processing. In Chapter 2, we provide background specific to rendering in graphics, examine the process of rendering as inherently related to filtering, and define the <b>rendering</b> <b>filter</b> itself. In the second Part, we see the application of these concepts by three specific examples of <b>rendering</b> <b>filters.</b> In addition to demonstrating the utility of the methods themselves, we show how these distinct algorithms are unified by the underlying <b>rendering</b> <b>filter</b> framework. In Chapter 3, we show various ways in which artists use “abstract, ” o...|$|R
30|$|As {{indicated}} by the cardinalities [0.*] and [1.*], the transform filters are optional and a filter graph can present none, one or several of them, and source and <b>rendering</b> <b>filters</b> are mandatory, i.e., a filter graph or pipeline must present {{at least one of}} each.|$|R
50|$|Proprietary UMS {{streaming}} protocol {{is based}} on Microsoft DirectShow, and therefore, UMS protocol is codec-independent. UMS protocol realizes a distributed DirectShow graph where source filter resides on the server computer and <b>renderer</b> <b>filter</b> resides on the player computer; a corresponding DirectShow decoder needs to be installed at the player computer/device.|$|R
50|$|Disadvantages {{compare to}} 2D {{photorealistic}} rendering may include a software learning curve and difficulty achieving certain photorealistic effects. Some photorealistic effects may {{be achieved with}} special <b>rendering</b> <b>filters</b> included in the 3D modeling software. For {{the best of both}} worlds, some artists use a combination of 3D modeling followed by editing the 2D computer-rendered images from the 3D model.|$|R
30|$|DirectShow is a pipeline-based media-streaming {{architecture}} and API based on component object model (COM) framework {{that provides a}} common interface for media across several programming languages. It’s a filter-based framework that implements a complex multimedia application by connecting several filters of three main kinds (i.e., source, transform and <b>renderer</b> <b>filters)</b> through their input and output pins using filters graphs to provide specific functionality[5].|$|R
3000|$|... where {{equality}} holds if {{and only}} if g(t) is a Gaussian function, <b>rendering</b> such <b>filter</b> to have optimal TFL [14].|$|R
30|$|In this research, {{the emotion}} rules cause the {{brightness}} to {{increase or decrease}} gradually as the arousal state increases or decreases. The color saturation and contrast increases or decreases as the valance state increases or decreases. The value of saturation, brightness and contrast is adjusted by 3 % level and used by the video <b>rendering</b> <b>filter</b> for calculating the YUV values of the images. YUV is a color model in terms of one luminance (Y) and two chrominance (UV).|$|R
40|$|This paper {{describes}} {{a method for}} jointly designing the crosstalk cancellation filters to facilitate binaural rendering of audio through loudspeakers. The minimax criterion is used to design the immer-sive audio <b>rendering</b> <b>filters</b> having finite impulse responses for a sin-gle listener using loudspeakers. The work presented {{is applied to the}} traditional Atal-Schroeder crosstalk canceler structure. The min-imax approach provides improved low frequency performance and a better overall separation of the direct path and cross path transfer functions than the conventional least-squares designs. Index Terms — Acoustic signal processing, crosstalk, loudspeak-ers, minimax methods...|$|R
25|$|Originally, in Windows 9x, DirectShow {{used the}} Video <b>Renderer</b> <b>filter.</b> This drew the images using DirectDraw 3, but could also fall back to GDI or overlay drawing modes in some {{circumstances}} (depending upon the visibility of the video window and the video card's capabilities). It had limited access to the video window. Video for Windows had been plagued with deadlocks caused by applications' incorrect handling of the video windows, so in early DirectShow releases, the handle to the playback window was hidden from applications. There was also no reliable way to draw caption text or graphics {{on top of the}} video.|$|R
30|$|The feature {{diagram of}} the filter graph, Figure 7, {{identifies}} and classifies all filters that compose the filter graph {{as well as all}} possible links between them. The root node represents the concept (i.e., filter graph) that consists of three features, one for each type of filters that make up the filter graph (i.e., source, transform and <b>renderer</b> <b>filters).</b> The source filter concept contains two alternative features, live device or file, meaning that in any video surveillance system instance, only one of them should be included. The transform filter concept consists of two or-features (i.e., codecs and Processing), meaning that any video surveillance system instance has at least one of them.|$|R
40|$|Abstract—This paper {{presents}} {{a method for}} jointly designing immersive audio <b>rendering</b> <b>filters</b> for a single listener using loud-speakers. The filters for crosstalk cancellation are assumed to have finite impulse responses and are designed using the minimax criterion. In addition to the traditional Atal–Schroeder crosstalk canceler structure, this paper explores an alternate topology that requires the approximation of a single filter. In general, the minimax approach provides improved low-frequency perfor-mance leading to a better overall separation of the direct-path and cross-path transfer functions than least-squares designs. The performance of the single-filter structure is better {{than that of the}} traditional crosstalk cancellation structure. Index Terms—Acoustic signal processing, crosstalk, loud-speakers, minimax methods. I...|$|R
50|$|Filter Forge Inc. hosts {{a web-based}} library of {{thousands}} of user-submitted filters that can be previewed and downloaded online or using the program's built-in browser. It maintains this model by offering a time-limited demo and rewards to authors of highly used library <b>filters.</b> <b>Renders</b> of library <b>filters</b> are available to anyone for free, but the program is needed to modify the filters and their parameters.|$|R
30|$|To {{implement}} the CFilterGraph class, specialized templates {{are used to}} instantiate an appropriate artifact template which creates an instance of filter graph with a predefined number of filters. The CFilterGraph artifact template receives a Boost MPL[24, 25] vector with the data types of all filters {{and the number of}} filters as its input parameters. The number and data type of each filter depends on the configuration required to {{implement the}} desired functionality and the simplest filter graph configuration contains at least two types of filters: a source <b>filter</b> and a <b>renderer</b> <b>filter</b> (see Listing Listing 17 Creating a CFilterGraph instance using a data type, Types, representing a vector with 2 filters: CV 4 L 2 Source and CXVRenderer).|$|R
40|$|This paper {{presents}} {{a novel approach}} for implementing immersive audio <b>rendering</b> <b>filters</b> for a single listener using loudspeakers. We {{address the problem of}} crosstalk cancellation inherent in loudspeaker rendering and propose to implement the crosstalk cancellation filters using minimax finite impulse response (FIR) filters. The formula-tion is based on the Atal-Schroeder crosstalk canceller. The use of the optimal FIR filter design procedure ensures significant amount of separation between the direct path and the cross path. An alter-native topology which requires the approximation of just one filter has also been explored using the same design principles. The min-imax techniques provides superior solutions as compared to a least-squares design and the alternate structure is shown to be robust in its performance. 1...|$|R
50|$|The {{commercial}} honey producers use Langstroth hive frames. The {{honey extraction}} process yields beeswax from the uncapping process. The highest quality beeswax is almost white. Lower quality beeswax from older cappings or comb is yellow or brown. Beeswax should be <b>rendered</b> and <b>filtered</b> {{before it is}} sold.|$|R
2500|$|In {{the above}} example, {{from left to}} right, the graph {{contains}} a source filter to read an MP3 file, stream splitter and decoder filters to parse and decode the audio, and a <b>rendering</b> <b>filter</b> to play the raw audio samples. Each filter has one or more pins {{that can be used}} to connect that filter to other filters. Every pin functions either as an output or input source for data to flow from one filter to another. Depending on the filter, data is either [...] "pulled" [...] from an input pin or [...] "pushed" [...] to an output pin in order to transfer data between filters. Each pin can only connect to one other pin and they have to agree on what kind of data they are sending.|$|R
30|$|Listing Listing 22 Ordered pair vector specifying {{connections}} between CRTSPSource, CJPEGDec and CXVRenderer filters shows {{an example of}} video image capture from an ONVIF compliant IP camera. To capture the images from the IP camera, the input filter RTSP (CRTSPSource) is used, as the IP camera sends images using the JPEG compressed video format, the JPEG transform filter (CJPEGDec) is used and the xvideo <b>renderer</b> <b>filter</b> allows seeing the images on the screen (CXVRenderer. To control and receive camera events a filter that implements web services is used. For that purpose several auxiliary artifact templates were implemented to validate and connect all the filters following a pipeline of streams that compose a filter graph artifact template. The connection between filters is represented by a vector of connections, Connections, in which each link is an ordered pair consisting of the index into the vector of filter types and the respective filter type.|$|R
40|$|This thesis {{presents}} a novel multi-object segmentation approach for volumetric grayscale data {{that separates the}} segmentation process into an unattended preprocessing phase and an interactive exploration phase. The first produces a set of feature candidates, which the user then filters repeatedly until only the desired features remain. The interactive, visualization-driven exploration completely hides the algorithmic complexity from the user because it is steered by feature descriptions rather than abstract algorithm parameters. The segmentation is based on morphological attribute filtering that extracts features based on descriptions of their size, shape, and gray level. An efficient implementation based on dual-input max-trees is presented that allows filtering within less than 100 ms with pre-processing times of {{less than five minutes}} for data sets up to 10 8 voxels. Second-generation connectivity is used to remove noise and smooth connectivity without altering the original image data. During the exploration, the current result is visualized in real-time via direct volume <b>rendering.</b> <b>Filtering</b> i...|$|R
40|$|Stony Brook, New York 11794 - 4400 hree-dimensional voxel-based {{objects are}} {{inherently}} discrete {{and do not}} l f maintain any notion of a continuous surface or normal values, which are crucia or the simulation of light behavior. Thus in volume rendering, the normal s vector of the displayed surfaces must be estimated prior to rendering. We urvey several methods for normal estimation and analyze their performance. s One unique method, the context sensitive approach, employs segmentation and egment-bounded operators {{that are based on}} object and slope discontinuities in c o order to achieve high fidelity normal estimation for rendering volumetri bjects. Key Words: discrete shading, volume <b>rendering,</b> <b>filtering,</b> segmentation, volume visualization. - 2 T 1. INTRODUCTION he use of volume representation in graphics and imaging has seen great, m progress in the last decade. The availability of multi-dimensional scanners ainly in the biomedical fields, coupled with enhanced computing power for t [...] ...|$|R
40|$|Multivariate {{polyhedral}} splines {{can be used}} {{to solve}} a common image synthesis problem: multivariate integrals defined over multiple geometrically defined domains. The theory is extended from applications in geometric design; this involves both the loosening of some overly restrictive assumptions as well as the introduction of hybridization, slicing, and weighted splines. Two applications are explored: analytic convolutional filtering for antialiasing and evaluation of projected reconstruction kernels for volume <b>rendering.</b> <b>Filtering</b> can be performed in the continuous domain for high quality antialiasing via B-spline filters. We extensively study a linearly interpolated, <b>filtered</b> triangle. Volume <b>rendering</b> via a linear splatting algorithm can be improved by using a box spline interpolation kernel. This approach avoids aliasing and reconstruction problems, allows progressive rendering directly from hierarchically compressed data, and allows precise evaluation of derivatives, which are necessary for shading. Both antialiasing and volume rendering can benefit from the close connection between continuous and discrete signal processing provided by the B-spline basis. An infinite extent analytic cardinal spline filter is equivalent to an analytic B-spline filter followed by a two-pas...|$|R
50|$|PenTile RGBG layout used in AMOLED and plasma {{displays}} uses green pixels interleaved with alternating red {{and blue}} pixels. The human eye is most sensitive to green, especially for high resolution luminance information. The green subpixels are mapped to input pixels on a one-to-one basis. The {{red and blue}} subpixels are subsampled, reconstructing the chroma signal at a lower resolution. The luminance signal is processed using adaptive subpixel <b>rendering</b> <b>filters</b> to optimize reconstruction of high spatial frequencies from the input image, wherein the green subpixels provide {{the majority of the}} reconstruction. The red and blue subpixels are capable of reconstructing the horizontal and vertical spatial frequencies, but not the highest of the diagonal. Diagonal high spatial frequency information in the red and blue channels of the input image are transferred to the green subpixels for image reconstruction. Thus the RG-BG scheme creates a color display with one third fewer subpixels than a traditional RGB-RGB scheme but with the same measured luminance display resolution. This is similar to the Bayer filter commonly used in digital cameras.|$|R
40|$|The voluminous {{amount of}} web {{documents}} has weakened {{the performance and}} reliability of web search engines. The subsistence of near-duplicate data {{is an issue that}} accompanies the growing need to incorporate heterogeneous data. Web content mining face huge problems due to the existence of duplicate and near-duplicate web pages. These pages either increase the index storage space or increase the serving costs thereby irritating the users. Near-duplicate detection has been recognized as an important one in the field of plagiarism detection, spam detection and in focused web crawling scenarios. Here we propose a novel idea for finding nearduplicates of an input web-page, from a huge repository. We proposes a TDW matrix based algorithm with three phases, <b>rendering,</b> <b>filtering</b> and verification, which receives an input web-page and a threshold in its first phase, prefix filtering and positional filtering {{to reduce the size of}} records in the second phase and returns an optimal set of near-duplicate web pages in the verification phase after calculating its similarity. The experimental results show that our algorithm outperforms in terms of two benchmark measures, precision and recall, and a reduction in the size of competing record set...|$|R
40|$|Current {{techniques}} for direct volume visualization offer only {{the ability to}} examine scalar fields. However most scientific explorations require the examination of vector and possibly tensor fields as well as numerous scalar fields. This paper describes an algorithm to directly render three-dimensional scalar and vector fields. The algorithm uses a combination of sampling and splatting techniques, that are extended to integrate the display of vector field data within the image. Additional Keywords: vector field, flow field, volume <b>rendering,</b> vector <b>filter,</b> compositing, scalar field, climate modeling...|$|R
40|$|A new domain, {{termed the}} frequency-delay domain, {{is used to}} design stable, all-pass digital filters {{resembling}} a given delay response in the least-squares sense. This spectral technique identifies the delay response of a stable, second-order, all-pass digital filter as a double sideband suppressed carrier amplitude modulated signal in the frequency-delay domain. Iterative maximum likelihood techniques are used to <b>render</b> the <b>filter</b> coefficients. The algorithm is a significant improvement over related methods because it results in a physically realizable stable all-pass filter that closely approximates a desired delay response...|$|R
40|$|The {{existence}} {{of billions of}} web data has severely affected the performance and reliability of web search. The presence of near duplicate web pages {{plays an important role}} in this performance degradation while integrating data from heterogeneous sources. Web mining faces huge problems due to the {{existence of}} such documents. These pages increase the index storage space and thereby increase the serving cost. By introducing efficient methods to detect and remove such documents from the Web not only decreases the computation time but also increases the relevancy of search results. We aim a novel idea for finding near duplicate web pages which can be incorporated in the field of plagiarism detection, spam detection and focused web crawling scenarios. Here we propose an efficient method for finding near duplicates of an input web page, from a huge repository. A TDW matrix based algorithm is proposed with three phases, <b>rendering,</b> <b>filtering</b> and verification, which receives an input web page and a threshold in its first phase, prefix filtering and positional filtering to reduce the size of record set in the second phase and returns an optimal set of near duplicate web pages in the verification phase by using Minimum Weight Overlapping (MWO) method. The experimental results show that our algorithm outperforms in terms of two benchmark measures, precision and recall, and a reduction in the size of competing record set...|$|R
40|$|Abstract—We {{present a}} method for {{constructing}} 3 D feature flow from video and its application to video stylization. Our method extracts smoothly aligned 3 D vectors that describe the smallest variation of colors within a spatiotemporal video cube, and thus effectively preserves both spatial and temporal coherence in a relatively inexpensive manner. As an application of this flow field we present a particle-based video stylization technique to rerender the video in a feature enhancing, painterly style. Our method consists of per-pixel operations and is suitable for GPU implementation, which enables real-time video stylization. Index Terms—Nonphotorealistic <b>rendering,</b> flow-based <b>filtering,</b> video abstraction, painterly rendering. Ç...|$|R
40|$|The strong {{nonlinearity}} and non-Gaussian {{statistics of}} an ocean mixed layer model, {{which is based}} on the second-moment closure of turbulence, <b>render</b> traditional <b>filtering</b> techniques (e. g., Kalman filter) impractical for data assimilation. To overcome this problem, the sampling-importance resampling filter is introduced in this study. This filter represents the required (non-Gaussian) probability density function as a set of samples for implementing recursive Bayesian inference. It is not restricted by the assumption of linearity or Gaussain statistics. The numerical experiments using real life data clearly demonstrate the validity of this filter for the estimation problem of the ocean mixed layer process...|$|R
50|$|This {{version of}} the game, ported by DotEmu, is {{compatible}} with Windows XP, Vista, 7, 32 and 64 bit. It contains the game music as WAV files, digitized from the original MIDI soundtrack. The game allows to play in several different resolutions (640 × 400, 960 × 600 and 1280 × 800). The nostalgics can still play with the original <b>rendering,</b> but <b>filtered</b> graphics are also available. Graphics may only be displayed in multiples of the original 320x200 DOS resolution, and essentially remain untouched. There is no support for varying aspect ratios or force feedback controllers.|$|R
5000|$|PTK uses a [...] "2D in 3D" [...] paradigm. While it is a 2D engine, it uses 3D {{acceleration}} for rendering, enabling very good, bicubic <b>filtered</b> <b>rendering</b> of scaled, rotated sprites and per-pixel {{alpha blending}} at no expense of computing time. A game such as Mystic Inn make {{extensive use of}} PTK's rendering capabilities.|$|R
40|$|We {{present a}} method for {{generating}} a 3 D feature flow field from a video and its application to video stylization. Our method extracts smoothly aligned 3 D vectors that describe the smallest variation of colors in both spatial and temporal dimensions of the video, and thus efficiently preserves both spatial and temporal coherence in a relatively inexpensive manner. We use this flow field forms {{the basis of a}} particle-based video stylization technique which can produce feature-enhancing painting-style renderings of a video. Furthermore, we show our method is performed in real-time using the GPU based implementation. Index Terms non-photorealistic <b>rendering,</b> flow-based <b>filtering,</b> video abstraction, painterly rendering. I...|$|R
40|$|Metal {{extraction}} {{offers the}} potential for resource recovery and simplified sludge disposal. A sulfuric acid leach. removes 99 percent of the metal from synthetic hydroxide sludge, and lime treatment <b>renders</b> the <b>filter</b> cake nonhazardous. The extract is treated by sulfide precipitation at controlled pH for metal separation followed by solvent extraction for further recovery. T he 23 US. Army installations engaged in plating employ {{a variety of techniques}} to treat wastewater. While some sites have implemented recovery and reuse, a majority still find it advantageous to precipitate the metals and discharge the wastewater. Sludge is collected in clarifiers, treated by gravity thickening, then dewatered in pressure or vacuum filters...|$|R
5000|$|Lasers can {{blind or}} damage them. However, since most lasers are monochromatic, color filters {{can reduce the}} effect of laser pointers. However, filters will also impair image quality and overall light {{sensitivity}} of cameras (see laser safety article for details on issues with filters). Also, complete protection from lasers of any wavelength would require use of completely black <b>filters,</b> <b>rendering</b> the camera useless.|$|R
40|$|This paper {{describes}} {{a method for}} implementing immersive aume <b>rendering</b> <b>filters</b> for single ormuFD)) z listeners andlouR speakers. In particuqqq the paper isfocuq) {{on the case of}} single or two listeners with different louDqRk@q(arrays to determine the weighting vectors for the necessary FIR and IIR filtersulte the LMS (least-mean-squuu adaptive inverse algorithm. It describes transform-domain LMS adaptive inverse algorithm that is designed for crosstalk cancellation necessary in louqFk@(DRwRku immersiveauer rendering. Specifically, each weighting vector of the inverse filter is generated based on psychoacouPFP critical band filters and udk the LMS adaptive inverse algorithm to improve performance in the sensitive frequtiv bands. We also investigate the sensitivity of the listening positionuiti differentnufer of listeners andlouR speakers withvariou louuD) k@(geometries. Performance is measuDw based on the ipsilateral signal to contralateral signal (crosstalk) ratio thatresuF(from the different filter types with andwithou psychoacouzwk critical band filtering. 1. INTROD CTION An important issut in the immersive aumer rendering is the reproduwk@Rq of 3 -D soukF fields that preserve the desired spatial location, response, and dynamic range of the soukRD There are two general methods for 3 -D au kR rendering that can be categorized as headphone reprodue kRF and loukRDP er reprodu@FzFF [1]. Head-related binaurel recording, or duWP((k@FD stereophony methods, attempt to accuDWWk@ reproduWk at each eardruR of the listener the soukR pressuF generated by a set of souFqFF and their interactions with the acouRDPz environment [2]. TransauD) k auans is a method utho to deliver binaur k signals to the ears of listeners uiste mustene lousten ers. The basic idea is to filter the bin [...] ...|$|R
40|$|Shadow {{maps are}} a very {{efficient}} means to add shadows to arbitrary scenes. In this paper, we introduce Translucent Shadow Maps, an extension to shadow maps which allows very efficient rendering of sub-surface scattering. Translucent Shadow Maps contain depth and incident light information. Sub-surface scattering is computed on-the-fly during <b>rendering</b> by <b>filtering</b> the shadow map neighborhood. This filtering is done efficiently using a hierarchical approach. We describe optimizations for an implementation of Translucent Shadow Maps on contemporary graphics hardware, that can render complex translucent objects with varying light and material properties in real-time. Categories and Subject Descriptors (according to ACM CCS) : I. 3. 7 [Computer Graphics]: Color, shading, shadowing, and textur...|$|R
50|$|GeForce 8 {{performs}} {{significantly better}} texture filtering than its predecessors that used various optimizations and visual tricks {{to speed up}} <b>rendering</b> without impairing <b>filtering</b> quality. The GeForce 8 line correctly renders an angle-independent anisotropic filtering algorithm along with full trilinear texture filtering. G80, though not its smaller brethren, is equipped with much more texture filtering arithmetic ability than the GeForce 7 series. This allows high-quality filtering with a much smaller performance hit than previously.|$|R
