42|1|Public
25|$|Morton order space filling curves for GPU cache {{coherency}} in texture mapping, <b>rasterisation</b> and indexing of turbulence data.|$|E
25|$|Raster image {{processors}} (RIPs) {{are used}} to convert PDF files into a raster format suitable for imaging onto paper and other media in printers, digital production presses and prepress in {{a process known as}} <b>rasterisation.</b> RIPs capable of processing PDF directly include the Adobe PDF Print Engine from Adobe Systems and Jaws and the Harlequin RIP from Global Graphics.|$|E
2500|$|The OpenRT project {{includes}} a highly optimized software core for ray tracing {{along with an}} OpenGL-like API in order to offer {{an alternative to the}} current <b>rasterisation</b> based approach for interactive 3D graphics. [...] Ray tracing hardware, such as the experimental Ray Processing Unit developed at the Saarland University, has been designed to accelerate some of the computationally intensive operations of ray tracing. [...] On March 16, 2007, the University of Saarland revealed an implementation of a high-performance ray tracing engine that allowed computer games to be rendered via ray tracing without intensive resource usage.|$|E
40|$|This short paper {{describes}} {{an attempt to}} construct a light field for virtual scenes with global illumination. The light field is constructed directly without the necessity for intermediate images produced by another rendering program. The light field is represented {{as a set of}} parallel subfields, where each subfield is a set of rectangularly organized parallel rays in some orientation. It is shown that rendering an object into the 4 -dimensional ray space can be decomposed into a set of 2 -dimensional <b>rasterisations.</b> Radiance is propagated through the light field starting from the emitters, using a method similar to progressive refinement radiosity. Once the light field is illuminated in this way, sets of parallel rays can be projected onto a lens and accumulate radiance onto an image plane. Thus constant time rendering walkthrough can be achieved. The light field so generated is approximate, and the resulting images are poor. However, this note suggests a line of research which may prov [...] ...|$|R
5000|$|Graphics {{pipeline}} for <b>rasterisation</b> in commodity graphics hardware ...|$|E
5000|$|Bresenham's line {{algorithm}} for {{a typical}} method in <b>rasterisation</b> ...|$|E
5000|$|Raster image {{processor}} for 2D <b>rasterisation</b> in printing systems ...|$|E
50|$|It is, however, a {{generally}} less well developed technique than standard polygon-based <b>rasterisation</b> schemes.|$|E
50|$|<b>Rasterisation</b> (or rasterization) is {{the task}} of taking an image {{described}} in a vector graphics format (shapes) and converting it into a raster image (pixels or dots) for output on a video display or printer, or for storage in a bitmap file format. It refers to both <b>rasterisation</b> of models and 2D rendering primitives such as polygons, line segments, etc.|$|E
5000|$|Morton order space filling curves for GPU cache {{coherency}} in texture mapping, <b>rasterisation</b> [...] and indexing of turbulence data.|$|E
50|$|Both {{ray-tracing}} and ray-casting, {{as well as}} <b>rasterisation,</b> can {{be applied}} to voxel data to obtain 2D raster graphics to depict on a monitor.|$|E
50|$|Since 3D {{graphics}} hardware accelerators {{have become}} popular in regular desktop computers the rendering algorithm of commercial computer games {{has been limited}} to the <b>rasterisation</b> technology that has certain advantages, but also limitations.|$|E
50|$|The {{process of}} {{rasterising}} 3D models onto a 2D plane for display {{on a computer}} screen ("screen space") is often carried out by fixed function hardware within the graphics pipeline. This is because there is no motivation for modifying the techniques for <b>rasterisation</b> used at render time and a special-purpose system allows for high efficiency.|$|E
50|$|Compared {{with other}} {{rendering}} {{techniques such as}} ray tracing, <b>rasterisation</b> is extremely fast. However, rasterization is simply the process of computing the mapping from scene geometry to pixels and does not prescribe a particular way to compute the color of those pixels. Shading, including programmable shading, may be based on physical light transport, or artistic intent.|$|E
50|$|In normal usage, {{the term}} {{refers to the}} popular {{rendering}} algorithm for displaying 3D models on a computer. <b>Rasterisation</b> is currently the most popular technique for producing real-time 3D computer graphics. Real-time applications need to respond immediately to user input, and generally need to produce frame rates of at least 30 frames per second to achieve smooth animation.|$|E
50|$|Raster image {{processors}} (RIPs) {{are used}} to convert PDF files into a raster format suitable for imaging onto paper and other media in printers, digital production presses and prepress in {{a process known as}} <b>rasterisation.</b> RIPs capable of processing PDF directly include the Adobe PDF Print Engine from Adobe Systems and Jaws and the Harlequin RIP from Global Graphics.|$|E
5000|$|For many purposes, such as layout, it doesn't {{matter what}} the outline data format is, but for some purposes, such as <b>rasterisation,</b> it is significant. The OpenType {{standard}} does not specify the outline data format: rather, it accommodates any of several existing standards. Sometimes terms like [...] "OpenType (PostScript flavor)", [...] "Type 1 OpenType", [...] "OpenType CFF", or [...] "OpenType (TrueType flavor)" [...] are used to indicate which outline format a particular OpenType font file contains.|$|E
50|$|The OpenRT project {{includes}} a highly optimized software core for ray tracing {{along with an}} OpenGL-like API in order to offer {{an alternative to the}} current <b>rasterisation</b> based approach for interactive 3D graphics. Ray tracing hardware, such as the experimental Ray Processing Unit developed at the Saarland University, has been designed to accelerate some of the computationally intensive operations of ray tracing. On March 16, 2007, the University of Saarland revealed an implementation of a high-performance ray tracing engine that allowed computer games to be rendered via ray tracing without intensive resource usage.|$|E
50|$|Ikarus uses a spline {{model of}} the outline shape of each {{character}} within a typeface to give a fully scalable representation. The curve segments are essentially circle arcs, with tangent continuity maintained at joins. It is a very simple format to manually mark up. Being a vector/curve based format, any rendering resolution can be attained (by <b>rasterisation)</b> with equal accuracy from one relatively small set of data. The Ikarus coordinates for a shape all fall on the outline of that shape (as opposed to Bézier curves where 'control' points can be inside or outside the outline).|$|E
5000|$|The Generic Mapping Tools (GMT) are an {{open-source}} {{collection of}} computer software tools for processing and displaying xy and xyz datasets, including <b>rasterisation,</b> filtering and other image processing operations, and {{various kinds of}} map projections. The software stores 2-D grids as COARDS-compliant netCDF files and comes with a comprehensive collection of free GIS data, such as coast lines, rivers, political borders and coordinates of other geographic objects. Users convert further data (like satellite imagery and digital elevation models) from other sources and import them. GMT stores the resulting maps and diagrams in PostScript (PS) or Encapsulated PostScript (EPS) format.|$|E
5000|$|Compared to a tiled raster map, data {{transfer}} is also greatly reduced, as vector data is typically {{much smaller than}} a rendered bitmap. Also, styling can be applied later in the process, {{or even in the}} browser itself, allowing much greater flexibility in how data is presented. It is also easy to provide interactivity with map features, as their vector representation already exists within the client. Yet another benefit is that less centralised server processing power is required, since <b>rasterisation</b> can be performed directly in the client. This has been described as making [...] "rendering ... a last-mile problem, with fast, high-quality GPUs in everyone’s pocket".|$|E
50|$|HLSL {{programs}} come in five forms: pixel shaders (fragment in GLSL), vertex shaders, geometry shaders, compute shaders and tessellation shaders (Hull and Domain shaders). A vertex shader is {{executed for}} each vertex that is {{submitted by the}} application, and is primarily responsible for transforming the vertex from object space to view space, generating texture coordinates, and calculating lighting coefficients such as the vertex's tangent, binormal and normal vectors. When a group of vertices (normally 3, to form a triangle) come through the vertex shader, their output position is interpolated to form pixels within its area; this process is known as <b>rasterisation.</b> Each of these pixels comes through the pixel shader, whereby the resultant screen colour is calculated.|$|E
50|$|AMD began {{releasing}} {{details of}} their next generation of GCN Architecture, termed the 'Next-Generation Compute Unit', in January 2017. The new design {{is expected to increase}} instructions per clock, higher clock speeds, support for HBM2, a larger memory address space, and the High Bandwidth Cache Controller. Additionally, the new chips are expected to include improvements in the <b>Rasterisation</b> and Render output units. The stream processors are heavily modified from the previous generations to support packed math Rapid Pack Math technology for 8-bit, 16-bit, and 32-bit numbers. With this there is a significant performance advantage when lower precision is acceptable (for example: processing two half-precision numbers {{at the same rate as}} a single single precision number).|$|E
50|$|Commonly, 3D {{geometry}} with transparency {{is rendered}} by blending (using alpha compositing) all surfaces {{into a single}} buffer (think {{of this as a}} canvas). Each surface occludes existing color and adds some of its own color depending on its alpha value, a ratio of light transmittance. The order in which surfaces are blended affects the total occlusion or visibility of each surface. For a correct result, surfaces must be blended from farthest to nearest or nearest to farthest, depending on the alpha compositing operation, over or under.Ordering may be achieved by rendering the geometry in sorted order, for example sorting triangles by depth, but can take a significant amount of time,not always produce a solution (in the case of intersecting or circularly overlapping geometry) and the implementation is complex.Instead, order-independent transparency sorts geometry per-pixel, after <b>rasterisation.</b> For exact results this requires storing all fragments before sorting and compositing.|$|E
5000|$|The NEC µPD7220, {{also known}} as the 7220, was the first true {{graphics}} processing unit (GPU), designed as a microprocessor, with VLSI, the first implemention of a graphics processor as a single Large Scale Integration (LSI) integrated circuit chip. This enabled the design of low-cost, high-performance video graphics cards, such as those from Number Nine Visual Technology, and was the basis for clones such as the Intel 82720. The 7220 project was started in 1979, and a paper was published in 1981. It debuted in Japan with NEC's PC-9800 series of personal computers in 1982, and then released independently. The 7220 had a fillrate of 1.25 megapixels per second and a <b>rasterisation</b> rate of 125 polygons (100-pixel by 100-pixel) per second, faster than central processing units (CPU) at the time. The 7220's high resolution color graphics led NEC to market it as a [...] "resolution revolution". By 1983, it was used in NEC's APC computers, and other computers from Digital Equipment Corporation and Wang Laboratories.|$|E
50|$|However, {{the cost}} of {{implementation}} was high; computers output raw PS code that would be interpreted by the printer into a raster image at the printer's natural resolution. This required high performance microprocessors and ample memory. The LaserWriter used a 12 MHz Motorola 68000, making it faster {{than any of the}} Macintosh computers to which it attached. When the laser printer engines themselves cost over a thousand dollars the added cost of PS was marginal. But as printer mechanisms fell in price, {{the cost of}} implementing PS became too great a fraction of overall printer cost; in addition, with desktop computers becoming more powerful, it no longer made sense to offload the <b>rasterisation</b> work onto the resource-constrained printer. By 2001, few lower-end printer models came with support for PostScript, largely due to growing competition from much cheaper non-PostScript ink jet printers, and new software-based methods to render PostScript images on the computer, making them suitable for any printer; PDF, a descendant of PostScript, provides one such method, and has largely replaced PostScript as de facto standard for electronic document distribution.|$|E
50|$|Yu's {{early career}} {{was as a}} {{programmer}} for the King's Quest series for the Apple II although {{she had her own}} 3D engine projects that she sold to various companies. She programmed for QuickDraw 3D, an early <b>rasterisation</b> API. She worked on the game Zombie, and created the video game engine used in Spec Ops. In November 1997, she was employed by video game developer Ion Storm. She worked on the 2001 video game Anachronox and served as Director of Technology at the studio. While at Ion she was responsible for the Quake 2 code base used in their games and any games based on that engine. In November 1998, she left Ion Storm and later became the Lead Technology Programmer at 3D Realms. Yu worked as Director of Technology of Gearbox Software, creator of Brothers in Arms and Borderlands. Yu worked to heavily modify the Epic Unreal Engine 3 with an emphasis on lighting, shadows and physics. Yu was a founding member of Microsoft's Direct 3D Advisory Board. She participated in CUDA and GPU simulation at NVidia.|$|E
40|$|In {{the last}} decades we could saw fast {{progress}} in computer graphics. Especially <b>rasterisation,</b> which uses hardware acceleration, {{made it possible to}} display and interact with even big and complex models. Beside <b>rasterisation,</b> which is used because of the abbility to display every scene very fast, also global illumination models were developed. This complex illumination models -like radiosity and ray tracing- are not as fast as <b>rasterisation,</b> but because of their physically based simulation of light distribution, they could produce photo realistic results in contrast to the just faked <b>rasterisation</b> values. Today is the focus of research on realtime ray tracing. With a huge amount of computation (usually with pc cluster) it is possible to get a fast ray tracing simulation even for interactive usage. The main problem is that the hardware requirement is too high for displays with very high resolution - e. g. the HEyeWall of the IGD Fraunhofer. The aim of this master thesis is the development of a hybrid rendering technique, which combines the advantages of <b>rasterisation</b> and ray tracing to obtain a rendering method which allows interactive use and physically correct display results. This work includes the development of a realtime ray tracer which will be linked with the <b>rasterisation</b> frontend and scenegraph system OpenSG...|$|E
40|$|Contour Trees and Reeb Graphs {{are firmly}} {{embedded}} in scientific visualisation for analysing univariate (scalar) fields. We generalize this analysis to multivariate fields with a data structure called the Joint Contour Net that quantizes the variation of multiple variables simultaneously. We report the first algorithm for constructing the Joint Contour Net, and demonstrate {{some of the}} properties that make it practically useful for visualisation, including accelerating computation by exploiting a relationship with <b>rasterisation</b> {{in the range of}} the function...|$|E
40|$|This paper {{describes}} an {{implementation of a}} surface based rendering algorithm used for virtual colonoscopy. The colon surface data is acquired by extracting a surface from computer tomography data sets. The connectivity meshes of the resulting triangles are reconstructed to determine which parts of the iso-surface belong to the colon. Further the colon is intersected {{into a number of}} pieces along its center-line. Then these pieces are rendered depending on their visibility using graphics hardware capable of triangle <b>rasterisation.</b> The implementation of the rendering algorithm is embedded into the virtual endoscopy environment VirEn...|$|E
30|$|Algorithms can be {{executed}} on fixed-function microarchitectures on platforms such as application-specific integrated circuits (ASICs) or on general-purpose microprocessors such as CPUs and GPUs. Microarchitectures sacrifice programmability to dissipate less power and exhibit superior throughput. These advantages result from providing the designer with complete control over component layout and from eliminating the overhead of executing instructions. As many graphics applications require the recurrent execution of algorithms at interactive frame rates, these algorithms are good candidates for microarchitectures, providing they are utilised sufficiently {{and do not}} require programmability. GPU <b>rasterisation</b> {{is a good example}} of an effective microarchitecture.|$|E
40|$|This paper {{describes}} {{a system for}} cross synthesis of rasterised time-domain audio. <b>Rasterisation</b> of the audio allows alignment of the macroscopic features of audio samples of instrument tones prior to principal component analysis (PCA). Specifically a novel algorithm for straightening and aligning rastogram features has been developed {{which is based on}} an interactive process incorpo-rating the Canny detection algorithm and variable resampling. Timbral cross-synthesis is achieved by projecting a given instru-ment tone onto the principal components derived from a training set of sounds for a different tone. The alignment algorithm im-proves the efficiency of PCA for resynthesizing tones. 1...|$|E
40|$|With the {{development}} of variable-data-driven digital presses - where each document printed is potentially unique - {{there is a need}} for pre-press optimization to identify material that is invariant from document to document. In this way <b>rasterisation</b> can be confined solely to those areas which change between successive documents thereby alleviating a potential performance bottleneck. Given a template document specified in terms of layout functions, where actual data is bound at the last possible moment before printing, we look at deriving and exploiting the invariant properties of layout functions from their formal specifications. We propose future work on generic extraction of invariance from such properties for certain classes of layout functions...|$|E
40|$|We {{present a}} method of adding {{sophisticated}} physical simulations to voxel-based games such as the hugely popular Minecraft (2012. [URL] thus providing a dynamic and realistic fluid simulation in a voxel environment. An assessment of existing simulators and voxel engines is investigated, and an efficient real-time method to integrate optimized fluid simulations with voxel-based <b>rasterisation</b> on graphics hardware is demonstrated. We compare graphics processing unit (GPU) computer processing for a well-known incompressible fluid advection method with recent results on geometry shader-based voxel rendering. The rendering of visibility-culled voxels from fluid simulation results stored intermediately in CPU memory is compared with a novel, entirely GPU-resident algorithm...|$|E
40|$|International audienceThe {{combination}} of ascending and descending Persistent Scatterers Interferometric (PSI) data {{by means of}} resampling and/or spatial interpolation, separately for each Synthetic Aperture Radar (SAR) geometry, is a commonly followed procedure, limited though by the reduced spatial coverage and the introduced uncertainties from multiple <b>rasterisation</b> steps. Herein, an alternative approach is proposed for combining different PSI line-of-sight (LOS) observables in the vector domain, based on the geographic proximity of PS point targets. An alternative procedure is presented herein, using PS data in their initial vector format and by exploiting vector manipulation capabilities {{as well as the}} geostatistical modules already available in many GIS software packages. In the proposed post-processing scheme all necessary analysis steps are performed by means of attributes transfer and calculations between features geodatabases, prior to any <b>rasterisation.</b> By increasing the number of input point vectors during subsequent interpolation, the overall error budget coming from spatial interpolation is being reduced. The increase of output surface resolution together with the reduction of interpolation error budget for the combined PSI results is of significant importance during modelling of ground motion or integration of PSI measurements with GNSS observations. The benefit of working with vector data, instead of raster layers, especially in saving storage space should be more pronounced when large stacks of PSI or wide area processing results are involved. The proposed approach are applicable to any PSI dataset independently of the processing scheme. The advantages of the proposed vector-based approach compared to the commonly used grid-based procedure is being demonstrated using real data...|$|E
40|$|We {{present a}} method for {{rendering}} aesthetically correct soft shadows that exhibit smooth inner and outer penumbrae and self-shadowing. Our approach {{is an extension of}} ordinary shadow mapping; in an additional step, occluder shadow silhouette edges, as seen from the center of an area light, are detected and extruded into so-called Skirts. This step is done entirely in image space, and as such does not require the construction of extra geometric primitives. During final rendering, penumbra regions are identified using the depth information of the Skirts and stochastic sampling of the shadow map. Our algorithm has been successfully implemented on programmable shader hardware, and interactive framerates are obtained. We observe that the main bottleneck of our implementation lies in the <b>rasterisation</b> stage; performance mainly depends {{on the size of the}} lightsource...|$|E
