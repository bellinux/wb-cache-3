4|10000|Public
30|$|Groundwater {{and soil}} {{pollution}} are noted {{to be the}} worst environmental problem related to the mining industry because of the pyrite oxidation, and hence acid mine drainage generation, release and transport of the toxic metals. The aim {{of this paper is to}} predict the concentration of Ni and Fe using a robust algorithm named support vector machine (SVM). Comparison of the obtained <b>results</b> <b>of</b> <b>SVM</b> <b>with</b> those of the back-propagation neural network (BPNN) indicates that the SVM can be regarded as a proper algorithm for the prediction of toxic metals concentration due to its relative high correlation coefficient and the associated running time. As a matter of fact, the SVM method has provided a better prediction of the toxic metals Fe and Ni and resulted the running time faster compared with that of the BPNN.|$|E
40|$|Part 1 : Simulation, Optimization, Monitoring and Control TechnologyInternational audienceThe {{development}} of low-carbon {{economy and the}} promotion of energy conservation are becoming a basic consensus of all countries. Therefore, global carbon cycle becomes a widespread concern research topic in scientific community. About 77 % of the vegetation carbon stores in forest biomass in terrestrial ecosystems. So forest biomass is the most important parameter in terrestrial ecosystem carbon cycle. In this paper, for estimating the forest biomass of Mount Tai, a support vector machine (SVM) optimization model based on remote sensing is proposed. The meteorological data, terrain data, remote sensing data are taken into account in this model. In comparison the <b>results</b> <b>of</b> <b>SVM</b> <b>with</b> that of regressive analysis method, both the training accuracy and testing accuracy of regressive analysis method are lower than those of SVM, so SVM could obtain higher accuracy...|$|E
40|$|DT log {{is one of}} {{the most}} {{frequently}} used wireline logs to determine compression wave velocity. This log is commonly used to gain insight into the elastic and petrophysical parameters of reservoir rocks. Acquisition of DT log is, however, a very expensive and time consuming task. Thus prediction of this log by any means can be a great help by decreasing the amount of money that needs to be allocated for acquisition. Support vector machine (SVM) {{is one of the}} best artificial intelligence techniques proven to be a reliable method in the prediction of various real world problems. The aim of this paper is to use SVM to predict the DT log data of a well located in the southern oilfields of Iran. By comparing the <b>results</b> <b>of</b> <b>SVM</b> <b>with</b> those obtained by a Back Propagation Neural Network (BPNN) we were able to verify the accuracy of SVM in the prediction of P-wave velocity. Hence, this method is recommended as a cost effective tool in the prediction of P- wave velocit...|$|E
40|$|Permeability {{is a key}} {{parameter}} {{associated with}} the characterization of any hydrocarbon reservoir. In fact, {{it is not possible}} to have accurate solutions to many petroleum engineering problems without having accurate permeability value. The conventional methods for permeability determination are core analysis and well test techniques. These methods are very expensive and time consuming. Therefore, attempts have usually been carried out to use artificial neural network for identification of the relationship between the well log data and core permeability. In this way, recent works on artificial intelligence techniques have led to introduce a robust machine learning methodology called support vector machine. This paper aims to utilize the SVM for predicting the permeability of three gas wells in the Southern Pars field. Obtained <b>results</b> <b>of</b> <b>SVM</b> showed that the correlation coefficient between core and predicted permeability is 0. 97 for testing dataset. Comparing the <b>result</b> <b>of</b> <b>SVM</b> <b>with</b> that <b>of</b> a general regression neural network (GRNN) revealed that the SVM approach is faster and more accurate than the GRNN in prediction of hydrocarbon reservoirs permeability...|$|R
40|$|Discrete hidden Markov model (HMM) and {{hybrid of}} neural network (NN) and HMM are popular methods in {{handwritten}} word recognition system. The hybrid system gives better recognition result due to better discrimination {{capability of the}} NN [Y. Bengio et al., 1995]. Support vector machine (SVM) is an alternative to NN. In speech recognition (SR), SVM has been successfully used {{in the context of}} a hybrid SVM/HMM system. It gives a better recognition result compared to the system based on hybrid NN/HMM [A. Ganapathiraju, January 2002]. This paper describes the work in developing a hybrid SVM/HMM OHR system. Some preliminary experimental <b>results</b> <b>of</b> using <b>SVM</b> <b>with</b> RBF kernel on IRONOFF, UNIPEN and IRONOFF- UNIPEN character database are provided...|$|R
40|$|A {{new class}} of kernels for object {{recognition}} based on local image feature representations are introduced in this paper. Formal proofs are given to show that these kernels satisfy the Mercer condition. In addition, multiple types of local features and semilocal constraints are incorporated. Experimental <b>results</b> <b>of</b> <b>SVM</b> classifiers coupled <b>with</b> the proposed kernels are reported on recognition tasks with the COIL- 100 database and compared with existing methods. The proposed kernels achieved competitive performance and were robust to changes in object configurations and image degradations. 1...|$|R
40|$|SVM {{has been}} given top {{consideration}} for addressing the challenging problem of data imbalance learning. Here, we conduct an empirical classification analysis of new UCI datasets that have dierent imbalance ratios, sizes and complexities. The experimentation consists of comparing the classification <b>results</b> <b>of</b> <b>SVM</b> <b>with</b> two other popular classifiers, Naive Bayes and decision tree C 4. 5, to explore their pros and cons. To make the comparative exper-iments more comprehensive and {{have a better idea}} about the learning performance of each classifier, we employ in total four performance metrics: Sensitive, Specificity, G-means and time-based eciency. For each benchmark dataset, we perform an empirical search of the learning model through numerous training of the three classifiers under dierent parameter settings and performance measurements. This paper exposes the most significant results i. e. the highest performance achieved by each classifier for each dataset. In summary, SVM outperforms the other two classifiers in terms of Sensitive (or Specificity) for all the datasets, and is more accurate in terms of G-means when classifying large datasets...|$|E
40|$|Human face {{recognition}} {{is one of}} the most direct technologies for personal identification and is the hotspot of pattern recognition and computer vision. In the current paper, a high exactness and real-time method based on extracting diverse features from human face images using two well known feature extractors; PCA and DCT, and applying a mixture <b>of</b> <b>SVMs</b> architecture on the extracted feature set is proposed. In our recommend method, to overcome the basic limitation of the previous works, i. e. low recognition rate, a set of robust features are extracted. After extracting feature vector for each image, these features are learned by several SVMs. Then by combining, the <b>results</b> <b>of</b> these <b>SVMs</b> <b>with</b> maximum rule, the entrance face is recognized. In the result part, the proposed approach is applied on ORL and Yale databases and the accuracy rate achieved 99. 50 % and 100 % respectively. In addition, experimental results have demonstrated our method robust in successful recognition of human faces even with variant lighting and poses...|$|R
40|$|An {{algorithm}} {{based on}} a support vector machine (SVM) is proposed for hydrometeor classification. The training phase {{is driven by the}} output of a fuzzy logic hydrometeor classification algorithm, i. e., the most popular approach for hydrometer classification algorithms used for ground-based weather radar. The performance <b>of</b> <b>SVM</b> is evaluated by resorting to a weather scenario, generated by a weather model; the corresponding radar measurements are obtained by simulation and by comparing <b>results</b> <b>of</b> <b>SVM</b> classification <b>with</b> those obtained by a fuzzy logic classifier. Results based on the weather model and simulations show a higher accuracy <b>of</b> the <b>SVM</b> classification. Objective comparison of the two classifiers applied to real radar data shows that SVM classification maps are spatially more homogenous (textural indices, energy, and homogeneity increases by 21 % and 12 % respectively) and do not present non-classified data. The improvements found by SVM classifier, even though it is applied pixel-by-pixel, can be attributed to its ability to learn from the entire hyperspace of radar measurements and to the accurate training. The reliability <b>of</b> <b>results</b> and higher computing performance make SVM attractive for some challenging tasks such as its implementation in Decision Support Systems for helping pilots to make optimal decisions about changes in the flight route caused by unexpected adverse weather...|$|R
40|$|Abstract. For better {{interpretability}} {{of class}} structure in data {{we want to}} use Support Vector Machines (SVM) for exploratory data analysis. This is easier to do when data is linearly separable. However, when data is not linearly separable, the <b>results</b> <b>of</b> <b>SVM</b> classifiers <b>with</b> non-linear kernels {{are more difficult to}} understand, partly due to the mapping to a higher dimensional space. In this paper, we design a method for weight-ing linear support vector machine classifiers or random hyperplanes, to obtain a classifier whose accuracy is comparable to the accuracy of a non-linear support vector machine classifier, and whose results can be readily visualized. We conduct a simulation study to examine how our weighted linear classifiers behave in the presence of known structure, compared to support vector machines with non-linear kernels. We describe the <b>results</b> <b>of</b> our simulation study on 2 -class non-linearly separable data, where the data sets are generated by varying the shape of the clusters, and vary-ing the number <b>of</b> variables. The <b>results</b> show that the weighted linear classifiers might perform well compared to the non-linear support vector machine classifiers, and they are more readily interpretable than the non-linear classifiers. The normals to the separating hyperplanes are viewed using rotations or tours of the data. ...|$|R
40|$|This paper {{describes}} a novel application of text categorization for mathematical word problems, namely Multiplicative Compare and Equal Group problems. The empirical results and analysis show that common text processing {{techniques such as}} stopword removal and stemming should be selectively used. It is highly beneficial not to remove stopwords and not to do stemming. Part of speech tagging should {{also be used to}} distinguish words in discriminative parts of speech from the non-discriminative parts of speech which not only fail to help but even mislead the categorization decision for mathematical word problems. An <b>SVM</b> classifier <b>with</b> these selectively used text processing techniques outperforms an <b>SVM</b> classifier <b>with</b> a default setting of text processing techniques (i. e. stopword removal and stemming). Furthermore, a probabilistic meta classifier is proposed to combine the weighted <b>results</b> <b>of</b> two <b>SVM</b> classifiers <b>with</b> different word problem representations generated by different text preprocessing techniques. The empirical results show that the probabilistic meta classifier further improves the categorization accuracy...|$|R
40|$|The Support Vector Machine (SVM) {{classification}} method has recently gained popularity {{due to the}} ease of implementing non-linear separating surfaces. SVM is an optimization problem with the two competing goals, minimizing misclassification on training data and maximizing a margin defined by the normal vector of a learned separating surface. We develop and implement new SVM models based on previously conceived <b>SVM</b> <b>with</b> L_ 1 -Norm regularization with ramp loss error terms. The goal being a new SVM model that is both robust to outliers due to ramp loss, while also easy to implement in open source and off the shelf mathematical programming solvers and relatively efficient in finding solutions due to the mixed linear-integer form of the model. To show {{the effectiveness of the}} models we compare <b>results</b> <b>of</b> ramp loss <b>SVM</b> <b>with</b> L_ 1 -Norm and L_ 2 -Norm regularization on human organ microbial data and simulated data sets with outliers...|$|R
40|$|Conditional expectiles are {{becoming}} {{an increasingly important}} tool in finance {{as well as in}} other areas of application such as demography when the goal is to explore the conditional distribution beyond the conditional mean. In this thesis, we consider a support vector machine (<b>SVM)</b> type approach <b>with</b> the asymmetric least squares loss for estimating conditional expectiles. Firstly, we establish learning rates for this approach that are minimax optimal modulo a logarithmic factor if Gaussian RBF kernels are used and the desired expectile is smooth in a Besov sense. It turns out that our learning rates, as a special case, improve the best known rates for kernel-based least squares regression in aforementioned scenario. As key ingredients of our statistical analysis, we establish a general calibration inequality for the asymmetric least squares loss, a corresponding variance bound as well as an improved entropy number bound for Gaussian RBF kernels. Furthermore, we establish optimal learning rates {{in the case of a}} generic kernel under the assumption that the target function is in a real interpolation space. Secondly, we complement the theoretical <b>results</b> <b>of</b> our <b>SVM</b> approach <b>with</b> the empirical findings. For this purpose we use a sequential minimal optimization method and design an SVM-like solver for expectile regression considering Gaussian RBF kernels. We conduct various experiments in order to investigate the behavior of the designed solver with respect to different combinations of initialization strategies, working set selection strategies, stopping criteria and number of nearest neighbors, and then look for the best combination of them. We further compare the <b>results</b> <b>of</b> our solver to the recent R-package ER-Boost and find that our solver exhibits a better test performance. In terms of training time, our solver is found to be more sensitive to the training set size and less sensitive to the dimensions of the data set, whereas, ER-Boost behaves the other way around. In addition, our solver is found to be faster than a similarly implemented solver for the quantile regression. Finally, we show the convergence of our designed solver...|$|R
5000|$|... #Caption: A {{training}} example <b>of</b> <b>SVM</b> <b>with</b> kernel {{given by}} φ((a, b)) = (a, b, a2 + b2).|$|R
30|$|In this study, we {{developed}} four different methods. “WPSE + SVM”, “WPSE + FSVM”, “WPTE + SVM”, and “WPTE + FSVM”. Theoretically, {{the last one}} will perform the best since WPSE in a special case of WPTE, and FSVM is an extension <b>of</b> <b>SVM</b> <b>with</b> additional ability to reduce influences from noises and outliers.|$|R
40|$|In this paper, {{we propose}} a new method {{to speed up}} SVM {{decision}} {{based on the idea}} of mirror points. Decisions based on multiple simple classifiers, which are formed as a <b>result</b> <b>of</b> mirror pairs, are combined to approximate a single SVM. A dynamic programmingbased method is used to find a suitable combination. Experimental results show that this method can increase classification e#ciencies <b>of</b> <b>SVM</b> <b>with</b> comparable classification performances...|$|R
40|$|The {{approximation}} {{capability of}} support vector machines (SVMs) is investigated. We show the universal approximation capability <b>of</b> <b>SVMs</b> <b>with</b> various kernels, including Gaussian, several dot product, or polynomial kernels, {{based on the}} universal approximation capability of their standard feedforward neural network counterparts. Moreover, it is shown that an <b>SVM</b> <b>with</b> polynomial kernel <b>of</b> degree p 1 which is trained on a training set of size p can approximate the p training points up to any accuracy...|$|R
40|$|The {{generalization}} {{properties of}} support vector machines (SVMs) are examined. From a geometrical point of view, the estimated parameter <b>of</b> an <b>SVM</b> {{is the one}} nearest the origin in the convex hull formed with given examples. Since introducing soft margins is equivalent to reducing the convex hull of the examples, an <b>SVM</b> <b>with</b> soft margins has a different learning curve from the original. In this paper we derive the asymptotic average generalization error <b>of</b> <b>SVMs</b> <b>with</b> soft margins in simple cases and quantitatively show that soft margins increase the generalization error...|$|R
40|$|Support Vector Machines (SVM) {{learning}} {{can be used}} to construct classification models of high accuracy. However, the performance <b>of</b> <b>SVM</b> learning should be improved. This paper proposes a bilinear grid search method to achieve higher computation efficiency in choosing kernel parameters (C, γ) <b>of</b> <b>SVM</b> <b>with</b> RBF kernel. Experiments show that the proposed method retains the advantages of a small number <b>of</b> training <b>SVMs</b> <b>of</b> bilinear search and the high prediction accuracy of grid search. It has been proved that bilinear grid search method (BGSM) is an effective way to train <b>SVM</b> <b>with</b> RBF kernel. With the application of BGSM, the protein secondary structure prediction can obtain a better learning accuracy compared with other related algorithms. Povzetek: Razvita je nova metoda iskanja parametrov za metodo SVM. ...|$|R
30|$|While several {{previous}} studies [16, 30, 39, 43] compared several algorithms, {{they did not}} use a widely accepted audio classification method for benchmarking their neural networks. In our study, we used the classification <b>results</b> <b>of</b> <b>SVMs</b> that use the MFCC features to benchmark our CNN algorithm.|$|R
40|$|The {{widespread}} {{habit of}} “plugging ” arbitrary symmetric functions as kernels in support vector machines (SVMs) often yields good empirical classification results. However, {{in case of}} non conditionally positive definite (non-cpd) functions they are hard to interpret due to missing geometrical and theoretical understanding. In this paper we provide a step towards comprehension <b>of</b> <b>SVM</b> classifiers in these situations. We give a geometric interpretation <b>of</b> <b>SVMs</b> <b>with</b> non-cpd kernel functions. We show that such SVMs are optimal hyperplane classifiers not by margin maximization but by minimization of distances between convex hulls in pseudo-Euclidean spaces. This interpretation is basis for further analysis, e. g. investigating uniqueness or characterizing situations where <b>SVMs</b> <b>with</b> noncpd kernels are suitable or not...|$|R
40|$|We propose {{and study}} a new variant <b>of</b> the <b>SVM</b> — the <b>SVM</b> <b>with</b> uneven margins, {{tailored}} for document categorisation problems (i. e. problems where classes are highly unbalanced). Our experiments {{showed that the}} new algorithm significantly outperformed the <b>SVM</b> <b>with</b> respect to the document categorisation for small categories. Furthermore, we report the <b>results</b> <b>of</b> the <b>SVM</b> {{as well as our}} new algorithm on the Reuters Chinese corpus for document categorisation, which we believe is the first result on this new Chinese corpus. ...|$|R
40|$|In {{this paper}} we propose some very simple {{algorithms}} and architectures for a digital VLSI implementation of Support Vector Machines. We discuss the main aspects concerning the realization of the learning phase <b>of</b> <b>SVMs,</b> <b>with</b> special attention on the effects of fixed-point math for computing and storing the paraneters of the network. Soime experiments on two classification problems are described that show the efficiency of the proposed methods in reaching optimal solutions with reasonable hardware requirements...|$|R
30|$|There is an unrecognized {{background}} {{region in the}} image {{that has not been}} subjected to SVM discriminant, except for the connected region. Given that the <b>result</b> <b>of</b> <b>SVM</b> discriminant is 0, the probability confidence is 0.5 which cannot identify road region or not. The grayscale value is 127 in the probability confidence map.|$|R
40|$|Abstract—This paper {{describes}} the combination <b>of</b> k-NN and <b>SVM</b> <b>with</b> LSI {{to improve their}} performance in single-label text categorization tasks, and the experiments performed with six datasets to show that both k-NN-LSI (the combination of k-NN with LSI) and SVM-LSI (the combination <b>of</b> <b>SVM</b> <b>with</b> LSI) outperform the original methods for a significant fraction of the datasets. Overall, both combinations present an average Accuracy over the six datasets used in this work that {{is higher than the}} average Accuracy of each original method. Having in mind that SVM is usually considered the best performing classification method, it is particularly interesting that the combinations perform even better for some datasets. I. INTRODUCTION AND EXPERIMENTAL SETTING The main goal of text categorization (TC) is to derive methods for the categorization of natural language text. Th...|$|R
40|$|Support vector machine (SVM) {{has been}} {{successfully}} applied for classification in this paper. This paper discussed the basic principle <b>of</b> the <b>SVM</b> at first, and then <b>SVM</b> classifier <b>with</b> polynomial kernel and the Gaussian radial basis function kernel are choosen to determine pupils who have difficulties in writing. The 10 -fold cross-validation method for training and validating is introduced. The aim {{of this paper is}} to compare the performance of support vector machine with RBF and polynomial kernel used for classifying pupils with or without handwriting difficulties. Experimental results showed that the performance <b>of</b> <b>SVM</b> <b>with</b> RBF kernel is better than the one with polynomial kernel...|$|R
40|$|This paper {{presents}} {{a new approach}} to auto-regressive and moving average (ARMA) modeling based on the support vector method (SVM) for identification applications. A statistical analysis of the characteristics of the proposed method is carried out. An analytical relationship between residuals andSVM-ARMA coefficients allows the linking of the fundamentals <b>of</b> <b>SVM</b> <b>with</b> several classical system identification methods. Additionally, the effect of outliers can be cancelled. Application examples show the performance of SVM-ARMA algorithm when it is compared with other system identification methods. Publicad...|$|R
40|$|Abstract—This paper {{presents}} {{a new approach}} to auto-regressive and moving average (ARMA) modeling based on the support vector method (SVM) for identification applications. A statistical analysis of the characteristics of the proposed method is carried out. An analytical relationship between residuals and SVM-ARMA coefficients allows the linking of the fundamentals <b>of</b> <b>SVM</b> <b>with</b> several classical system identification methods. Additionally, the effect of outliers can be cancelled. Application examples show the performance of SVM-ARMA algorithm when it is compared with other system identification methods. Index Terms—ARMA modeling, cross-correlation, support vector method, system identification, time series...|$|R
40|$|Support Vector Machine (<b>SVM)</b> is one <b>of</b> the {{important}} classification method {{used in many}} areas. Normal support vector machine is not suitable for classification of large data sets due to its high training complexity. Training <b>of</b> <b>SVM</b> <b>with</b> data number n has time complexity between O(n 2) and O(n 3). This paper introduces a novel data reduction method Fisher’s decision tree for SVM classification. It is a classifier uses the dimensionality reduction of Fisher Linear Discriminant and decomposition strategy of decision trees. The proposed classifier has distinctive advantages on dealing with large data sets...|$|R
40|$|AbstractThe goal of {{this paper}} is to {{describe}} a forecasting model for the hourly electricity load. The model takes into account the meteorological factors (temperature and natural illumination) in the area covered by the Rostov utility dispatcher. In this study, support vector machine (<b>SVM)</b> <b>with</b> particle swarm optimization (PSO) were used to forecast electricity consumption. To get more accurate evaluation <b>of</b> the <b>results</b> <b>of</b> <b>SVM</b> model, the standard measures for quantitative evaluation of statistical performance and mean absolute percentage error (MAPE) were employed to evaluate the performance of various models developed. The results also suggest that the SVM method can be successfully applied to the forecasting model for the hourly electricity consumption in the area covered by the Rostov utility dispatcher...|$|R
40|$|This paper {{reports on}} {{research}} analysing {{the potential of}} Support Vector Machines (SVMs) for mapping vegetation from high spatial resolution Ikonos imagery. The work investigated the utility <b>of</b> <b>SVMs</b> for mapping regional scale upland vegetation using limited ground data. Additionally, it analysed the ability <b>of</b> <b>SVMs</b> to be transferred as a classifier to pixels from remote geographical locations, which {{were not included in}} the training process. The classification and transferability <b>of</b> <b>SVMs</b> was investigated when varying their design and training. Overall, the classification and transferability <b>results</b> <b>of</b> <b>SVMs</b> showed very promising results, highlighting their capability and suitability for use in remote sensing classification. 1...|$|R
40|$|The eye events (eye blink, eyes {{close and}} eyes open) are usually {{considered}} as biological artifacts in the electroencephalographic (EEG) signal. One can con-trol {{his or her}} eye blink by proper training and hence {{can be used as}} a control signal in Brain Computer Interface (BCI) applications. Support vector ma-chines (SVM) in recent years proved to be the best classification tool. A comparison <b>of</b> <b>SVM</b> <b>with</b> the Artificial Neural Network (ANN) always provides fruitful results. A one-against-all SVM and a multi-layer ANN is trained to detect the eye events. A com-parison of both is made in this paper...|$|R
40|$|In {{the present}} study, Support Vector Machines (<b>SVM)</b> and hybrid <b>of</b> Genetic Algorithm (GA) <b>with</b> <b>SVM</b> models are {{developed}} {{to predict the}} damage level of non-reshaped berm breakwaters. Optimal kernel parameters <b>of</b> <b>SVM</b> are determined by using GA algorithm. The models are trained and tested on the data set obtained from the experiments which were carried out at Marine Structures Laboratory, Department of Applied Mechanics and Hydraulics, National Institute of Technology Karnataka, Surathkal, India. The <b>results</b> <b>of</b> <b>SVM</b> and GA-SVM models are compared in terms of statistical measures like correlation coefficient, {{root mean square error}} and scatter index. The results on SVM and GA-SVM models reveals that the performance of GA-SVM is better compared to SVM models in predicting the damage level of non-reshaped berm breakwater...|$|R
40|$|Abstract. The {{degree of}} {{malignancy}} in brain glioma {{needs to be}} assessed by MRI findings and clinical data before operations. There have been previous attempts {{to solve this problem}} by using fuzzy max-min neural networks and support vector machines (SVMs), while in this paper, a novel algorithm named PRIFEB is proposed by combining bagging <b>of</b> <b>SVMs</b> <b>with</b> embedded feature selection for its individuals. PRIFEB is compared with the general case of bagging on UCI data sets, experimental results show PRIFEB can obtain better performance than the general case of bagging. Then, PRIFEB is used to predict the degree of malignancy in brain glioma, computation results show that PRIFEB obtains better accuracy than other several methods like bagging <b>of</b> <b>SVMs</b> and single SVMs does. ...|$|R
40|$|Co-occurrence histograms {{are used}} as {{features}} to classify magnifying endoscope imagery <b>with</b> k-NN, <b>SVM,</b> and NN classifiers. In the k-NN classification case these histograms may improve the classification accuracy of simple 1 D color histograms up to 10 % in the 2 classes case and up to 5 % in the 6 classes case. The classification <b>results</b> <b>of</b> <b>SVM</b> and NN classifiers {{have turned out to}} be noncompetitive and do not improve the classification <b>result</b> <b>of</b> 1 D color histograms. 1...|$|R
40|$|We {{propose a}} {{projected}} semi-stochastic gradient descent method with mini-batch for improving both the theoretical complexity and practical {{performance of the}} general stochastic gradient descent method (SGD). We are able to prove linear convergence under weak strong convexity assumption. This requires no strong convexity assumption for minimizing the sum of smooth convex functions subject to a compact polyhedral set, which remains popular across machine learning community. Our PS 2 GD preserves the low-cost per iteration and high optimization accuracy via stochastic gradient variance-reduced technique, and admits a simple parallel implementation with mini-batches. Moreover, PS 2 GD is also applicable to dual problem <b>of</b> <b>SVM</b> <b>with</b> hinge loss...|$|R
