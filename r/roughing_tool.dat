3|59|Public
5000|$|On long-running jobs it {{is common}} to use a <b>roughing</b> <b>tool</b> on a {{different}} slide or turret station to remove the bulk of the material to reduce wear on the form tool.|$|E
5000|$|It {{should not}} be assumed that all {{features}} on any given model of machine are supported by BobCAD. It is the users responsibility to determine, prior to sale, if particular features of a given machine will be used by BobCAD, and what additional effort {{may be required to}} do so. For example, it is possible to draw a turned part with tapped holes situated perpendicular to the main axis, however; what is meant by [...] "supported" [...] is subject to interpretation. While {{it may be possible to}} make some machine functions operable with some effort, such as live tooling on a lathe the degree of difficulty varies, and technically, live tooling support for lathe is not provided. Industrial robots can be used for non-conventional milling for example. [...] BobCAD-CAM software is modular. Meaning that a CNC business can implement a core 2 & 3 axis milling software and [...] "add-on" [...] to it as the business grows and needs higher levels of machining tool path capabilities. The 3 Axis CNC Software has a Standard and Professional version. There are also Standard and PRO versions for 4 Axis CNC Milling as well as the 5 Axis CNC Milling CAD/CAM. The 2013 Multi-axis CAD/CAM Software offers the first High-Speed Adaptive <b>Roughing</b> <b>tool</b> path strategy in the world for simultaneous 5 Axis CNC Milling. SWARF Milling along with 7 Surface-Based cutting toolpath machining strategies have also been developed into the Multi-axis CAD/CAM Software. The latest release of the CAD-CAM modules uses CAM Wizards for each machining strategy which is a planned series of dialog pages that pertain directly to the machining strategy that the user selects. Recently Dynamic Machining Strategies™ were added. DMS™ functionality requires the user to use a single or multiple machining operations for a CAD Feature that was selected in the process. This basically allows multiple machining operations to be used based on a selected CAD feature. CNC Software modules are available for: ...|$|E
40|$|The chip shape – {{besides the}} cutting forces, tool wear and surface {{roughness}} – {{is one of}} the most commonly used criteria for the evaluation of the machinability. The importance of the chip shape can be explained by its strong influence on process reliability. In consequence an automation of cutting operations is only possible for fa-vourable chip shapes. For longitudinal turning as well as for other processes with con-tinuous cutting edge contact, periodic chip breakage is necessary to avoid unfavourable ribbon or thread chips. Chip breakage is caused by a variety of mutually dependant in-fluencing factors related to workpiece, tool or process parameters. A possibility to predict chip breakage is to model these influences. The three-dimensional Finite Element Method (3 D-FEM) offers the possibility to take the complex chip breaker geometries of the cutting tool into account. For FE-modelling of chip breakage, a criterion is needed, capable of calculating material failure at the position of chip breakage. However, the definition of such a criterion requires research into the thermo-mechanical loads that cause chip breakage. Accordingly, this thesis aims to predict chip breakage using a damage model, which is based on the mechanical and thermal loads in the chip. It contributes to a more funda-mental understanding of cutting processes with geometrically defined cutting edges in general and contributes the prediction of chip breakage in longitudinal turning of AISI 1045. A model-based approach was chosen in order to calculate thermo-mechanical loads. Based on these loads, an adequate damage model could be defined. The localisation of chip breakage and the dominant failure mechanisms in the chip breakage zone were determined in empirical investigations of the cutting process. By applying a sensitivity analysis, the strongest tool- and process-related influences that cause chip breakage were identified and different process conditions for finishing and <b>roughing</b> <b>tool</b> geome-tries were determined. The process conditions included parameter sets with controlled chip breakage as well as sets with unfavourable chip shapes. For the parameter sets with controlled chip breakage, the time and position of material failure were identified using a high speed filming device. The analysis of the chip fracture faces revealed duc-tile material failure as the dominant failure mechanism. Different damage models for this type of material failure were presented and discussed regarding their potential and ap-plicability to predict chip breakage. The decision between the use of existing damage models and the definition of a new damage model was made on the basis of the thermo-mechanical loads in the chip breakage position. An analytic model was then de-veloped to transform the distribution of stress in a blocked chip to a status of plane stress. The maximum tensile stresses depending on the cutting conditions and tool ge-ometry were calculated based on this model. The model correlated with the real borders of controlled chip breakage in a wide range of cuttings depths and feed rates. Only for small cutting depths and large feed rates a significant difference compared to real chip breakage was identified. This deviation is caused by the complex three-dimensional chip flow under these process conditions. It is assumed that these cutting conditions require three-dimensional modelling of the chip flow. Consequently the chip formation, chip flow and expansion of the chip were modelled three-dimensionally using the Finite Element Method (FEM). In this model the current loads as well as their time-dependent developments could be determined. The evalua-tion of the existing damage criteria showed that none of the presented criteria offer suf-ficient reliability for the prediction of chip breakage. Therefore an independent damage criterion for chip breakage prediction was developed based on a damage model of Johnson and Cook. This criterion calculated the residual deformability of the material depending on the tolerated temperatures, strain rates and stress conditions. The calcu-lated damage value lead to a reduction of the material strength and to a local softening in the chip. The implementation of this damage criterion in the FEM-model enabled three-dimensional simulation of chip breakage. The model correlated well with the chip flow and breakage as well as with the empirically determined cutting forces and tem-peratures on the lower surface of the chip. The FEM-model developed enables system-atic investigation of the influence of tool geometries and cutting conditions on chip breakage for turning operations of AISI 1045...|$|E
50|$|A modern bow saw is a metal-framed {{crosscut}} {{saw in the}} shape of a bow with a coarse wide blade. This type of saw is also known as a Swede saw, Finn saw or buck saw. It is a <b>rough</b> <b>tool</b> that can be used for cross-cutting branches or firewood (maybe up to 6 inches in diameter) down to size.|$|R
5000|$|According to Thomas de Waal, Mammadova's {{theories}} on the Albanians were formulated {{in such a}} way as [...] "to separate the Armenians completely from the Caucasus." [...] "She has placed Caucasian Albania on the territory of modern Republic of Armenia: all the territories, churches and monasteries in Republic of Armenia have been designated as Albanian." [...] He describes Mammadova's theories as [...] "an improved version of what became a very <b>rough</b> <b>tool</b> in Azerbaijan".|$|R
6000|$|... "Ah!" [...] {{said the}} Prioress. [...] "I think I can guess now; but, Emlyn, you choose <b>rough</b> <b>tools.</b> Well, fear not; your secret is safe with me." [...] She paused a moment; then went on, [...] "Oh! I am glad, who feared lest the Fiend's finger {{was in it}} all, as, in truth, they believe. Now I see my path clear, and will follow it to the death. Yes, yes; I will save you all or die." ...|$|R
40|$|Abstract. This paper {{presents}} an algorithm through which 3 -axis NC rough tool-paths {{can be directly}} generated from discrete data points. Based on Inverse Tool Offset (ITO) method, the algorithm generates direction-parallel (DP) tool paths for relief point clouds. The algorithm includes four steps: dividing data points into 3 D cell grids; constructing inverse tool model and calculating the grids intersecting the surface of inverse tool; obtaining the grids containing cutter location points; calculating tool paths. The experiment {{results indicate that the}} algorithm of the <b>rough</b> <b>tool</b> paths is efficient...|$|R
40|$|Bachelor’s thesis {{deals with}} {{roughing}} strategies especially with those included in chosen CAM software. The initial part states the common {{information about the}} effects on precision of machining and tool load. Next chapter deals with methods of machining and their resulting requirements on construction of the machine. It {{is followed by the}} description of new roughing strategies and their utilization; also <b>roughing</b> <b>tools</b> were selected for machining of specified models of mold parts, made of steel and aluminium alloy. In the practical part, roughing strategies were applied to stocks which were subsequently compared by the machining times...|$|R
40|$|Asperity {{flattening}} {{has a huge}} {{influence on}} friction and wear in metal forming processes. Nevertheless, phenomena that occur at the microscopic scale are still not well understood. Since no experiment can be easily performed in real forming conditions, numerical models are essential to achieve a better knowledge {{of what happens in}} these contact regions. In this paper, a threedimensional model of a rough strip flattened by a rigid <b>rough</b> <b>tool</b> is presented. The boundary conditions applied to this model correspond to the ones encountered in a real cold-rolling case. The results are compared to experimental measurements from the pilot mill of ArcelorMittal Maizières R&D...|$|R
6000|$|... "They are wonderfully {{clever and}} ingenious," [...] Charlie said. [...] "Look what <b>rough</b> <b>tools</b> {{that man is}} working with, and what {{delicate}} and intricate work he is turning out. If these fellows could but fight {{as well as they}} work, and were but united among themselves, not only should we be unable to set a foot in India, but the emperor, with the enormous armies which {{he would be able to}} raise, would be able to threaten Europe. I suppose they never have been really good fighting men. Alexander, a couple of thousand years ago, defeated them; and since then the Afghans, and other northern peoples, have been always overrunning and conquering them.|$|R
40|$|As {{hot metal}} forming {{processes}} {{are becoming more}} and more popular, especially in the automotive industry, the need for a better understanding about the tribological behaviour of tool and workpiece is increasing. Ultimately the enhanced knowledge should lead to better quality of the produced parts as well as improved process economy through reduced maintenance and longer life of the tools. This masters’ thesis has been carried out at the Division of Machine Elements at Luleå University of Technology as a part of an ongoing project. The aim of this work was to analyse the failure mechanisms of real hot forming tools and also to investigate the influence of contact pressure and tool surface roughness on the tribological behaviour of tool steels and high strength boron steel at elevated temperatures. The project has been carried out in cooperation with Accra Teknik AB, a manufacturer of hardened boron steel components through roll forming and form fixture hardening. To perform the failure analysis, a Wyko 1100 NT optical surface profiler and SEM/EDS have been used to analyse the surfaces. Microhardness measurements and microstructural investigations were also carried out. To study the influence of contact pressure and surface roughness on friction and wear at elevated temperature, a high-temperature pin-on-disc tribometer was used. The results show that the two tools (Stützrohr and A 76) seem to experience similar damage mechanism with subsurface initiated cracks caused by thermal cycling. The tool Stützrohr has a lower hardness than what is expected in the bulk. Tool A 76 suffers from quite severe corrosive wear as a result of exposure to cyclic heating in presence of water. A strong gradient between the nitrided layer and the bulk material will make cracks propagate faster and this has been especially found in case of Stützrohr. Steadier friction in case of <b>rougher</b> <b>tool</b> surface is caused by formation of compacted layers of (Fe and O) oxidized wear particles. The rougher surface will generate more particles initially and facilitate the formation of compacted layers quickly thereby resulting in relatively stable friction and smother wear scars. Similar friction at 10 and 15 MPa on both smooth and <b>rough</b> <b>tool</b> steel surfaces has been attributed to formation of similar surface layers on the UHSS and tool steel. Plasma nitriding of the tool steel results in a higher surface roughness and a smoother surface will be affected more compared to a rough surface. A <b>rougher</b> <b>tool</b> surface will induce more wear on the counter surface at higher contact pressures. There is no difference in wear of the work piece material when sliding against a smooth tool surface, regardless of the contact pressure. Validerat; 20101217 (root...|$|R
40|$|We {{describe}} an algorithm for solving an important geometric problem arising in computer-aided manufacturing. When machining a pocket in a solid piece of material such as steel using a <b>rough</b> <b>tool</b> in a milling machine, sharp convex {{corners of the}} pocket cannot be done properly, but have to be left for finer tools that are more expensive to use. We want to determine a tool path that maximizes {{the use of the}} <b>rough</b> <b>tool.</b> Mathematically, this boils down to the following problem. Given a simply-connected set of points P in the plane such that the boundary ∂ P is a curvilinear polygon consisting of n line segments and circular arcs of arbitrary radii, compute the maximum subset Q⊆ P consisting of simply-connected sets where the boundary of each set is a curve with bounded convex curvature. A closed curve has bounded convex curvature if, when traversed in counterclockwise direction, it turns to the left with curvature at most 1. There is no bound on the curvature where it turns to the right. The difference in the requirement to left- and right-curvature is a natural consequence of different conditions when machining convex and concave areas of the pocket. We devise an algorithm to compute the unique maximum such set Q. The algorithm runs in O(n n) time and uses O(n) space. For the correctness of our algorithm, we prove a new generalization of the Pestov-Ionin Theorem. This is needed to show that the output Q of our algorithm is indeed maximum in the sense that if Q' is any subset of P with a boundary of bounded convex curvature, then Q'⊆ Q. Comment: A short version of this paper will be presented at SoCG 201...|$|R
30|$|The law openly {{recognizes that}} reforms are not perfect {{intellectual}} products {{handed down from}} above into an imperfect world. Rather they resemble fairly <b>rough</b> <b>tools</b> that need regular monitoring, maintenance and adjustment, must be strengthened where they are effective and corrected where they do not work or live up to expectations; they must be tuned to social and economic evolution and also to non-responsiveness by firms and workers. A permanent flow of data collected from various administrative sources 14, to be made freely available to the scientific community for independent evaluation of the reform, has been officially started. A monitoring process is under way and the new government has embraced the idea both {{as the basis for}} scientific investigation and as the recognition of the principle that changes must be introduced where necessary.|$|R
50|$|John Viega {{was also}} a pioneer in static {{analysis}} for security vulnerabilities. He {{was responsible for the}} first publicly available tool, ITS4., as well as the prominent open source <b>Rough</b> Auditing <b>Tool</b> for Security (RATS). He also founded Secure Software, the first commercial vendor for such tools, which was bought by Fortify Software (now part of HP).|$|R
40|$|The {{bachelor}} thesis {{deals with}} roughing milling. Beginning of this thesis {{is concerned with}} common description milling and example work surface. Next part refers about necessary information for selection of <b>roughing</b> milling <b>tool</b> and its toolholder. Next chapter deals with basic information about CNC milling machines. Last part is devoted selection of concrete configuration machine, tool and its toolholder for roughing milling of plane and form surface with CNC machines...|$|R
50|$|Also, <b>rough</b> market {{comparison}} <b>tools</b> {{such as the}} PE {{ratio and}} the PEG ratio are used. More sophisticated forms of analysis (fundamental analysis, quantitative analysis, and behavioral analysis) use also some market criteria, such as the risk premium or beta coefficient.|$|R
2500|$|Schiller's {{accusations against}} the metaphysician in Riddles now {{appear in a}} more pragmatic light. His {{objection}} is similar to one we might make against a worker who constructs a flat-head screwdriver to help him build a home, and who then accuses a screw of unreality when he comes upon a Phillips-screw that his flat-head screwdriver won't fit. In his works after Riddles, Schiller's attack {{takes the form of}} reminding the abstract metaphysician that abstractions are meant as tools for dealing with the [...] "lower" [...] world of particulars and physicality, and that after constructing abstractions we cannot simply drop the un-abstracted world out of our account. The un-abstracted world is the entire reason for making abstractions in the first place. We did not abstract to reach the unchanging and eternal truths; we abstract to construct an imperfect and <b>rough</b> <b>tool</b> for dealing with life in our particular and concrete world. It is the working of the higher in [...] "making predictions about the future behavior of things for the purpose of shaping the future behavior of things for the purpose of shaping our own conduct accordingly" [...] that justifies the higher.|$|R
2500|$|The Mode 1 {{industries}} created <b>rough</b> flake <b>tools</b> {{by hitting}} a suitable stone with a hammerstone. The resulting flake that broke off {{would have a}} natural sharp edge for cutting and could afterwards be sharpened further by striking another smaller flake from the edge if necessary (known as [...] "retouch"). These early toolmakers may also have worked the stone they took the flake from (known as a core) to create chopper cores although there is some debate over whether these items were tools or just discarded cores.|$|R
40|$|The Knowledge Infrastructures {{research}} group convened a workshop in May 2012, {{sponsored by the}} U. S. National Science Foundation and the Sloan Foundation. Some 25 international scholars from many domains, including sociology, science and technology studies, computer science, human-computer interaction, and the digital humanities, participated in three days of intensive discussions and breakout groups. This document reports the outcomes, organized around three central questions: How are knowledge infrastructures changing? How do changes in knowledge infrastructures reinforce or redistribute authority, influence, and power? And how can we best study, know, and imagine knowledge infrastructures moving forward? This report offers key examples of change, considers the consequences (good and bad) of emergent practices, and offers some <b>rough</b> <b>tools</b> and approaches that might support new ways of thinking and acting on the changing knowledge infrastructures around us. We conclude with recommendations for a more e!ective program of research and action in this space. As always, the real-world terrain is more vast and complex than any single representation can capture. The report that follows is meant to open conversations rather than close them. Our goal is to gather and connect existing threads {{in a way that}} supports learning, insight, and more e!ective modes of infrastructure development moving forward...|$|R
6000|$|Neither in his {{subsequent}} misfortunes does Antonio make the least struggle {{to prove himself}} worthy of his mistress's affection. He is very resigned and loving, and so forth. To win renown by great deeds, and so prove {{his wife in the}} right to her brothers and all the world, never crosses his imagination. His highest aim (and that only at last) is slavishly to entreat pardon from his brothers-in-law for the mere offence of marrying their sister; and he dies by an improbable accident, the same pious and respectable insipidity which he has lived,--'ne valant pas la peine qui se donne pour lui.' The prison-scenes between the Duchess and her tormentors are painful enough, if to give pain be a dramatic virtue; and she appears in them really noble; and might have appeared far more so, had Webster taken half as much pains with her as he has with the madmen, ruffians, ghosts, and screech-owls in which his heart really delights. The only character really worked out so as to live and grow under his hand is Bosola, who, of course, is the villain of the piece, and being a rough fabric, is easily manufactured with <b>rough</b> <b>tools.</b> Still, Webster has his wonderful touches here and there - ...|$|R
40|$|Abstract. We {{discuss some}} <b>rough</b> set <b>tools</b> for {{perception}} modelling {{that have been}} developed in our project for a system for modelling networks of classifiers for compound concepts. Such networks make it possible to recognize behavioral patterns of objects and their parts changing over time. We present a method that we call a method for on-line elimination of non-relevant parts (ENP). This method was developed for on-line elimination of complex object parts that are irrelevant for identifying a given behavioral pattern. Some results of experiments with data from the road simulator are included. ...|$|R
40|$|One of {{the most}} widely spread {{techniques}} to estimate the compressive strength of concrete is the rebound hammer test, also known as Schmidt Hammer test. In spite {{of a large number of}} scientific works trying to calibrate the test, to identify the parameters affecting its results and to estimate its reliability, the original Schmidt curve is still provided by the producers along with the hammer and is used in Structural Engineering Applications. This paper discussed an extensive research, and application, of this technique to a large number of cubes provided by the Laboratory for Building Materials of the University of Genoa, Italy, showing that several phenomena strongly affect the test: moisture content, maturity, stress state among the others. Strength estimates may differ as much as 70 % if these parameters are not taken into account. Besides, several in situ investigations on existing buildings were affected by a large dispersion of data, so that we should conclude that the Rebound Hammer is unable of giving a reliable estimate of the concrete strength. This is probably due to the very limited area of the material on which the test is performed that allows also small local inhomogeneity to affect quite strongly the test. Therefore, the rebound hammer seems to be useless in the estimation of concrete compressive strength, being only a <b>rough</b> <b>tool</b> for estimating material homogeneity inside a specific concrete typ...|$|R
50|$|They {{are only}} used for static face sealing, not moving glands. The thin tube walls are {{sensitive}} to damage from <b>rough</b> handling, point <b>tools</b> and crimping during assembly. The pressure-actuated form {{is considered to be}} slightly more resistant to point damage, but more at risk of folding and crimping, as they are not supported by internal pressurisation during assembly.|$|R
40|$|Waste {{incineration}} is {{an important}} part of global waste management concepts. Thermal waste treatment should combine effective mineralisation and the reduction of toxic emissions from the gaseous and solid residues. Incineration systems with firing grate have been developed out of typical power plant technology. It has be stated that the firing grate technology is still a <b>rough</b> <b>tool,</b> which leads to not very stable process conditions. But this is still the most implemented technology. The fundamental problem is the very inhomogeneous waste composition. This work shows, based on fundamental data collected in three years at the waste incineration plant Darmstadt, Germany, how process optimisation with new simulation and analysis tools can work for the primary part of a waste incineration plant. It is pointed out whether the proposed techniques are feasible and whether there is an improvement in emission levels for the plant. It has been noticed, that at normal process conditions, some of the typical process situations cannot be recognised and controlled by the existing controller. The appearance of these typical process situations have such an effect on the overall plant behaviour, that detailed investigations make sense. For the incineration process, an optimal control strategy with complete sensor technique is existing. This strategy has been developed for the plant in Darmstadt. Nevertheless, at this plant in Darmstadt not all of the necessary sensors for an optimal control system are implemented. Therefore a control system has been developed, where early process information, especially from the incoming waste, is used to identify and control typical process situations successfully. (orig.) SIGLEAvailable from TIB Hannover: RN 7868 (119) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|R
5000|$|Schiller's {{accusations against}} the metaphysician in Riddles now {{appear in a}} more pragmatic light. His {{objection}} is similar to one we might make against a worker who constructs a flat-head screwdriver to help him build a home, and who then accuses a screw of unreality when he comes upon a Phillips-screw that his flat-head screwdriver won't fit. In his works after Riddles, Schiller's attack {{takes the form of}} reminding the abstract metaphysician that abstractions are meant as tools for dealing with the [...] "lower" [...] world of particulars and physicality, and that after constructing abstractions we cannot simply drop the un-abstracted world out of our account. The un-abstracted world is the entire reason for making abstractions in the first place. We did not abstract to reach the unchanging and eternal truths; we abstract to construct an imperfect and <b>rough</b> <b>tool</b> for dealing with life in our particular and concrete world. It is the working of the higher in [...] "making predictions about the future behavior of things for the purpose of shaping the future behavior of things for the purpose of shaping our own conduct accordingly" [...] that justifies the higher. To assert this methodological character of eternal truths is not, of course, to deny their validity …. To say that we assume the truth of abstraction because we wish to attain certain ends, is to subordinate theoretic 'truth' to a teleological implication; to say that, the assumption once made, its truth is 'proved' by its practical working …. For the question of the 'practical' working of a truth will always ultimately be found to resolve itself into the question whether we can live by it.|$|R
40|$|AbstractAutomatic {{classification}} of audio data arose increasing interest recently. This paper addresses {{the problem of}} automatic recognition of musical instrument sounds, applying rough set based techniques {{as a tool of}} classification. Instruments representing wind and string families were used in the experiments. Since the main problem in case of audio data is the proper parameterization, we also investigated issues regarding various parameterization methods. Fourier transform and wavelet analysis were applied as parameterization tools. The obtained feature vectors were tested using <b>rough</b> set <b>tools.</b> The analyzed data represent singular sounds of full musical range of 11 musical instruments, played with various articulation techniques. Results of experiments are presented and discussed in this paper. We summarize our paper with conclusions on musical signal representation for timbre classification purposes...|$|R
40|$|Abstract—Trust {{management}} in Multi Agent Systems {{plays a key}} role in today’s growing need for such systems. Methods of trust management try to approximate a set of best agents, in terms of some pre-defined measures. The theory of Rough Sets deals with the approximation of classifying objects in an environment for which we do not have a certain definition. In this research, we propose a new trust management approach based on the concepts of the theory of rough sets. We apply this approach on an Information Retrieval (IR) MAS. This application includes defining the attribute and their domain of values, discretizing the attribute values, collecting these values, and employing a <b>rough</b> set <b>tool</b> for analyzing them. The results of this application are presented...|$|R
40|$|The master thesis {{deals with}} the use of the Sinumerik 840 D control system for {{programming}} of blanks for gear manufacturing. The first part of the thesis is focused on analysis of machinability of the material followed by experimental testing of machinability of material 16 MnCr 5. An experimental evaluation of the effect of cutting parameters was carried out to force load of semi <b>roughing</b> cutting <b>tool</b> CoroTurn 300. In the next part of the thesis there is a technical documentation of gearing parts, for which a NC program is created. Finally, the possibilities of using the Sinumerik 840 D control system are listed and demonstrated by workshop-oriented programming of the considered components for the SP 280 SY turning center...|$|R
40|$|Abstract: The paper {{describes}} {{the whole process}} of design of the cavity parts taking the ashtay,which is common in our life, as an example. Firstly,using MasterCAM to complete the model design of ashtray, <b>rough</b> set, <b>tool</b> path settings and NC program. Secondly,editing the program. finally using the Guangzhou NC machining to complete the process of NC machining simulation. The results show the processing form model design to simulation can be completed, the final results is almost ideals. The emergence and development of The NC machining automatic programming technology and the NC machining simulation technology satisfy the requirements that the processing manufacturing tends to be complicated and highly precise. By comparing the simulated and cut workpiece model and the design of the part model，it can get the cutting conditions, so that we ca...|$|R
40|$|Classification of voluminous protein data {{based on}} the {{structural}} and functional properties is a challenging task for researchers in bioinformatics field. In this paper a faster, accurate and efficient classification <b>tool</b> <b>Rough</b> Set Protein Classifier has been developed which has a classification accuracy of 97. 7 %. It is a hybridized tool comprising Sequence Arithmetic, Rough Set Theory and Concept Lattice. It reduces the domain search space to 9 % without losing the potentiality of classification of proteins...|$|R
50|$|A blank is a thick, shaped stone biface of {{suitable}} {{size and}} configuration for refining into a stone tool. Blanks are the beginning products of lithic reduction, and during prehistoric times were often created for trade or later refinement at another location. Blanks were often formed through the initial reduction of lumps of tool stone at simple quarries, often {{no more than}} easily accessible outcroppings of the local tool stone (although this was certainly not the case at Grimes Graves in England). Sometimes {{the shape of the}} blank hints at the shape of the final tool it will become, but this is not always the case. A blank may consist of either a large, unmodified flake or a reduced core, often with a rough subtriangular or lanceolate shape. <b>Rough</b> chopping <b>tools,</b> derived by removing a few flakes along one edge of the cobble, can also be considered to fall into this group.|$|R
40|$|An {{approach}} to the attribute set decomposition of decision tables is proposed. It enables to combine non-deterministic decision rules based on the generalized decision functions for different subsets of conditions. Optimal decomposition onto conditions subsets is proposed to be searched from Bayesian-like networks. Computational complexity of searching for such networks is discussed. 1 Introduction In recent years rough set approach, originated by [8], {{turned out to be}} very effective as applicable to data mining and decision support systems. However, real-life problems require reconsidering <b>rough</b> set <b>tools</b> in view of large data bases, where the number of objects as well as the average number of conditional attributes in rough set based decision rules becomes too high to classify new cases. For these and also other purposes a great effort has been spent on initial decomposition of information systems and decision tables with large number of objects and attributes (see e. g. [6], [7], [...] ...|$|R
40|$|This paper {{highlights}} {{the prediction of}} learning disabilities (LD) in school-age children using rough set theory (RST) {{with an emphasis on}} application of data mining. In rough sets, data analysis start from a data table called an information system, which contains data about objects of interest, characterized in terms of attributes. These attributes consist of the properties of learning disabilities. By finding the relationship between these attributes, the redundant attributes can be eliminated and core attributes determined. Also, rule mining is performed in rough sets using the algorithm LEM 1. The prediction of LD is accurately done by using Rosetta, the <b>rough</b> set <b>tool</b> kit for analysis of data. The result obtained from this study is compared with the output of a similar study conducted by us using Support Vector Machine (SVM) with Sequential Minimal Optimisation (SMO) algorithm. It is found that, using the concepts of reduct and global covering, we can easily predict the learning disabilities in children...|$|R
40|$|A {{method is}} {{proposed}} to generate <b>rough</b> cut machining <b>tool</b> paths for multipatched B-spline surfaces. For {{a group of}} B-spline surfaces, smoothly connected, separated or intersecting one another, this method can guarantee generating paths without overcutting any of the surfaces under consideration. The use of multipatched surfaces to construct complex surfaces can greatly increase the controllability and friendliness {{in the design of}} surfaces. A method for rough cut planning by convex hull boxing is proposed to generate paths guaranteeing no over-cut. since no computation for solving nonlinear equation is involved, the rough cut plan is robust and efficient...|$|R
50|$|Less than 1% of the world's {{diamonds}} are cut to {{hearts and}} arrows optical symmetry precision. This is {{in large part}} due to the greater amount of rough diamond that necessitates additional polishing to create diamonds with this precise optical symmetry. Diamond polishers take up to three times longer to cut diamonds of this cut quality, with much greater waste of the original diamond <b>rough</b> material.Using specialized <b>tooling</b> and high quality cutting wheels and in some cases 100X magnification, factories must employ careful analysis through every stage of production. Diamonds cut in this way are more expensive than average cut diamonds.|$|R
40|$|<b>Rough</b> sets, a <b>tool</b> {{for data}} mining, {{deal with the}} vagueness and {{granularity}} in information systems. Rough approximations on a complete completely distributive lattice(CCD lattice for short) and brings generalizations of rough sets into a unified framework are discussed in [3]. This paper {{is devoted to the}} discussion of the relationship between approximations and topologies on a CCD lattice. It is proved that the set of all upper approximations (or of lower approximations) with respect to a partition consists of a clopen topology; and conversely, a clopen topology which obey disjoint axiom can be induced by approximations. Furthermore, the axiomatic characterizations of upper and lower approximations are presented. </p...|$|R
