118|210|Public
2500|$|The future king of Spain, {{eager to}} take with him {{the image of his}} grandfather, {{convinced}} Louis XIV to order Hyacinthe Rigaud to paint what would become the absolute image of royal power and the <b>reference</b> <b>picture</b> for generations to come: ...|$|E
5000|$|HEVC {{allows for}} two MV modes which are Advanced Motion Vector Prediction (AMVP) and merge mode. AMVP uses {{data from the}} <b>reference</b> <b>picture</b> and can also use data from {{adjacent}} prediction blocks. The merge mode allows for the MVs to be inherited from neighboring prediction blocks. Merge mode in HEVC is similar to [...] "skipped" [...] and [...] "direct" [...] motion inference modes in H.264/MPEG-4 AVC but with two improvements. The first improvement is that HEVC uses index information to select one of several available candidates. The second improvement is that HEVC uses information from the <b>reference</b> <b>picture</b> list and <b>reference</b> <b>picture</b> index.|$|E
50|$|A popular AzEl rotator {{system for}} a typical small antenna array {{as shown in the}} <b>reference</b> <b>picture</b> would be the Yaesu G-5500.|$|E
50|$|<b>Reference</b> <b>Pictures</b> {{available}} at http://www.armyawards.com/arng/ut/utawards.shtml.|$|R
5000|$|Search for <b>reference</b> <b>pictures</b> to {{help with}} drawing and the environments ...|$|R
40|$|Considering inter-picture {{dependencies}} {{when selecting}} transform coefficient levels in hybrid video coding {{can be done}} via formulating the decoding process as a linear signal model and solving a quadratic program. The basic method assumes motion estimation and quantization parameters as being given and then selects the transform coefficient levels. However, when motion vectors are determined in advance, motion estimation must be conducted using uncoded <b>reference</b> <b>pictures</b> which is known to deliver inferior results compared to motion estimation on decoded <b>reference</b> <b>pictures.</b> In this work, we expand the basic method to incorporate the case where the motion estimation is considering decoded <b>reference</b> <b>pictures.</b> We propose an approach that iterates between transform coefficient selection and motion estimation. We find that a simple two-pass iteration works reasonably well. Our simulation results using an H. 264 /AVC-conforming encoder show coding gains up to 1 dB {{in comparison to the}} quantization method specified in the test model of H. 264 /AVC. 1...|$|R
5000|$|... motion vector: A {{two-dimensional}} vector {{used for}} inter prediction that provides an offset from the coordinates in the decoded picture to the coordinates in a <b>reference</b> <b>picture.</b>|$|E
50|$|Motion {{compensation}} is an algorithmic technique {{used to predict}} a frame in a video, given the previous and/or future frames by accounting for motion of the camera and/or objects in the video. It is employed in the encoding of video data for video compression, for example in the generation of MPEG-2 files. Motion compensation describes a picture {{in terms of the}} transformation of a <b>reference</b> <b>picture</b> to the current picture. The <b>reference</b> <b>picture</b> may be previous in time or even from the future. When images can be accurately synthesised from previously transmitted/stored images, the compression efficiency can be improved.|$|E
50|$|In video compression, {{a motion}} vector {{is the key}} element in the motion {{estimation}} process. It is used to represent a macroblock in a picture based on the position of this macroblock (or a similar one) in another picture, called the <b>reference</b> <b>picture.</b>|$|E
5000|$|B {{picture or}} B frame (bipredictive coded picture) - {{contains}} motion-compensated difference information relative to previously decoded pictures. In older designs such as MPEG-1 and H.262/MPEG-2, each B <b>picture</b> can only <b>reference</b> two <b>pictures,</b> {{the one which}} precedes the B picture in display order and the one which follows, and all <b>referenced</b> <b>pictures</b> must be I or P pictures. These constraints do not apply in newer standards H.264/MPEG-4 AVC and HEVC.|$|R
50|$|The {{frame to}} be coded {{is divided into}} blocks of equal size {{as shown in the}} picture above. Each block {{prediction}} will be blocks of {{the same size as the}} <b>reference</b> <b>pictures,</b> offset by a small displacement.|$|R
50|$|The {{design for}} the crystal magic circles and related {{animation}} was first done in 2D based off some <b>reference</b> <b>pictures.</b> Different colors and symbols were assigned to each character. It was later created in CGI. Animation tools used include Toon Boom Harmony, Adobe After Effects, and Blender.|$|R
5000|$|The {{measurement}} {{paradigm is}} to assess degradations of a decoded video sequence output from the network (for example as received by a TV set top box) {{in comparison to}} the original <b>reference</b> <b>picture</b> (broadcast from the studio). Consequently, the setup is referred to as end-to-end (E2E) quality testing.|$|E
50|$|As seen in {{the center}} of the <b>reference</b> <b>picture,</b> we can see an AzEl {{installation}} (abbreviation for Azimuth/Elevation). It is a rotator type that can control the azimuth and also the elevation direction of an antenna system or array. This type of antenna configuration is used in Amateur radio satellite or EME communication for example.|$|E
50|$|Multiple {{references}} to motion estimation allows finding the best reference in 2 possible buffers (List 0 to past pictures, List 1 to future pictures) which contain up to 16 frames each. Block prediction {{is done by}} a weighted sum of blocks from the <b>reference</b> <b>picture.</b> It allows enhanced picture quality in scenes where there are changes of plane, zoom, or when new objects are revealed.|$|E
5000|$|The {{ability to}} use {{multiple}} motion vectors per macroblock (one or two per partition) with a maximum of 32 {{in the case of}} a B macroblock constructed of 16 4×4 partitions. The motion vectors for each 8×8 or larger partition region can point to different <b>reference</b> <b>pictures.</b>|$|R
40|$|In {{this paper}} we {{describe}} a real-time system for AR/MR rendering applications in a painterly style. Impressionistic images are created using {{a large number}} of brush strokes, which are organized as 3 d particles to achieve frame-to-frame coherence. <b>Reference</b> <b>pictures</b> are used to compute the properties of each stroke. The presented technique is based on B. J. Meier's Painterly Rendering for Animation. We modied the algorithm of Meier for real-time AR/MR environments by extensively using modern 3 d hardware. Vertex and pixel shaders allow both the rendering of thousands of brush strokes per frame and the correct application of their properties. Direct rendering to textures allows rapid genera-tion of <b>reference</b> <b>pictures</b> and assures great exibility, since arbi-trary rendering systems can be combined (e. g. painterly rendering of toon shaded objects, etc.) ...|$|R
40|$|In {{this paper}} we {{describe}} a real-time system for AR/MR rendering applications in a painterly style. Impressionistic images are created using {{a large number}} of brush strokes, which are organized as 3 d particles to achieve frame-to-frame coherence. <b>Reference</b> <b>pictures</b> are used to compute the properties of each stroke. The presente...|$|R
5000|$|In motion-predicted video coding with {{a closed}} {{prediction}} loop, the encoder uses the decoder output as the prediction reference from which future frames are predicted. To that end, the encoder conceptually integrates a decoder. If this [...] "decoder" [...] performs a deblocking, the deblocked picture is then {{used as a}} <b>reference</b> <b>picture</b> for motion compensation, which improves coding efficiency by preventing a propagation of block artifacts across frames. This {{is referred to as}} an in-loop deblocking filter. Standards which specify an in-loop deblocking filter include VC-1, H.263 Annex J, H.264/AVC, and H.265/HEVC.|$|E
5000|$|On {{the death}} of King Charles II of Spain on 18 November 1700, Spain was beset by the dynastic ambitions of other European powers, {{resulting}} in a succession war. The Spanish king's will ruled out any idea of sharing and placed Philip, Duke of Anjou, second son of the Grand Dauphin and grand-son of Louis XIV {{at the forefront of}} legitimate contenders for the crown.The future king of Spain, eager to take with him the image of his grandfather, convinced Louis XIV to order Hyacinthe Rigaud to paint what would become the absolute image of royal power and the <b>reference</b> <b>picture</b> for generations to come: His reputation Rigaud is come to the king, by the portrait he had done of my lord, commander outside the headquarters of Philipsburg, he had the honor in 1700, to be appointed by His Majesty to paint Philippe V, King of Spain, his little son a few days before his departure to take possession of their kingdoms. This work gave rise to the king of Spain's request to the king, his grandfather, giving it as his portrait painted by the same hand; that His Majesty granted him. Rigaud had the honor to start the following year; and being completed, the monarch found the resemblance so perfect and so beautifully decorated, he ordered him to make a copy of the same size, to send to the King of Spain, instead of original. His Most Christian Majesty is painted foot, clad in royal apparel. This table is ten feet and a half high; it is located in Versailles, in the throne room, and the king of Spain in the office of Her Majesty. Spoke Hyacinthe Rigaud, through a friend, in the autobiography he sent to the Grand Duke of Tuscany Cosimo III in 1716.These statements are corroborated by the mention of the corresponding payment in the books of accounts of the artist, in 1701: [...] "The King and the King of Spain, and a copy of Kings's portrait of {{the same size as the}} original for his Catholic Majesty, all 12,000 pounds [...] ", the price of three pictures. The same payment is charged to royal buildings accounts on September 16, 1702: [...] "Two large portraits of King Length, with sketching small portraits of such as also the length portrait of the king of Spain." ...|$|E
30|$|Compared {{with other}} {{prediction}} modes, the SKIP modes require less computational complexity. Each inter mode coded CU {{will determine the}} best motion parameters, including the motion vector, <b>reference</b> <b>picture</b> index, and <b>reference</b> <b>picture</b> list flag, while a CU coded in SKIP mode only contains one PU without a significant transform coefficient or motion vectors, and the <b>reference</b> <b>picture</b> list flag is inherited from the merge mode. The merge mode {{can be applied to}} the SKIP mode and any inter mode.|$|E
40|$|In the {{conventional}} video codec, B pictures usually employ five prediction modes, including bi-prediction, direct prediction, forward prediction, backward prediction and intra modes. Among them, {{the direct and}} bi-prediction modes, whose prediction values are achieved from both forward and backward <b>reference</b> <b>pictures,</b> are more efficient in exploiting the temporal correlation between the <b>reference</b> <b>pictures</b> and the current B picture. In addition, the direct mode does not require any bits for coding the motion vectors. Therefore, the blocks coded with direct or bi-predictive mode are usually {{much more than the}} other modes. To further take advantage of the bi-prediction, in this paper we propose a new bi-predictive coding technique, which can achieve the good tradeoff between the bit-rate saving for motion vector coding and the prediction accuracy. Moreover, we also propose the spatial motion vector prediction and motion vector scaling techniques to improve the accuracy of derived direct mode motion vectors. All these techniques have been adopted in AVS 1 video coding standard. 1...|$|R
40|$|Abstract—Memory size {{occupation}} and memory access bandwidth are capital issues for high resolution video codec design {{because of the}} large scale of data, and the high power consumption especially for wireless terminals. An adaptive and random access-obeyed <b>reference</b> <b>pictures</b> memory compression (RPMC) scheme based on as small granularity as 2 x 2 blocks for 2 -bit truncation is proposed in this paper to solve the problems. The impact of granularity in RPMC to memory access bandwidth during motion estimation and/or motion compensation is analyzed firstly. Then an adaptive RPMC scheme based on 2 x 2 block size is proposed, based on min-max scalar quantization (MMSQ). Finally, the results based on HM are provided which show that compared with the common used 4 x 4 block-based methods, little performance loss is introduced. At the same time, based on the adaptively merge scheme, the average memory access bandwidth is saved than the 4 x 4 block based method by up to 17 %. Keywords- Video processing; <b>reference</b> <b>pictures</b> memory compression (RPMC); memory bandwidth; power consumption; granularity I...|$|R
40|$|AbstractIn video coding {{standard}} of H. 264 /AVC, motion estimation (ME) using multiple <b>reference</b> <b>pictures</b> improves compression efficiency considerably. However, the motion estimation includes {{a large amount}} of useless computations regardless of picture contents. This paper proposes a fast motion estimation algorithm that removes the worthless computations in the motion estimation process with switching single and multiple <b>reference</b> <b>pictures</b> adaptively. The proposed algorithm classifies blocks into valid and invalid blocks for the multiple references based ME, and removes the unnecessary computations by applying a single reference based ME to the invalid blocks. In order to evaluate the performance of the proposed algorithm, measures with respects to image quality, bit rate, and motion estimation time are compared with those of the scheme in a reference software JM 9. 5. The simulation results show that the proposed algorithm can considerably save 39 % on average motion estimation time while keeping the image quality (0. 025 dB degradation) and the bit rate (0. 8 % decrease) as good as the reference algorithm...|$|R
40|$|Abstract—The {{increasing}} {{proportion of}} video traffic in telecommunication networks puts {{an emphasis on}} efficient video compression technology. High Efficiency Video Coding (HEVC) is the forthcoming video coding standard that provides substantial bit rate reductions compared to its predecessors. In the HEVC standardization process, technologies such as picture partitioning, <b>reference</b> <b>picture</b> management, and parameter sets are categorized as “high-level syntax. ” The design of the high-level syntax impacts the interface to systems and error resilience, and provides new functionalities. This paper presents {{an overview of the}} HEVC high-level syntax, including network abstraction layer unit headers, parameter sets, picture partitioning schemes, <b>reference</b> <b>picture</b> management, and supplemental enhancement information messages. Index Terms—High Efficiency Video Coding (HEVC), Joint Collaborative Team on Video Coding (JCT-VC), parameter set, <b>reference</b> <b>picture</b> list, <b>reference</b> <b>picture</b> set, video coding. I...|$|E
30|$|Each {{partition}} in an inter-coded macroblock {{is predicted}} {{from an area}} of the <b>reference</b> <b>picture.</b> The MV between the two areas has sub-pixel resolution. The luma and chroma samples at sub-pixel positions do not exist in the <b>reference</b> <b>picture</b> and so it is necessary to create them using interpolation from nearby image samples.|$|E
40|$|The {{direct mode}} {{used in the}} bi-predictive {{pictures}} (B-pictures) can efficiently improve the coding performance of B pictures, because it has small overhead and obtains a predictive picture from two reference pictures. The traditional temporal direct mode (TDM) derives the motion vector of the current block by scaling the motion vector of the co-located block in the backward <b>reference</b> <b>picture.</b> However, when the current block and its co-located block in backward <b>reference</b> <b>picture</b> belong to different objects with different motion directions, the prediction efficiency of TDM is drastically reduced. In this paper, we propose an improved direct mode prediction method. In the method, a virtual <b>reference</b> <b>picture</b> is generated using the pixel projection technique. Then the virtual <b>reference</b> <b>picture</b> is used to predict the direct mode blocks in B pictures. The proposed method can enhance the prediction performance of the direct mode blocks and achieve a higher coding efficiency...|$|E
5000|$|In 1615 the Queen's Revels players {{moved to}} Rosseter's {{short-lived}} Porter's Hall Theatre and then {{passed out of}} existence. After that point, {{the story of the}} Whitefriars Theatre grows obscure; Prince Charles's Men may have used the theatre, though they were also acting at the Hope. A 1616 <b>reference</b> <b>pictures</b> the place as poorly furnished and suffering from rain damage. In 1621 the building's then-current landlord, Sir Anthony Ashley, [...] "turned out the players." ...|$|R
40|$|This paper {{describes}} novel transcoding techniques {{aimed for}} low-complexity MPEG- 2 to H. 264 /AVC transcoding. An important application {{for this type}} of conversion is efficient storage of broadcast video in consumer devices. The architecture for such a system is presented, which includes novel motion mapping and mode decision algorithms. For the motion mapping, two algorithms are presented. Both efficiently map incoming MPEG- 2 motion vectors to outgoing H. 264 /AVC motion vectors regardless of the block sizes that the motion vectors correspond to. In addition, the algorithm maps motion vectors to different <b>reference</b> <b>pictures,</b> which is useful for picture type conversion and prediction from multiple <b>reference</b> <b>pictures.</b> We also prpose an efficient rate-distortion optimized macroblock coding more decision algorithm, which first evaluates candidate modes based on a simple cost function so that a reduced set of candidate modes is formed, then based on this reduced set, we evaluate the more complex Lagrangian cost calculation to determine the coding mode. Extensive simulation results show that our proposed transcoder incorporating the proposed algorithms achieves very good rate-distortion performance with low complexity. Compared with the cascaded decoder-encoder solution, the coding efficiency is maintained while the complexity is significantly reduced...|$|R
40|$|This paper {{proposes a}} fast motion {{estimation}} method which {{can reduce the}} computational complexity of HEVC encoding process. While the previous method determines its search range based on a distance between a current and a <b>reference</b> <b>pictures</b> to accelerate the time-consuming motion estimation, the proposed method adaptively sets the search range according to motion vector difference between prediction units. Experimental {{results show that the}} proposed method achieves about 10. 7 % of reduction in processing time of motion estimation under the random access configuration whereas it...|$|R
40|$|Multiview video coding (MVC), {{which is}} {{becoming}} an extension of H. 264 /AVC, is currently under development by the Joint Video Team (JVT). Compared to H. 264 /AVC, the main new compression tool in MVC is inter-view prediction, which, among others, causes a substantial increase of the decoded picture buffer (DPB) size. Therefore to have an efficient buffer management for MVC is highly desirable. In this paper, we provide analyses of minimum buffer requirements for typical MVC coding structure with two coding methods, viewfirst coding and time-first coding. The analysis results are helpful in designing <b>reference</b> <b>picture</b> management or <b>reference</b> <b>picture</b> marking methods. Index Terms — Multiview video coding, decoded picture buffer, <b>reference</b> <b>picture</b> marking, H. 264 /AVC 1...|$|E
40|$|Abstract — In this paper, {{we present}} error-resilient Internet video {{transmission}} using path diversity and rate-distortion opti-mized <b>reference</b> <b>picture</b> selection. Under this scheme, the optimal packet dependency is determined adapting to channel character-istics and video content, {{to achieve a}} better trade-off between cod-ing efficiency and forming independent streams to increase error-resilience. Packets are sent over the selected path that minimizes the distortion, while taking advantage of path diversity. Experi-ments demonstrate that the proposed scheme provides significant gains over video redundancy coding and the NACK mode of con-ventional <b>reference</b> <b>picture</b> selection. I...|$|E
40|$|Abstract. This paper proposes {{the use of}} unequally {{protected}} key {{pictures to}} prevent temporal error propagation in error-prone video communications. The key picture may either be an intra-coded picture or a picture using a long-term motion compensation <b>reference</b> <b>picture</b> through <b>reference</b> <b>picture</b> selection. The inter-coded key picture uses previous key pictures as motion compensation reference. Key pictures are better protected than other pictures using forward error correction in either source or transport coding. Simulation results show significantly improved error resiliency performance of the proposed technique compared to conventional methods. ...|$|E
40|$|Video {{content is}} {{expected}} to account for 80 percent of all Internet traffic in 2019. There is therefore an increasing need for better video compression methods, to decrease the use of internet bandwidth. One way of achieving high video compression is to predict pixel values for a video frame based on prior and succeeding pictures in the video. The H. 265 video compression standard supports this method, and in particular {{makes it possible to}} specify in which order pictures are coded, and which pictures are predicted from which. The coding order is specified for Groups Of Pictures (GOP), where a number of pictures are grouped together and predicted from each other in a specified order. This thesis evaluates how the GOPs should be structured, for instance in terms of sizing, to maximize the compression efficiency relative to the video quality. It also investigates the effect of multiple <b>reference</b> <b>pictures,</b> a functionality that enables the picture that renders the best prediction to be selected. The results show that the largest tested GOP size of 32 pictures is preferable for all tested video characteristics, and that support for multiple <b>reference</b> <b>pictures</b> renders a similar increase in compression efficiency for all GOP sizes...|$|R
40|$|Abstract. With the {{development}} of multimedia technology, the medical CT images become {{more important in the}} process of diagnostic cases, at the same time, how to retrieve the medical images that we need becomes more and more important. Usually, images could be got precisely but not intelligently using database. Therefore, this paper, taking advantages of both ontology and data structure of the medical image, introduces a semantic retrieval system programmed by Java and helps to achieve the intelligent retrieval of medical CT images and provides better <b>reference</b> <b>pictures</b> to the doctors...|$|R
5000|$|Poet Elizabeth Bishop's poem [...] "In the Waiting Room" [...] <b>references</b> a <b>picture</b> of Martin and Osa Johnson in a February, 1918 National Geographic {{she read}} as a child.|$|R
