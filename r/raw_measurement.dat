89|584|Public
25|$|Defining {{structure}} and detecting {{the emergence of}} complexity in nature are inherently subjective, though essential, scientific activities. Despite the difficulties, these problems can be analysed {{in terms of how}} model-building observers infer from measurements the computational capabilities embedded in non-linear processes. An observer’s notion of what is ordered, what is random, and what is complex in its environment depends directly on its computational resources: the amount of <b>raw</b> <b>measurement</b> data, of memory, and of time available for estimation and inference. The discovery of structure in an environment depends more critically and subtly, though, on how those resources are organized. The descriptive power of the observer’s chosen (or implicit) computational model class, for example, can be an overwhelming determinant in finding regularity in data.|$|E
2500|$|By {{comparing}} extant sequences, one {{can determine}} the amount of sequence divergence. This <b>raw</b> <b>measurement</b> of divergence provides information about the number of changes that have occurred along the path separating the sequences. The simple count of differences (the Hamming distance) between sequences will often underestimate the number of substitution because of multiple hits (see homoplasy). Trying to estimate the exact number of changes that have occurred is difficult, and usually not necessary. Instead, branch lengths (and path lengths) in phylogenetic analyses are usually expressed in the expected number of changes per site. The path length is the product of the duration of the path in time and the mean rate of substitutions. [...] While their product can be estimated, the rate and time are not identifiable from sequence divergence.|$|E
50|$|MS assisted: The MS (mobile phone) {{performs}} E-OTD or GPS measurements, {{and passes}} the <b>raw</b> <b>measurement</b> {{data to the}} network. The computation of the geolocation is then performed inside the carrier network, not on the phone itself.|$|E
5000|$|... result storage (<b>raw</b> <b>measurements</b> {{together}} with reconciled values) ...|$|R
40|$|Satellite orbit {{tomography}} is a {{newly developed}} method {{for addressing the}} Dy-namic Calibration of the Atmosphere (DCA). The focus {{of this paper is}} a side-by-side comparison with other DCA methods that use the <b>raw</b> tracking <b>measurements</b> and solve simultaneously for the orbit state and parameterized density correction. The main contribution of this work is to test the notion that, in general, an es-timator benefits from using <b>raw</b> <b>measurements</b> to solve for the state, in contrast with an estimator that uses intermediate estimated quantities in place of the <b>raw</b> <b>measurements...</b>|$|R
50|$|Using the {{subscriber}} identity module (SIM) in GSM and Universal Mobile Telecommunications System (UMTS) handsets, it {{is possible}} to obtain <b>raw</b> radio <b>measurements</b> from the handset. Available measurements include the serving Cell ID, round-trip time, and signal strength. The type of information obtained via the SIM can differ from that which is available from the handset. For example, it may not be possible to obtain any <b>raw</b> <b>measurements</b> from the handset directly, yet still obtain measurements via the SIM.|$|R
50|$|Industrial {{process data}} {{validation}} and reconciliation, or more briefly, data validation and reconciliation (DVR), is {{a technology that}} uses process information and mathematical methods in order to automatically correct measurements in industrial processes. The use of DVR allows for extracting accurate and reliable information {{about the state of}} industry processes from <b>raw</b> <b>measurement</b> data and produces a single consistent set of data representing the most likely process operation.|$|E
5000|$|Data {{originates}} typically from measurements {{taken at}} different places throughout the industrial site, for example temperature, pressure, {{volumetric flow rate}} measurements etc. To understand {{the basic principles of}} DVR, it is important to first recognize that plant measurements are never 100% correct, i.e. <b>raw</b> <b>measurement</b> [...] is not a solution of the nonlinear system [...] When using measurements without correction to generate plant balances, it is common to have incoherencies. Measurement errors can be categorized into two basic types: ...|$|E
50|$|Defining {{structure}} and detecting {{the emergence of}} complexity in nature are inherently subjective, though essential, scientific activities. Despite the difficulties, these problems can be analysed {{in terms of how}} model-building observers infer from measurements the computational capabilities embedded in non-linear processes. An observer’s notion of what is ordered, what is random, and what is complex in its environment depends directly on its computational resources: the amount of <b>raw</b> <b>measurement</b> data, of memory, and of time available for estimation and inference. The discovery of structure in an environment depends more critically and subtly, though, on how those resources are organized. The descriptive power of the observer’s chosen (or implicit) computational model class, for example, can be an overwhelming determinant in finding regularity in data.|$|E
40|$|A LiDAR system {{calibration}} procedure estimates {{a set of}} parameters that represent biases in the system parameters and measurements. These parameters {{can be used to}} improve the quality of any subsequently-collected LiDAR data. Current LiDAR calibration techniques require full access to the system parameters and <b>raw</b> <b>measurements</b> (e. g., platform position and orientation, laser ranges, and scan-mirror angles). Unfortunately, the <b>raw</b> <b>measurements</b> are not usually available to end-users. The absence of such information is limiting the widespread adoption of LiDAR calibration activities by the end users. This research proposes alternative methods for LiDAR system calibration, without the need for the system <b>raw</b> <b>measurements.</b> The simplified method that is proposed in this paper uses the available coordinates of the LiDAR points in overlapping parallel strips to estimate biases in the system parameters and measurements (more specifically, biases in the planimetric lever-arm offset components, boresight angles, ranges, and mirror-angles). In this approach, the conventional LiDAR equation is simplified based on a few reasonable assumptions; the simplified LiDAR equation is then used to model the mathematical relationship between conjugate surface elements in overlapping Lidar system calibration using overlapping strip...|$|R
40|$|Abstract Background Open-angle {{glaucoma}} (OAG) is a prevalent, degenerate {{ocular disease}} {{which can lead}} to blindness without proper clinical management. The tests used to assess disease progression are susceptible to process and measurement noise. The aim {{of this study was to}} develop a methodology which accounts for the inherent noise in the data and improve significant disease progression identification. Methods Longitudinal observations from the Collaborative Initial Glaucoma Treatment Study (CIGTS) were used to parameterize and validate a Kalman filter model and logistic regression function. The Kalman filter estimates the true value of biomarkers associated with OAG and forecasts future values of these variables. We develop two logistic regression models via generalized estimating equations (GEE) for calculating the probability of experiencing significant OAG progression: one model based on the <b>raw</b> <b>measurements</b> from CIGTS and another model based on the Kalman filter estimates of the CIGTS data. Receiver operating characteristic (ROC) curves and associated area under the ROC curve (AUC) estimates are calculated using cross-fold validation. Results The logistic regression model developed using Kalman filter estimates as data input achieves higher sensitivity and specificity than the model developed using <b>raw</b> <b>measurements.</b> The mean AUC for the Kalman filter-based model is 0. 961 while the mean AUC for the <b>raw</b> <b>measurements</b> model is 0. 889. Hence, using the probability function generated via Kalman filter estimates and GEE for logistic regression, we are able to more accurately classify patients and instances as experiencing significant OAG progression. Conclusion A Kalman filter approach for estimating the true value of OAG biomarkers resulted in data input which improved the accuracy of a logistic regression classification model compared to a model using <b>raw</b> <b>measurements</b> as input. This methodology accounts for process and measurement noise to enable improved discrimination between progression and nonprogression in chronic diseases...|$|R
40|$|All <b>raw</b> <b>measurements</b> are {{fluorescence}} intensities Target cDNA (or mRNA) is fluorescently labeled Molecules in dye {{are excited}} using a laser Measurement is {{a count of}} the photons emitted Entire slide or chip is scanned, {{and the result is}} a digital image Image is processed to locate probes and assign intensity measurements to each prob...|$|R
50|$|By {{comparing}} extant sequences, one {{can determine}} the amount of sequence divergence. This <b>raw</b> <b>measurement</b> of divergence provides information about the number of changes that have occurred along the path separating the sequences. The simple count of differences (the Hamming distance) between sequences will often underestimate the number of substitution because of multiple hits (see homoplasy). Trying to estimate the exact number of changes that have occurred is difficult, and usually not necessary. Instead, branch lengths (and path lengths) in phylogenetic analyses are usually expressed in the expected number of changes per site. The path length is the product of the duration of the path in time and the mean rate of substitutions. While their product can be estimated, the rate and time are not identifiable from sequence divergence.|$|E
50|$|In this method, {{proposed}} by Philipp Lindner and Gerd Wanielik, laser data is processed using a multidimensional occupancy grid. Data from a 4 layer laser is pre-processed at the signal level and then processed {{at a higher}} level to extract the features of the obstacles. A combination 2- and 3-dimensional grid structure is utilized and the space in these structures is tessellated into several discrete cells. This method allows a huge amount of <b>raw</b> <b>measurement</b> data to be effectively handled by collecting it in spatial containers, the cells of the evidence grid. Each cell is associated with a probability measure that identifies the cell occupation. This probability is calculated by using the range measurement of the lidar sensor obtained over time and a new range measurement, which are related using Bayes' theorem. A two dimensional grid can observe an obstacle in front of it, but cannot observe the space behind the obstacle. TO address this, the unknown state behind the obstacle is assigned a probability of 0.5. By introducing the third dimension or in other terms using a multi-layer laser, the spatial configuration of an object could be mapped into the grid structure to a degree of complexity. This is achieved by transferring the measurement points into a 3 dimensional grid. The grid cells which are occupied will possess a probability greater than 0.5 and the mapping would be color coded based on the probability. The cells which are not occupied will possess a probability less than 0.5 and this area will usually be white space. This measurement is then transformed to a grid coordinate system by using the sensor position on the vehicle and the vehicle position in the world coordinate system. The coordinates of the sensor depends upon its location on the vehicle and the coordinates of the vehicle is computed using egomotion estimation, which is estimating the vehicle motion relative to a rigid scene. For this method, the grid profile must be defined. The grid cells touched by the transmitted laser beam are calculated by applying Bresenham's line algorithm. To obtain the spatial extended structure, a connected component analysis of these cells is performed. This information is then passed on to a rotating caliper algorithm to obtain the spatial characteristics of the object. In addition to the lidar detection, RADAR data obtained by using two short range radars is integrated to get additional dynamic properties of the object, such as its velocity. The measurements are assigned to the object using a potential distance function.|$|E
40|$|Abstract—This paper {{presents}} a data fusion framework for wireless localization via the weighted least square estimator (WLSE). Three types of fusion schemes are presented: measurement fusion, estimate fusion and mixed fusion. Theoretical performance comparison among these schemes {{in terms of}} the estimation error covariance matrix is conducted. We show that, if the <b>raw</b> <b>measurement</b> vectors are correlated, then measurement fusion achieves the best performance, followed by mixed fusion and estimate fusion is the worst. If the <b>raw</b> <b>measurement</b> vectors are uncorrelated, then they can achieve the same performance. The benefits that can be earned from data fusion are also investigated and numerical case studies are presented to validate our theoretical analysis. Index Terms—Wireless localization, data fusion, weighted least square estimator (WLSE), Cramer-Rao lower bound (CRLB). I...|$|E
30|$|At {{each of the}} UK {{observatories}} three identical systems, {{each with}} two different instruments, record the magnetic field direction and magnitude. At ASC and PST {{there is a single}} system with vector and scalar instruments. The ability to derive QD data in near real-time relies on the standard of the instruments used and quality of the <b>raw</b> <b>measurements.</b>|$|R
40|$|Display {{combines}} bar charts, vector diagrams, and {{numerical values}} to inform operator of forces and torques exerted by end effector of manipulator. On voice or keyboard command, eight-channel strip-chart recorder traces force and torque components and claw position of <b>raw</b> <b>measurements</b> from eight strain gage sensors in end effector. Especially helpful when operator's view of end effector is obscured...|$|R
5000|$|Atmospheric effects: The actual {{composition}} of the atmosphere (in particular with respect to water vapor and aerosols) can significantly affect the measurements made in space. Hence, the latter may be misinterpreted if these effects are not properly taken into account (as is the case when the NDVI is calculated directly {{on the basis of}} <b>raw</b> <b>measurements).</b>|$|R
40|$|Resistance (<b>Raw)</b> <b>measurement</b> is not {{included}} in the guidelines for the diagnosis and management of asthma. Actually, spirometry is more widely available and less expensive and <b>Raw</b> <b>measurement</b> in the body plethysmograph can be difficult for some patients. Devices to measure oscillatory resistance are now available. The forced oscillation technique is a non-invasive method requiring no active contribution from the subject. We aimed to assess the utility of respiratory resistance measurement and the correlation with spirometric data in asthmatic patients. We studied 15 asthmatic subjects, (8 M, 7 F,mean age 43, 8 4, 8) from our outpatients clinic, before and after the administration of bronchodilator (salbutamol 200 mcg). A significant negative correlation has been found between FEV 1 and Raw both before and after salbutamol administration (p= 0, 02 and 0, 05 respectively). A significant negative correlation has been found between FEF 25 - 75 and Raw before bronchodilation (p= 0, 008) but not after. No correlation has been found between MEF 25 and Raw. Our data suggest that <b>Raw</b> <b>measurement</b> can be used in detection of airway obstruction and reversibility and can sometimes have potential advantages in the assessment of patients unable to perform accettable forced expiration curve (elderly persons, children) or when the spirometry is contraindicated (unstable cardiovascular status, recent thoracic or abdominal surgery [...] .) ...|$|E
40|$|Measurement and {{monitoring}} {{are important for}} correct and efficient operation of a network, since these activities provide reliable information and accurate analysis for characterizing and troubleshooting a network’s performance. The focus of network measurement is to measure the volume and types of traffic on a particular network and to record the <b>raw</b> <b>measurement</b> results. The focus of network monitoring is to initiate measurement tasks, collect <b>raw</b> <b>measurement</b> results, and report aggregated outcomes. Network systems are continuously evolving: besides incremental change to accommodate new devices, more drastic changes occur to accommodate new applications, such as overlay-based content delivery networks. As a consequence, a network can experience significant increases in size and significant levels of long-range, coordinated, distributed activity; furthermore, heterogeneous network technologies, services and applications coexist and interact. Reliance upon traditional, point-to-point, ad hoc measurements to manage such networks is becoming increasingly tenuous. In particular, correlated, simultaneous 1 -way measurements are needed, as {{is the ability to}} access measurement information stored throughout the network of interest...|$|E
40|$|In this paper, {{we present}} a data fusion {{framework}} for parametric-model- based wireless localization where the mobile station location is treated as a deterministic unknown vector. Three types of fusion schemes are presented: measurement fusion, estimate fusion and mixed fusion. Theoretical performance comparison among these schemes {{in terms of the}} estimation root mean square error via the weighted least square estimator (WLSE) is conducted. Such a performance metric coincides with the Cramer-Rao lower bound (CRLB) in the case of Gaussian noise. We show that, if the <b>raw</b> <b>measurement</b> vectors are correlated, then measurement fusion achieves the best performance, mixed fusion follows and estimate fusion is the worst. If the <b>raw</b> <b>measurement</b> vectors are uncorrelated, then these different fusion schemes achieve the same performance. Benefits that can be earned from data fusion for wireless localization are also investigated and numerical examples are presented to validate our theoretical analysis. © Springer Science+Business Media, LLC 2011...|$|E
40|$|The SandT-Pro {{experiment}} {{was a large}} scale laboratory experiment, conducted in the CIEM wave flume {{as part of the}} HydraLab IV framework between November 2013 - January 2014. The dataset contains processed measurements of wave height, velocity, sand concentration and bed profile evolution for two monochromatic wave conditions. The dataset further contains <b>raw</b> <b>measurements</b> of velocity and concentration for eight bichromatic wave conditions...|$|R
40|$|Specifications of pyro shock {{tests are}} treated as the {{interconnection}} between <b>raw</b> <b>measurements</b> (or estimates) {{of the environment and}} the various test methods available. After a definition of the environment, various aspects of test method specification are discussed including one-sided pulses, test simulation parameters, and the effects of Q. Different test configurations are considered including rigid fixture tests, pseudo-real structure, and real structure...|$|R
30|$|Objects and actions. The {{objects of}} the {{hospital}} policies and the possible actions on them {{are determined by the}} structure of the data in the HPMS. The previous section mentioned five types of application data: (1) the <b>raw</b> <b>measurements,</b> (2) the overview of the patient’s status, (3) the notifications sent to physicians, (4) the notes added to a patient’s status overview and (5) the patient questionnaires. The actions on these objects are as follows: The <b>raw</b> <b>measurements,</b> the patient’s status overview and the notifications are all created by the system and cannot be altered; end-users can only view them. Notes on the other hand can be created, viewed, updated and deleted. Patient questionnaires can be created and assigned to patients by physicians. Patients can view and fill in open patient questionnaires and both patients and physicians can view completed patient questionnaires. Next to the five types of application data, the hospital can also constrain access to the HPMS as a whole.|$|R
30|$|Kalman filter is {{constructed}} epoch wise {{by applying the}} least squares principle, which utilizes all of the random information as three groups of statistically independent measurements: the predicted state vector {{as a group of}} pseudo-measurements, the zero mean process noise vector also as a group of pseudo-measurements, and the <b>raw</b> <b>measurement</b> vector, whose residual or correction vectors can directly be calculated as the projection of the system innovation vector.|$|E
40|$|This dataset {{contains}} figure {{data for}} the publication "High order coherent communications using mode-locked dark-pulse Kerr combs from microresonators". To complement the main transmission results in the paper, the figure 3 c subfolder also includes the related <b>raw</b> <b>measurement</b> data {{as well as the}} digital signal processing (DSP) code that is required to calculate the bit error ratios. The program code is distributed under a GPLv 3 license...|$|E
40|$|AbstractWe {{report on}} a novel method to {{determine}} the thermal conductivity, thermal diffusivity, and average emissivity of a thin-film diaphragm embedded in a MEMS multi-parameter wind sensor. Compared to other measurement techniques for thermal thin-film parameters, our method does not require fabrication of custom specimens. The results {{can be obtained from}} frequency response measurements directly carried out on the wind sensor. We describe the theoretical background of this method, provide an efficient analytical model (validated by FEM simulations) for the parameter extraction from the <b>raw</b> <b>measurement</b> data, and demonstrate its application by sample measurements performed on multi-layer SixNy-SiO 2 thin-film diaphragms...|$|E
40|$|Abstract—The {{problem of}} minimum cost in-network fusion of measurements, {{collected}} from distributed sensors via multihop routing is considered. A designated fusion center performs an optimal statistical-inference test on the correlated measurements, {{drawn from a}} Markov random field. Conditioned on the delivery of a sufficient statistic for inference to the fusion center, the structure of optimal routing and fusion is {{shown to be a}} Steiner tree on a transformed graph. This Steiner-tree reduction preserves the approximation ratio, which implies that any Steinertree heuristic can be employed for minimum cost fusion with the same approximation ratio. The proposed fusion scheme involves routing packets of two types viz., <b>raw</b> <b>measurements</b> sent for local processing, and aggregates obtained on combining these processed values. The performance of heuristics for minimum cost fusion are evaluated through theory and simulations, showing a significant saving in routing costs, when compared to routing all the <b>raw</b> <b>measurements</b> to the fusion center. Index Terms — Sensor networks, in-network processing and aggregation, statistical inference, cost minimization I...|$|R
40|$|In this paper, we {{describe}} a hybrid-extended Kalman filter algorithm to synchronize the clocks and to precisely determine the inter-spacecraft distances for space-based gravitational wave detectors, such as (e) LISA. According to the simulation, the algorithm has significantly improved the ranging accuracy and synchronized the clocks, making the phase-meter <b>raw</b> <b>measurements</b> qualified for time- delay interferometry algorithms. Comment: 14 pages, Phys. Rev. D 90, 064016 (2014...|$|R
40|$|The KEK Accelerator test {{facility}} (ATF) extraction line laser-wire {{system has been}} upgraded last year allowing the measurement of micron scale transverse size electron beams. The last measurements using the upgraded system from recent operation at the ATF are presented, demonstrating <b>raw</b> <b>measurements</b> of order 3 μm RMS. The main component contributions to this measurement are also discussed. © 2010 Elsevier B. V. All rights reserved...|$|R
40|$|The Seebeck {{coefficient}} {{is one of}} the key {{quantities of}} thermoelectric materials and routinely measured in various laboratories. There are, however, several ways to calculate the Seebeck coefficient from the <b>raw</b> <b>measurement</b> data. We compare these different ways to extract the Seebeck coefficient, evaluate the accuracy of the results, and show methods to increase this accuracy. We furthermore point out experimental and data analysis parameters that can be used to evaluate the trustworthiness of the obtained result. The shown analysis can be used to find and minimize errors in the Seebeck coefficient measurement and therefore increase the reliability of the measured material properties...|$|E
40|$|A non-hydrostatic free-surface {{model was}} set up to {{simulate}} salt and heat transport in a solar pond in order to: 1) investigate the added value of free-surface models for these types of simulations, and 2) assess the importance of heat transport along a sloping side wall. This data set presents the source code, the <b>raw</b> <b>measurement</b> and model data, and several movies comparing the vertical two-dimensional (2 DV) model simulations to the measurements. The presented model code is an extension of the SWASH non-hydrostatic model, which is briefly introduced in this document. A complete discussion of the model results and conclusions are provided in an accompanying article...|$|E
40|$|We {{consider}} sensor power scheduling for {{estimating the}} state of a general high-order Gauss-Markov system. A sensor decides whether to use a high or low transmission power to communicate its local state estimate or <b>raw</b> <b>measurement</b> data with a remote estimator over a packet-dropping network. We construct the optimal sensor power schedule which minimizes the expected terminal estimation error covariance at the remote estimator under the constraint that the high transmission power can only be used m < T + 1 times, given the time-horizon from k = 0 to k = T. We also discuss how to extend the result to cases involving multiple power levels scheduling. Simulation examples are the provided to demonstrate the results...|$|E
30|$|Let us {{mention that}} the Dst index is {{calculated}} as an average of four mid-latitude geomagnetic observatories after {{taking into account the}} secular variation and the system of the external Sq currents at each location. Consequently, the Dst index catches corrections applied to the magnetic field measurements with respect to these influences [[URL] whereas the observatory data, to which the wavelet transform has been applied, are <b>raw</b> <b>measurements.</b>|$|R
50|$|FreeTrack has {{a simple}} {{interface}} {{that can be}} freely used by third party programs to access 6DOF tracking data, both real <b>raw</b> <b>measurements</b> and virtual. It is hardware agnostic, so is not dependent on a specific brand or version of hardware {{and can be used}} without restriction. Bohemia Interactive's ARMA 2 is the first game to support the FreeTrack interface and GP Bikes is the first to have exclusive support.|$|R
40|$|We {{consider}} {{the problem of}} optimal reactive power compensation for the minimization of power distribution losses in a smart microgrid with <b>raw</b> <b>measurements.</b> We provide two distributed estimation algorithms, one ADMM-based and one JACOBI-like, in order to estimate using only local exchange of information. We prove the convergence of the ADMM algorithm to the maximum likelihood solution. Numerical simulations are included to validate the proposed algorithms, for different magnitude of error...|$|R
