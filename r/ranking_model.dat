477|1415|Public
50|$|Training data {{is used by}} a {{learning}} algorithm to produce a <b>ranking</b> <b>model</b> which computes relevance of documents for actual queries.|$|E
50|$|The United States law {{enforcement}} <b>ranking</b> <b>model</b> is generally quasi-military in structure. Each level of {{law enforcement}} (federal, state, and local) has different ranks and vary considerably from agency to agency. There is no nationally set law enforcement rank structure, {{but they tend to}} follow similar patterns.|$|E
50|$|Typically, users {{expect a}} search query to {{complete}} {{in a short}} time (such as a few hundred milliseconds for web search), which makes it impossible to evaluate a complex <b>ranking</b> <b>model</b> on each document in the corpus, and so a two-phase scheme is used. First, a small number of potentially relevant documents are identified using simpler retrieval models which permit fast query evaluation, such as the vector space model, boolean model, weighted AND, or BM25. This phase is called top- document retrieval and many heuristics were proposed in the literature to accelerate it, such as using a document's static quality score and tiered indexes. In the second phase, a more accurate but computationally expensive machine-learned model is used to re-rank these documents.|$|E
40|$|Prognostic {{procedures}} can {{be based}} on <b>ranked</b> linear <b>models.</b> <b>Ranked</b> regression type <b>models</b> are designed {{on the basis of}} feature vectors combined with set of relations defined on selected pairs of these vectors. Feature vectors are composed of numerical results of measurements on particular objects or events. Ranked relations defined on selected pairs of feature vectors represent additional knowledge and can reflect experts' opinion about considered objects. <b>Ranked</b> <b>models</b> have the form of linear transformations of feature vectors on a line which preserve a given set of relations in the best manner possible. <b>Ranked</b> <b>models</b> can be designed through the minimization of a special type of convex and piecewise linear (CPL) criterion functions. Some sets of ranked relations cannot be well represented by one <b>ranked</b> <b>model.</b> Decomposition of global model into a family of local <b>ranked</b> <b>models</b> could improve representation. A procedures of <b>ranked</b> <b>models</b> decomposition is described in this paper...|$|R
40|$|Massive {{spatial data}} have been {{observed}} in many disciplines such as environmental studies, earth science and ecology. Those massive spatial data present a computational challenge to statistical analysis {{because of the large}} covariance matrix involved. One of the most useful techniques for analyzing massive spatial data is to approximate the spatial process by a set of latent variables and latent functions since it simplifies the operation of the large covariance matrix. This leads to a low <b>rank</b> <b>model.</b> Various low <b>rank</b> <b>models</b> have been constructed for spatial data. However, the optimal low <b>rank</b> <b>model</b> is based on Karhunen-Loéve expansion since it minimizes the total mean square error. ^ We proposed two algorithms to obtain Karhunen-Loéve expansion for spatial process and compared them with an existing one. Based on our efficient algorithm, we developed the Karhunen-Loéve Low <b>Rank</b> <b>Model</b> (KL Low <b>Rank</b> <b>Model)</b> for univariate spatial massive data and compared with predictive process Low <b>Rank</b> <b>Model</b> through simulations and real data analysis. The results show that KL Low <b>Rank</b> <b>Model</b> provides better predictive performance than predictive process Low <b>Rank</b> <b>Models.</b> ^ KL Low <b>Rank</b> <b>Model</b> can be extended for multivariate spatial process. A major challenge in modelling multivariate spatial data is to specify appropriate covariance function which should be positive definite. There have been recent developments of the parametric covariance functions for multivariate spatial processes. However, usually a larger number of parameters need to be estimated and hence the complexity of the model would be increased significantly. In addition, because of the positive definite constraint, the unknown parameters have to satisfy certain constraints which further complicates the model. We model the marginal spatial process with KL Low <b>Rank</b> <b>Model.</b> Based upon the marginal KL Low <b>Rank</b> <b>Model,</b> a positive definite non-parametric cross covariance function can be specified (see Wang [2011]). There is no constraint on the marginal models to ensure a valid covariance function. The results from simulations and real data analysis show that this model outperforms. ...|$|R
40|$|Online {{learning}} to rank methods aim to optimize <b>ranking</b> <b>models</b> based on user interactions. The dueling bandit gradient descent (DBGD) algorithm {{is able to}} effectively optimize linear <b>ranking</b> <b>models</b> solely from user interactions. We propose an extension of DBGD, called probabilistic multileave gradient descent (P-MGD) that builds on probabilistic multileave, a recently proposed highly sensitive and unbiased online evaluation method. We demonstrate that P-MGD significantly outperforms state-of-the-art online {{learning to}} rank methods in terms of online performance, without sacrificing offline performance and at greater learning speed...|$|R
50|$|A 2014 study {{published}} in Research in Higher Education removed the mystique of the U.S. News ranking process by producing a <b>ranking</b> <b>model</b> that faithfully recreated U.S. News outcomes and quantified the inherent “noise” in the rankings for all nationally ranked universities. The model developed provided detailed insight into the U.S. News ranking process. It allowed the impact of changes to U.S. News subfactors to be studied when variation between universities and within subfactors was present. Numerous simulations were run using this model to understand the amount of change required for a university to improve its rank or move into the top 20. Results show that for a university ranked in the mid-30s {{it would take a}} significant amount of additional resources, directed in a very focused way, to become a top-ranked national university, and that rank changes of up to +/- 4 points should be considered “noise”.|$|E
5000|$|Social search {{may not be}} demonstrably {{better than}} algorithm-driven search. In the {{algorithmic}} <b>ranking</b> <b>model</b> that search engines used in the past, relevance of a site is determined after analyzing the text and content on the page and link structure of the document. In contrast, search results with social search highlight content that was created or touched by other users {{who are in the}} Social Graph of the person conducting a search. It is a personalized search technology with online community filtering to produce highly personalized results. Social search takes many forms, ranging from simple shared bookmarks or tagging of content with descriptive labels to more sophisticated approaches that combine human intelligence with computer algorithms. Depending on the feature-set of a particular search engine, these results may then be saved and added to community search results, further improving the relevance of results for future searches of that keyword. The principle behind social search is that human network oriented results would be more meaningful and relevant for the user, instead of computer algorithms deciding the results for specific queries, [...]|$|E
50|$|Formerly the Draconis Empire, the Empire of Terra (commonly {{known as}} Terran Empire) wishes {{to conquer the}} entire galaxy and rule upon all {{humanity}} by sheer force. Imperator Vlaana Azleea leads the imperial offensive against the NSA. The Terrans boast sheer numerical superiority. The Empire of Terra features two types of combat vehicles. The first are combat hovercrafts called hoverdynes, which are more maneuverable than the NSA terradynes. The second are striders, large bipedal mechs armed with autocannon or missiles. The Empire of Terra also features three defensive turrets: anti-infantry guns, anti-armor cannons and the all-around powerful Pulverizer grand cannons. Imperial units are equipped with energy weapons, which often equal or supersede their opponent's projectile weaponry in terms of damage. The Empire uses a military <b>ranking</b> <b>model</b> {{similar to that of}} the Ancient Rome; their foot soldiers, field commanders and generals are respectively called legionnaires, centurions and imperators. The Empire's use of hoverdynes, energy- or flame-based weapons and the red as their main color is reminiscent of the Order of New Dawn in the original video game. Although the Terran Empire appears throughout the campaign, it is not a playable multiplayer faction.|$|E
40|$|In [12] Lehmann and Magidor study {{a strong}} nonmonotonic, {{so-called}} rational consequence relation, which extends the preferential consequence relation of [10] by also validating {{the rule of}} rational monotonicity. Every rational consequence relation can be semantically represented by a <b>ranked</b> <b>model,</b> and vice versa. To answer for a conditional assertion a→b the question whether it is entailed {{by a set of}} conditional assertions K, it is not sufficient to check if it is derivable by the rules for rational consequence relations, or semantically, to check if it is valid in all <b>ranked</b> <b>models</b> of K, as it can be shown that the intersection of all <b>ranked</b> <b>models</b> does not in general satisfy rational monotonicity. The authors therefore define a semantic selection in order to obtain the so-called rational closure. However, a proof theory for rational closure is missing. This paper will fill the syntactical gap for a finite language by defining an adaptive logic ARCs such that an assertion a→b is derivable from a knowledge base K containing conditional assertions and negated conditional assertions iff it is in the rational closure of K...|$|R
40|$|AbstractRight {{invariant}} metrics (ri-metrics) {{have several}} {{applications in the}} theory of rank correlation methods. For example, <b>ranking</b> <b>models</b> based on ri-metrics generalize Mallow's <b>ranking</b> <b>models.</b> We explore the relationship between right invariant metrics and measures of presortedness (mops). The latter have been used to evaluate the behavior of sorting algorithms on nearly-sorted inputs. We give necessary and sufficient conditions for a measure of presortedness to be extended to a ri-metric; we characterize those ri-metrics that can be used as mops; and we show that those mops that are extendible to ri-metrics can be constructed from sets of sorting operations. Our results provide a paradigm for the construction of mops and ri-metrics...|$|R
40|$|There {{has been}} a recent surge of {{interest}} in studying permutation-based <b>models</b> for <b>ranking</b> from pairwise comparison data. Despite being structurally richer and more robust than parametric <b>ranking</b> <b>models,</b> permutation-based models are less well understood statistically and generally lack efficient learning algorithms. In this work, we study a prototype of permutation-based <b>ranking</b> <b>models,</b> namely, the noisy sorting model. We establish the optimal rates of learning the model under two sampling procedures. Furthermore, we provide a fast algorithm to achieve near-optimal rates if the observations are sampled independently. Along the way, we discover properties of the symmetric group which are of theoretical interest. Comment: 27 pages, 2 figure...|$|R
5000|$|Ye Chunji {{came up with}} a <b>ranking</b> <b>model</b> for consumptionary {{products}} on the local level that could be applied to his county and many others in the empire. At the top of this pyramid was the [...] "greatest" [...] (zui) product, which was grain; this vital item of subsistence was not traded out of the county as a commercial item. Taxes were paid in grain throughout the Ming Dynasty, but as early as 1436 a portion of the grain tax was commuted to payments of silver instead; the 1581 Single Whip Reform of Zhang Juzheng finally assessed land taxes entirely in silver and not in grain. The middle level of importance in Ye's pyramid of county-level consumptionary goods were so-called [...] "great" [...] (zhong) products, which were mulberry, cotton, hemp, and ramie, the essential raw materials for local textile production. The lowest level in Ye's pyramid of goods were the [...] "lesser" [...] (ci) products, which were salt, cloth, vegetable oil, lumber, sugar, fruit, vegetables, fish, and livestock—all of which were traded out of the county by peddlers, itinerant retailers, or merchant wholesalers shipping large amounts of commercial goods.|$|E
40|$|Abstract- An {{adaptation}} {{process is}} described to adapt a <b>ranking</b> <b>model</b> constructed for a broad-based search engine {{for use with}} a domain-specific <b>ranking</b> <b>model.</b> It’s difficult to applying the broad-based <b>ranking</b> <b>model</b> directly to different domains due to domain differences, to build a unique <b>ranking</b> <b>model</b> for each domain it time-consuming for training models. In this paper,we address these difficulties by proposing algorithm called ranking adaptation SVM (RA-SVM), Our algorithm only requires the prediction from the existing ranking models, rather than their internal representations or the data from auxiliary domains The <b>ranking</b> <b>model</b> is adapted {{for use in a}} search environment focusing on a specific segment of online content, for example, a specific topic, media type, or genre of content. a domain-specific <b>ranking</b> <b>model</b> reduces search results to the data from a specific domain that are relevant with respect to the search terms input by the user. The ranking order may be determined with reference to a given numerical score, an ordinal score, or a binary judgment such as “relevant ” or “irrelevant”...|$|E
40|$|Search engines {{train and}} apply a single <b>ranking</b> <b>model</b> across all users, but searchers ’ {{information}} needs are diverse and cover {{a broad range}} of topics. Hence, a single user-independent <b>ranking</b> <b>model</b> is insufficient to satisfy different users ’ result preferences. Conventional personalization methods learn separate models of user interests and use those to re-rank the results from the generic model. Those methods require significant user history information to learn user preferences, have low coverage in the case of memory-based methods that learn direct associations between query-URL pairs, and have limited opportunity to markedly affect the ranking given that they only re-order top-ranked items. In this paper, we propose a general <b>ranking</b> <b>model</b> adaptation framework for personalized search. Using a given userindependent <b>ranking</b> <b>model</b> trained offline and limited number of adaptation queries from individual users, the framework quickly learns to apply a series of linear transformations, e. g., scaling and shifting, over the parameters of the given global <b>ranking</b> <b>model</b> such that the adapted model can better fit each individual user’s search preferences. Extensive experimentation based on a large set of search logs from a major commercial Web search engine confirms the effectiveness of the proposed method compared to several state-of-the-art <b>ranking</b> <b>model</b> adaptation methods...|$|E
40|$|The {{purpose of}} {{extractive}} document summarization is to automatically select {{a number of}} indicative sentences, passages, or paragraphs from the original document according to a target summarization ratio and then sequence them to form a concise summary. In the paper, we present a comparative study of various supervised and unsupervised probabilistic <b>ranking</b> <b>models</b> for spoken document summarization on the Chinese broadcast news. Moreover, we also investigate {{the possibility of using}} unsupervised summarizers to boost the performance of supervised summarizers when manual labels are not available for the training of supervised summarizers. Encouraging results were initially demonstrated. Index Terms — spoken document summarization, extractive summarization, probabilistic <b>ranking</b> <b>models,</b> unsupervised summarizers 1...|$|R
5000|$|Learning to rank or machine-learned ranking (MLR) is the {{application}} of machine learning, typically supervised, semi-supervised or reinforcement learning, {{in the construction of}} <b>ranking</b> <b>models</b> for information retrieval systems. Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. [...] "relevant" [...] or [...] "not relevant") for each item. The <b>ranking</b> <b>model's</b> purpose is to rank, i.e. produce a permutation of items in new, unseen lists in a way which is [...] "similar" [...] to rankings in the training data in some sense.|$|R
50|$|Top <b>ranking</b> <b>models</b> Daphne Groeneveld and Ashleigh Good were {{featured}} on the magazine's April 2013 and May 2013 covers respectively. Soo Joo Park modeled for Numéro Russia's August 2013 cover. Pat Cleveland was {{featured on}} the May 2014 cover.|$|R
40|$|Feature {{design and}} feature {{selection}} are two key problems in facial image based age perception. In this paper, we proposed to using <b>ranking</b> <b>model</b> to do feature selection on the haar-like features. In {{order to build}} the pairwise samples for the <b>ranking</b> <b>model,</b> age sequences are organized by personal aging pattern within each subject. The pairwise samples are extracted from the sequence of each subject. Therefore, the order information is intuitively contained in the pairwise data. <b>Ranking</b> <b>model</b> is used to select the discriminative features based on the pairwise data. The combination of the <b>ranking</b> <b>model</b> and personal aging pattern are powerful to select the discriminative features for age estimation. Based on the selected features, different kinds of regression models are used to build prediction models. The experiment results show the performance of our method {{is comparable to the}} state-of-art works. ...|$|E
30|$|In {{order to}} test the {{proposed}} <b>ranking</b> <b>model,</b> we asked 1048 volunteers who are relatively active in Sina micro-blog to participate in our experiments. The number of their followees ranges from 10 to 1000, and {{the average number of}} newly arrived tweets from their followees per hour is 56. They are asked to give their feedbacks to the chronological and intelligent <b>ranking</b> <b>model</b> by Sina and our proposed <b>ranking</b> <b>model.</b> If a tweet is useful to them, the tweet is marked as true, otherwise false. Their feedbacks are collected five times per day and the time interval between each time is over 2  h. We keep track of their opinions for 1  month.|$|E
40|$|In {{this article}} we analyze {{existence}} web portal ranking methods. New web portal <b>ranking</b> <b>model</b> suggested which calculates ratings for ranking units, such as users or placed articles. Also this method works without administrative user intervention but has possibility to extend ranking units set without changing data collection structure in data base. This <b>ranking</b> <b>model</b> applicable for news web portal and mainly all functional work performs by itself...|$|E
40|$|We {{introduce}} a novel emotion recognition approach which integrates <b>ranking</b> <b>models.</b> The approach is speaker independent, {{yet it is}} designed to exploit information from utterances from the same speaker in the test set before making predictions. It achieves much higher precision in identifying emotional utterances than a conventional SVM classifier. Furthermore we test several possibilities for combining conventional classification and predictions based on ranking. All combinations improve overall prediction accuracy. All experiments are performed on the FAU AIBO database which contains realistic spontaneous emotional speech. Our best combination system achieves 6. 6 % absolute improvement over the Interspeech 2009 emotion challenge baseline system on the 5 -class classification tasks. Index Terms: emotion classification, <b>ranking</b> <b>models,</b> spontaneous speec...|$|R
40|$|Abstract. Information about small genetic {{variations}} in organisms, known as {{single nucleotide polymorphism}} (SNPs), is crucial to identify candidate genes that {{have a role in}} disease susceptibility, a long-standing research goal in biology. While a number of established public SNP databases are available, the specification of effective techniques for SNP analysis remains an open issue. We describe a secondary SNP database that integrates data from multiple public sources, designed to support various experimental <b>ranking</b> <b>models</b> for SNPs. By prioritizing SNPs within large regions of the genome, scientists are able to rapidly narrow their search for candidate genes. In the paper we describe the <b>ranking</b> <b>models,</b> the data integration architecture, and preliminary experimental results. ...|$|R
40|$|The well-studied {{problem of}} {{statistical}} rank aggregation {{has been applied}} to comparing sports teams, information re-trieval, and most recently to data generated by human judg-ment. Such human-generated rankings may be substantially different from traditional statistical ranking data. In this work, we show that a recently proposed generalized random utility model reveals distinctive patterns in human judgment across three different domains, and provides a succinct representa-tion of variance in both population preferences and imperfect perception. In contrast, we also show that classical statisti-cal <b>ranking</b> <b>models</b> fail to capture important features from human-generated input. Our work motivates the use of more flexible <b>ranking</b> <b>models</b> for representing and describing the collective preferences or decision-making of human partici-pants. ...|$|R
40|$|In the market, various domain-specific {{search engines}} emerged, which are {{restricted}} to specific topicalities or document formats, and vertical to the broad-based search. Simply applying the <b>ranking</b> <b>model</b> trained for the broad-based search to the verticals cannot achieve a sound performance due to the domain differences, while building different ranking models for each domain is both laborious for labelling sufficient training samples and time-consuming or the training process. In this paper, to address the above difficulties, we investigate two problems: (1) whether we can adapt the <b>ranking</b> <b>model</b> learned for existing Web page search or verticals, to the new domain, so {{that the amount of}} labelled data and the training cost is reduced, while the performance requirement is still satisfied; and (2) how to adapt the <b>ranking</b> <b>model</b> from auxiliary domains to a new target domain. We address the second problem from the regularization framework and an algorithm called ranking adaptation SVM is proposed. The results demonstrate the applicability’s of the proposed <b>ranking</b> <b>model</b> adaptation algorithm and the ranking adaptability measurement...|$|E
30|$|Therefore, some micro-blogging {{services}} have released new tweets ranking models, aiming to present users the tweets {{that they may}} be willing to see on top, for example, the tweets published by acquaintances or the ones he likes. Some <b>ranking</b> <b>model</b> can even merge the tweets with similar or the same contents, so as to avoid passive flooding, while some <b>ranking</b> <b>model</b> helps users filter tweets according to their followers, tags, and tweet contents.|$|E
40|$|We {{present a}} machine {{learning}} approach {{for the task}} of ranking previously answered questions in a question repository {{with respect to their}} relevance to a new, unanswered reference question. The <b>ranking</b> <b>model</b> is trained on a collection of question groups manually annotated with a partial order relation reflectingtherelativeutilityofquestionsinsideeach group. Based on a set of meaning and structure aware features, the new <b>ranking</b> <b>model</b> is able to substantially outperform more straight-forward, unsupervised similarity measures...|$|E
40|$|In {{different}} fields like decision making, psychology, game theory and biology, {{it has been}} observed that paired-comparison data like preference relations defined by humans and animals can be intransitive. Intransitive relations cannot be modeled with existing machine learning methods like <b>ranking</b> <b>models,</b> because these models exhibit strong transitivity properties. More specifically, in a stochastic context, where often the reciprocity property characterizes probabilistic relations such as choice probabilities, it has been formally shown that <b>ranking</b> <b>models</b> always satisfy the well-known strong stochastic transitivity property. Given this limitation of <b>ranking</b> <b>models,</b> we present a new kernel function that together with the regularized least-squares algorithm is capable of inferring intransitive reciprocal relations in problems where transitivity violations cannot be considered as noise. In this approach it is the kernel function that defines the transition from learning transitive to learning intransitive relations, and the Kronecker-product is introduced for representing the latter type of relations. In addition, we empirically demonstrate on two benchmark problems, one in game theory and one in theoretical biology, that our algorithm outperforms methods not capable of learning intransitive reciprocal relations. Transitivity Reciprocal relations Utility functions Kernel methods Preference learning Decision theory Game theory...|$|R
40|$|Model {{selection}} is often conducted by <b>ranking</b> <b>models</b> by their out-of-sample forecast error. Such criteria only incorporate {{information about the}} expected value, whereas models usually describe the entire probability distribution. Hence, researchers may desire a criteria evaluating {{the performance of the}} entire probability distribution. Such a method is proposed and is found to increase the likelihood of selecting the true model relative to conventional <b>model</b> <b>ranking</b> techniques. Research Methods/ Statistical Methods,...|$|R
40|$|Abstract: This paper {{describes}} our participa-tion in the Federated Web Search {{track at}} TREC 2014. For the resource selection task we employ a learning-to-rank approach to combine various (in-stantiations of) resource <b>ranking</b> <b>models.</b> For the vertical selection task we treat the estimated col-lection relevance scores as binary judgements. ...|$|R
40|$|With {{the growth}} of {{different}} search engines, itbecomes difficult for an user to search particular informationeffectively. If a search engine could provide domain specificinformation such as that confines only to a particulartopicality, it {{is referred to as}} domain specific engine. Applyingthe <b>ranking</b> <b>model</b> trained for broad-based search to adomain specific search does not achieve good performancebecause of domain differences. Building a different rankingmodel for each domain is laborious and time consuming. Inthis paper, the <b>ranking</b> <b>model</b> used in broad-based search isadapted to domain specific search. An algorithm calledRanking Adaptation SVM is used to effectively adapt aranking model to a target domain. Such an adaptation hasadvantages since it needs only the predictions from existingranking models. Ranking Adaptability measurement is usedto quantitatively estimate whether a <b>ranking</b> <b>model</b> can beadapted to new domain...|$|E
40|$|Retrieval {{effectiveness}} of temporal queries {{can be improved}} by {{taking into account the}} time dimension. Existing temporal ranking models follow one of two main approaches: 1) a mixture model linearly combining textual similarity and temporal similarity, and 2) a probabilistic model generating a query from the textual and temporal part of document independently. In this paper, we propose a novel time-aware <b>ranking</b> <b>model</b> based on learning-to-rank techniques. We employ two classes of features for learning a <b>ranking</b> <b>model,</b> entity-based and temporal features, which are derived from annotation data. Entity-based features are aimed at capturing the semantic similarity between a query and a document, whereas temporal features measure the temporal similarity. Through extensive experiments we show that our <b>ranking</b> <b>model</b> significantly improves the retrieval effectiveness over existing time-aware ranking models...|$|E
40|$|Query {{performance}} {{prediction is}} aimed at predicting the retrieval effectiveness that a query will achieve {{with respect to a}} particular <b>ranking</b> <b>model.</b> In this paper, we study query performance prediction for a <b>ranking</b> <b>model</b> that explicitly incorporates the time dimension into ranking. Different time-based predictors are proposed as analogous to existing keyword-based predictors. In order to improve predicting performance, we combine different predictors using linear regression and neural networks. Extensive experiments are conducted using queries and relevance judgments obtained by crowdsourcing...|$|E
40|$|Incorporating {{features}} {{extracted from}} clickthrough data (called clickthrough features) {{has been demonstrated}} to significantly improve the performance of <b>ranking</b> <b>models</b> for Web search applications. Such benefits, however, are severely limited by the data sparseness problem, i. e., many queries and documents have no or very few clicks. The ranker thus cannot rely strongly on clickthrough features for document ranking. This paper presents two smoothing methods to expand clickthrough data: query clustering via Random Walk on click graphs and a discounting method inspired by the Good-Turing estimator. Both methods are evaluated on real-world data in three Web search domains. Experimental {{results show that the}} <b>ranking</b> <b>models</b> trained on smoothed clickthrough features consistently outperform those trained on unsmoothed features. This study demonstrates both the importance and the benefits of dealing with the sparseness problem in clickthrough data...|$|R
40|$|Machine-learned ranking {{techniques}} automatically learn {{a complex}} document ranking function given training data. These techniques {{have demonstrated the}} effectiveness and flexibility required of a commercial web search. However, manually labeled training data (with multiple absolute grades) has become the bottleneck for training a quality ranking function, particularly for a new domain. In this paper, we explore the adaptation of machine-learned <b>ranking</b> <b>models</b> across a set of geographically diverse markets with the market-specific pairwise preference data, which can be easily obtained from clickthrough logs. We propose a novel adaptation algorithm, Pairwise-Trada, which is able to adapt <b>ranking</b> <b>models</b> that are trained with multi-grade labeled training data to the target market using the target-market-specific pairwise preference data. We present results demonstrating the efficacy of our technique {{on a set of}} commercial search engine data. ...|$|R
40|$|Modelling {{survival}} data from long-term follow-up studies presents challenges. The commonly used {{proportional hazards model}} should be extended to account for dynamic behaviour {{of the effects of}} fixed covariates. This work illustrates the use of reduced <b>rank</b> <b>models</b> in {{survival data}}, where some of the covariate effects are allowed to behave dynamically in time and some as fixed. Time-varying effects of the covariates can be fitted by using interactions of the fixed covariates with flexible transformations of time based on b-splines. To avoid overfitting, a reduced <b>rank</b> <b>model</b> will restrict the number of parameters, resulting in a more sensible fit to the data. This work presents the basic theory and the algorithm to fit such models. An application to breast cancer data is used for illustration of the suggested methods. © 2013...|$|R
