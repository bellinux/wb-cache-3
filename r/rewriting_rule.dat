83|2396|Public
25|$|For the untyped lambda calculus, β-reduction as a <b>rewriting</b> <b>rule</b> {{is neither}} {{strongly}} normalising nor weakly normalising.|$|E
2500|$|BioNetGen is a {{software}} suite that provides both specification and simulation capacities. Rule-based models {{can be written}} down using a specified syntax, the BioNetGen language (BNGL). [...] The underlying concept is to represent biochemical systems as graphs, where molecules are represented as nodes (or collections of nodes) and chemical bonds as edges. A reaction rule, then, corresponds to a graph <b>rewriting</b> <b>rule.</b> BNGL provides a syntax for specifying these graphs and the associated rules as structured strings. BioNetGen can then use these rules to generate ordinary differential equations (ODEs) to describe each biochemical reaction. Alternatively, it can generate {{a list of all}} possible species and reactions in SBML, which can then be exported to simulation software packages that can read SBML. [...] One can also make use of BioNetGen's own ODE-based simulation software and its capability to generate reactions on-the-fly during a stochastic simulation. In addition, a model specified in BNGL can be read by other simulation software, such as DYNSTOC, RuleMonkey, and NFSim.|$|E
5000|$|Next, the Variable <b>Rewriting</b> <b>Rule</b> {{transforms}} pronouns and anaphors into variables at LF: ...|$|E
40|$|Graphical <b>rewrite</b> <b>rules,</b> {{as a form}} of {{end-user}} programming, {{suffer from}} their implicit underlying model. Interpretation of <b>rewrite</b> <b>rules</b> limited to syntactic properties makes it laborious for end users to define non-trivial behavior. Semantically enriched graphical <b>rewrite</b> <b>rules</b> have increased expressiveness, resulting in a significantly reduced number of <b>rewrite</b> <b>rules.</b> This reduction is essential in order to keep rewrite rule-based programming approaches feasible for end-user programming. The extension of the <b>rewrite</b> <b>rule</b> model with semantics not only benefits the definition of behavior but additionally it supports the entire visual programming process. Specifically the benefits include support for defining object look, laying out scenes consisting of dependent objects, defining behavior with a reduced number of <b>rewrite</b> <b>rules,</b> and reusing existing behaviors via <b>rewrite</b> <b>rule</b> analogies. These benefits are described {{in the context of the}} Agentsheets programming substrate...|$|R
5000|$|This module {{introduces}} two new sorts, {{and a set}} of <b>rewrite</b> <b>rules.</b> We {{also include}} our previous module, to illustrate how equations and <b>rewrite</b> <b>rules</b> differ. The <b>rewrite</b> <b>rules</b> is thought of as a set of legal state changes, so while equations hold the same meaning {{on both sides of the}} equality sign, <b>rewrite</b> <b>rules</b> do not (<b>rewrite</b> <b>rules</b> use a => token instead of an equality sign). You are still the same person after you're married (this is open for debate), but something has changed, your marital status at least. So this is illustrated by a <b>rewrite</b> <b>rule,</b> not an equation. <b>Rewrite</b> <b>rules</b> do not have to be confluent and terminating so it does matter a great deal what rules are chosen to rewrite the term. The rules are applied at [...] "random" [...] by the Maude system, meaning that you can not be sure that one rule is applied before another rule and so on. If an equation can be applied to the term, it will always be applied before any <b>rewrite</b> <b>rule.</b>|$|R
30|$|The {{creation}} of the set of <b>rewrite</b> <b>rules</b> is an essential step in the reduction algorithm. With the <b>rewrite</b> <b>rules,</b> the original graph {{can be obtained from}} the reduced graph. Therefore, <b>rewrite</b> <b>rules</b> guarantee no loss of information, and so the reduction process is reversible.|$|R
5000|$|Some {{rewriting}} rules sometimes {{increase and}} sometimes decrease {{the size of}} the expressions to which they are applied. This is the case of distributivity or trigonometric identities. For example, the distributivity law allows rewriting [...] and [...] As {{there is no way to}} make a good general choice of applying or not such a <b>rewriting</b> <b>rule,</b> such rewritings are done only when explicitly asked for by the user. For the distributivity, the computer function that apply this <b>rewriting</b> <b>rule</b> is generally called [...] "expand". The reverse <b>rewriting</b> <b>rule,</b> called [...] "factor", requires a non-trivial algorithm, which is thus a key function in computer algebra systems (see Polynomial factorization).|$|E
50|$|Variable <b>Rewriting</b> <b>Rule</b> 20.i) John (x visits x’s children) and Bill does VP∅ too.|$|E
50|$|For the untyped lambda calculus, β-reduction as a <b>rewriting</b> <b>rule</b> {{is neither}} {{strongly}} normalising nor weakly normalising.|$|E
5000|$|This {{simplification}} {{is normally}} done through <b>rewriting</b> <b>rules.</b> There are several classes of <b>rewriting</b> <b>rules</b> {{that have to}} be considered. The simplest consists in the <b>rewriting</b> <b>rules</b> that always reduce the size of the expression, like [...] or [...] They are systematically applied in the computer algebra systems.|$|R
50|$|To {{make this}} rewrite theory {{a bit less}} morbid, we can alter some of our <b>rewrite</b> <b>rules</b> a bit, and make them {{conditional}} <b>rewrite</b> <b>rules,</b> which basically means they have to fulfill some criteria {{to be applied to}} the term (other than just matching the left hand side of the <b>rewrite</b> <b>rule).</b>|$|R
40|$|Context-dependent <b>rewrite</b> <b>rules</b> {{are used}} {{in many areas of}} natural {{language}} and speech processing. Work in computational phonology has demonstrated that, given certain conditions, such <b>rewrite</b> <b>rules</b> can be represented as finite-state transducers (FSTs). We describe a new algorithm for compiling <b>rewrite</b> <b>rules</b> into FSTs. We show the algorithm to be simpler and more efficient than existing algorithms. Further, man...|$|R
5000|$|... is {{a binary}} {{relation}} on strings from , i.e., [...] Each element [...] {{is called a}} (<b>rewriting)</b> <b>rule</b> and is usually written [...]|$|E
50|$|As we see, the anaphors {{have been}} co-indexed to their {{respective}} NPs. Lastly, The Variable <b>Rewriting</b> <b>Rule</b> replaces pronouns and anaphors with variables in Logical Form.|$|E
50|$|Due to {{the fact}} the pronoun his is already co-indexed with John, {{and it was not}} rewritten as a {{variable}} before being copied into the elided VP, there is no way for it to be bound by Bill. Therefore, the strict reading is thus derived by omitting the Variable <b>Rewriting</b> <b>Rule.</b>|$|E
5000|$|Changes to ASTs can be {{accomplished}} by both procedural methods coded in PARLANSE and source-to-source tree transformations coded as <b>rewrite</b> <b>rules</b> using surface-syntax conditioned by any extracted program facts, using DMS's Rule Specification Language (RSL). The <b>rewrite</b> <b>rule</b> engine supporting RSL handles associative and commutative <b>rules.</b> A <b>rewrite</b> <b>rule</b> for C to replace a complex condition by the [...] operator be written as: ...|$|R
40|$|Unfailing {{completion}} is {{a commonly}} used technique for equational reasoning. For equational problems with associative and commutative functions, unfailing completion often generates {{a large number}} of <b>rewrite</b> <b>rules.</b> By comparing it with a ground completion procedure, we show that many of the <b>rewrite</b> <b>rules</b> generated are redundant. A set of consistency constraints is formulated to detect redundant <b>rewrite</b> <b>rules.</b> We propose a new completion algorithm, consistent unfailing completion, in which only consistent <b>rewrite</b> <b>rules</b> are used for critical pair generation and rewriting. Our approach does not need to use flattened terms. Thus it avoids the double exponential worst case complexity of AC unification. It also allows the use of more flexible termination orderings. We present some sufficient conditions for detecting inconsistent <b>rewrite</b> <b>rules.</b> The proposed algorithm is implemented in PROLOG. ...|$|R
40|$|Program {{transformation}} {{through the}} repeated application of simple <b>rewrite</b> <b>rules</b> {{is conducive to}} formal verification. However, when dealing with complex program structures, situations arise where data needs to be moved between two or more structurally unrelated portions of a program. In these cases it becomes necessary to construct a set of first-order <b>rewrite</b> <b>rules</b> that share data. Sharing of data often requires the construction of intermediate values such as lists, accompanying lookup functions, and rule parameterization. This increases the complexity of <b>rewrite</b> <b>rules</b> and their verification. In this article we explore the use of higherorder <b>rewrite</b> <b>rules</b> as the mechanism for moving data throughout a program structure. The effectiveness of higher-order <b>rewrite</b> <b>rules</b> is demonstrated by showing {{how they can be}} used to perform field distribution within the Java class loader. ...|$|R
50|$|In Sag’s approach, VP Ellipsis is {{analyzed}} as a deletion {{that takes}} place in between S-structure (Shallow Structure) and PF (Surface Structure). It is claimed that the deleted VP is recoverable at the level of LF due to alphabetic variance holding between two λ-expressions. In this deletion approach, the sloppy identity is made possible, first, by the indexing of anaphors, and then by the application of a variable <b>rewriting</b> <b>rule.</b>|$|E
5000|$|In {{contrast}} a graph <b>rewriting</b> <b>rule</b> of the SPO {{approach is}} a single morphism {{in the category of}} labeled multigraphs and partial mappings that preserve the multigraph structure: [...] Thus a rewriting step is defined by a single pushout diagram. Practical understanding of this is similar to the DPO approach. The difference is, that there is no interface between the host graph G and the graph G being the result of the rewriting step.|$|E
50|$|Yet another {{approach}} to graph rewriting, known as determinate graph rewriting, {{came out of}} logic and database theory. In this approach, graphs are treated as database instances, and rewriting operations as a mechanism for defining queries and views; therefore, all rewriting is required to yield unique results (up to isomorphism), and this is achieved by applying any <b>rewriting</b> <b>rule</b> concurrently throughout the graph, wherever it applies, {{in such a way}} that the result is indeed uniquely defined.|$|E
40|$|The ZX-calculus is a {{graphical}} {{language for}} quantum processes with built-in <b>rewrite</b> <b>rules.</b> The <b>rewrite</b> <b>rules</b> allow equalities to be derived entirely graphically, {{leading to the}} question of completeness: can any equality that is derivable using matrices also be derived graphically? The ZX-calculus is known to be complete for scalar-free pure qubit stabilizer quantum mechanics, meaning any equality between two pure stabilizer operators that is true up to a non-zero scalar factor can be derived using the graphical <b>rewrite</b> <b>rules.</b> Here, we replace those scalar-free <b>rewrite</b> <b>rules</b> with correctly scaled ones and show that, by adding one new diagram element and a new <b>rewrite</b> <b>rule,</b> the calculus can be made complete for pure qubit stabilizer quantum mechanics with scalars. This completeness property allows amplitudes and probabilities to be calculated entirely graphically. We also explicitly consider stabilizer zero diagrams, i. e. diagrams that represent a zero matrix, and show that two new <b>rewrite</b> <b>rules</b> suffice to make the calculus complete for those. Comment: In Proceedings QPL 2015, arXiv: 1511. 0118...|$|R
5000|$|... is {{a finite}} {{relation}} from [...] to [...] such that [...] The members of [...] {{are called the}} (<b>rewrite)</b> <b>rules</b> or productions of the grammar. There are three kinds of <b>rewrite</b> <b>rules.</b> For , [...] and ...|$|R
40|$|This paper defines and {{presents}} {{a method of}} inheritance for structures that are defined by <b>rewrite</b> <b>rules.</b> This method is natural {{in the sense that}} it can be easily and cleanly implemented in <b>rewrite</b> <b>rules</b> themselves. This framework of inheritance is not that of classical Object-Oriented Programming. It is shown that this inheritance has particular application to structures implemented in <b>rewrite</b> <b>rules</b> and, more generally, to symbolic computation. The treatment is practical, and examples are presented in Mathematica for concreteness. 1 Introduction An algebraic specification is a way of describing an abstract data type in an implementation independent way. Throughout this paper, an implementation of an algebraic specification or an abstract structure in terms of a system of <b>rewrite</b> <b>rules</b> will be called a symbolic specification. So a symbolic specification is a set of <b>rewrite</b> <b>rules</b> describing how to manipulate symbols in keeping with some algebraic specification or abstract structure [...] ...|$|R
5000|$|In his {{approach}} to the sloppy identity problem, Williams (1977) adopts the Derived VP Rule as well. He also suggests that anaphors and pronouns are rewritten as variables at LF by a Variable <b>Rewriting</b> <b>Rule.</b> Afterwards, by using the VP Rule, these variables are then copied into the elided VP. Following t{{his approach}}, both the sloppy and strict readings are possible. The following examples will go through the derivation of sentence 18.i) as a sloppy reading: ...|$|E
5000|$|If {{the input}} proof {{is not a}} tree (in general, {{resolution}} graphs are directed acyclic graphs), then the clause [...] of a context {{may be involved in}} more than one resolution step. In this case, to ensure that an application of a <b>rewriting</b> <b>rule</b> is not going to interfere with other resolution steps, a safe solution is to create a copy of the node represented by clause [...] This solution increases proof size and some caution is needed when doing this.|$|E
50|$|The main {{difference}} between the sloppy and the strict reading lies in the Variable <b>Rewriting</b> <b>Rule.</b> The presence of this rule allows for a sloppy reading because variables are bound by the lambda operator within the same VP. By converting the pronoun his in 20.i) into a variable, and once the VP is copied into the elided VP in sentence 21.i), the variable in the elided VP is then able to be bound by Bill. Therefore, in order to derive the strict reading, this step is simply omitted.|$|E
40|$|Planning by Rewriting (PbR) {{is a new}} {{paradigm}} for efficient high-quality planning that exploits plan <b>rewriting</b> <b>rules</b> and e#cient local search techniques to transform an easy-to-generate, but possibly suboptimal, initial plan into a high-quality plan. Despite the advantages of PbR in terms of scalability, plan quality, and anytime behavior, PbR requires the user to define a set of domain-specific plan <b>rewriting</b> <b>rules</b> which can be di#cult and time-consuming. This paper presents an approach to automatically learning the plan <b>rewriting</b> <b>rules</b> based on comparing initial and optimal plans. We report results for several planning domains showing that the learned rules are competitive with manually-specified ones, and in several cases the learning algorithm discovered novel <b>rewriting</b> <b>rules...</b>|$|R
40|$|Abstract. Deduction modulo is a {{framework}} in which theories are inte-grated into proof systems such as natural deduction or sequent calculus by presenting them using <b>rewriting</b> <b>rules.</b> When only terms are rewritten, cut admissibility in those systems {{is equivalent to the}} confluence of the rewriting system, as shown by Dowek, RTA 2003, LNCS 2706. This is no longer true when considering <b>rewriting</b> <b>rules</b> involving propositions. In this paper, we show that, {{in the same way that}} it is possible to recover confluence using Knuth-Bendix completion, one can regain cut admis-sibility in the general case using standard saturation techniques. This work relies on a view of proposition <b>rewriting</b> <b>rules</b> as oriented clauses, like term <b>rewriting</b> <b>rules</b> can be seen as oriented equations. This also leads us to introduce an extension of deduction modulo with conditional term <b>rewriting</b> <b>rules.</b> Whatever their origin, proofs rarely need to be search for without context: Program verification requires arithmetic, theories of lists or arrays, etc. Mathe...|$|R
3000|$|<b>Rewriting</b> <b>rules</b> simplify {{functions}} {{prior to}} their evaluation and speed up the search. <b>Rewriting</b> <b>rules</b> are rudimentary representations of DSP theorems. Unlike heuristics, they are not used by the genetic algorithm to favor combinations, but they do impact the search by [...]...|$|R
5000|$|Their {{claim was}} disputed by staff of Conxion, the ISP hosting the conference website, who {{deployed}} a URL <b>rewriting</b> <b>rule</b> to redirect attack traffic {{to the attack}} page itself. It was claimed that this counter-attack [...] "crashed" [...] the Ehippies' server within seconds, forcing them {{to move to another}} ISP. The majority of hits to the Ehippies' site were thus their own attack page attacking itself. Conxion claimed to have logged fewer than 10,000 unique-source IP addresses. The attack page consisted of nine frames, three attacking the San Jose conference server, three against the Virginia server and three against the main WTO server. The Chicago conference server was not attacked and remained entirely unaffected. However, the WTO main website server, hosted by another provider, did not benefit from the rewrite-engine fix and did suffer significantly from the DOS attack.|$|E
5000|$|BioNetGen is a {{software}} suite that provides both specification and simulation capacities. Rule-based models {{can be written}} down using a specified syntax, the BioNetGen language (BNGL). [...] The underlying concept is to represent biochemical systems as graphs, where molecules are represented as nodes (or collections of nodes) and chemical bonds as edges. A reaction rule, then, corresponds to a graph <b>rewriting</b> <b>rule.</b> BNGL provides a syntax for specifying these graphs and the associated rules as structured strings. BioNetGen can then use these rules to generate ordinary differential equations (ODEs) to describe each biochemical reaction. Alternatively, it can generate {{a list of all}} possible species and reactions in SBML, which can then be exported to simulation software packages that can read SBML. One can also make use of BioNetGen's own ODE-based simulation software and its capability to generate reactions on-the-fly during a stochastic simulation. In addition, a model specified in BNGL can be read by other simulation software, such as DYNSTOC, RuleMonkey, and NFSim.|$|E
5000|$|From the {{perspective}} of the DPO approach a graph <b>rewriting</b> <b>rule</b> is a pair of morphisms in the category of graphs and graph homomorphisms between them: [...] (or [...] ) where [...] is injective. The graph K is called invariant or sometimes the gluing graph. A rewriting step or application of a rule r to a host graph G is defined by two pushout diagrams both originating in the same morphism , where D is a context graph (this is where the name double-pushout comes from). Another graph morphism [...] models an occurrence of L in G and is called a match. Practical understanding of this is that [...] is a subgraph that is matched from [...] (see subgraph isomorphism problem), and after a match is found, [...] is replaced with [...] in host graph [...] where [...] serves as an interface, containing the nodes and edges which are preserved when applying the rule. The graph [...] is needed to attach the pattern being matched to its context: if it is empty, the match can only designate a whole connected component of the graph [...]|$|E
40|$|Abstract. Deduction modulo is a {{powerful}} way to replace axioms by <b>rewrite</b> <b>rules</b> and allows to integrate computation in deduction. But adding <b>rewrite</b> <b>rules</b> is not always safe for properties of the deduction system such as consistency or cut elimination. Proving completeness of the cut-free calculus with respect to semantical models {{is a way to}} prove the redundancy of the cut rule. The result obtained this way is slightly weaker than that obtained with a normalization proof, but more general, and the proof is much simpler. We here give some conditions on <b>rewrite</b> <b>rules</b> and present the results and techniques that lead to the cut elimina-tion theorem for the classical sequent calculus modulo. At last, we give a <b>rewrite</b> <b>rule</b> featuring cut-elimination, but non-normalizing...|$|R
40|$|Abstract. We present {{constructive}} arithmetic in Deduction modulo with <b>rewrite</b> <b>rules</b> only. In {{natural deduction}} and in sequent calculus, the cut elimination theoremand {{the analysis of}} the structure of cut free proofs is the key to many results about predicate logic with no axioms: analyticity and non-provability results,completeness results for proof search algorithms, decidability results for fragments, constructivity results for the intuitionistic case [...] . Unfortunately, the properties of cut free proofs do not extend in the presenceof axioms and the cut elimination theorem is not as powerful in this case as it is in pure logic. This motivates the extension of the notion of cut for variousaxiomatic theories such as arithmetic, Church's simple type theory, set theory and others. In general, we can say that a new axiom will necessitate a specificextension of the notion of cut: there still is no notion of cut general enough to be applied to any axiomatic theory. Deduction modulo [2, 3] is one attempt, amongothers, towards this aim. In deduction modulo, a theory is not a set of axioms but a set of axiomscombined with a set of <b>rewrite</b> <b>rules.</b> For instance, the axiom 8 x x + 0 = xcan be replaced by the <b>rewrite</b> <b>rule</b> x + 0 -! x. The point is that replacingthe axiom by the <b>rewrite</b> <b>rule</b> introduces short-cuts in the corresponding proofs, which avoid axiomatic cuts. When the set of <b>rewrite</b> <b>rules</b> is empty, one is simplyback to regular predicate logic. On the other hand, when the set of axioms is empty we have theories expressed by <b>rewrite</b> <b>rules</b> only. For such theories, cutfree proofs are similar to cut free proofs in pure logic, in particular they end with an introduction rule. Thus, when a theory can be expressed in deduction modulowith <b>rewrite</b> <b>rules</b> only and, in addition, cuts can be eliminated modulo these <b>rewrite</b> <b>rules,</b> the theory has most of the properties of pure logic. This leads tothe question of which theories can be expressed with <b>rewrite</b> <b>rules</b> only {{in such a way that}} cut-elimination holds...|$|R
30|$|Axiomatizations {{can give}} rise to TRSs that are not weakly confluent, which can be {{remedied}} by Knuth–Bendix completion (Knuth and Bendix 1970). It determines overlaps in left hand sides of <b>rewrite</b> <b>rules,</b> and introduces extra <b>rewrite</b> <b>rules</b> to join the resulting right hand sides, which are called critical pairs.|$|R
