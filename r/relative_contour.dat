2|47|Public
40|$|In a retinal image, {{contours}} {{belonging to}} a figure of interest may be intermixed with other contours (caused by occlusion, camouflage, low contrast, etc.), making difficult the identification of figure contours and thus the figure itself. In psychophysical experiments, we found that identification of a figure is facilitated by: differences in <b>relative</b> <b>contour</b> orientation, <b>relative</b> <b>contour</b> curvature, and <b>relative</b> <b>contour</b> length between contours that belong to the figure {{and those that do}} not. In short, a difference in any contour property seems to facilitate correct identification of a figure. A computational model, based on the exponential pyramid architecture, was constructed and model simulations of several conditions from the psychophysical experiments were performed. A critical aspect of the model is that it performs contour classification by using statistics computed from the entire image. Model simulations accounted well for the results of 11 experimental conditions, using just one free parameter. These results suggest that the human observer uses global features to make local contour classification decisions in the image and that the exponential pyramid architecture can adequately model perceptual mechanisms involved in figure-ground segregation...|$|E
40|$|In this work, {{we report}} {{experimental}} and computational evidences for the intercalation into the DNA base pairs {{of the free}} quinones Quinizarin (Q), Naphthazain (N) and the interstrad covalent binding of their p-cymene di-Ruthenium(II) complexes (Cl 2 Ru 2 X, with X = N, Q bridging ligands). The intercalation extent for the N complex was larger than for Q, in good agreement with higher <b>relative</b> <b>contour</b> length and melting temperature for the same CX/CDNA ratio and with the computacional mean stacking distances {{between the ligand and}} the nearest base-pair (3. 34 Å and 3. 19 Å) for N and Q, respectively. However, the apparent binding constant of Q/DNA, two orders higher than that of N/DNA, denotes that the thermal stability of X/DNA complex is more related to the degree of intercalation than to the binding constants magnitude. Cl 2 Ru 2 X complexes undergo aquation, forming the aqua-derivatives [(H 2 O) 2 Ru 2 X] 2 +. These can further bind covalently to DNA via interstrand crosslinking, through both Ru centres and two N 7 sites of consecutive Guanines, to give (DNA 1, 2) Ru 2 X complexes, by a mechanism similar to that of cisplatin. To the best of our knowledge, this type of interaction with dinuclear Ru(II) complexes has not been reported hitherto. The experimental and computational results reveal that the number of rings of the aromatic moiety and the covalent binding to DNA {{play a key role in}} the behaviour of the quinones and their Ru(II) derivatives. The cytotoxicity of the ligands and the corresponding Ru(II) complexes was evaluated in the MCF- 7, A 2780, A 2780 cis tumour cells and in the healthy cell line MRC- 5. The cytotoxic activity was notable for the N compound and negligible for Q. The IC 50 values and the resistance (RF) and selectivity (SF) factors show that the Cl 2 Ru 2 N complex is the most promising among the four studied anticancer drugs...|$|E
5000|$|... #Caption: <b>Relative</b> fundamental-frequency <b>contours</b> for six Cantonese tones with {{examples}} and Jyutping/Yale tone numbers (modified from [...] ) ...|$|R
40|$|A {{method for}} the {{solution}} of the incompressible nonviscous flow through a centrifugal impeller, including the inlet region, is presented. Several numerical solutions are obtained for four weight flows through an impeller at one operating speed. These solutions are refined in the leading-edge region. The results are presented in a series of figures showing streamlines and <b>relative</b> velocity <b>contours.</b> A comparison is made with the results obtained by using a rapid approximate method of analysis...|$|R
40|$|Introduction In {{pernicious anemia}} besides the {{presence}} of megaloblasts in the bone marrow, changes in myeloid series were seen; being the most evident among the metamyelocyte. The {{aim of this study}} was to perform the quantification of metamyelocyte of the bone marrow in pernicious anemia. Material and methods Between 2000 - 2006 in the Clinic of Hematology-Niš, 68 patients with pernicious anemia were examined and 30 with dyspeptic syndrome (control group). The group of patients with pernicious anemia in relation to pathohistologic changes of gastric mucosa was divided into three sub-groups. Morphometrical analysis of metamyelocyte of the bone marrow was carried out by the application of the double netlike system (B 100). The following parameters were used: <b>relative</b> surface, <b>contour</b> length, absolute surface of nucleus and cytoplasm, absolute contour nucleus and cytoplasm density, shaped nucleus and cytoplasmic factor and nuclear-cytoplasmatic ratio of meta- myelocytes. Results <b>Relative</b> surface, <b>contour</b> length, absolute surface and contour density of nucleus and cytoplasm of metamyelocytes increased simultaneously with the degree of atrophic gastritis. Shaped nucleus and cytoplasmic factor and nuclear-cytoplasmatic ratio of metamyelocytes decreased in all examined groups in relation to the control group. Conclusion Not only are bone marrow erythroid elements scoped with megaloblastic changes but the changes on the level of leukocyte cells as well. The result of this is the phenomena of giant metamyelocytes...|$|R
30|$|This map (Fig.  9) shows more <b>relative</b> regular <b>contour</b> {{lines with}} local {{features}} of different trends and amplitudes. As this map shows a downward-continued picture, {{it is clear}} that as we approaching the basement surface, so the magnetic effect will get bigger (in its positivity and negativity). Therefore, the middle portion of the study area shows relative high magnetic values (up to + 750  gammas at the eastern part), while also the negativity increased {{in the northern part of}} the study area down to − 250 gammas). The many localized features, in some localities, are signs that the basement surface still not reached yet. Sharper contour gradients can be seen especially at the southern half of the study area. Such gradients illustrate the presence of sharp contacts between the subsurface causative features. These contacts are most likely of fracturing effect.|$|R
30|$|To {{further reduce}} the {{computational}} costs {{and to improve}} {{the performance of the}} lattice structures,an LRDM method is presented. First, the SIMP method is used to gain a topology optimization result at the macroscopic scale. The <b>relative</b> density <b>contour</b> is then extracted using the density contour approach and a triangular mesh is generated using a mesh generation algorithm. Finally, a new mapping relationship between the local relative densities and local finite element mesh (FEM) is established to generate the lattice structures. The rest of this paper is organized as follows. We first describe a mesh generating process in Section  2. In Section  3, we present the LRDM method, and in Section  4, some case studies are used to verify the effectiveness and efficiency of the proposed method. The conclusions drawn are presented in the final section.|$|R
40|$|Abstract: The {{objective}} {{of this study is}} investigating the impact of synthetic jet on the boundary layer and optimising the slot yaw angle (). A rectangular synthetic jet with yaw angle relative to freestream is applied for flat plate boundary layer control. Various slot yaw angles are applied to find optimized amount and their impacts on the boundary layer are measured using a boundary layer probe with 2 -D traversing system. The slot yaw angles are varied from 0 °~ 90 °. The assessment carried out using non-dimensional velocity profiles and lateral <b>relative</b> velocity (u/U) <b>contours...</b>|$|R
40|$|Hydrological {{models are}} the basis of {{operational}} flood-forecasting systems. The accuracy of these models {{is strongly dependent on}} {{the quality and quantity of}} the input information represented by rainfall height. Finer space-time rainfall resolution results in more accurate hazard forecasting. In this framework, an optimum raingauge network is essential in predicting flood events. This paper develops an entropy-based approach to evaluate the maximum information content achievable by a rainfall network for different sampling time intervals. The procedure is based on the determination of the coefficients of transferred and nontransferred information and on the <b>relative</b> isoinformation <b>contours.</b> The nontransferred information value achieved by the whole network is strictly dependent on the sampling time intervals considered. An empirical curve is defined, to assess the objective of the research: the nontransferred information value is plotted versus the associated sampling time on a semi-log scale. The curve has a linear trend. In this paper, the methodology is applied to the high-density raingauge network of the urban area of Rome...|$|R
40|$|Part 3 : Biometrics and Biometrics ApplicationsInternational audienceDental {{signature}} captures {{information about}} teeth, including tooth <b>contours,</b> <b>relative</b> positions of neighboring teeth, and {{shapes of the}} dental work. However, this is complicated as dental features change with time. In this paper, we proposed a new, safe and low cost dental biometric technique based on RGB images. It uses three phases: image acquisition with noise removal, segmentation and feature extraction. The key issue that makes our approach distinct is that the features are extracted mainly from incisor teeth only. Thus the proposed solution is low cost besides being safe for human...|$|R
40|$|The {{long-term}} {{evolution of}} initially Gaussian eddies is studied in a reduced-gravity shallow-water model using both linear and nonlinear quasigeostrophic theory {{in an attempt}} to understand westward-propagating mesoscale eddies observed and tracked by satellite altimetry. By examining both isolated eddies and a large basin seeded with eddies with statistical characteristics consistent with those of observed eddies, it is shown that long-term eddy coherence and the zonal wavenumber–frequency power spectral density are best matched by the nonlinear model. Individual characteristics of the eddies including amplitude decay, horizontal length scale decay, and zonal and meridional propagation speed of a previously unrecognized quasi-stable state are examined. The results show that the meridional deflections from purely westward flow (poleward for cyclones and equatorward for anticyclones) are consistent with satellite observations. Examination of the fluid transport properties of the eddies shows that an inner core of the eddy, defined by the zero <b>relative</b> vorticity <b>contour,</b> contains only fluid from the eddy origin, whereas a surrounding outer ring contains a mixture of ambient fluid from throughout the eddy’s lifetime...|$|R
40|$|Finding {{an optimal}} phase pattern in a multidimensional {{solution}} landscape becomes easier and faster if local optima are suppressed and contour lines are tailored towards closed convex patterns. Using wideband {{second harmonic generation}} as a coherent control test case, we show that a linear combination of spectral phase basis functions can result in such improvements and also in separable phase terms, each {{of which can be}} found independently. The improved shapes are attributed to a suppressed nonlinear shear, changing the <b>relative</b> orientation of <b>contour</b> lines. The first order approximation of the process shows a simple relation between input and output phase profiles, useful for pulse shaping at ultraviolet wavelengths...|$|R
40|$|AbstractThe {{properties}} of a discrete Wiener-Hopf equation {{are closely related}} to the factorization of the symbol of the equation. We give a necessary and sufficient condition for existence of a canonical Wiener-Hopf factorization of a possibly nonregular rational matrix function W <b>relative</b> to a <b>contour</b> which is a positively oriented boundary of a region in the finite complex plane. The condition involves decomposition of the state space in a minimal realization of W and, if it is satisfied, we give explicit formulas for the factors. The results are generalized by means of centered realizations to arbitrary rational matrix functions. The proposed approach can be used to solve discrete Wiener-Hopf equations whose symbols are rational matrix functions which admit canonical factorization relative to the unit circle...|$|R
40|$|AbstractStudy on {{motion and}} {{deposition}} characteristics of particles in a wind tunnel {{is important for}} understanding particle transfer in ventilation duct flows. Firstly, polydisperse particles with smaller mean diameter were taken as tracers for airflow velocity test in the wind tunnel under ventilation case and airflow velocities were measured by a Particle Image Velocimetry (PIV) system. Then, the average velocity contours of the particles with the mean (median) diameter of 25 μm were determined by the PIV. Next, the <b>relative</b> concentration <b>contours</b> were analyzed for the particle phase at the different test sections. Finally, deposition rates of the particles were determined to the various surfaces in the wind tunnel. The experimental results indicate that PIV can accurately measure the two-dimensional airflow velocities {{and there is a}} difference between air and particle phase velocity contours. The smaller the airflow velocity is, the weaker the particles follow the airflow is. During the transfer of the polydisperse particles along the flow, the stratification of relative concentration of the particles along the height seems to take place. The deposition rates of polydisperse particles to the floor are higher than that to the wall and ceiling. For polydisperse particles, the mean diameter, size distribution, and spread parameter should have a comprehensive impact on the floor, wall and ceiling deposition...|$|R
40|$|A {{procedure}} for using an efficient axisymmetric code to generate downstream pressure input for more costly Euler codes is discussed. Two and three dimensional inviscid {{solutions for the}} flow within a transonic axial compressor rotor at design speed are compared to laser anemometer measurements at maximum flow and near stall operating points. Computational details of the 2 -D axisymmetric stream function solution and the 3 -D full Euler solution are described. <b>Relative</b> Mach number <b>contours,</b> shock location, and shock strength as measured and as predicted by the 3 -D code are compared. Downstream of the rotor the inviscid computations agree with each other but predict higher pressure ratios than those measured. Euler codes require a downstream pressure as input. Since that pressure controls the computed mass flow and shock system, it must be consistent with an inviscid solution...|$|R
40|$|A {{preliminary}} assessment {{is made of}} two NASA-developed unsteady turbine stage computer codes. The methodology and previous partial validation of the codes are briefly outlined. Application of these codes to a Space Shuttle main engine turbine for two sets of operating conditions is then described. Steady and unsteady, two and three-dimensional results are presented, compared, and discussed. These results include time-mean and instantaneous airfoil pressure distributions and pressure fluctuations, streamlines on the airfoil surfaces and endwalls, and <b>relative</b> total pressure <b>contours</b> at different axial locations in the rotor passage. Although not {{available at the time}} of this writing, experimental data for one of the operating conditions simulated is forthcoming and will be used to assess the accuracy of the unsteady, as well as, the steady predictions presented. Issues related to code usage and resource requirements of the two codes are also discussed...|$|R
40|$|The use of {{automated}} biometrics-based personal identification {{systems is}} an omnipresent procedure. Many technologies {{are no more}} secure, and they have certain limitations such as in cases when bodies are decomposed or burned. Dental enamel {{is one of the}} most mineralized tissues of an organism that have a post-mortem degradation resistance. In this article we describe the dental biometrics which utilizes dental radiographs for human identification. The dental radiographs provide information about teeth, including tooth <b>contours,</b> <b>relative</b> positions of neighboring teeth, and shapes of the dental work (crowns, fillings, and bridges). Then we propose a new system for the dental biometry that consists of three main stages: segmentation, features extraction and matching. The features extraction stage uses grayscale transformation to enhance the image contrast and a mixture of morphological operations to segment the dental work. The matching stage consists of the edge and the dental work comparison...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references. Issued also on microfiche from Lange Micrographics. This study presents the quantification of glass bead micromodel experiments through a combination of computational modeling and experimental analysis. The computational model simulates two-dimensional solute flow through porous media using a finite-difference Laplace Transform Galerkin (LTG) method. The glass bead micromodel simulates an ideal porous medium using a novel design by fusing one layer of glass beads between two glass plates. Various scale levels of solute flow through the micromodel were observed experimentally and recorded on video tape for use with image analyzers. Input parameters for the numerical model were estimated from hydraulic parameters determined for the micromodel three ways: using empirical relationships, constant head experiment, and previous citations in literature for micromodel studies. Both experimental and numerical results were used with image analyzers to obtain <b>relative</b> concentration <b>contours</b> for the bulk model and a target area equal to 36 representative elementary volumes. Relative concentration breakthrough curves were obtained from the target area and three separate pore-scale points. The results show favourable comparisons with experimental and numerical breakthrough data. The glass bead micromodel study was a conceivable procedure for quantifying micromodel experiments...|$|R
40|$|The {{presence}} of uniformly small collagen fibrils in tendon repair {{is believed to}} play a major role in suboptimal tendon healing. Collagen V is significantly elevated in healing tendons and plays an important role in fibrillogenesis. The objective of this study was to investigate the effect of a particular chain of collagen V on the fibrillogenesis of Sprague-Dawley rat tenocytes, as well as the efficacy of Col V siRNA engineered tenocytes for tendon tissue engineering. RNA interference gene therapy and a scaffold free tissue engineered tendon model were employed. The results showed that scaffold free tissue engineered tendon had tissue-specific tendon structure. Down regulation of collagen V a 1 or a 2 chains by siRNAs (Col 5 a 1 siRNA, Col 5 a 2 siRNA) had different effects on collagen I and decorin gene expressions. Col 5 a 1 siRNA treated tenocytes had smaller collagen fibrils with abnormal morphology; while those Col 5 a 2 siRNA treated tenocytes had the same morphology as normal tenocytes. Furthermore, it was found that tendons formed by coculture of Col 5 a 1 siRNA treated tenocytes with normal tenocytes at a proper ratio had larger collagen fibrils and <b>relative</b> normal <b>contour.</b> Conclusively, it was demonstrated that Col V siRNA engineered tenocytes improved tendon tissue regeneration. And an optimal level of collagen V is vital in regulating collagen fibrillogenesis. This may provide a basis for future development of novel cellular- and molecular biology-based therapeutics for tendon diseases...|$|R
40|$|Pyroxene {{reflectance}} and transmittance spectra {{have been}} examined {{in a search for}} systematic relationships between spectral features and compositional variations and to assess the applicability of reflectance spectroscopy to pyroxene geothermometry. Orthopyroxenes containing up to about 11 percent Wollastonite show a positive correlation between Fe(2 +) content and wavelength positions of the major absorption bands. Aluminum-rich orthopyroxenes display absorption bands at lower than expected wavelengths. Spectral-compositional relationships are more complex for clinopyroxenes, showing both positive and negative correlations between band positions and major cation abundances. These relationships are further complicated by the presence of significant amounts of other transition series elements such as Ti and Cr and by the presence of exsolved phases and compositional zonations. Contours of the wavelength positions of band minima projected onto the pyroxene tetralateral generally exhibit concave downward shapes. The orientations of the <b>contours</b> <b>relative</b> to pyroxene geotherms are such as to effectively preclude the use of spectroscopy to significantly constrain the temperatures of formation of pyroxenes...|$|R
40|$|Novel prototype-based {{framework}} for image segmentation is introduced and successfully applied for cell segmentation in microscopy imagery. This study {{is concerned with}} precise contour detection for objects representing the Prorocentrum minimum species in phytoplankton images. The framework requires a single object with the ground truth contour as a prototype to perform detection of the contour for the remaining objects. The level set method is chosen as a segmentation algorithm and its parameters are tuned by differential evolution. The fitness function {{is based on the}} distance between pixels near contour in the prototype image and pixels near detected contour in the target image. Pixels “of interest correspond to several concentric bands of various width in outer and inner areas, <b>relative</b> to the <b>contour.</b> Usefulness of the introduced approach was demonstrated by comparing it to the basic level set and advanced Weka segmentation techniques. Solving the parameter selection problem of the level set algorithm considerably improved segmentation accuracy...|$|R
40|$|AbstractWe {{consider}} how local motion signals are combined {{to represent the}} movements of spatially extensive objects. A series of band-pass target dots, whose collective motion defined a moving contour, was positioned within a field of randomly moving noise dots. The visibility of the contours did {{not depend on the}} direction of movement <b>relative</b> to local <b>contour</b> orientation unless the contour was constrained to pass through fixation, suggesting that a previously reported advantage for collinear motion trajectories depends on the probability of detecting any of the target elements rather than the integrated contour. Contour visibility was invariant of the spatial frequency of the elements, but it did depend on the speed, number and spacing of elements defining it, as well as the angle and spatial frequency difference between adjacent elements. Local averaging of directional signals is not sufficient to explain these results. The visibility of these moving contours identifies narrow-band grouping processes that are sensitive to the shape defined by the directions of the elements forming the contour...|$|R
40|$|University of Minnesota M. S. thesis. August 2015. Major: Civil Engineering. Advisors: Gary Davis, John Hourdos. 1 {{computer}} file (PDF); vii, 102 pages. The {{objective of this}} project was to develop guidelines for time-of-day use of permitted left-turn phasing, which can then be implemented using flashing yellow arrows (FYA). This required determining how the risk for left-turn crashes varied as traffic-flow conditions varied {{during the course of}} a representative day. This was accomplished by developing statistical models, which expressed the risk of the occurrence of a left-turn crash during a given hour as a function of the left-turn demand, the opposing traffic volume, and a classification of the approach with respect to the opposing traffic speed limit, the type of left-turn protection, and whether or not opposing left-turn traffic could obstruct sight distance. The models were embedded in a spreadsheet tool which will allow operations personnel to enter, for a candidate intersection approach, existing turning movement counts, and a classification of the approach with respect to speed limit, turn protection, and sight distance issues and receive a prediction of how the risk of left-turn crash occurrence varies throughout the day, relative to a user-specified reference condition. In order to relate relative risk values with crash frequency, a method was suggested to combine historic left-turn crashes at the approach of interest with the <b>relative</b> risk <b>contour</b> diagram. This method can be used to identify the threshold relative risk at which a left-turn phasing should change from permitted to protected...|$|R
40|$|Global {{translation}} preferred active contour is {{much more}} suitable for object tracking. The prior information of active contour with global translation preference {{can be interpreted as}} the velocity field along the evolving contour with equivalency preference. According to this,a simple gradient flow which preferes global translation is acquired by defining a new inner product on the set of perturbations of a curve. The new inner product is obtained by adding the variance of the perturbation of a curve to the inner product relative to the H 0 active contour. The active <b>contour</b> <b>relative</b> to the new inner product is called variance active contour. In contrast to H 1 active contour generated by convolution of H 0 active contour and certain kernel functional,variance active contour needs no convolution and is a weighting sum of H 0 active contour and corresponding average gradient flow. Thus,variance active contour can be implemented much faster and easier than H 1 active contour. We also compared H 0,H 1 and variance active contours in space and frequency domains. 机器人学国家重点实验室开放课题基金项目(07 A 1210101...|$|R
40|$|This paper {{deals with}} the problem of {{exploiting}} prosodic in-formation in syntactic analysis of spontaneous monologue ut-terances of non-professional speakers. Duration of pauses at phrase boundaries and <b>relative</b> F 0 <b>contour</b> features, which im-prove parsing accuracy of read sentences, were also found to be effective for parsing spontaneous speech. Dependency anal-ysis was performed by the minimum penalty parser on aca-demic presentation speech recorded in Corpus of Spontaneous Japanese, a large-scale database of spontaneous Japanese with rich linguistic annotations. Preliminary experiments on rela-tively clean parts of the monologue data utterances showed that the pause and F 0 features are effective to improve the accu-racy of dependency analysis of spontaneous utterances, and that combined use of both features will give further improvement. It was also found that the effectiveness of pause information was larger when pause models were estimated separately for zero-duration and non-zero-duration pauses, which better model the actual distribution of pause duration than a simple Gaussian dis-tribution. Although this is a preliminary study, the results are promising. 1...|$|R
40|$|Waves of {{activity}} following a focal stimulation are reliably observed to {{spread across the}} cortical tissue. The origin of these waves remains unclear and the underlying mechanisms and function are still debated. In this study, we ask whether waves {{of activity}} modulate the MEG signals recorded in humans during visual stimulation with Gabor patches sequentially flashed along a vertical path, eliciting a perception of vertical apparent motion. Building upon the functional properties of long-rang horizontal connections, proposed to contribute to spreading activity, we specifically probe the amplitude and latency of MEG responses {{as a function of}} Gabor contrast and orientation. The results indicate that the response amplitude is enhanced and the response latency is shortened for co-aligned Gabor as compared to misaligned Gabor patches at a low but not at a high contrast. Building upon these findings, we develop a biologically plausible computational model that performs a ‘spike time alignment’ of the responses to elongated contours with varying contrast, endowing them with a phase advance <b>relative</b> to misaligned <b>contours...</b>|$|R
40|$|Three-dimensional {{contouring}} of {{the compressor}} and turbine endwalls in a {{gas turbine engine}} {{has been shown to}} be an effective method of reducing aerodynamic losses by mitigating the strength of the complex vortical structures generated at the endwall. Reductions in endwall heat transfer in the turbine have been also previously measured and reported in the literature. In this study, computational fluid dynamics simulations of a turbine blade with and without non-axisymmetric endwall contouring were compared to experimental measurements of the exit flowfield, endwall heat transfer and endwall film-cooling. Secondary kinetic energy at the cascade exit was closely predicted with a simulation using the SST k-ω turbulence model. Endwall heat transfer was overpredicted in the passage for both the SST k-ω and realizable k-ε turbulence models, but heat transfer augmentation for a non-axisymmetric <b>contour</b> <b>relative</b> to a flat endwall showed fair agreement to the experiment. Measured and predicted film-cooling results indicated that the non-axisymmetric contouring limits the spread of film-cooling flow over the endwall depending upon the interaction of the film with the contour geometry...|$|R
40|$|Abstract. When {{a figure}} is only {{partially}} visible and its contours represent {{a small fraction}} of total image contours (as when there is much background clutter), a fast contour classification mechanism may filter non-figure contours in order to restrict the size of the input to subsequent contour grouping mechanisms. The results of two psychophysical experiments suggest that the human visual system can classify figure from non-figure contours {{on the basis of a}} difference in some contour property (eg length, orientation, curvature, etc). While certain contour properties (eg orientation, curvature) require only local analysis for classification, other contour properties (eg length) may require more global analysis of the retinal image. We constructed a pyramid-based computational model based on these observations and performed two simulations of experiment 1 : one simulation with classification enabled and the other simulation with classification disabled. The classification-based simulation gave the superior account of human performance in experiment 1. When a figure is partially visible, with few <b>contours</b> <b>relative</b> to the number of non-figure contours, contour classification followed by contour grouping can be more efficient than contour grouping alone, owing to smaller input to grouping mechanisms. ...|$|R
40|$|Dental {{biometrics}} utilizes dental radiographs {{for human}} identification. The dental radiographs {{provide information about}} teeth, including tooth <b>contours,</b> <b>relative</b> positions of neighboring teeth, and shapes of the dental work (e. g., crowns, fillings, and bridges). The proposed system has two main stages: feature extraction and matching. The feature extraction stage uses anisotropic diffusion to enhance the images and a Mixture of Gaussians model to segment the dental work. The matching stage has three sequential steps: tooth-level matching, computation of image distances, and subject identification. In the tooth-level matching step, tooth contours are matched using a shape registration method, and the dental work is matched on overlapping areas. The distance between the tooth contours and {{the distance between the}} dental work are then combined using posterior probabilities. In the second step, the tooth correspondences between the given query (postmortem) radiograph and the database (antemortem) radiograph are established. A distance based on the corresponding teeth is then used to measure the similarity between the two radiographs. Finally, all the distances between the given postmortem radiographs and the antemortem radiographs that provide candidate identities are combined to establish the identity of the subject associated with the postmortem radiographs...|$|R
40|$|A {{comprehensive}} engineering {{analysis of}} the coastal sediment transport processes along a 42 -kilometer segment of the North Carolina shoreline from Wrightsville Beach to Fort Fisher is presented. Included in the analysis is {{an interpretation of the}} littoral processes, longshore transport, and the behavior and success of beach nourishment projects at Wrightsville Beach and Carolina Beach, North Carolina. The historical position of the MLW, MSL, and MHW <b>contours,</b> <b>relative</b> to a fixed base line, is plotted for the period between 1964 and 1975. An equivalent volumetric erosion or accretion between successive surveys is determined by multiplying the average excursion distance of the contours by a constant of proportionality. The plots of excursion distance versus time for the MLW, MSL, and MHW contours also show the time response of the beach fills. This response is described by a mathematical function. The alongshore components of wave-induced energy flux are also determined within the study area through wave refraction analysis. This information, together with the information on volumetric change, is used in a sediment budget analysis to determine the coefficient of alongshore sediment transport and the inlet trapping characteristics. (Author). Contract no. : DACW 72 - 79 -C- 0001. "June 1981. ""Environmental Science and Engineering, Inc. " [...] Report documentation page. Cover title. Includes bibliographical references (pages 96 - 97). A comprehensive engineering {{analysis of the}} coastal sediment transport processes along a 42 -kilometer segment of the North Carolina shoreline from Wrightsville Beach to Fort Fisher is presented. Included in the analysis is an interpretation of the littoral processes, longshore transport, and the behavior and success of beach nourishment projects at Wrightsville Beach and Carolina Beach, North Carolina. The historical position of the MLW, MSL, and MHW <b>contours,</b> <b>relative</b> to a fixed base line, is plotted for the period between 1964 and 1975. An equivalent volumetric erosion or accretion between successive surveys is determined by multiplying the average excursion distance of the contours by a constant of proportionality. The plots of excursion distance versus time for the MLW, MSL, and MHW contours also show the time response of the beach fills. This response is described by a mathematical function. The alongshore components of wave-induced energy flux are also determined within the study area through wave refraction analysis. This information, together with the information on volumetric change, is used in a sediment budget analysis to determine the coefficient of alongshore sediment transport and the inlet trapping characteristics. (Author). Mode of access: Internet...|$|R
40|$|To {{prevent the}} {{deterioration}} of groundwater quality, mathematical simulation models have been formulated to predict the transport of contaminants in complex aquifer systems and to design remedial schemes for the problems. Existing analytical and numerical approaches have serious disadvantages for large-scale nonhomogeneous field problems where well-pumping or injection is involved. The major difficulties relate to numerical dispersion and oscillations in highly advective-dominated simulations, computational accuracy, excessive computer expense, grid orientation problems, and an inability for simulating with random conductivity fields. Recent work by Ewing, Russell, and Wheeler (1983) has produced a very efficient and accurate method for miscible displacement in oil reservoirs. Their concept was adapted and then applied to groundwater contaminant transport problems in this thesis. The highly efficient code combines a mixed finite element procedure for groundwater flow and a modified method of characteristics and finite element procedure (MMOC) for the parabolic transport equation. The preconditioned conjugate gradient method was used to solve the resulting matrices for both equations. The method has been compared with two analytical solutions on a homogeneous domain. Excellent agreements were demonstrated through <b>relative</b> concentration <b>contours</b> and breakthrough curves. The method has also been compared with the currently popular USGS Solute Transport model. More accurate resolutions were achieved for the MMOC method than for the USGS Solute Transport model. In addition, much larger time steps were allowed in the MMOC method than the USGS Solute Transport model obtaining similar resolutions. The method {{has been applied to}} highly advective-dominated problems on a CRAY-XMP supercomputer and the results showed there are no dispersion or oscillation problems common in many existing numerical codes. The method has also been used to simulate cases with random hydraulic conductivity fields that were simulated from Turning Bands Method. Fingering phenomena developed because the concentration front is transported more rapidly in the zones of higher hydraulic conductivity. The method {{has been shown to be}} superior in many respects to currently used models in groundwater transport, especially in the presence of strong pumping or injection centers or heterogeneities in the flow field...|$|R
40|$|DE 19963010 A UPAB: 20010829 NOVELTY - The {{focusing}} a {{light beam}} via {{one or two}} scanning mirrors onto the workpiece surface and deflecting it along at least one axis by tilting at least one mirror. Light reflected from the workpiece is directed via the mirror(s) to an optical detector connected to an evaluation and control unit that controls the deflection of the beam depending on the current contour position. DETAILED DESCRIPTION - The method involves performing a workpiece actual-desired position comparison before laser processing using at least one <b>contour</b> <b>relative</b> to the laser processing head. A light beam (7) is focused via one or two scanning mirrors (2, 3) onto the workpiece (4) surface and deflected along at least one axis by tilting at least one mirror. Light reflected from the workpiece is directed via the mirror(s) to an optical detector (5) connected to an evaluation and control unit (6) that controls the deflection of the beam depending on the current contour position. INDEPENDENT CLAIMS are also included for the following: an arrangement for laser processing of workpieces. USE - For laser processing of workpieces. ADVANTAGE - Enables {{a high degree of}} positioning accuracy to be achieved inexpensively when processing workpieces with defined contours...|$|R
40|$|Detailed laser Doppler {{velocimeter}} (LDV) {{flow field}} measurements were made upstream of two fans, one forward-swept and one aft-swept, {{in order to}} learn more about the shocks which propagate upstream of these rotors when they are operated at supersonic tip speeds. The blade-to-blade variations in the flows associated with these shocks are thought to be responsible for generating Multiple Pure Tone (MPT) noise. The measured blade-to-blade variations are documented in this report through a series of slideshows which show <b>relative</b> Mach number <b>contours</b> computed from the velocity measurements. Data are presented for the forward-swept fan operating at three speeds (corresponding to tip relative Mach numbers of 0. 817, 1. 074, and 1. 189), and for the aft-swept fan operating at two (tip relative Mach numbers of 1. 074 and 1. 189). These LDV data illustrate how the perturbations in the upstream flow field created by the rotating blades vary with axial position, radial position and rotor speed. As expected, at the highest tested speed the forward-swept fan swallowed the shocks which occur in the tip region, whereas the aftswept fan did not. This resulted in a much smaller flow disturbance just upstream of the tip of the forward-swept fan. Nevertheless, further upstream the two fan flows were much more similar...|$|R
40|$|Digitized {{contours}} {{are increasingly}} being applied as a data source for generating regular grid digital elevation models (OEMs). The special characteristics of contours as a DEM data source, and some published contour-specific interpola tion algorithms, are reviewed in this paper. Test results for three algorithms are presented, employing both synthetic and real surface data. The algorithms are: linear interpo lation with four data points found in the grid axis direc tions (LIXY), linear interpolation within two data points found in the approximate direction of steepest slope (LISS), and cubic interpolation within four data points found in the approximate direction of steepest slope (CISS). The results indicate that high fidelity OEMs can be generated from cont ours, particularly when associated terrain features, such as break lines, ridges and spot heights, are incorporated into the input data. The root mean square errors of interpolated heights, <b>relative</b> to the <b>contour</b> data, range from 3 % to 27 % of the contour interval, depending on the interpolation al gorithm, surface structure, and composition of the input data. Error surface contours are employed to illustrate the extent of systematic errors in the interpolated OEMs. The fidelities of the OEMs interpolated {{by means of the}} steepest slope algorithms are significantly higher than those result ing from grid axis interpolation...|$|R
40|$|Keywordwavelet transform; phase extraction; {{instantaneous}} contour; shadow moiré AbstractThe {{reconstruction of}} instantaneous contour {{is a common}} method to analyze the kinetic characteristic of a continual deformation object. In this paper a continuous wavelet transform method (CWT) is applied to analyze the instantaneous contour of a continual deformation object based on shadow moiré technique. The modulated moiré fringe patterns are captured by use of a high-speed CCD camera and the temporal intensity variation of each pixel related to the object deformations is recorded. The intensity variation of each pixel is analyzed along the time axis by CWT. From the extraction of the ridges and from {{the value of the}} CWT along the ridges, the information of modulated phase <b>relative</b> to the <b>contour</b> of object can be obtained. In this application, a cantilever beam with a motion in the Z direction is tested by use of the method and the high-quality instantaneous contour of the continual deformation object can be retrieved. Experimental results prove that the CWT can successfully be applied to the instantaneous contour analysis of continual deformation object and these results demonstrate the advantages of the CWT with respect to the applicable simplicity and the resistance of noise pollution. 1...|$|R
40|$|Mentor: Andrew J. OxenhamOn {{hearing a}} {{sequence}} of pitches, listeners develop expectations for how that sequence will continue. Research on melodic continuation generally supposes two kinds of factors: the top-down influence of perceived tonality, and the bottom-up influence of melodic <b>contour</b> (<b>relative</b> size {{and direction of the}} intervals). For bottom-up, contour-based factors, there is converging evidence that melodies with good continuation tend to have small intervals between notes and narrow overall ranges. Since melodic contour can also be perceived in sequences of notes varying in brightness (an aspect of timbre or sound quality) or loudness instead of pitch, it is reasonable to suppose that the same contour-based expectations that apply to pitch sequences also apply to brightness and loudness sequences. The present study found that perceptive continuation ratings for brightness and loudness sequences generally conform to the same contour-based expectations as pitch sequences, though some differences between dimensions were found. This is compatible with the hypothesis that perception of melodic contour is a general auditory phenomenon that is not unique to pitch. The ratings for brightness and loudness sequences were more similar to each other than to ratings for pitch sequences, and {{it is likely that the}} factors that set pitch apart from other auditory dimensions are closely related to perceived tonality. This research was supported by the Undergraduate Research Opportunities Program (UROP) ...|$|R
