26|24|Public
50|$|FFmpeg {{linked with}} the VP8/VP9 <b>reference</b> <b>codec</b> library libvpx can extract VP8 key frames from WebM media and a script can then add the WebP RIFF header and the NUL pad byte for odd frame lengths. Meanwhile, FFmpeg {{supports}} libwebp directly.|$|E
50|$|The {{roots of}} the project precede the Alliance, however.Individual {{contributors}} started experimental technology platforms years before: Daala already published code in 2010, VP10 was announced on September 12, 2014, and Thor was published on August 11, 2015.The first version 0.1.0 of the AV1 <b>reference</b> <b>codec</b> was published on April 7, 2016.|$|E
5000|$|FLAC ( [...] ; Free Lossless Audio Codec) is {{an audio}} coding format for {{lossless}} compression of digital audio, {{and is also}} {{the name of the}} <b>reference</b> <b>codec</b> implementation. Digital audio compressed by FLAC's algorithm can typically be reduced to between 50 to 60 percent of its original size [...] and decompress to an identical copy of the original audio data.|$|E
30|$|Speech Material. Speech {{material}} {{has to be}} processed through 12 ?WB <b>reference</b> speech <b>codecs</b> and the codec under investigation. Additional conditions may be processed such as mixed tandems of the codec under investigation with the <b>reference</b> <b>codecs,</b> or transmission errors possibly concealed by a packet-loss concealment algorithm.|$|R
3000|$|... are {{determined}} numerically, approximating all the <b>reference</b> wideband <b>codecs</b> in a least-squares sense.|$|R
3000|$|... values {{should be}} stable over the {{different}} databases and thus values {{based on one}} database only {{should have the same}} accuracy as values based on many databases. This is not the case in Table 5, due to the different number and type of codecs included in each test corpus. Therefore, [15] recommends to include a minimum of 12 <b>reference</b> <b>codecs</b> in such calculations in order to derive stable [...]...|$|R
40|$|This paper {{proposes a}} Wideband-CELP-Coding scheme (bandwidth 7 kHz) at 24 kbit/s. The codec {{introduces}} a de-lay of just 10 ms. This fulfills {{the requirements of}} a possible codec candidate for wideband speech coding within DECT or video applications [I]. The analysis-by-synthesis struc-ture of the proposed Wideband-CELP-Codec includes an alternative LPC analysis concept, where the autocorrela-tion function is calculated recursively [2]. This special LPC scheme provides an improved speech quality and a reduction of computational complexity in comparison to conventional algorithms for the LPC analysis. In addition a stochastic sparse codebook with extremely low computational effort is presented, comparable to the one presented in [12] re-sulting in a neglectable amount of storage. The CCITT G. 722 standard was applied as <b>reference</b> <b>codec,</b> in order to compare the new coding scheme in terms of subjective qual-ity. With the proposed Wideband-CELP a speech quality is achieved, which {{is equivalent to the}} <b>reference</b> <b>codec</b> op erating at 56 kbit/s. 1...|$|E
40|$|In {{this paper}} we propose an {{improved}} motion estimation algorithm based on evolutionary strategy (ES) for H. 264 video codec applied to video. The proposed technique works in a parallel local search for macroblocks. For this purpose (mu+lambda) ES is used with an initial population of heuristically and randomly generated motion vectors. Experimental {{results show that the}} proposed scheme can reduce the computational complexity up to 50 % of the motion estimation algorithm used in the H. 264 <b>reference</b> <b>codec</b> at the same picture quality. Therefore, the proposed algorithm provides a significant improvement in motion estimation in the H. 264 video codec...|$|E
40|$|In this paper, {{we propose}} a new motion {{estimation}} algorithm based on evolutionary strategy (ES) for the H. 264 video codec applied to monoscopic video. The proposed technique applies in macroblock basis and performs a parallel local {{search for the}} motion vector associated with the minimum motion compensated residue. For this purpose (/spl mu/+/spl lambda/) -ES is used with heuristically and randomly generated population of initial motion vectors. Experimental {{results show that the}} proposed scheme can reduce the computational complexity up to 50 % of the motion estimation algorithm used in the H. 264 <b>reference</b> <b>codec</b> at the same picture quality. Therefore, the proposed algorithm provides a significant improvement in motion estimation in the H. 264 video codec...|$|E
40|$|International audienceThe MPEG Reconfigurable Video Coding {{working group}} is {{developing}} a new library-based process for building the <b>reference</b> <b>codecs</b> of future MPEG standards, {{which is based on}} dataflow and uses an actor language called Cal. The paper presents a code generator producing RTL targeting FPGAs for Cal, outlines its structure, and demonstrates its performance on an MPEG- 4 Simple Profile decoder. The resulting implementation is smaller and faster than a comparable RTL reference design, and {{the second half of the}} paper discusses some of the reasons for this counter-intuitive result...|$|R
40|$|Abstract in Undetermined The MPEG Reconfigurable Video Coding {{working group}} is {{developing}} a new library-based pro- cess for building the <b>reference</b> <b>codecs</b> of future MPEG standards, {{which is based on}} dataflow and uses an actor language called Cal. The paper presents a code genera- tor producing RTL targeting FPGAs for Cal, outlines its structure, and demonstrates its performance on an MPEG- 4 Simple Profile decoder. The resulting imple- mentation is smaller and faster than a comparable RTL reference design, and {{the second half of the}} paper discusses some of the reasons for this counter-intuitive result...|$|R
40|$|EVS, {{the newly}} {{standardized}} 3 GPP Codec for Enhanced Voice Services (EVS) {{was developed for}} mobile services such as VoLTE, where error resilience is highly essential. The presented paper outlines {{all aspects of the}} advances brought during the EVS development on packet loss concealment, by presenting a high level description of all technical features present in the final standardized codec. Coupled with jitter buffer management, the EVS codec provides robustness against late or lost packets. The advantages of the new EVS <b>codec</b> over <b>reference</b> <b>codecs</b> are further discussed based on listening test results...|$|R
40|$|International audienceThis {{research}} {{proposed a}} method for adaptive Lagrange multiplier determination for rate-distortion optimization with dynamic texture in High Efficiency Video Coding (HEVC). Inspired by the experimental results of the Lagrange multiplier selection test, the presented approach adaptively predicts the optimum Lagrange multiplier for different dynamic texture sequences, based on {{the features of the}} dynamic texture sequences such as normal flow and spatial-temporal information. The Lagrange multiplier among the given values will be chosen based on the Bjontegaard delta measurements. After that, the data of training dynamic texture will be used for Support Vector Machine (SVM) in machine learning for getting the predicting results. The proposed algorithm has been fully integrated into HEVC <b>reference</b> <b>codec.</b> The result shows that the proposed method can improve 0. 5 in Structural Similarity Metric (SSIM) and 2 in Peak Signal-to-Noise Ratio (PSNR) ...|$|E
40|$|This paper {{proposes a}} {{multi-layer}} super-wideband embedded speech and audio coding algorithm extending bit rates from 36 to 64 kb/s {{on the basis}} of ITU-T Recommendation G. 729. 1 with a multi-stage coding structure. This codec consists of three embedded stages: G. 729. 1 wideband coding operating in the range from 8 to 32 kb/s, modified Modulated Lapped Transform (MLT) coding of the band (7 - 14 kHz) at 36, 40 & 48 kb/s and MDCT transform coding for wideband residual signal at 56 and 64 kb/s. In addition, some methods are proposed in transform coding according to perception significance. The objective and subjective listening tests show that this codec has good performance compared with <b>reference</b> <b>codec.</b> APSIPA ASC 2009 : Asia-Pacific Signal and Information Processing Association, 2009 Annual Summit and Conference. 4 - 7 October 2009. Sapporo, Japan. Poster session: Speech Processing (7 October 2009) ...|$|E
40|$|In {{this paper}} an audio coding {{procedure}} for piano signals is presented {{based on a}} physical model of the piano. Instead of coding the waveform of the signal, the compression is realized by extracting relevant parameters at the encoder. The signal is then re-synthesized at the decoder using the physical model. We describe {{the development and implementation}} of algorithms for parameter extraction and the combination of all the components into a coder. A formal listening test was conducted, which shows that we can obtain a high sound quality at a low bit rate, lower than conventional coders. We obtain a bitrate of 11. 6 kbps for the proposed piano coder. We use HE-AAC as <b>reference</b> <b>codec</b> at a gross bitrate of 16 kbps. For low and medium chords the proposed piano coder outperforms HE-AAC in terms of subjective quality, while the quality falls below HE-AAC for high chords...|$|E
40|$|The MPEG Reconfigurable Video Coding {{working group}} is {{developing}} a new library-based process for building the <b>reference</b> <b>codecs</b> of future MPEG standards, {{which is based on}} dataflow and uses an actor language called CAL. The paper presents a code generator producing RTL targeting FPGAs for CAL, outlines its structure, and demonstrates its performance on an MPEG- 4 Simple Profile decoder. The resulting implementation is smaller and faster than a comparable RTL reference design, and {{the second half of the}} paper discusses some of the reasons for this counter-intuitive result...|$|R
50|$|Vorbis is a {{free and}} {{open-source}} software project headed by the Xiph.Org Foundation. The project produces an audio coding format and software <b>reference</b> encoder/decoder (<b>codec)</b> for lossy audio compression. Vorbis is most commonly {{used in conjunction with}} the Ogg container format and it is therefore often referred to as Ogg Vorbis.|$|R
40|$|Concentric mosaics {{have the}} ability to quickly capture a {{complete}} 3 D view of a realistic environment and to enable a user to wander freely in the environment. However, the data amount of the concentric mosaics is huge. In this paper, we propose an algorithm to compress the concentric mosaic image array through motion compensation and residue coding, which we called <b>reference</b> block <b>codec</b> (RBC). A two-level index table is embedded in the compressed bitstream for random access. During the rendering, the entire compressed concentric mosaic scene is not fully expanded at any time. In stead, only the contents necessary to render the current view are decoded in real time. We denote such rendering scheme as just-in-time (JIT) rendering. Four decoder caches are implemented to speed up the rendering. Keywords: Image-based rendering (IBR), concentric mosaics, <b>reference</b> block <b>codec</b> (RBC), data compression, just-in-time (JIT) rendering, cache management. 1...|$|R
40|$|Abstract — We {{consider}} block-based interview coding {{techniques for}} multiview video sequences that are robust to illumination variations across views. We consider both global illumination differences {{which could be}} due to lack of camera calibration or heterogeneity, as well as local ilumination changes caused by lack of camera aligment. We propose a two-parameter model for illumination compensation (IC) that is used at the block matching search step and can be adaptively applied by taking into account the rate-distortion characteristics of each block. We also present a modified search (MS) method for block-based interview disparity estimation that makes use of feature points in each frame in order to provide a good prediction of likely disparity vectors. We present coding experiments on different multiview sequences based on the H. 264 /AVC <b>reference</b> <b>codec.</b> The proposed techniques show significant coding gains for interview coded frames, as compared to methods that do not employ IC and MS. I...|$|E
40|$|Abstract — In this paper, {{we propose}} a {{cascaded}} sparse/DCT (S/DCT) two-layer representation of prediction residuals, and implement this idea {{on top of}} the state-of-the-art high efficiency video coding (HEVC) standard. First, a dictionary is adaptively trained to contain featured patterns of residual signals so that a high portion of energy in a structured residual can be efficiently coded via sparse coding. It is observed that the sparse representation alone is less effective in the R-D performance due to the side information overhead at higher bit rates. To overcome this problem, the DCT representation is cascaded at the second stage. It is applied to the remaining signal to improve coding efficiency. The two representations successfully complement each other. It is demonstrated by experimental results that the proposed algorithm outperforms the HEVC <b>reference</b> <b>codec</b> HM 5. 0 in the Common Test Condition. Index Terms — ρ domain rate model, discrete cosine transform (DCT), high efficiency video coding (HEVC), multilayered coding, overcomplete dictionary based video coding, residual coding, sparse representation. I...|$|E
40|$|Abstract. Two fast mode {{decision}} {{methods for}} intra prediction in H. 264 are proposed {{in this work}} to reduce the encoder complexity. The first method, the so-called two-level fast Intra 4 x 4 mode decision, {{is based on the}} idea of reducing possible candidate directions of a 4 x 4 luma block in Intra 4 x 4 mode decision. The second method enables an early selection of suitable 4 x 4 or 16 x 16 luma partitions of a given macroblock. The performance of the proposed algorithms are evaluated using the H. 264 <b>reference</b> <b>codec</b> JM 10. 1, which is compared with exhaustive RD mode decision of H. 264 in metrics such as the encoding time, the average PSNR and the coding bit-rate for test sequences. It is observed that the proposed fast algorithms can save about 52 % of encoding time resulting in a minor PSNR degradation of 0. 03 dB lower PSNR and a 2. 5 % higher bit rate. Index Terms—H. 264 /AVC, fast intra mode decision, video coding 1...|$|E
40|$|In this paper, we {{introduce}} a new motion vector prediction method {{that could be used}} within multiple picture <b>reference</b> <b>codecs,</b> such as the H. 264 (MPEG- 4 AVC) video coding standard. Our method considers for each candidate motion vector the temporal distance of its corresponding reference picture compared to the current one for the generation of the predictor motion vector. This allows for more accurate motion vector prediction, and better exploitation of the temporal correlation that may exist within a video sequence. Furthermore, we also {{introduce a}} modification to the SKIP motion vector macroblock mode, according to which not only the motion vectors but also the reference indices are adaptively generated. Simulation results suggest that our proposed methods, combined with an improved Rate Distortion optimization strategy, if implemented within the existing H. 264 codec, can allow for a considerable performance improvement of up to 8. 6 % bitrate reduction compared to the current H. 264 standard...|$|R
50|$|Apple Lossless, {{also known}} as Apple Lossless Audio Codec (ALAC), or Apple Lossless Encoder (ALE), is an audio coding format, and its <b>reference</b> audio <b>codec</b> implementation, {{developed}} by Apple Inc. for lossless data compression of digital music. After initially keeping it proprietary from its inception in 2004, in late 2011 Apple made the codec available open source and royalty-free. Traditionally, Apple has referred to the codec as Apple Lossless, though more recently {{they have begun to}} use the abbreviated term ALAC when referring to the codec.|$|R
40|$|Abstract Voice over Internet Protocol VoIP is {{a rapidly}} growing {{technology}} that enables transport of voice over data networks such as Ethernet Wide area networks WANs due to this important different codec scheme is developed to meet the QoS requirements. This thesis presents a comprehensive study {{about the impact of}} active queue management AQM on Voice over Internet Protocol VoIP quality of service using different codec scheme such as G 711 G 723 G 729 and GSM using simulations tools. The evaluation is done using the OPNET Modeler which provides a convenient and easy-to-use platform for simulating large scale networks and this also give a power to go through different levels of designing a network even with the ability to program the mechanism you want which is used here to implement two types of AQM mechanism which is not included by default in the OPNET and these two mechanisms are ARED and GRED. The performance metrics used in the study are jitter throughput and delay. The study shows that G. 711 and G 729 codecs in a simulation gives a significant result for the performance of VoIP that codec G 711 and G. 729 A has acceptable throughput and less deviation of received to transmit packet as compared to GSM and G. 723 also average delay like end to end delay and Voice jitter is lesser in codec G 711 and G. 729 as compared to the other two <b>referenced</b> <b>codecs...</b>|$|R
40|$|This paper {{proposes a}} direct DCT-to-DCT {{resizing}} algorithm for 3 -D DCT based video coding. An 8 � 8 � 8 cube is resized to three modes along temporal dimension: a single 8 � 8 block, a downsized 8 � 8 � 4 cube and two 8 � 8 � 4 cubes. The mode selection {{is based on}} the local motion activity and determined after 2 -D DCT on each block. In addition, the proposed resizing scheme directly resizes the DCT blocks in the transform domain using the DCT-to-DCT algorithm. Compared to traditional resizing approaches the proposed algorithm does not require the inverse transform and the computations in the spatial domain, thus is superior to other methods in terms of complexity. The proposed model is evaluated with the baseline video codec and the <b>reference</b> <b>codec</b> in the literature. Experimental results show a promising performance in terms of both coding efficiency and computational complexity. Potential applications could be for portable digital devices with low-power processors and other areas with real-time requirement. 1...|$|E
40|$|The JCT-VC {{standardized}} Screen Content Coding (SCC) extension in the HEVC HM RExt + SCM <b>reference</b> <b>codec</b> {{offers an}} impressive coding efficiency performance {{when compared with}} HM RExt alone; however, it is not significantly perceptually optimized. For instance, {{it does not include}} advanced HVS-based perceptual coding methods, such as JND-based spatiotemporal masking schemes. In this paper, we propose a novel JND-based perceptual video coding technique for HM RExt + SCM. The proposed method is designed to further improve the compression performance of HM RExt + SCM when applied to YCbCr 4 : 4 : 4 SC video data. In the proposed technique, luminance masking and chrominance masking are exploited to perceptually adjust the Quantization Step Size (QStep) at the Coding Block (CB) level. Compared with HM RExt 16. 10 + SCM 8. 0, the proposed method considerably reduces bitrates (Kbps), with a maximum reduction of 48. 3 %. In addition to this, the subjective evaluations reveal that SC-PAQ achieves visually lossless coding at very low bitrates. Comment: Preprint: 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2018...|$|E
40|$|In {{order to}} achieve a high {{compression}} ratio, the Context-Based Adaptive Variable Length Coding (CBAVLC) standard has incorporated {{a large number of}} coding modes which must be evaluated during the coding process to determine the optimal rate-distortion trade-off. The coding gains of CBAVLC arise at the expense of significant coder complexity. One coder process that has been identified as having potential for achieving computation savings is the selection between skipping the coding of a macro block and coding of the macro block in one of the remaining coding modes. In low contrast images, a large percentage of macro blocks are “skipped”, that is, no coded data are transmitted for these macro blocks. By estimating and identifying macro blocks to be skipped during the coding process, significant savings in computation can be realized, since the coder then does not evaluate the rate-distortion costs of all candidate coding modes. The proposed scheme shows that this approach can result in a time savings of over 80 % for lowcontrast images at a negligible decrease or, in certain cases, a slight increase in quality over a <b>reference</b> <b>codec...</b>|$|E
40|$|International {{audience}} Side {{information has}} a strong impact {{on the performance of}} Distributed Video Coding. Commonly, side information is generated using motion compensated temporal interpolation. In this paper, we propose a new method for the fusion of global and local side information using Support Vector Machine. The global side information is generated at the decoder using global motion parameters estimated at the encoder using the Scale-Invariant Feature Transform. Experimental results show that the proposed approach can achieve a PSNR improvement of up to 1. 7 dB for a GOP size of 2 and up to 3. 78 dB for larger GOP sizes, with respect to the <b>reference</b> DISCOVER <b>codec.</b> </p...|$|R
40|$|Publication interne n˚ 1627 — Juin 2004 — 29 pages Abstract: In {{this paper}} {{we present a}} method for {{streaming}} video generated by the state-of-the-art H. 264 codec over IP networks supporting the Differentiated Services (DiffServ) architecture, in particular the Assured Forwarding (AF) per-hop behavior. The scheme takes advantage of both AF’s packet drop priorities and some novel features of the H. 264 codec, so as to protect the most important information in terms of visual quality and reduce distorsion under network congestion. The proposed method is evaluated {{by means of the}} H. 264 <b>reference</b> software <b>codec,</b> network simulation and objective video quality measurements. Our results show that the proposed method allows to achieve a higher quality than traditional best-effort streaming...|$|R
40|$|It {{is assumed}} that the textures in a video scene can be {{classified}} in two categories: textures with unimportant subjective details and the remainder. We use this idea for video coding with a texture analyzer at the encoder side and a texture synthesizer at the decoder side. The texture analyzer identifies the texture regions with unimportant subjective details and generates side information for the texture synthesizer, which in turn inserts synthetic textures at the specified locations. Our approach can be integrated in any video codec. This paper focuses on the texture synthesizer and its potentially subjectively annoying spatial artifacts. The automatic detector we developed yields an artifact identification rate of up to 79 %. The former enables automatic online evaluation {{of the quality of}} synthesized frames, which allows eventual fallback on the <b>reference</b> video <b>codec</b> built on, for coding erroneous...|$|R
40|$|Further {{compression}} gains {{beyond the}} state of the art in image coding are difficult to achieve when the pixel fidelity paradigm is retained. It is necessary to find an image representation that addresses the definitions of “irrelevance” and “redundancy” in a way that is closer to human perception. In this thesis, linear random field models, and specifically Gauss-Markov Random Fields, are investigated as models of microtexture. Beyond their maximum-entropy role in information theory, Gaussian random fields are special with respect to feature detection in the human visual cortex. A hybrid coding system is designed which encodes texture content by a synthesis approach. The properties of Gaussian random fields allow to replace the common segmentation-classification approach of previous methods with a conceptually simple and elegant statistical testing framework. This gives rise to a unique structure-texture decomposition, thus avoiding problems of over- or under-segmentation. Results are evaluated for a set of established test images using objective metrics, which are verified by visual experiments. The presented coding system is able to provide up to 35 % of bitrate savings for natural images compared to a state-of-the-art <b>reference</b> <b>codec,</b> and more than 60 % bitrate savings when the algorithm is applied on noisy content...|$|E
40|$|Due to the lossy {{nature of}} image/video {{compression}} and the expensive bandwidth and computation resources in a multimedia system, {{one of the}} key design issues for image and video coding/transcoding is to optimize trade-off among distortion, rate, and/or complexity. This thesis studies the application of rate distortion (RD) optimization approaches to image and video coding/transcoding for exploring the best RD performance of a video codec compatible to the newest video coding standard H. 264 and for designing computationally efficient down-sampling algorithms with high visual fidelity in the discrete Cosine transform (DCT) domain. RD optimization for video coding in this thesis considers two objectives, i. e., to achieve the best encoding efficiency in terms of minimizing the actual RD cost and to maintain decoding compatibility with the newest video coding standard H. 264. By the actual RD cost, we mean a cost based on the final reconstruction error and the entire coding rate. Specifically, an operational RD method is proposed based on a soft decision quantization (SDQ) mechanism, which has its root in a fundamental RD theoretic study on fixed-slope lossy data compression. Using SDQ instead of hard decision quantization, we establish a general framework in which motion prediction, quantization, and entropy coding in a hybrid video coding scheme such as H. 264 are jointly designed to minimize the actual RD cost on a frame basis. The proposed framework is applicable to optimize any hybrid video coding scheme, provided that specific algorithms are designed corresponding to coding syntaxes of a given standard codec, so as to maintain compatibility with the standard. Corresponding to the baseline profile syntaxes and the main profile syntaxes of H. 264, respectively, we have proposed three RD algorithms [...] -a graph-based algorithm for SDQ given motion prediction and quantization step sizes, an algorithm for residual coding optimization given motion prediction, and an iterative overall algorithm for jointly optimizing motion prediction, quantization, and entropy coding [...] -with them embedded in the indicated order. Among the three algorithms, the SDQ design is the core, which is developed based on a given entropy coding method. Specifically, two SDQ algorithms have been developed based on the context adaptive variable length coding (CAVLC) in H. 264 baseline profile and the context adaptive binary arithmetic coding (CABAC) in H. 264 main profile, respectively. Experimental results for the H. 264 baseline codec optimization show that for a set of typical testing sequences, the proposed RD method for H. 264 baseline coding achieves a better trade-off between rate and distortion, i. e., 12 % rate reduction on average at the same distortion (ranging from 30 dB to 38 dB by PSNR) when compared with the RD optimization method implemented in H. 264 baseline <b>reference</b> <b>codec.</b> Experimental results for optimizing H. 264 main profile coding with CABAC show 10 % rate reduction over a main profile <b>reference</b> <b>codec</b> using CABAC, which also suggests 20 % rate reduction over the RD optimization method implemented in H. 264 baseline <b>reference</b> <b>codec,</b> leading to our claim of having developed the best codec in terms of RD performance, while maintaining the compatibility with H. 264. By investigating trade-off between distortion and complexity, we have also proposed a designing framework for image/video transcoding with spatial resolution reduction, i. e., to down-sample compressed images/video with an arbitrary ratio in the DCT domain. First, we derive a set of DCT-domain down-sampling methods, which can be represented by a linear transform with double-sided matrix multiplication (LTDS) in the DCT domain. Then, for a pre-selected pixel-domain down-sampling method, we formulate an optimization problem for finding an LTDS to approximate the given pixel-domain method to achieve the best trade-off between visual quality and computational complexity. The problem is then solved by modeling an LTDS with a multi-layer perceptron network and using a structural learning with forgetting algorithm for training the network. Finally, by selecting a pixel-domain reference method with the popular Butterworth lowpass filtering and cubic B-spline interpolation, the proposed framework discovers an LTDS with better visual quality and lower computational complexity when compared with state-of-the-art methods in the literature...|$|E
30|$|We {{describe}} a fully scalable wavelet-based 2 D+t (in-band) video coding architecture. We propose new coding tools {{specifically designed for}} this framework aimed at two goals: reduce the computational complexity at the encoder without sacrificing compression; improve the coding efficiency, especially at low bitrates. To this end, we focus our attention on motion estimation and motion vector encoding. We propose a fast motion estimation algorithm that works in the wavelet domain and exploits the geometrical properties of the wavelet subbands. We show that the computational complexity grows linearly {{with the size of}} the search window, yet approaching the performance of a full search strategy. We extend the proposed motion estimation algorithm to work with blocks of variable sizes, in order to better capture local motion characteristics, thus improving in terms of rate-distortion behavior. Given this motion field representation, we propose a motion vector coding algorithm that allows to adaptively scale the motion bit budget according to the target bitrate, improving the coding efficiency at low bitrates. Finally, we show how to optimally scale the motion field when the sequence is decoded at reduced spatial resolution. Experimental results illustrate the advantages of each individual coding tool presented in this paper. Based on these simulations, we define the best configuration of coding parameters and we compare the proposed codec with MC-EZBC, a widely used <b>reference</b> <b>codec</b> implementing the t+ 2 D framework.|$|E
40|$|This memo {{provides}} {{information for the}} Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (1998). All Rights Reserved. Internet applications may <b>reference</b> specific <b>codecs</b> within the WAVE and AVI registries as follows: * video/vnd. avi; codec=XXX identifies a specific video codec (i. e., XXX) within the AVI Registry. * audio/vnd. wave; codec=YYY identifies a specific audio codec (i. e., YYY) within the WAVE Registry. Appendix A and Appendix B provides an authoritative reference for {{the interpretation of the}} required "codec " parameter. That is, the current set of audio codecs that are registered within the WAVE Registry are enumerated in Appendix A. Appendix B enumerates the current set of video codecs that have been registered to date within the AVI Registry. ...|$|R
40|$|The {{document}} m 13416 {{presents the}} encoding {{performance of the}} wavelet scalable video codec developed by aceMedia consortium. The codec architecture, concerning the encoding schemes (t+ 2 D, 2 D+t+ 2 D, etc.) that can be realized, are basically the same allowed in the current MSRA VidWav scalable video coding model. The main differences {{can be found in}} the fundamental tools, such as Motion Estimation, Entropy Encoder, etc., used to implement a given encoding architecture. The evaluation of the proposed technology and its performance will be useful for improving the current VidWav <b>reference</b> scalable video <b>codec...</b>|$|R
5000|$|FFV1, {{which stands}} for [...] "FF video codec 1", is a {{lossless}} intra-frame video codec. It can use either variable length coding or arithmetic coding for entropy coding. The encoder and decoder {{are part of the}} free, open-source library libavcodec in the project FFmpeg since June 2003. FFV1 is also included in ffdshow and LAV Filters, which makes the video codec available to Microsoft Windows application that support system-wide codecs over Video for Windows (VfW) or DirectShow.FFV1 is particularly popular for its performance regarding speed and size, compared to other lossless preservation codecs, such as M-JPEG2000.The European Broadcasting Union (EBU) lists FFV1 under the codec-family index [...] "31" [...] in their combined list of video <b>codec</b> <b>references.</b>|$|R
