99|450|Public
5000|$|In {{the above}} experiment, {{participants}} {{were presented with}} a list of 100 familiar words and were asked to read them aloud while simultaneously trying to remember each one. Subsequent to this, participants were asked to make a <b>recognition</b> <b>decision</b> {{based on the number of}} [...] "yes" [...] responses that were accompanied by some recollective experience. The results demonstrate the differing relationships between the [...] "yes" [...] and [...] "no" [...] conditions and [...] "remember" [...] and [...] "know" [...] memory performance. The outcome confirms that although familiarity and recollection may involve different processes, the remember/know exemplar does not probe them directly.|$|E
50|$|Gist-based similarity, {{the robust}} {{encoding}} of semantic information rather than distinctive encoding, is another cause of false recognition. When studying {{a list of}} numerous related words, {{there is a high}} level of semantic overlap between memory items. The inability to keep each concepts separate and distinct from one another makes it difficult to recollect specific details, subsequently causing people to make responses based on memory gist's rather than specific details. People may form a well-organized idea of what the semantic gist is, and anything that is semantically similar to that idea may be falsely recognized. Gist-based similarity has also been shown to occur in circumstances in which implicit associative responses are an unlikely source of misattribution. The false recognition error also becomes evident when a time pressure is presented during a <b>recognition</b> <b>decision.</b> Processes that work to discover a source for the basis of recognition take time to execute, {{as a result of a}} lack of time, false recognitions errors are made more often.|$|E
5000|$|The dual-process signal-detection/high-threshold theory {{tries to}} {{reconcile}} dual-process theory and signal-detection theory into one main theory. This theory states that recollection {{is governed by}} a threshold process, while familiarity is not. Recollection is a high-threshold process (i.e., recollection either occurs or does not occur), whereas familiarity is a continuous variable that is governed by an equal-variance detection model. [...] On a recognition test, item recognition is based on recollection if the target item has exceeded threshold, producing an [...] "old" [...] response. If the target item does not reach threshold, the individual must make an item <b>recognition</b> <b>decision</b> based on familiarity. According to this theory, an individual makes a [...] "remember" [...] response when recollection has occurred. A know response is made when recollection has not occurred, and the individual must decide whether they recognize the target item solely on familiarity.Thus, in this model, the participant is thought to resort to familiarity as a backup process whenever recollection fails to occur.|$|E
40|$|In a field study, we {{examined}} choice blindness for eyewitnesses' facial <b>recognition</b> <b>decisions.</b> Seventy-one pedestrians {{were engaged in}} a conversation by two experimenters who pretended to be tourists {{in the center of a}} European city. After a short interval, pedestrians were asked to identify the two experimenters from separate simultaneous six-person photo lineups. Following each of the two forced-choice <b>recognition</b> <b>decisions,</b> they were confronted with their selection and asked to motivate their decision. However, for one of the <b>recognition</b> <b>decisions,</b> the chosen lineup member was exchanged with a previously unidentified member. Blindness for this identity manipulation occurred at the rate of 40. 8 %. Furthermore, the detection rate varied as a function of similarity (high vs. low) between the original choice and the manipulated outcome. Finally, choice manipulations undermined the confidence-accuracy relation for detectors to a greater degree than for blind participants. Stimulus ambiguity is discussed as a moderator of choice blindness...|$|R
40|$|Two-alternative forced-choice {{recognition}} {{tests are}} commonly used to assess recognition accuracy that is uncontaminated by changes in bias. In such tests, participants are asked to endorse the studied item out of 2 presented alternatives. Participants may be further asked to provide confidence judgments for their <b>recognition</b> <b>decisions.</b> It is often assumed that both <b>recognition</b> <b>decisions</b> and confidence judgments in 2 -alternative forced-choice recognition tests depend on participants’ assessments of a difference in strength of memory evidence supporting the 2 alternatives—the relative account. In the present study {{we focus on the}} basis of confidence judgments and we assess the relative account of confidence against the absolute account of confidence, by which in assigning confidence participants consider only strength of memory evidence supporting the chosen alternative. The results of the study show that confidence in 2 -alternative forced-choice <b>recognition</b> <b>decisions</b> is higher when memory evidence is stronger for the chosen alternative and also when memory evidence is stronger for the unchosen alternative. These patterns of results are consistent with the absolute account of confidence in 2 -alternative forced-choice recognition but they are inconsistent with the relative account. (PsycINFO Database Record (c) 2017 APA, all rights reserved...|$|R
5000|$|... #Article: Convention on the <b>recognition</b> of <b>decisions</b> {{recording}} a sex reassignment ...|$|R
40|$|In most {{handwriting}} recognition systems, the processing steps of segmentation, <b>recognition,</b> <b>decision</b> making and postprocessing are serially taken. These systems usually use the resources exhaustively in {{each stage of}} the serial engine. Every stage is tuned to maximize global performance. However, such a paradigm is prone to miss the gloabl optimal point because the individual stages often do not have all the information available. A more interactive model is desirable. In this paper we describe such a model extending the concepts of satis#cing decision mechanisms. Our experiments show proof of validity of the proposed model. 1. INTRODUCTION General processing steps of handwriting document recognition are preprocessing segmentation, <b>recognition,</b> <b>decision</b> making and postprocessing. Preprocessing is primary related to image processing operations such as normalization to remove irregularities of handwriting. Segmentation separates an image into meaningful units of recognition. Recogni [...] ...|$|E
40|$|Similarity {{measures}} play {{an important}} role in data mining, pattern <b>recognition,</b> <b>decision</b> making, machine learning, image process etc. Then, single valued neutrosophic sets (SVNSs) can describe and handle the indeterminate and inconsistent information, which fuzzy sets and intuitionistic fuzzy sets cannot describe and deal with. Therefore, the paper proposes new similarity meas-ures between SVNSs based on the minimum and maxi-mum operators...|$|E
30|$|In this {{simplest}} case, {{confidence in}} the chosen item would be {{based solely on the}} strength of the memory signal generated by that item. Alternatively, the subject might create a new psychological variable by subtracting the familiarity of one item from the other, and the <b>recognition</b> <b>decision</b> (and confidence) might be based on that transformed variable. For this latent variable, d’ 2 AFC > d’old/new.|$|E
40|$|A major puzzle in {{recognition}} memory {{has been the}} process by which participants set reasonable old/new decision criteria when the study and test lists are comprised of items of widely varying types, with differing degrees of baseline familiarity and experience (e. g., words vs. random dot patterns). We present a model of the recognition process that addresses this issue. Its core assumption is that <b>recognition</b> <b>decisions</b> are based not on the absolute value of familiarity, but on how familiarity changes over time as features are sampled from the test item. We model <b>recognition</b> <b>decisions</b> as the outcome of a race between two parallel accumulators: one that accumulates positive changes in familiarity (leading to an “old ” decision) and another that accumulates negative changes (leading to a “new ” decision). Simulations with this model make realistic predictions for recognition performance and latency regardless of the baseline familiarity of study and test items...|$|R
40|$|Background: Theories of {{categorization}} make different {{predictions about}} the underlying processes used to represent categories. Episodic theories suggest that categories are represented in memory by storing previously encountered exemplars in memory. Prototype theories suggest that categories are represented {{in the form of}} a prototype independently of memory. A number of studies that show dissociations between categorization and recognition are often cited as evidence for the prototype account. These dissociations have compared recognition judgements made to one set of items to categorization judgements to a different set of items making a clear interpretation difficult. Instead of using different stimuli for different tests this experiment compares the processes by which participants make decisions about category membership in a prototype-distortion task and with <b>recognition</b> <b>decisions</b> about the same set of stimuli by examining the Event Related Potentials (ERPs) associated with them. Method: Sixty-three participants were asked to make categorization or <b>recognition</b> <b>decisions</b> about stimuli that eithe...|$|R
40|$|Abstract Recognition {{memory is}} {{typically}} examined as a discrete end-state, describable by static variables, such as accuracy, response time, and confidence. In the present study, we combined real-time mouse-tracking with subsequent, overt confidence estimates {{to examine the}} dynamic nature of memory decisions. By examining participants’ streaming x-, y- mouse coordinates during <b>recognition</b> <b>decisions,</b> we observed that movement trajectories revealed underlying response confidence. More confident decisions were associated with shorter decision times and more linear response trajectories. Less confident decisions were made slowly, with increased trajectory curvature. Statistical indices of curvature and decision times, including area-underthe-curve and time to maximum deviation, suggested that memory strength relates to response dynamics. Whether participants were correct or incorrect, old responses showed a stronger correspondence between mouse trajectories and confidence, relative to new responses. We suggest that people subjectively experience a correspondence between feelings of memory and feelings of confidence; that subjective experience reveals itself in real-time decision processes, as suggested by sequential sampling models of <b>recognition</b> <b>decisions...</b>|$|R
40|$|The CALO Meeting Assistant (MA) {{provides}} for distributed meeting capture, annotation, automatic transcription and semantic analysis of multiparty meetings, and {{is part of}} the larger CALO personal assistant system. This paper presents the CALO-MA architecture and its speech recognition and understanding components, which include real-time and offline speech transcription, dialog act segmentation and tagging, topic identification and segmentation, question-answer pair identification, action item <b>recognition,</b> <b>decision</b> extraction, and summarization...|$|E
30|$|To {{directly}} {{test this}} claim, Benjamin, Tullis, and Lee (2013) conducted a recognition experiment with words and manipulated {{the range of}} the scale for the <b>recognition</b> <b>decision</b> between subjects. Subjects provided recognition judgments using only two-value (i.e., binary yes/no) or four- or eight-value scales. On the four- and eight-value scales, the lowest value was labeled “sure no,” whereas the highest value was labeled “sure yes.” Benjamin et al. concluded that the more alternatives given, the poorer the performance: “Rating scales with more options led to lower estimates of recognition than did scales with fewer options” (p. 1601) (but see Kellen, Klauer, & Singmann, 2012). However, one important difference between the procedure in this experiment and that in most confidence-accuracy research is that, in the latter research, experimenters first asked subjects to make a binary yes/no <b>recognition</b> <b>decision</b> and then rated their confidence on a scale for that decision. Thus, in Benjamin et al.’s (2013) terms, the initial judgment is always on a binary scale. Still, this research does provide a reason to expect that in other settings subjects will not use widely varying confidence scales in the same way.|$|E
40|$|Experimental cutting {{tests on}} C 45 carbon steel turning were {{performed}} for sensor fusion based monitoring of chip form through cutting force components and radial displacement measurement. A Principal Component Analysis algorithm was implemented to extract characteristic features from acquired sensor signals. A pattern <b>recognition</b> <b>decision</b> making support system {{was performed by}} inputting the extracted features into feed-forward back-propagation neural networks aimed at single chip form classification and favourable/unfavourable chip type identification. Different neural network training algorithms were adopted and a comparison was propose...|$|E
40|$|People are {{generally}} skilled at using a confidence scale {{to rate the}} strength of their memories over a wide range. Specifically, low-confidence <b>recognition</b> <b>decisions</b> are often associated with close-to-chance accuracy, whereas high-confidence <b>recognition</b> <b>decisions</b> can be associated with close-to-perfect accuracy. However, using a 20 -point rating scale, the authors found that the ability to scale memory strength had its limitations in that a high proportion of list items received the highest rating of 20. Efforts to induce participants to differentiate between these strong memories using emphatic instructions and alternative scales were not successful. Remember/know judgments indicated that these strong and hard-to-scale memories were often based on familiarity (not just recollection). Providing error feedback on a plurals discrimination task finally produced a high-confidence criterion shift. The authors suggest that the ability to scale strong (and almost perfectly accurate) memories may be limited because of the absence of differential error feedback for very strong memories in the past (the kind of differential error feedback that may account for the memory-scaling expertise that participants otherwise exhibit) ...|$|R
40|$|This study {{reports the}} {{findings}} of a study assessing the acceptability differences in decisions made by Certified Public Accounting practitioners (CPA) and students studying to become CPAs. The study responds to researchers’ call for additional research on topics related to accounting decision ethics. Modified managerial and accounting recognition scenarios were used to collect the acceptability of ethical judgments. The analysis employs factor analysis to affirm whether the scenarios are mana­gerial or accounting <b>recognition</b> <b>decisions.</b> The analyses further divides the managerial decisions into either revenue or expense related. The accounting <b>recognition</b> <b>decisions</b> are further divided into those involving an accounting manipulation or inventory related. Students’ acceptability of the accounting transactions was far harsher than the practitioners. However, both students and practitioners considered the accounting scenarios to be unethical. Both students and practitioners judged the managerial revenue scenarios to be ethical but the managerial expense scenarios to be moderately unethical. In addition to the ethical acceptability of accounting transaction, student and practitioner demographic data including age, work experience and academic credentials are investigated to explain the differences...|$|R
40|$|The aim of {{the current}} {{research}} was to identify conditions under which choice blindness in facial <b>recognition</b> <b>decisions</b> occurs. In five experiments, participants watched four mock-crime videos and made choices that were either evaluative (Experiment 1) or absolute in nature (Experiments 2 a-c and 3). When participants were subsequently asked to motivate their choice, they were sometimes presented with choices they had not made. For evaluative decisions, concurrent (27 %) and retrospective blindness rates (21 %) were relatively low compared with previous studies. For absolute decisions, choice-blindness rates varied, depending on when exposure to the manipulated outcome took place (immediate: concurrent 32 - 35 %, retrospective 0 - 6 % [Experiments 2 a-c]; 48 hours' delay: concurrent 68 %, retrospective 39 % [Experiment 3]). We argue that blindness for facial <b>recognition</b> <b>decisions</b> is more likely for evaluative decisions and for longer intervals between decision and manipulation and also for conditions of increased task complexity, which we interpret in terms of ambiguity. Copyright (c) 2014 John Wiley & Sons, Ltd...|$|R
40|$|Abstract. Decision {{trees have}} proved to be {{valuable}} tools for the description, classification and generalization of data. Work on constructing decision trees from data exists in multiple disciplines such as statistics, pattern <b>recognition,</b> <b>decision</b> theory, signal processing, machine learning and artificial neural networks. Researchers in these disciplines, sometimes working on quite different problems, identified similar issues and heuristics for decision tree construction. This paper surveys existing work on decision tree construction, attempting to identify the important issues involved, directions the work has taken and {{the current state of the}} art...|$|E
40|$|Abstract:- A {{method for}} {{improving}} the sea traffic control and surveillance {{is presented in the}} paper. Two signatures are extracted from the primary data, which are provided by a high-resolution radar. A decision is made using each of them by means of a simple or fuzzy logic based k-NN lassifier. We show that the final decision can be improved by the fusion of the two partial decisions corresponding to the two signatures using the fuzzy integral developed by Sugeno. Key-Words:- Radar tracking and <b>recognition,</b> <b>decision</b> fusion, fuzzy integral. ...|$|E
40|$|An {{accurate}} and timely decision {{is crucial in}} any emergency situation. This paper presents a <b>recognition</b> <b>decision</b> making model that adopts the temporal data mining approach in making decisions. Reservoir water level and rainfall measurement were used as the case study to test the developed computational recognition-primed decision (RPD) model in predicting {{the amount of water}} to be dispatched represented by the number of spillway gates. Experimental results indicated that new events can be predicted from historical events. Patterns were extracted and can be transformed into readable and descriptive rule based form. ...|$|E
50|$|According to Krugman, {{there are}} only three levels of {{exposure}} in psychological, not media, terms: Curiosity, <b>recognition</b> and <b>decision.</b>|$|R
40|$|International audienceIn {{the vast}} {{majority}} of the existing statistical systems of <b>recognition,</b> <b>decisions</b> are made based on the probability of correct recognition of object classes, and the probability of their mixing up is not taken into account or taken into account not comprehensively, partially or indirectly. To recognize the object classes it is offered options of integrating recording of all the information that is contained in the matrix of conditional probabilities of recognition...|$|R
5000|$|Agents use a {{model of}} human {{decision}} making process (called <b>recognition</b> primed <b>decision</b> RPD model) to link decision-making tasks to information relevant to the decisions.|$|R
40|$|This paper {{presents}} {{an approach to}} the texture recognition problem that deals with noisy learning and testing data. The method incorporates symbolic machine learning to acquire texture descriptions. Then, these descriptions are optimized in order to remove some nOisylimperfect components. We present methodology and experimental results showing the increase in system recognition effectiveness when optimization of texture descriptions is proceeded continuously. Such a matching of partial concept prototypes with test data gives a recognition characteristics obtained for different concept optimization degrees. Then. the dynamics of this characteristics is used to make <b>recognition</b> <b>decision...</b>|$|E
40|$|We {{investigated}} {{whether the}} use of perceptual fluency as recognition cue by patients with Alzheimer disease (AD) depends on whether fluency is perceived as relevant to the <b>recognition</b> <b>decision.</b> In normal subjects, enhanced perceptual fluency increased positive recognition responses when study and test stimuli were presented in the same sensory modality but not when stimuli were presented in different modalities (Westerman et al., J. of Mem. & Lang., 47, 2002). These results suggest that {{the use of}} perceptual fluency as a heuristic in recognition memory depends on the correspondence between study and test modalities and thus on the perceived usefulness of fluency. We investigated this change of sensory modality between study and test phases in 16 AD patients and 16 matched normal controls by using a verbal recognition task. The perceptual fluency of recognition test items was enhanced by briefly presenting a prime that matched the subsequent test item. We observed that changes in modality attenuated the contribution of fluency to the <b>recognition</b> <b>decision</b> in both subjects groups. In addition, we noted a positive correlation between fluency use and metamemory self-evaluation. These {{results suggest that the}} fluency heuristic is subject to metacognitive control in AD patients, exactly {{in the same way as}} normal subject, since patients’ attributions of perceptual fluency depend on expectations about relevance of fluency as memory cue. Peer reviewe...|$|E
30|$|When a final <b>recognition</b> <b>decision</b> can be {{acquired}} by combining {{two or more}} match scores of different biometric matchers, fusion {{is said to be}} done at the score-level. After capturing the raw data from sensors and extracting feature vectors, the next level of fusion is based on match scores. It is relatively easy to access and combine the scores generated by different biometric matchers; as a result, score-level fusion is the most commonly used methods in multibiometric systems. There are many types of score-level fusion such as likelihood-ratio-based fusion and transformation-based fusion. In this paper, transformation-based fusion (sum rule) was used.|$|E
40|$|Context {{plays an}} {{important}} role in a discriminator's ability to make appropriate <b>recognition</b> <b>decisions,</b> such as accepting what is acceptable and rejecting what is not acceptable. Previously it was shown that in both honey bees and stingless bees, discriminating workers (guards) make more errors towards conspecific non-nestmates when the guards are removed from the natural hive entrance. However, it may be that guards, in addition to making incorrect <b>recognition</b> <b>decisions,</b> also may adopt non-guarding behaviours. Here, we tested honey bee guards in two contexts (natural versus unnatural) against five types of introduced arthropods (conspecific nestmates and non-nestmates; allospecific wasps, beetles and woodlice), which should be rejected without error. We scored a guard's response as accept, reject, avoid and ignore. Total errors significantly increased from natural to unnatural contexts. Specifically, guards were significantly more likely to make an acceptance error, guarding and accepting both conspecific and allospecific non-nestmates, in the unnatural context. Importantly, guards were significantly more likely to adopt a non-guarding behaviour in the unnatural context, which usually involved ignoring or avoiding, where a guard makes contact but then immediately retreats, the introduced arthropod. Overall, these data demonstrate the context is important. Removing a guard from the home that it protects elicits either incorrect discrimination or, additionally, a complete lack of discriminator behaviour altogether...|$|R
50|$|The dual-process account {{states that}} <b>recognition</b> <b>decisions</b> {{are based on}} the {{processes}} of recollection and familiarity. Recollection is a conscious, effortful process in which specific details of the context in which an item was encountered are retrieved. Familiarity is a relatively fast, automatic process in which one gets the feeling the item has been encountered before, but the context in which it was encountered is not retrieved. According to this view, remember responses reflect recollections of past experiences and know responses are associated with recognition on the basis of familiarity.|$|R
40|$|It {{has been}} {{suggested}} that hippocampal activity predicts subsequent recognition success when <b>recognition</b> <b>decisions</b> are based disproportionately on recollection, whereas perirhinal activity predicts <b>recognition</b> success when <b>decisions</b> are based primarily on familiarity. Another perspective is that both hippocampal and perirhinal activity are predictive of overall memory strength. We tested the relationship between brain activity during learning and subsequent memory strength. Activity in a number of cortical regions (including regions within the ‘‘default network’’) was negatively correlated with subsequent memory strength, suggesting that this activity reflects inattention or mind wandering (and, consequently, poor memory). In contrast, activity in both hippocampus and perirhinal cortex positively correlated with the subsequent memory strength of remembered items. This finding suggests that both structures cooperate during learning to determine the memory strength of what is being learned...|$|R
40|$|Abstract — This paper {{addresses}} {{the problem of}} recognizing complex objects in images. The proposed approach {{is based on a}} prototype-centered object representation which describes objects as sets of local features. During an evolutionary learning step the model is derived from a set of sample images. The proceeding of the training is measured with regard to the recognition rate as well as the coverage of the training samples. The proposed method is tested by the recognition of 14 classes of cars in highway scenes. A classification rate of 98 percent is achieved. Index Terms — Image processing, object <b>recognition,</b> <b>decision</b> trees, genetic algorithms...|$|E
40|$|Abstract. In this paper, we {{investigate}} {{how to improve}} Mandarin LVCSR performance by integrating multiple hypotheses from recognizers running in parallel. Different recognizers are trained by employing: (1) different phone sets, (2) different front-ends, and (3) different training sets. N-best hypotheses are merged into a character transition network (CTN) and ROVER is used to select the final <b>recognition</b> <b>decision.</b> Both read and spontaneous speech are tested in the ROVER framework. In comparing with the best individual recognizer in the parallel group, the fully integrated ROVER system achieves a relative Chinese character error reduction of 10. 1 %. ...|$|E
40|$|D-S {{evidence}} theory is widely {{applied to the}} fields of information fusion, pattern <b>recognition,</b> <b>decision</b> analysis and other fields. When information are given as interval numbers with high conflicting evidences, traditional combinations rules may result in antinomy that some evidences are discarded while conflict factor is zero. To avoid this inconsequence, a method of disjointing algorithm is proposed to reallocate the focal elements and their basic probability assignments for intersecting intervals. Then the weighted average method is used to combine the evidences. Simulation {{results show that the}} proposed method can get more reasonable results in combining interval-valued evidences...|$|E
40|$|International audienceIn this paper, {{we propose}} a query by string word {{spotting}} system able to extract arbitrary key-words in handwritten documents, taking both segmen-tation and <b>recognition</b> <b>decisions</b> {{at the line}} level. The system relies on {{the combination of a}} HMM line model made of keyword and non-keyword (filler) models, with a deep neural network (DNN) that estimates the state-dependent observation probabilities. Experiments are carried out on RIMES database, an unconstrained hand-written document database that is used for benchmark-ing different handwriting recognition tasks. The ob-tained results show the superiority of the proposed frame-work over the classical GMM-HMM and standard HMM hybrid architectures...|$|R
5000|$|In {{the hybrid}} {{multi-level}} fusion, {{the integration of}} input modalities is distributed among the <b>recognition</b> and <b>decision</b> levels. The hybrid multi-level fusion includes the following three methodologies: finite-state transducers, multimodal grammars [...] and dialogue moves.|$|R
40|$|The testing effect, or {{the finding}} that taking an initial test {{improves}} subsequent memory performance, is a robust and reliable phenomenon—as long as the final test involves recall. Few {{studies have examined the}} effects of taking an initial recall test on final recognition performance, and results from these studies are equivocal. In 3 experiments, we attempt to demonstrate that initial testing can change the ways in which later <b>recognition</b> <b>decisions</b> are executed even when no difference can be detected in the recognition hit rates. Specifically, initial testing was shown to enhance later recollection but leave familiarity unchanged. This conclusion emerged from three dependent measures: source memory, exclusion per-formance, and remember/know judgments...|$|R
