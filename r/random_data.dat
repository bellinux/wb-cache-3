1152|2704|Public
25|$|The Medical Director will {{compare the}} {{reported}} case to <b>random</b> <b>data.</b>|$|E
25|$|The many {{applications}} of randomness {{have led to}} many different methods for generating <b>random</b> <b>data.</b> These methods may vary as to how unpredictable or statistically random they are, and how quickly they can generate random numbers.|$|E
25|$|As a {{potential}} counter-measure to forced disclosure some cryptographic software supports plausible deniability, where the encrypted data is indistinguishable from unused <b>random</b> <b>data</b> (for example {{such as that}} of a drive which has been securely wiped).|$|E
40|$|This paper {{focuses on}} variational {{solutions}} of the Cauchy {{problem for a}} nonlinear wave equation with space-time fractional Brownian noise driving force of Hurst index H∈ (1 / 2, 1) and <b>random</b> initial <b>data.</b> It is shown that this problem has a unique solution which depends continuously on the <b>random</b> initial <b>data...</b>|$|R
5000|$|... #Caption: Evolution of <b>random</b> initial <b>data</b> {{under the}} Cahn-Hilliard {{equation}} with [...] and , demonstrating phase separation.|$|R
5000|$|Marr Prize Paper: Bradley Davis, P. Thomas Fletcher, Elizabeth Bullitt, Sarang Joshi: Population Shape Regression From <b>Random</b> Design <b>Data</b> ...|$|R
25|$|Windows NT will {{allocate}} {{disk space}} to files on FAT in advance, selecting large contiguous areas, but {{in case of}} a failure, files which were being appended will appear larger than they were ever written into, with a lot of <b>random</b> <b>data</b> at the end.|$|E
25|$|The {{number of}} swaps {{can be reduced}} by calculating the {{position}} of multiple elements before moving them. For example, if the target position of two elements is calculated before they are moved into the right position, the number of swaps can be reduced by about 25% for <b>random</b> <b>data.</b> In the extreme case, this variant works similar to merge sort.|$|E
25|$|To {{explain the}} {{categories}} in more detail, {{they are the}} preconditions {{of the construction of}} objects in the mind. Indeed, to even think of the sun and stone presupposes the category of subsistence, that is, substance. For the categories synthesize the <b>random</b> <b>data</b> of the sensory manifold into intelligible objects. This means that the categories are also the most abstract things one can say of any object whatsoever, and hence one can have an a priori cognition of the totality of all objects of experience if one can list all of them. To do so, Kant formulates another transcendental deduction.|$|E
3000|$|Calculating {{how long}} exactly the data {{stays in the}} queue is not possible, due to the <b>random</b> arrival <b>data</b> A [...]...|$|R
50|$|However, <b>Random</b> Test <b>Data</b> Generation {{is usually}} {{used as a}} {{benchmark}} as it has the lowest acceptable rate of generating test data.|$|R
40|$|Test campaigns usually {{require only}} a {{restricted}} subset of paths {{in a program}} to be thoroughly tested. As random testing (RT) offers interesting fault-detection capacities at low cost, we face the problem of building a sequence of <b>random</b> test <b>data</b> that execute only a subset of paths in a program. We address this problem with an original technique based on backward symbolic execution and constraint propagation to generate <b>random</b> test <b>data</b> based on an uniform distribution. Our approach derives path conditions and computes an over-approximation of their associated subdomain to find such a uniform sequence. The challenging problem consists in building efficiently a path-oriented <b>random</b> test <b>data</b> generator by minimizing the number of rejects within the generated random sequence. Our first experimental results, conducted over a few academic examples, clearly show a dramatic improvement of our approach over classical random testing. 1...|$|R
25|$|While these {{algorithms}} are asymptotically efficient on <b>random</b> <b>data,</b> {{for practical}} efficiency on real-world data various modifications are used. First, the overhead of these algorithms becomes significant on smaller data, so often a hybrid algorithm is used, commonly switching to insertion sort once {{the data is}} small enough. Second, the algorithms often perform poorly on already sorted data or almost sorted data – these are common in real-world data, and can be sorted in O(n) time by appropriate algorithms. Finally, {{they may also be}} unstable, and stability is often a desirable property in a sort. Thus more sophisticated algorithms are often employed, such as Timsort (based on merge sort) or introsort (based on quicksort, falling back to heap sort).|$|E
500|$|Belldandy is {{depicted}} as being a Goddess working with the fictional [...] "Goddess Relief Agency". Although the series never specifically mentions her age, there are hints that she is between 18 and 28 when the series begins: in the original manga her birthdate is shown as NOT KNOWN—the English translation offers no year, but simply says [...] "UNKNOWN"—while in the anime the more specific 1985/01/01 is employed (even {{though it is not}} her actual birthdate,she just created a <b>random</b> <b>data</b> to be accepted in Nekomi and because her actual birthday is October 1, based on her personality). This should not be seen as conclusive as Eileen Stevens, who provides the voice of Belldandy in the English-language version of the TV series, states that while Belldandy is [...] "young in appearance, late teens to early 20s, she's ageless, perhaps thousands of years old." ...|$|E
2500|$|... 2008 – In a {{comic book}} written by Scott McCloud about Google Chrome, monkeys on laptops are used as an analogy to <b>random</b> <b>data.</b>|$|E
5000|$|Covariance or cross-covariance {{between two}} <b>random</b> {{variables}} or <b>data</b> sets ...|$|R
50|$|<b>Random</b> test <b>data</b> {{generation}} {{is probably the}} simplest method for generation of test data. The advantage {{of this is that}} {{it can be used to}} generate input for any type of program. Thus to generate test data we can randomly generate a bit stream and let it the represent the data type needed. However, <b>random</b> test <b>data</b> generation does not generate quality test data as it does not perform well in terms of coverage. Since the data generated is based solely on probability it cannot accomplish high coverage as the chances of it finding semantically small faults is quite low.|$|R
50|$|Inphase Technologies {{researchers}} use axicons in holographic data storage. Their goal is {{to determine}} the effects of axicons on the Fourier distribution of <b>random</b> binary <b>data</b> spectrum of a spatial light modulator (SLM).|$|R
2500|$|Pareidolia ( [...] ) is a {{psychological}} phenomenon {{in which the}} mind responds to a stimulus, usually an image or a sound, by perceiving a familiar pattern where none exists (e.g., in <b>random</b> <b>data).</b>|$|E
2500|$|Each {{share of}} the secret {{must be at least}} as large as the secret itself. This result is based in {{information}} theory, but can be understood intuitively. Given [...] shares, no information whatsoever can be determined about the secret. Thus, the final share must contain as much information as the secret itself. There is sometimes a workaround for this limitation by first compressing the secret before sharing it, but this is often not possible because many secrets (keys for example) look like high-quality <b>random</b> <b>data</b> and thus are hard to compress.|$|E
2500|$|Several {{operating}} systems include arc4random, an API originating in OpenBSD {{providing access to}} a random number generator originally based on RC4. In OpenBSD 5.5, released in May 2014, arc4random was modified to use ChaCha20. The implementations of arc4random in NetBSD and Linux's libbsd also use ChaCha20. In the 2017 release of its desktop and mobile {{operating systems}}, Apple replaced RC4 with AES in its implementation of arc4random. Man pages for the new arc4random include the backronym [...] "A Replacement Call for Random" [...] for ARC4 as a mnemonic, as it provides better <b>random</b> <b>data</b> than rand (...) does.|$|E
30|$|Before {{the data}} analysis, the missing <b>data</b> was verified. <b>Random</b> missing <b>data</b> for each {{participant}} did not exceed 5 %; hence, missing values were treated by mean imputation (Hair Jr., Black, Babin, Anderson, & Tatham, 2009).|$|R
50|$|These {{forms of}} missingness take {{different}} types, with different {{impacts on the}} validity of conclusions from research: Missing completely at random, missing at random, and missing not at <b>random.</b> Missing <b>data</b> can be handled similarly as censored data.|$|R
3000|$|MIMO-OFDM {{systems were}} used for simulations, where each packet {{consists}} of a training sequence followed by 34 <b>random</b> OFDM <b>data</b> symbols. In this paper, we mainly consider 2 × 2 and 3 × 3 MIMO-OFDM systems, where N [...]...|$|R
2500|$|The server {{responds}} with a ServerHello message, containing the chosen protocol version, a random number, cipher suite and compression method from the choices {{offered by the}} client. If the server recognizes the session id sent by the client, it {{responds with}} the same session id. The client uses this to recognize that a resumed handshake is being performed. If the server does not recognize the session id sent by the client, it sends a different value for its session id. This tells the client that a resumed handshake will not be performed. At this point, both the client and server have the [...] "master secret" [...] and <b>random</b> <b>data</b> to generate the key data {{to be used for}} this connection.|$|E
2500|$|In {{practice}} {{it might be}} possible to construct scenarios by eliciting experts' opinions on the future. The number of constructed scenarios should be relatively modest so that the obtained deterministic equivalent can be solved with reasonable computational effort. It is often claimed that a solution that is optimal using only a few scenarios provides more adaptable plans than one that assumes a single scenario only. In some cases such a claim could be verified by a simulation. In theory some measures of guarantee that an obtained solution solves the original problem with reasonable accuracy. Typically in applications only the first stage optimal solution [...] has a practical value since almost always a [...] "true" [...] realization of the <b>random</b> <b>data</b> will be different from the set of constructed (generated) scenarios.|$|E
2500|$|In an {{ordinary}} full handshake, the server sends a session id {{as part of}} the ServerHello message. The client associates this session id with the server's IP address and TCP port, so that when the client connects again to that server, it can use the session id to shortcut the handshake. In the server, the session id maps to the cryptographic parameters previously negotiated, specifically the [...] "master secret". Both sides must have the same [...] "master secret" [...] or the resumed handshake will fail (this prevents an eavesdropper from using a session id). The <b>random</b> <b>data</b> in the ClientHello and ServerHello messages virtually guarantee that the generated connection keys will be different from in the previous connection. In the RFCs, this type of handshake is called an abbreviated handshake. It is also described in the literature as a restart handshake.|$|E
50|$|It is also {{possible}} to apply the above considerations to a single <b>random</b> variable (<b>data</b> point) x, rather than a set of observations. In a Bayesian context, this {{is equivalent to the}} prior predictive distribution of a data point.|$|R
40|$|We present {{parallel}} {{computational geometry}} algorithms that are scalable, architecture independent, easy to implement, and have, with high probability, an optimal time complexity for uniformly distributed <b>random</b> input <b>data.</b> Our methods apply to multicomputers with arbitrary interconnection network or bus system...|$|R
50|$|The Linux kernel generates entropy from {{keyboard}} timings, mouse movements, and IDE timings {{and makes}} the <b>random</b> character <b>data</b> available to other operating system processes through the special files /dev/random and /dev/urandom. This capability was introduced in Linux version 1.3.30.|$|R
2500|$|Jürgen Schmidhuber's formal {{theory of}} {{creativity}} postulates that creativity, curiosity, and interestingness are by-products {{of a simple}} computational principle for measuring and optimizing learning progress. Consider an agent able to manipulate its environment and thus its own sensory inputs. The agent can use a black box optimization method such as reinforcement learning to learn (through informed trial and error) sequences of actions that maximize the expected sum of its future reward signals. There are extrinsic reward signals for achieving externally given goals, such as finding food when hungry. But Schmidhuber's objective function to be maximized also includes an additional, intrinsic term to model [...] "wow-effects." [...] This non-standard term motivates purely creative behavior of the agent even {{when there are no}} external goals. A wow-effect is formally defined as follows. As the agent is creating and predicting and encoding the continually growing history of actions and sensory inputs, it keeps improving the predictor or encoder, which can be implemented as an artificial neural network or some other machine learning device that can exploit regularities in the data to improve its performance over time. The improvements can be measured precisely, by computing the difference in computational costs (storage size, number of required synapses, errors, time) needed to encode new observations before and after learning. This difference depends on the encoder's present subjective knowledge, which changes over time, but the theory formally takes this into account. The cost difference measures the strength of the present [...] "wow-effect" [...] due to sudden improvements in data compression or computational speed. It becomes an intrinsic reward signal for the action selector. The objective function thus motivates the action optimizer to create action sequences causing more wow-effects. Irregular, <b>random</b> <b>data</b> (or noise) do not permit any wow-effects or learning progress, and thus are [...] "boring" [...] by nature (providing no reward). Already known and predictable regularities also are boring. Temporarily interesting are only the initially unknown, novel, regular patterns in both actions and observations. This motivates the agent to perform continual, open-ended, active, creative exploration.|$|E
50|$|Attacks {{that allow}} {{distinguishing}} ciphertext from <b>random</b> <b>data.</b>|$|E
50|$|To measure cluster {{tendency}} is to measure to what degree clusters exist in the data to be clustered, and may be performed as an initial test, before attempting clustering. One {{way to do this}} is to compare the data against <b>random</b> <b>data.</b> On average, <b>random</b> <b>data</b> should not have clusters.|$|E
40|$|We study shock {{statistics}} in the scalar conservation law ∂tu+∂xf(u) = 0, x ∈ R, t> 0, with a convex flux f and <b>random</b> initial <b>data.</b> We {{show that a}} large class of <b>random</b> initial <b>data</b> (Markov processes with downward jumps and derivatives of Lévy processes with downward jumps) is preserved by the entropy solution to the conservation law and we derive kinetic equations that describe the evolution of shock statistics. These kinetic equations are equivalent to a Lax pair. Moreover, they admit remarkable exact solutions for Burgers equation (f(u) = u 2 / 2) suggesting the complete integrability of Burgers turbulence. MSC classification: 60 J 75, 35 R 60, 35 L 67, 82 C 99...|$|R
40|$|It is {{well known}} that in {{decision}} making under uncertainty, while we are guided by a general (and abstract) theory of probability and of statistical inference, each specific type of observed data requires its own analysis. Thus, while textbook techniques treat precisely observed data in multivariate analysis, there are many open research problems when data are censored (e. g., in medical or bio-statistics), missing, or partially observed (e. g., in bioinformatics). Data can be imprecise due to various reasons, e. g., due to fuzziness of linguistic data. Imprecise observed data are usually called coarse data. In this chapter, we consider coarse data which are both random and fuzzy. Fuzziness is a form of imprecision often encountered in perception-based information. In order to develop statistical reference procedures based on such data, we need to model <b>random</b> fuzzy <b>data</b> as bona fide random elements, i. e., we need to place <b>random</b> fuzzy <b>data</b> completely within the rigorous theory of probability. This chapter presents the most general framework for <b>random</b> fuzzy <b>data,</b> namely the framework of random fuzzy sets. We also describe several applications of this framework...|$|R
50|$|Data masking or data {{obfuscation}} is {{the process}} of hiding original <b>data</b> with <b>random</b> characters or <b>data.</b>|$|R
