202|614|Public
25|$|The {{lifetime}} is a {{specification of}} a collection of tested capacitors and delivers an expectation of the behavior of similar types. This lifetime definition corresponds with the time of the constant <b>random</b> <b>failure</b> rate in the bathtub curve.|$|E
25|$|The {{published}} {{figures show}} that both capacitor types, tantalum and aluminum, are reliable components, comparable with other electronic components and achieving safe operation for decades under normal conditions. But a great difference exists {{in the case of}} wear-out failures. Tantalum capacitors with solid electrolyte have no wear-out mechanism so that the constant failure rate is least, up to the point when all capacitors fail. Electrolytic capacitors with non-solid electrolyte, however, have a limited time of constant random failures up to that point when the wear-out failures start. This time of the constant <b>random</b> <b>failure</b> rate corresponds with the lifetime or service life of “wet” aluminum electrolytic capacitors.|$|E
2500|$|Encouraging a Relapse - To bypass simple {{short-lived}} [...] "obedience" [...] {{which tends}} to lead to lapses {{in the absence of}} the therapist, Erickson would occasionally arrange for his patients to fail in their attempts to improve, for example by overreaching. Failure is part of life, and in that fragile time where the patient is learning to live, think and behave differently, a <b>random</b> <b>failure</b> can be catastrophic. Deliberately causing a relapse allowed Erickson to control the variables of that failure, and to cast it in a positive therapeutic light for the patient.|$|E
40|$|Many {{networks}} {{are characterized by}} highly heterogeneous distributions of links, which are called scale-free networks and the degree distributions follow p(k) ∼ ck −α. We study the robustness of scale-free networks to <b>random</b> <b>failures</b> from the character of their heterogeneity. Entropy of the degree distribution can be an average measure of a network’s heterogeneity. Optimization of scale-free network robustness to <b>random</b> <b>failures</b> with average connectivity constant is equivalent to maximize the entropy of the degree distribution. By examining the relationship of entropy of the degree distribution, scaling exponent and the minimal connectivity, we get the optimal design of scale-free network to <b>random</b> <b>failures.</b> We conclude that entropy of the degree distribution is an effective measure of network’s resilience to <b>random</b> <b>failures.</b> Key words: scale-free networks; information theory; entropy; <b>random</b> <b>failures</b> PACS: 89. 75. -k; 89. 75. Fb...|$|R
50|$|The {{second part}} is a {{constant}} failure rate, known as <b>random</b> <b>failures.</b>|$|R
40|$|The scale-fee networks, having {{connectivity}} distribution P(k) ∼ k −α (where k is {{the site}} connectivity), is very resilient to <b>random</b> <b>failures</b> but fragile to intentional attack. The {{purpose of this paper}} is to find the network design guideline which can make the robustness of the network to both <b>random</b> <b>failures</b> and intentional attack maximum while keeping the average connectivity per node constant. We find that when = 3 the robustness of the scale-free networks reach its maximum value if the minimal connectivity m = 1, but when is larger than four, the networks will become more robust to <b>random</b> <b>failures</b> and targeted attacks as the minimal connectivity m gets larger...|$|R
2500|$|The default IEEE 754 {{exception}} handling behaviour of resumption following pre-substitution of a default value avoids the risks inherent in changing flow of program control on numerical exceptions. For example, in 1996 the maiden {{flight of the}} Ariane 5 (Flight 501) ended in a catastrophic explosion {{due in part to}} the Ada programming language {{exception handling}} policy of aborting computation on arithmetic error, which in this case was a 64-bit floating point to 16-bit integer conversion overflow. In the Ariane Flight 501 case, the programmers protected only four out of seven critical variables against overflow due to concerns about the computational constraints of the on-board computer and relied on what turned out to be incorrect assumptions about the possible range of values for the three unprotected variables because they reused code from the Ariane 4, for which their assumptions were correct. According to William Kahan, the loss of Flight 501 would have been avoided if the IEEE 754 exception-handling policy of default substitution had been used because the overflowing 64-bit to 16-bit conversion that caused the software to abort occurred in a piece of code that turned out to be completely unnecessary on the Ariane 5. The official report on the crash (conducted by an inquiry board headed by Jacques-Louis Lions) noted that [...] "An underlying theme in the development of Ariane 5 is the bias towards the mitigation of <b>random</b> <b>failure.</b> The supplier of the inertial navigation system (SRI) was only following the specification given to it, which stipulated that in the event of any detected exception the processor was to be stopped. The exception which occurred was not due to <b>random</b> <b>failure</b> but a design error. The exception was detected, but inappropriately handled because the view had been taken that software should be considered correct until it is shown to be at fault. [...] Although the failure was due to a systematic software design error, mechanisms can be introduced to mitigate this type of problem. For example the computers within the SRIs could have continued to provide their best estimates of the required attitude information. There is reason for concern that a software exception should be allowed, or even required, to cause a processor to halt while handling mission-critical equipment. Indeed, the loss of a proper software function is hazardous because the same software runs in both SRI units. In the case of Ariane 501, this resulted in the switch-off of two still healthy critical units of equipment." ...|$|E
50|$|During the <b>random</b> <b>failure</b> of nodes or {{targeted}} attack hubs are {{key components}} of the network. During the <b>random</b> <b>failure</b> of nodes in network hubs are responsible for exceptional robustness of network. The chance that a <b>random</b> <b>failure</b> would delete the hub is very small, because hubs coexists {{with a large number}} of small degree nodes. The removal of small degree nodes does not have a large effect on integrity of network. Even though the random removal would hit the hub, the chance of fragmantation of network is very small because the remaining hubs would hold the network together. In this case, hubs are the strength of a scale-free networks.|$|E
5000|$|A <b>random</b> <b>failure</b> {{to execute}} correctly: This {{is called a}} [...] "random fault" [...] or [...] "random Byzantine" [...] fault.|$|E
30|$|The {{results from}} this {{evaluation}} show clearly that the proposed scheme is robust in terms of <b>random</b> node <b>failures,</b> as the benefits are clearly visible for well-connected parts of the network, while not reducing the performance in case of <b>random</b> <b>failures</b> compared to the original protocol.|$|R
30|$|The {{robustness}} values {{recorded for}} each metric, for each network considered, are then compared. It has, so far, been {{established that the}} random networks respond similarly to both <b>random</b> <b>failures</b> and targeted attacks. In comparison, the scale-free networks are robust against <b>random</b> <b>failures</b> but are highly sensitive to targeted attacks (Albert et al., 2000). This {{is due to the}} presence of hubs (highly connected nodes) in scale-free networks, which are the nodes targeted by an attacker.|$|R
40|$|It {{has been}} found that the {{networks}} with scale-free distribution are very resilient to <b>random</b> <b>failures.</b> The purpose of this work is to determine the network design guideline which maximize the network robustness to <b>random</b> <b>failures</b> with the average number of links per node of the network is constant. The optimal value of the distribution exponent and the minimum connectivity to different network size are given in this paper. Finally, the optimization strategy how to improve the evolving network robustness is given. Comment: 6 pages, 1 figur...|$|R
50|$|The {{value of}} k shows {{the kind of}} failure being experienced. If k<1, then the failure rate {{decreases}} with time. This implies that the weak and defective parts fail in the beginning, with the harder sections surviving. If k=1, the rate of failure remains constant. This implies that there is <b>random</b> <b>failure</b> occurring. Thus, {{there should be some}} external factor strong enough to cause <b>random</b> <b>failure</b> irrespective of whether the section is strong or weak. If the value of k>1, the rate of failure increases over time. This points to some kind of ageing process, the weakening of the material with the passage of time.|$|E
50|$|The {{lifetime}} is a {{specification of}} a collection of tested capacitors and delivers an expectation of the behavior of similar types. This lifetime definition corresponds with the time of the constant <b>random</b> <b>failure</b> rate in the bathtub curve.|$|E
5000|$|... #Caption: The 'bathtub curve' hazard {{function}} (blue, upper solid line) is {{a combination}} of a decreasing hazard of early failure (red dotted line) and an increasing hazard of wear-out failure (yellow dotted line), plus some constant hazard of <b>random</b> <b>failure</b> (green, lower solid line).|$|E
5000|$|... #Caption: [...] Bathtub curve with {{times of}} [...] "early failures", [...] "random failures", and [...] "wear-out failures". The time of <b>random</b> <b>failures</b> {{is the time}} of {{constant}} failure rate ...|$|R
40|$|In {{distributed}} soft real-time systems, {{maximizing the}} aggregate quality-of-service (QoS) {{is a typical}} system-wide goal, and addressing the problem through distributed optimization is challenging. Subtasks are subject to unpredictable failures in many practical environments, and this makes the problem much harder. In this paper, we present a robust optimization framework for maximizing the aggregate QoS {{in the presence of}} <b>random</b> <b>failures.</b> We introduce the notion of K-failure to bound the effect of <b>random</b> <b>failures</b> on schedulability. Using this notion we define the concept of K-robustness that quantifies the degree of robustness on QoS guarantee in a probabilistic sense. The parameter K helps to tradeoff achievable QoS versus robustness. The proposed robust framework produces optimal solutions through distributed computations on the basis of Lagrangian duality, and we present some implementation techniques. Our simulation results show that the proposed framework can probabilistically guarantee sub-optimal QoS which remains feasible even in the presence of <b>random</b> <b>failures.</b> ...|$|R
40|$|A {{central issue}} in complex {{networks}} is tolerance to <b>random</b> <b>failures</b> and intentional attacks. Current literature emphasizes the dichotomy between networks with a power-law node connectivity distribution, which are robust to <b>random</b> <b>failures</b> but fragile to targeted attacks, versus networks with an exponentially decaying connectivity distribution, which are less tolerant to failures but more resilient to attacks. We prove analytically that the optimal network configuration under a classic measure of robustness is altogether different {{from both of}} the above: in all cases, failure and/or attack, {{there are no more}} than three distinct node connectivities in the optimal network...|$|R
5000|$|... #Caption: The {{life time}} (load life) of {{capacitors}} correspondents {{with the time}} of constant <b>random</b> <b>failure</b> rate shown in the bathtub curve. For electrolytic capacitors with non-solid electrolyte and supercapacitors ends {{this time with the}} beginning of wear out failures due to evaporation of electrolyte ...|$|E
5000|$|Chaos Monkeys: Obscene Fortune and <b>Random</b> <b>Failure</b> in Silicon Valley is an {{autobiography}} written by Antonio García Martínez. The book compares Silicon Valley to the [...] "chaos monkeys" [...] of society. It details his career experiences with launching a tech startup, {{selling it to}} Twitter, and working at Facebook from its pre-IPO stage.|$|E
50|$|This {{equation}} {{cannot be}} solved analytically, {{but can be}} graphed numerically. To summarize the important points, when gamma is large, the network acts as a random network, and attack robustness become similar to <b>random</b> <b>failure</b> robustness of a random network. However, when gamma is smaller, the critical threshold for attacks on scale-free networks becomes relatively small, indicating a weakness to targeted attacks.|$|E
50|$|Recently, {{the study}} of complex {{networks}} has been expanded to networks of networks. If those networks are interdependent, they become significantly more vulnerable to <b>random</b> <b>failures</b> and targeted attacks and exhibit cascading failures and first-order percolation transitions.|$|R
5000|$|... #Caption: Bathtub curve with {{times of}} [...] "early failures", [...] "random failures", and [...] "wear-out failures". The time of <b>random</b> <b>failures</b> {{is the time}} of {{constant}} failure rate and corresponds with the lifetime of non-solid electrolytic capacitors.|$|R
25|$|Reliability {{normally}} {{is shown}} as a bathtub curve and {{is divided into}} three areas: early failures or infant mortality <b>failures,</b> constant <b>random</b> <b>failures</b> and wear out failures. Failures totalized in a failure rate are short circuit, open circuit, and degradation failures (exceeding electrical parameters).|$|R
5000|$|Duke Energy {{has noted}} that a rapid failure of the Jocassee dam would flood the plant and cause the loss of power and safety equipment, {{potentially}} damaging its three reactor cores within 8 to 9 hours. It could further lead to reactor containment failure within 59 to 68 hours, triggering a significant release of radioactivity into the environment. Duke informed the NRC about this flooding hazard as early as January 1996. [...] Duke Energy estimated {{the probability of a}} <b>random</b> <b>failure</b> of Jocassee Dam is 1.3(10−5)/year, while the NRC puts the estimate at 2.8(10−4)/year.|$|E
5000|$|Encouraging a Relapse - To bypass simple {{short-lived}} [...] "obedience" [...] {{which tends}} to lead to lapses {{in the absence of}} the therapist, Erickson would occasionally arrange for his patients to fail in their attempts to improve, for example by overreaching. Failure is part of life, and in that fragile time where the patient is learning to live, think and behave differently, a <b>random</b> <b>failure</b> can be catastrophic. Deliberately causing a relapse allowed Erickson to control the variables of that failure, and to cast it in a positive therapeutic light for the patient.|$|E
50|$|In skip graphs, fault {{tolerance}} describes {{the number of}} nodes which can be disconnected from the skip graph by failures of other nodes. Two failure models have been examined; random failures and adversarial failures. In the <b>random</b> <b>failure</b> model any node may fail independently from any other node with some probability. The adversarial model assumes node failures are planned such that the worst possible failure is achieved at each step, the entire skip graph structure is known and failures are chosen to maximize node disconnection. A drawback of skip graphs {{is that there is}} no repair mechanism; currently the only way to remove and to repair a skip graph is to build a new skip graph with surviving nodes.|$|E
40|$|We {{develop a}} {{methodology}} for analyzing the percolation phenomena of two mutually coupled (interdependent) networks {{based on the}} cavity method of statistical mechanics. In particular, we {{take into account the}} influence of degree-degree correlations inside and between the networks on the network robustness against targeted attacks and <b>random</b> <b>failures.</b> We show that the developed methodology is reduced to the well-known generating function formalism in the absence of degree-degree correlations. The validity of the developed methodology is confirmed by a comparison with the results of numerical experiments. Our analytical results imply that the robustness of the interdependent networks depends considerably on both the intra- and internetwork degree-degree correlations in the case of targeted attacks, whereas the significance of the degree-degree correlations is relatively low for <b>random</b> <b>failures.</b> Comment: 12 pages, 6 figure...|$|R
40|$|We study {{cascading}} failures {{in a system}} comprising interdependent networks/systems, in which nodes rely on other nodes both in the same system and in other systems to perform their function. The (inter-) dependence among nodes is modeled using a dependence graph, where the degree vector of a node determines the number of other nodes it can potentially cause to fail in each system through aforementioned dependency. In particular, we {{examine the impact of}} the variability and dependence properties of node degrees on the probability of {{cascading failures}}. We show that larger variability in node degrees hampers widespread failures in the system, starting with <b>random</b> <b>failures.</b> Similarly, positive correlations in node degrees make it harder to set off an epidemic of failures, thereby rendering the system more robust against <b>random</b> <b>failures.</b> Comment: 1 figur...|$|R
5000|$|The {{bathtub curve}} is {{generated}} by mapping the rate of early [...] "infant mortality" [...] failures when first introduced, the rate of <b>random</b> <b>failures</b> with constant failure rate during its [...] "useful life", and finally the rate of [...] "wear out" [...] failures as the product exceeds its design lifetime.|$|R
5000|$|It uses a {{mechanical}} system called the Adventure Learning System, and is (as of 2006) the only role-playing game {{to use that}} system. In the ALS system, the rule set used by the game master (called the [...] "Adventure Master") to operate the environment and non-player characters is {{significantly different from the}} rule set used by the players to operate their personal characters. In particular, enemies roll a smaller die than the players (d8 versus d10), making it markedly more likely that PCs will succeed in their actions than their antagonists. This also has the effect of making <b>random</b> <b>failure</b> more likely for NPCs than for PCs, as the lowest value on an eight-sided die comes up 12.5% of the time, compared to 10% of the time for a ten-sided die.|$|E
5000|$|The default IEEE 754 {{exception}} handling behaviour of resumption following pre-substitution of a default value avoids the risks inherent in changing flow of program control on numerical exceptions. For example, in 1996 the maiden {{flight of the}} Ariane 5 (Flight 501) ended in a catastrophic explosion {{due in part to}} the Ada programming language {{exception handling}} policy of aborting computation on arithmetic error, which in this case was a 64-bit floating point to 16-bit integer conversion overflow. In the Ariane Flight 501 case, the programmers protected only four out of seven critical variables against overflow due to concerns about the computational constraints of the on-board computer and relied on what turned out to be incorrect assumptions about the possible range of values for the three unprotected variables because they reused code from the Ariane 4, for which their assumptions were correct. According to William Kahan, the loss of Flight 501 would have been avoided if the IEEE 754 exception-handling policy of default substitution had been used because the overflowing 64-bit to 16-bit conversion that caused the software to abort occurred in a piece of code that turned out to be completely unnecessary on the Ariane 5. The official report on the crash (conducted by an inquiry board headed by Jacques-Louis Lions) noted that [...] "An underlying theme in the development of Ariane 5 is the bias towards the mitigation of <b>random</b> <b>failure.</b> The supplier of the inertial navigation system (SRI) was only following the specification given to it, which stipulated that in the event of any detected exception the processor was to be stopped. The exception which occurred was not due to <b>random</b> <b>failure</b> but a design error. The exception was detected, but inappropriately handled because the view had been taken that software should be considered correct until it is shown to be at fault. ... Although the failure was due to a systematic software design error, mechanisms can be introduced to mitigate this type of problem. For example the computers within the SRIs could have continued to provide their best estimates of the required attitude information. There is reason for concern that a software exception should be allowed, or even required, to cause a processor to halt while handling mission-critical equipment. Indeed, the loss of a proper software function is hazardous because the same software runs in both SRI units. In the case of Ariane 501, this resulted in the switch-off of two still healthy critical units of equipment." ...|$|E
50|$|Diverse {{infrastructures}} such {{as water}} supply, transportation, fuel and power stations are coupled together. Owing to this coupling, interdependent networks are extremely sensitive to <b>random</b> <b>failure,</b> and in particular to targeted attacks, such that a failure of {{a small fraction of}} nodes from one network can produce an iterative cascade of failures in several interdependent networks. Electrical blackouts frequently result from a cascade of failures between interdependent networks, and the problem has been dramatically exemplified by the several large-scale blackouts that have occurred in recent years. Blackouts are a fascinating demonstration of the important role played by the dependencies between networks. For example, the September 28, 2003 blackout in Italy resulted in a widespread failure of the railway network, health care systems, and financial services and, in addition, severely influenced communication networks. The partial failure of the communication system in turn further impaired the power grid management system, thus producing a positive feedback on the power grid. This example emphasizes how inter-dependence can significantly magnify the damage in an interacting network system. A framework to study the cascading failures between coupled networks based on percolation theory was developed recently. Cascading failures in spatially embedded systems have beenshown to lead to extreme vulnerability.|$|E
50|$|Random walks {{can be used}} {{to explore}} a {{multilayer}} system with the ultimate goal to unravel its mesoscale organization, i.e. to partition it in communities, and have been recently used to better understand navigability of multilayer networks and their resilience to <b>random</b> <b>failures,</b> as well as for exploring efficiently this type of topologies.|$|R
2500|$|FIT is {{the number}} of {{failures}} that can be expected in one billion (109) component-hours of operation at fixed working conditions (e.g., 1000 components for 1nbsp&million hours, or 1nbsp& million components for 1000 hours (1nbsp&ppm/1000 hours) each during the period of constant <b>random</b> <b>failures.</b> This failure rate model implicitly assumes the idea of [...] "random failure". Individual components fail at random times but at a predictable rate. Failures are short circuits, open circuits and degradation failures (exceeding specified limits of electrical parameters).|$|R
40|$|We {{developed}} a scheme {{for evaluating the}} size of the largest connected subnetwork (giant component) in random networks and the percolation threshold when sites (nodes) and/or bonds (edges) are removed from the networks based on the cavity method of statistical mechanics of disordered systems. An advantage of our scheme is the capability of handling targeted attacks on sites/bonds in the presence of degree correlations beyond naive analyses on <b>random</b> <b>failures</b> (crashes) in networks of no degree correlations. We apply our scheme particularly to random networks of bimodal degree distribution (two-peak networks), which have been proposed in earlier studies as robust networks against <b>random</b> <b>failures</b> of site and/or targeted attacks on sites, and show that the correlations among degrees affect a network's robustness against targeted attacks on sites or bonds non-trivially depending on details of network configurations. Comment: 11 pages, 6 figure...|$|R
