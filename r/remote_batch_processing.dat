1|1691|Public
50|$|<b>Remote</b> <b>Batch</b> <b>Processing</b> (RBP) was a {{capability}} {{that existed}} in VS/9, although it was never completely exploited, probably due to limited demand. RBP allowed remote users to submit batch jobs for execution on the mainframe and receive the results back at their offsite printer. Typically, a remote batch device consisted of a card reader and a printer connected to a communication line which interfaced with the remote batch services in the operating system. Like a local batch job, operators could receive requests for tape or disk mounts/dismounts and program prompts for responses to questions.|$|E
50|$|Like CP-V, CP-6 {{had five}} access modes, which {{operated}} concurrently: <b>batch</b> <b>processing,</b> <b>remote</b> <b>batch,</b> timesharing, transaction <b>processing,</b> and real-time processing. It included multiprogramming and operated on multiple CPUs.|$|R
50|$|The {{remaining}} models initially ran the <b>Batch</b> <b>Processing</b> Monitor (BPM), later augmented with a timesharing option (BTM); {{the combined}} system was usually {{referred to as}} BPM/BTM. The Universal Time-Sharing System (UTS) became available in 1971, supporting much enhanced time-sharing facilities. A compatible upgrade (or renaming) of UTS, Control Program V (CP-V) became available starting in 1973 and added real-time, <b>remote</b> <b>batch,</b> and transaction <b>processing.</b> A dedicated real-time OS, Control Program for Real-Time (CP-R) was also available for Sigma 9 systems. The Xerox Operating System (XOS), intended as an IBM DOS replacement, also runs on Sigma 6/7/9 systems, but never gained real popularity.|$|R
50|$|The terms <b>Remote</b> <b>Batch,</b> <b>Remote</b> Job System and Remote Job Processing {{are also}} used for RJE facilities.|$|R
50|$|Early {{mainframe}} computers (in the 1950s) were non-interactive, instead using <b>batch</b> <b>processing.</b> IBM's Job Control Language (JCL) is the {{archetype of}} languages {{used to control}} <b>batch</b> <b>processing.</b>|$|R
30|$|There {{are a few}} {{differences}} between utterance-based <b>batch</b> <b>processing</b> and full <b>batch</b> <b>processing.</b> In utterance-based <b>batch</b> <b>processing,</b> we normalize the features of each utterance to zero mean and compute a 100 -dimensional i-vector from this utterance. In full <b>batch</b> <b>processing,</b> we normalize the features of each speaker in a room to zero mean and compute a 100 -dimensional i-vector from this speaker in the room. In order to assign utterances in a room to speakers, we carry out speaker diarization using {{a modified version of}} the multi-stage segmentation and clustering system [42] as described before.|$|R
30|$|Another {{difference}} between utterance-based versus full <b>batch</b> <b>processing</b> {{is that we}} are able to decode with MLIFD features in full <b>batch</b> <b>processing.</b> The MLIFD features for an utterance are transformed using LDA + STC + FMLLR before input to the neural net. FMLLR transform per utterance resulted in significant increase in WER, and therefore, the MLIFD feature was not used in utterance-based <b>batch</b> <b>processing.</b> In full <b>batch</b> <b>processing,</b> the FMLLR is computed from all the utterances of a speaker in the room. In this scenario, MLIFD features gave very good results.|$|R
50|$|Memo-posting is a {{term used}} in {{traditional}} computerized banking environments where <b>batch</b> <b>processing</b> is employed. It represents temporary credit or debit transactions/entries made to an account for which the complete posting to update the balance will be done {{as part of the}} EOD(end-of-day) <b>batch</b> <b>processing.</b> The temporary transaction created as part of the memo-posting will be reversed/removed after the actual transaction is posted in <b>batch</b> <b>processing.</b>|$|R
5000|$|<b>Batch</b> <b>processing</b> - the {{traditional}} {{date and time}} based execution of background tasks based on a defined period during which resources were available for <b>batch</b> <b>processing</b> (the <b>batch</b> window). In effect the original mainframe approach transposed onto the open systems environment.|$|R
30|$|The {{decoding}} {{algorithm is}} slightly different {{depending on whether}} we are doing utterance-based <b>batch</b> <b>processing</b> or full <b>batch</b> <b>processing.</b> For the maximum likelihood inverse filtering-based dereverberation (MLIFD) features that use FMLLR transform, we only use full <b>batch</b> <b>processing,</b> since we need to compute the FMLLR transform for the speaker from all the utterances of the speaker in the room. Computing the FMLLR transform from a single short utterance gives poor results (we need over 20 s of audio to estimate reasonable FMLLR transforms).|$|R
40|$|This paper {{presents}} a constraint programming approach for a <b>batch</b> <b>processing</b> machine {{on which a}} finite number of jobs of non-identical sizes must be sched-uled. A <b>batch</b> <b>processing</b> machine can process several jobs simultaneously. Such machines are encountered in chemical, pharmaceutical, aeronautical and semi...|$|R
5000|$|Multiple user {{interfaces}} (<b>batch</b> <b>processing,</b> ncurses, QT, Java) ...|$|R
30|$|In utterance-based <b>batch</b> <b>processing,</b> we {{computed}} i-vectors {{separately for}} each utterance {{from three different}} features, and the corresponding i-vector was used when recognizing using that feature. In full <b>batch</b> <b>processing,</b> we computed the i-vector for each speaker using the multi-taper MFCC features and used these i-vectors during training/recognition using other features. This strategy did not work well. Only the WER for MMFBl features went down while the results for other features were worse than utterance-based processing. Therefore, we used the results from utterance-based <b>batch</b> <b>processing</b> for the other features (note MLIFD does not use i-vectors).|$|R
30|$|Some {{frameworks}} {{adopt the}} micro <b>batch</b> <b>processing</b> on Mapreduce model for real-time processing [3, 4] which performs {{the map and}} reduce operation many times whenever input data occurs in real time. It is a special case of <b>batch</b> <b>processing</b> when the <b>batch</b> size is small. It can simply process real-time streams using existing Mapreduce models. However, it is even less time-sensitive than near real-time. Generally, <b>batch</b> <b>processing</b> involves three separate processes such as data collection, map, and reduce. For this reason, it could incur latency costs when processing large-scale images.|$|R
40|$|Strong {{competition}} in banking market {{has led to}} a significant reliance of banks on information technology. In the last decade, main {{progress has been made in}} introducing straightthrough <b>processing</b> (STP) and <b>batch</b> <b>processing</b> in banking information systems. In this paper we analyse the impact of application of these processes in banks. We choose four parameters to follow: system quality information quality, service quality and user satisfaction. As a sample of case study we select Aseba BI integrated banking information system, produced by ASSECO-SEE. Through the analysis of several examples: <b>batch</b> <b>processing</b> in core banking system, <b>batch</b> <b>processing</b> in credit module, STP in national payment processes, STP in international payment processes, automation of Treasury back office (TBO) and Treasury (Trading) and Securities trading we conclude that <b>batch</b> <b>processing</b> and STP have great impact on selected parameters...|$|R
5000|$|... #Subtitle level 3: Scheduling in the <b>batch</b> <b>processing</b> {{environment}} ...|$|R
5000|$|<b>Batch</b> <b>processing</b> ability by Marko Kuder, mentored by Zoran Mesec ...|$|R
50|$|Scripting {{languages}} {{became popular}} as they evolved along with <b>batch</b> <b>processing.</b>|$|R
50|$|<b>Batch</b> <b>processing</b> of {{multiple}} images is possible via the Batch Inpaint version.|$|R
50|$|MapReduce can be {{used for}} <b>batch</b> <b>processing</b> of data and {{aggregation}} operations.|$|R
5000|$|Classic Operating Systems: From <b>Batch</b> <b>Processing</b> to Distributed Systems (editor, 2001, [...] ) ...|$|R
50|$|Sometimes {{real-time}} posting {{is thought}} to mean 'there is no batch'. This is not the case. Real-time posting systems still need to support <b>batch</b> <b>processing.</b> <b>Batch</b> <b>processing</b> is attractive for some processing {{as it is a}} cost effective means to process large groups of items. Examples of those batches would be check (cheque) clearing files or payment exchange files.|$|R
40|$|Abstract We {{consider}} {{the problem of}} minimizing the makespan(Cmax) on m identical parallel <b>batch</b> <b>processing</b> machines. The <b>batch</b> <b>processing</b> machine can process up to B jobs simultaneously. The jobs that are processed together form a batch, and all jobs in a batch start and complete at the same time. For a batch of jobs, the processing time of the batch {{is equal to the}} largest processing time among the jobs in the batch. In this paper, we design a fully polynomial time approximation scheme (FPTAS) to solve the bounded identical parallel batch scheduling problem Pm|B < n|Cmax when the number of identical parallel <b>batch</b> <b>processing</b> machines m is constant...|$|R
50|$|BACHO-format {{transactions}} are primarily used in <b>batch</b> <b>processing</b> systems running on MVS mainframe computers.|$|R
50|$|It {{can be used}} {{either through}} command line, text based or <b>batch</b> <b>processing</b> mode.|$|R
50|$|MapEditor enhances {{productivity}} for vector {{editing and}} automatic <b>batch</b> <b>processing</b> in AutoCAD or MicroStation.|$|R
50|$|QC-format {{transactions}} are primarily used in <b>batch</b> <b>processing</b> systems running on MVS mainframe computers.|$|R
5000|$|Job Processing Cycle - for {{detailed}} description of <b>batch</b> <b>processing</b> in the mainframe field ...|$|R
5000|$|The JobScheduler can be {{used for}} <b>batch</b> <b>processing</b> to run a series of operations.|$|R
5000|$|Intuitive, easy to learn, {{property}} driven {{user interface}} including molecule editor and <b>batch</b> <b>processing.</b>|$|R
5000|$|Time-sharing, which {{replaced}} sequential <b>batch</b> <b>processing</b> of {{jobs with}} concurrent {{use of a}} system ...|$|R
3000|$|To {{obtain the}} optimal {{parameters}} combination of MAFFT program, we used <b>batch</b> <b>processing</b> through Perl programming (ActivePerl 5.16. 2 version) language on Windows 7 OS: the step of GOP is 0.1, the step of GEP is 0.03, the SM is BLOSUM 30 /BLOSUM 45 /BLOSUM 62 /BLOSUM 80 /PAM 100 /PAM 200 respectively. The <b>batch</b> <b>processing</b> script is following: [...]...|$|R
40|$|In {{this paper}} we {{consider}} the problem of scheduling jobs with equal processing times on a single <b>batch</b> <b>processing</b> machine so as to minimize a primary and a secondary criteria. We provide optimal polynomial algorithms for various combinations of the primary and secondary criteria. This is the Pre-Published Version. 1 Bicriterion scheduling with equal processing times on a <b>batch</b> <b>processing</b> machin...|$|R
40|$|The {{computational}} {{complexity of}} scheduling jobs with released dates on an unbounded <b>batch</b> <b>processing</b> machine to minimize total completion time and on parallel unbounded <b>batch</b> <b>processing</b> machines to minimize total weighted completion time remains open. In this note {{we show that}} the first problem is NP-hard with respect to id-encoding, and the second one is strongly NP-hard. Department of Logistics and Maritime Studie...|$|R
50|$|Transaction {{processing}} {{is distinct}} from other computer <b>processing</b> models <b>batch</b> <b>processing,</b> time-sharing, and real-time processing.|$|R
5000|$|... 1975 - Unipersonnel launched. Systems updated {{to enable}} on-line data entry instead of <b>batch</b> <b>processing.</b>|$|R
