10000|10000|Public
5|$|The {{game has}} a {{different}} system in terms of <b>rewarding</b> experience points. It rewards experience points for killing enemies, but only until their respective entries in the bestiary are completed. Additionally, the game gives experience points only for completing quests and discovering new areas. This means that non-violent approaches such as stealth are just as <b>rewarding.</b>|$|E
5|$|Animal studies {{indicate}} that administration of bupropion at less than the recommended therapeutic dose may actually enhance the <b>rewarding</b> properties of nicotine, i.e., low doses augment nicotine self-administration and high doses attenuate it.|$|E
5|$|Dark Souls (PS3, Xbox 360) by From Software {{generated}} universal {{critical acclaim}} upon release. Known for its brutally challenging gameplay, critics consider Dark Souls {{to be one}} of the most influential and <b>rewarding</b> video games of the seventh console generation.|$|E
40|$|SummaryThe time of <b>reward</b> and the {{temporal}} structure of <b>reward</b> occurrence fundamentally influence behavioral reinforcement and decision processes [1 – 11]. However, despite knowledge about timing in sensory and motor systems [12 – 17], we {{know little about}} temporal mechanisms of neuronal <b>reward</b> processing. In this experiment, visual stimuli predicted different instantaneous probabilities of <b>reward</b> occurrence that resulted in specific temporal <b>reward</b> structures. Licking behavior demonstrated that the animals had developed expectations for the time of <b>reward</b> that reflected the instantaneous <b>reward</b> probabilities. Neurons in the amygdala, {{a major component of}} the brain's <b>reward</b> system [18 – 29], showed two types of <b>reward</b> signal, both of which were sensitive to the expected time of <b>reward.</b> First, the time courses of anticipatory activity preceding <b>reward</b> delivery followed the specific instantaneous <b>reward</b> probabilities and thus paralleled {{the temporal}} <b>reward</b> structures. Second, the magnitudes of responses following <b>reward</b> delivery covaried with the instantaneous <b>reward</b> probabilities, reflecting the influence of temporal <b>reward</b> structures at the moment of <b>reward</b> delivery. In being sensitive to temporal <b>reward</b> structure, the <b>reward</b> signals of amygdala neurons reflected the temporally specific expectations of <b>reward.</b> The data demonstrate an active involvement of amygdala neurons in timing processes that are crucial for <b>reward</b> function...|$|R
40|$|Abstract. In this paper, total <b>reward</b> {{stochastic}} {{games are}} surveyed. Total <b>reward</b> games are motivated as a refinement of average <b>reward</b> games. The total <b>reward</b> {{is defined as}} the limiting average of the partial sums of the stream of payoffs. It is shown that total <b>reward</b> games with finite state space are strategically equivalent to a class of average <b>reward</b> games with an infinite countable state space. The role of stationary strategies in total <b>reward</b> games is investigated in detail. Further, it is outlined that, for total <b>reward</b> games with average <b>reward</b> value 0 and where additionally both players possess average <b>reward</b> optimal station-ary strategies, it holds that the total <b>reward</b> value exists. Key Words. Stochastic games, total <b>reward,</b> average <b>reward,</b> value existence. 1...|$|R
30|$|A {{weighted}} <b>reward</b> criterion {{consists of}} a weighted combination of the average <b>reward</b> criterion and the discounted <b>reward</b> criterion. The decision maker can pay more or less emphasis on the long-term <b>reward</b> versus short-term <b>reward</b> by changing their associated weights. Krass et al. (1992) presented a general formula as shown in Eq. (1) to calculate the weighted <b>reward</b> {{in terms of the}} average <b>reward</b> and the discounted <b>reward.</b> This “weighted reward” is a convex combination of the average <b>reward</b> and discounted <b>reward</b> by varying their weights (Krass et al. 1992).|$|R
5|$|Mephedrone {{is often}} {{consumed}} with alcohol. A study in mice investigated the interrelation {{between these two}} substances, focusing on the psychostimulant and <b>rewarding</b> properties of mephedrone. It found that at low (non stimulant) doses alcohol significantly enhanced the psychostimulant effects of mephedrone. This effect was mediated {{by an increase in}} synaptic dopamine, as haloperidol, but not ketanserin, was able to block the potentiation by alcohol. Similarly, the <b>rewarding</b> properties of mephedrone were enhanced by a low non-rewarding dose of alcohol.|$|E
5|$|The MTV Millennial Awards {{also known}} as MTVMiAw or MTV MA are awards created by MTV Latin America that reward {{the best of the}} Millennial Generation as well as <b>rewarding</b> music and films and the best of the digital world.|$|E
5|$|The game's {{multiplayer}} received mixed reviews. Prell {{thought that}} the mission-design was varied, and the voting system kept the mode from being repetitive. He also praised the interconnected structure between the single-player and multiplayer, noting that the items that could be carried over from multiplayer to campaign made the mode feel <b>rewarding</b> for players. Reiner {{thought that the}} action featured in this mode is satisfying, but thought that the system lacked enough depth and complexity to engage players. Patterson echoed similar thoughts, and felt that the ability of players to switch between the campaign and the Chaos Squad mode made the multiplayer mode a <b>rewarding</b> experience. Brown criticized the mode, saying that its difficulty was not properly scaled.|$|E
40|$|The {{representation}} of <b>reward</b> anticipation and <b>reward</b> prediction errors {{is the basis}} for reward-associated learning. The {{representation of}} whether or not a <b>reward</b> occurred (<b>reward</b> receipt) is important for decision making. Recent studies suggest that, while <b>reward</b> anticipation and <b>reward</b> prediction errors are encoded in the midbrain and the ventral striatum, <b>reward</b> receipts are encoded in the medial orbitofrontal cortex. In order to substantiate this functional specialization we analyzed data from an fMRI study in which 59 subjects completed two simple monetary <b>reward</b> paradigms. Because <b>reward</b> receipts and <b>reward</b> prediction errors were correlated, a statistical model comparison was applied separating the effects of the two. <b>Reward</b> prediction error fitted BOLD responses significantly better than <b>reward</b> receipt in the midbrain and the ventral striatum. Conversely, <b>reward</b> receipt fitted BOLD responses better in the orbitofrontal cortex. Activation related to <b>reward</b> anticipation was found in the orbitofrontal cortex. The results confirm a functional specialization of behaviorally important aspects of <b>reward</b> processing within the mesolimbic dopaminergic system...|$|R
40|$|The authors give an {{overview}} of how various video game <b>reward</b> systems provide positive experiences to players, and propose classifications for <b>rewards</b> and <b>reward</b> characteristics for further analysis. We also discuss what <b>reward</b> systems encourage players to do, and describe how they provide fun even before players receive their <b>rewards.</b> Next, we describe how game <b>reward</b> systems {{can be used to}} motivate or change behaviors in the physical world. One of our main suggestions is that players can have fun with both <b>rewards</b> and <b>reward</b> mechanisms—enjoying <b>rewards</b> while reacting to the motivation that such <b>rewards</b> provide. Based on relevant psychological theories, we discuss how <b>reward</b> mechanisms foster intrinsic motivation while giving extrinsic <b>rewards.</b> We think that <b>reward</b> systems and mechanisms in modern digital games provide social meaning for players primarily through motivation, enhanced status within gaming societies, and the use of <b>rewards</b> as social tools...|$|R
50|$|Primary <b>reward</b> {{are those}} {{necessary}} {{for the survival of}} one's self and offspring, and include homeostatic (e.g., palatable food) and reproductive (e.g., sexual contact and parental investment) <b>rewards.</b> Intrinsic <b>rewards</b> are unconditioned <b>rewards</b> that are attractive and motivate behavior because they are inherently pleasurable. Extrinsic <b>rewards</b> (e.g., money) are conditioned <b>rewards</b> that are attractive and motivate behavior, but are not inherently pleasurable. Extrinsic <b>rewards</b> derive their motivational value {{as a result of a}} learned association (i.e., conditioning) with intrinsic <b>rewards.</b> Extrinsic <b>rewards</b> may also elicit pleasure (e.g., from winning a lot of money in a lottery) after being classically conditioned with intrinsic <b>rewards.</b>|$|R
5|$|Walking Safaris are {{possible}} in the buffer zone areas - and very <b>rewarding</b> with Corbett having a very healthy and lush, rich buffer zone around; look for lodges around with trained staff for the same.|$|E
5|$|Pacino found acting enjoyable and {{realized}} he had a gift for it while studying at The Actors Studio. However, his early work was not financially <b>rewarding.</b> After his success on stage, Pacino made his film debut in 1969 with a brief appearance in Me, Natalie, an independent film starring Patty Duke. In 1970, Pacino signed with the talent agency Creative Management Associates (CMA).|$|E
5|$|Philip-Jon Haarsma , more {{commonly}} known as PJ Haarsma, is a Canadian born science fiction author {{best known for his}} creation of the Rings of Orbis universe, which encompasses The Softwire series of books. Haarsma created a free, online role-playing game, also called the Rings of Orbis, set in the same universe. Both the book-series and the game target young, often reluctant readers in an attempt to encourage them by <b>rewarding</b> them for reading.|$|E
40|$|The {{current study}} {{investigated}} monetary and social <b>reward</b> processing in children, adolescents and adults with adapted incentive-delay tasks and self-report questionnaires. Both tasks had {{three levels of}} <b>reward</b> magnitudes (no, low, and high). Qualified participants received 15 Chinese Yuan and an honor certificate as monetary and social <b>rewards,</b> respectively. The results indicated that both monetary and social <b>rewards</b> effectively speeded up responses for all three age groups as <b>reward</b> magnitude increased in the choice reaction time task. Among adolescents and adults, males exhibited faster responses in high <b>reward</b> than in low <b>reward</b> condition, while females responded equally fast in both conditions. Among children, girls responded faster to high <b>reward</b> than low <b>reward</b> condition. However, boys committed more errors than girls in low and high <b>reward</b> conditions, and they had exhibited more errors in high <b>reward</b> than that in no <b>reward</b> condition for social <b>reward.</b> Regarding the subjective ratings, both children and adolescents reported higher motivation for social <b>reward</b> than for monetary <b>reward.</b> These findings indicated that the males in the adolescent and adult groups were more sensitive to <b>reward</b> than were the females. Moreover, tangible and quantitative social <b>reward</b> had stronger incentive power than monetary <b>reward</b> among children and adolescents. </p...|$|R
40|$|Prediction about {{outcomes}} {{constitutes a}} basic mechanism underlying informed economic decision making. A stimulus constitutes a <b>reward</b> predictor when it provides {{more information about}} the <b>reward</b> than the environmental background. <b>Reward</b> prediction can be manipulated in two ways, by varying the <b>reward</b> paired with the stimulus, as done traditionally in neurophysiological studies, and by varying the background <b>reward</b> while holding stimulus-reward pairing constant. Neuronal mechanisms involved in <b>reward</b> prediction should also be sensitive to changes in background <b>reward</b> independently of stimulus-reward pairing. We tested this assumption on a major brain structure involved in <b>reward</b> processing, the central and basolateral amygdala. In a 2 × 2 design, we examined the influence of <b>rewarded</b> and unrewarded backgrounds on neuronal responses to <b>rewarded</b> and unrewarded visual stimuli. Indeed, responses to the unchanged <b>rewarded</b> stimulus depended crucially on background <b>reward</b> in a population of amygdala neurons. Elevating background <b>reward</b> {{to the level of the}} <b>rewarded</b> stimulus extinguished these responses, and lowering background <b>reward</b> again reinstated the responses without changes in stimulus-reward pairing. None of these neurons responded specifically to an inhibitory stimulus predicting less <b>reward</b> compared with background (negative contingency). A smaller group of amygdala neurons maintained stimulus responses irrespective of background <b>reward,</b> possibly reflecting stimulus-reward pairing or visual sensory processes without <b>reward</b> prediction. Thus in being sensitive to background <b>reward,</b> the responses of a population of amygdala neurons to phasic stimuli appeared to follow the full criteria for excitatory <b>reward</b> prediction (positive contingency) rather than reflecting simple stimulus-reward pairing (contiguity) ...|$|R
40|$|Gender {{differences}} in <b>reward</b> sensitivity and information processing {{were examined in}} two studies using a dynamic decision-making task. In Experiment 1, the optimal strategy involved forgoing an option that provided larger immediate <b>rewards</b> in favor of one yielding larger delayed <b>rewards.</b> In Experiment 2, the optimal strategy was to select the option that provided larger immediate <b>rewards</b> because the delayed <b>reward</b> option never gave larger <b>rewards</b> than the immediate <b>reward</b> option. Foregone <b>reward</b> information was either presented or withheld. In Experiment 1, information regarding foregone <b>rewards</b> biased participants toward the sub-optimal choice, whereas in Experiment 2, foregone <b>rewards</b> directed participants toward the optimal option. Males selected the optimal choice more in the delayed <b>rewards</b> task, while females were more biased toward the poorer choice by foregone <b>reward</b> information. In contrast, females outperformed males in the immediate <b>rewards</b> task. The results suggest a gender difference in information processing styles during decision-making...|$|R
5|$|The {{experience}} was <b>rewarding</b> for Pei, {{and he agreed}} immediately {{to work with the}} group again. The new project was the Miho Museum, to display Koyama's collection of tea ceremony artifacts. Pei visited the site in Shiga Prefecture, and during their conversations convinced Koyama to expand her collection. She conducted a global search and acquired more than 300items showcasing the history of the Silk Road.|$|E
5|$|The game {{received}} negative {{reviews from}} critics and {{was described as}} another entry {{in a long line}} of poorly developed movie tie-ins. Reviewers enjoyed the opportunity to play as a Predator, but complained that the game was too easy and not <b>rewarding,</b> particularly the simple artificial intelligence of enemies. The visuals and audio of the game were also considered of poor quality.|$|E
5|$|The {{music for}} Final Fantasy Tactics A2: Grimoire of the Rift was also {{composed}} by Hitoshi Sakimoto, {{this time with}} the assistance of composers from his company Basiscape. The music was released as Final Fantasy Tactics A2: Grimoire of the Rift Original Soundtrack by Square Enix in 2007. It was enjoyed by reviewers, who found it to be pleasant and <b>rewarding.</b>|$|E
40|$|Human <b>reward</b> pursuit {{is often}} assumed to involve {{conscious}} processing of <b>reward</b> information. However, recent research revealed that <b>reward</b> cues enhance cognitive performance even when perceived without awareness. Building on this discovery, the present functional MRI study tested two hypotheses using a <b>rewarded</b> mental-rotation task. First, we examined whether subliminal <b>rewards</b> engage the ventral striatum (VS), an area implicated in <b>reward</b> anticipation. Second, we examined differences in neural responses to supraliminal versus subliminal <b>rewards.</b> Results indicated that supraliminal, but not subliminal, high-value <b>reward</b> cues engaged brain areas involved in <b>reward</b> processing (VS) and task performance (supplementary motor area, motor cortex, and superior temporal gyrus). This pattern of findings is striking given that subliminal <b>rewards</b> improved performance {{to the same}} extent as supraliminal <b>rewards.</b> So, the neural substrates of conscious versus unconscious <b>reward</b> pursuit are vastly different-but despite their differences, conscious and unconscious <b>reward</b> pursuit may still produce the same behavioral outcomes. Hum Brain Mapp 35 : 5578 - 5586, 2014...|$|R
50|$|<b>Reward</b> {{management}} {{consists of}} analysing and controlling employee remuneration, compensation {{and all of}} the other benefits for the employees. <b>Reward</b> management aims to create and efficiently operate a <b>reward</b> structure for an organisation. <b>Reward</b> structure usually consists of pay policy and practices, salary and payroll administration, total <b>reward,</b> minimum wage, executive pay and team <b>reward.</b>|$|R
40|$|Monetary <b>rewards</b> {{are uniquely}} human. Because money {{is easy to}} {{quantify}} and present visually, it is the <b>reward</b> of choice for most fMRI studies, even though it cannot be handed over to participants inside the scanner. A typical fMRI study requires hundreds of trials and thus small amounts of monetary <b>rewards</b> per trial (e. g. 5 p) if all trials are to be treated equally. However, small payoffs can have detrimental effects on performance due to their limited buying power. Hypothetical monetary <b>rewards</b> can overcome the limitations of smaller monetary <b>rewards</b> but it is less well known whether predictors of hypothetical <b>rewards</b> activate <b>reward</b> regions. In two experiments, visual stimuli were associated with hypothetical monetary <b>rewards.</b> In Experiment 1, we used stimuli predicting either visually presented or imagined hypothetical monetary <b>rewards,</b> together with non-rewarding control pictures. Activations to <b>reward</b> predictive stimuli occurred in <b>reward</b> regions, namely the medial orbitofrontal cortex and midbrain. In Experiment 2, we parametrically varied the amount of visually presented hypothetical monetary <b>reward</b> keeping constant the amount of actually received <b>reward.</b> Graded activation in midbrain was observed to stimuli predicting increasing hypothetical <b>rewards.</b> The results demonstrate the efficacy of using hypothetical monetary <b>rewards</b> in fMRI studies...|$|R
5|$|With {{characteristic}} caution, {{the brothers}} first flew the 1902 glider as an unmanned kite, {{as they had}} done with their two previous versions. <b>Rewarding</b> their wind tunnel work, the glider produced the expected lift. It also had a new structural feature: a fixed, rear vertical rudder, which the brothers hoped would eliminate turning problems.|$|E
5|$|A stealth {{game is a}} type {{of video}} game that tasks the player with using stealth to avoid or {{overcome}} antagonists. Games in the genre typically allow the player to remain undetected by hiding, using disguises or avoiding noise. Some games allow the player to choose between a stealthy approach or directly attacking antagonists, but mostly <b>rewarding</b> the player for greater levels of stealth. The genre has employed espionage, counter-terrorism and rogue themes, with protagonists who are special forces operatives, spies, thieves, ninjas, and assassins. Some games have also combined stealth elements with other genres, such as first-person shooters and even platformers.|$|E
5|$|After {{the death}} of his father in 1853 Markham needed paid employment, and in December 1853 secured a junior clerkship in the Legacy Duty Office of the Inland Revenue at a salary of £90 per annum (around £6,000 in 2008). He found the work tedious, but after six months was able to {{transfer}} to the forerunner of what became, in 1857, the India Office. Here, the work was interesting and <b>rewarding,</b> with sufficient time to allow him to travel and pursue his geographical interests.|$|E
40|$|This {{research}} has been conducted to ascertain the validity of existing videogame <b>reward</b> categorisations. An overview of current videogame <b>reward</b> types is provided and the need for further {{research in the area of}} videogame <b>reward</b> systems is identified. Possible limitations of the primary existing <b>reward</b> taxonomy are identified. We propose a definition of videogame <b>rewards</b> and present initial findings on a partially validated videogame <b>reward</b> taxonomy. Future games and gamified applications stand to benefit from a categorisation of videogame <b>rewards,</b> as videogame <b>rewards</b> play a pivotal role in player motivation...|$|R
40|$|Costs and <b>rewards</b> are {{important}} ingredients for cyberphysical systems, modelling critical aspects like energy consumption, task completion, repair costs, and memory usage. This paper introduces Markov <b>reward</b> automata, {{an extension of}} Markov automata that allows the modelling of systems incorporating <b>rewards</b> (or costs) in addition to nondeterminism, discrete probabilistic choice and continuous stochastic timing. <b>Rewards</b> come in two flavours: action <b>rewards,</b> acquired instantaneously when taking a transition; and state <b>rewards,</b> acquired while residing in a state. We present algorithms to optimise three <b>reward</b> functions: the expected accumulative <b>reward</b> until a goal is reached; the expected accumulative <b>reward</b> until a certain time bound; and the long-run average <b>reward.</b> We have implemented these algorithms in the SCOOP/IMCA tool chain and show their feasibility via several case studies...|$|R
30|$|<b>Reward</b> : We {{suppose that}} the <b>reward</b> is unknown. We can also compute the {{expected}} immediate <b>reward</b> in a specific state as the average <b>reward</b> observed in state s.|$|R
5|$|Approach-avoidance {{conflict}} {{happens when}} a situation is presented that can either be <b>rewarding</b> or punishing, and the ensuing decision-making {{has been associated with}} anxiety. fMRI findings from studies in approach-avoidance decision-making found evidence for a functional role that is not explained by either long-term memory or spatial cognition. Overall findings showed that the anterior hippocampus is sensitive to conflict, and that it may be part of a larger cortical and subcortical network seen to be important in decision making in uncertain conditions.|$|E
5|$|Evidence from {{microelectrode}} recordings {{from the}} brains of animals shows that dopamine neurons in the ventral tegmental area (VTA) and substantia nigra are strongly activated by {{a wide variety of}} <b>rewarding</b> events. These reward-responsive dopamine neurons in the VTA and substantia nigra are crucial for reward-related cognition and serve as the central component of the reward system.The brain reward circuitry that is targeted by addictive drugs normally mediates the pleasure and strengthening of behaviors associated with natural reinforcers, such as food, water, and sexual contact. Dopamine neurons in the VTA are activated by food and water, and dopamine release in the NAc is stimulated by the presence of natural reinforcers, such as food, water, or a sexual partner....The NAc and VTA are central components of the circuitry underlying reward and memory of reward. As previously mentioned, the activity of dopaminergic neurons in the VTA appears to be linked to reward prediction. The NAc is involved in learning associated with reinforcement and the modulation of motoric responses to stimuli that satisfy internal homeostatic needs. The shell of the NAc appears to be particularly important to initial drug actions within reward circuitry; addictive drugs appear to have a greater effect on dopamine release in the shell than in the core of the NAc.... If motivational drive is described in terms of wanting, and hedonic evaluation in terms of liking, it appears that wanting can be dissociated from liking and that dopamine may influence these phenomena differently. Differences between wanting and liking are confirmed in reports by human addicts, who state that their desire for drugs (wanting) increases with continued use even when pleasure (liking) decreases because of tolerance.}} The function of dopamine varies in each axonal projection from the VTA and substantia nigra; for example, the VTA–nucleus accumbens shell projection assigns incentive salience ("want") to <b>rewarding</b> stimuli and its associated cues, the VTA–orbitofrontal cortex projection updates the value of different goals in accordance with their incentive salience, the VTA–amygdala and VTA–hippocampus projections mediate the consolidation of reward-related memories, and both the VTA–nucleus accumbens core and substantia nigra–dorsal striatum pathways are involved in learning motor responses that facilitate the acquisition of <b>rewarding</b> stimuli. Some activity within the VTA dopaminergic projections appears to be associated with reward prediction as well.|$|E
5|$|Gaze {{becomes more}} complex {{with age and}} practice. As gaze {{increases}} in complexity, individuals {{are better able to}} discriminate what others are referring to. Joint attention is also important for social learning. Gaze following reflects an expectation-based type of orienting in which an individual's attention is cued by another's head turn or eye turn. Individuals are motivated to follow another's gaze and engage in joint attention because gaze is a cue for which <b>rewarding</b> events occur.|$|E
40|$|Difference <b>rewards</b> and potential-based <b>reward</b> shaping {{can both}} {{significantly}} improve the joint policy learnt by multiple reinforcement learning agents acting simultaneously {{in the same}} environment. Difference <b>rewards</b> capture an agent’s contribution to the system’s performance. Potential-based <b>reward</b> shaping has been proven to not alter the Nash equi-libria of the system but requires domain-specific knowledge. This paper introduces two novel <b>reward</b> functions that com-bine these methods to leverage the benefits of both. Using the difference <b>reward’s</b> Counterfactual as Poten-tial (CaP) allows the application of potential-based <b>reward</b> shaping {{to a wide range}} of multiagent systems without the need for domain specific knowledge whilst still maintaining the theoretical guarantee of consistent Nash equilibria. Alternatively, Difference <b>Rewards</b> incorporating Potential-Based <b>Reward</b> Shaping (DRiP) uses potential-based <b>reward</b> shaping to further shape difference <b>rewards.</b> By exploiting prior knowledge of a problem domain, this paper demon-strates agents using this approach can converge either up to 23. 8 times faster than or to joint policies up to 196 % better than agents using difference <b>rewards</b> alone...|$|R
40|$|Sensory {{decisions}} may {{be influenced}} by non-sensory information regarding <b>reward</b> magnitude or <b>reward</b> likelihood. Given identical sensory information, it is more optimal to choose an option if it is a priori more likely to be correct and hence <b>rewarded</b> (prior <b>reward</b> likelihood bias), or if it yields a larger <b>reward,</b> given that it is the correct choice (<b>reward</b> magnitude bias). Here, we investigated the ability of macaque monkeys to integrate <b>reward</b> magnitude and prior <b>reward</b> likelihood information into a categorical decision about stimuli with high signal strength but variable decision uncertainty. In the asymmetric <b>reward</b> magnitude condition, monkeys over-adjusted their decision criterion such that they chose the highly <b>rewarded</b> alternative far more often than was optimal; in contrast, monkeys did not adjust their decision criterion in response to asymmetric <b>reward</b> likelihood. This finding shows that in this setting, monkeys did not adjust their decision criterion based on the product of <b>reward</b> likelihood and <b>reward</b> magnitude as has been reported to be the case in value based decisions that do not involve decision uncertainty due to stimulus categorization...|$|R
40|$|In {{line with}} {{previous}} research {{on the subject of}} subliminal <b>reward</b> processing, which suggests that monetary <b>rewards</b> {{have a positive effect on}} people’s motivation to perform better on a specific task, we designed a study to investigate whether indirect <b>rewards</b> motivate people to do better on a specific task as well. We were also interested in the question if these indirect <b>rewards,</b> in the form of tokens, have to be processed supraliminally to motivate people, or if the effect also occurs if they process the <b>reward</b> only subliminally. Thirty subjects participated in our study at University College London. They had to perform a mental rotation task on which they could either earn a <b>reward</b> or no <b>reward.</b> The trials were either hard or easy. Analysis of the data revealed partial support for the effect of indirect <b>rewards</b> on motivation and subliminal <b>reward</b> processing. Furthermore, participants were not faster on subliminal <b>reward</b> trials than on supraliminal <b>reward</b> trials, but they were more accurate on supraliminal <b>reward</b> trials than on subliminal <b>reward</b> trials. Finally, there was support for the expectation that participants are more prone to <b>rewards</b> when a task is harder...|$|R
