2|270|Public
50|$|A {{data report}} {{is similar to}} a birth certificate. Among the {{information}} included are: date of manufacture, materials of construction, specific details regarding design, and certification statements by both the manufacturer and inspector. Registration is required by most US jurisdictions for installation of pressure equipment. <b>Registered</b> <b>pressure</b> relief devices are stamped with a National Board NB Mark. For the manufacturer, data reports provide an essential form of customer service {{over the life of the}} equipment - a value-added quality of significant worth to the owner or user. Since the process began in 1921, there have been over 45 million data reports registered with the National Board.|$|E
40|$|Compressed air {{is a low}} {{efficiency}} media, and is thus {{very expensive}} to produce. This thesis work began by mind mapping how to create savings on the compressed air system at Billerud Skärblacka AB. Certain issues have been chosen for further studies. In order to identify the consumption of compressed air at PM 8 and 9, several measurements were made. At PM 8 there were not found any pressure drop, only large pressure variations for short periods of time. The causes of these pressure variations were not established. At PM 9 a <b>registered</b> <b>pressure</b> drop of around 1 bar was found. The cause of the pressure drop at PM 9 was not found. A solution for the pressure drop was presented, which also could give an opportunity to reduce the nominal pressure in the compressed air system. An idea for improvement of the compressed air system structure has also been presented. A search for leakages on the compressed air system was carried out both at PM 8 and PM 9. Leakages at PM 8 seem to be lower than at PM 9. The search for leakages pointed out that those leakages on the compressed air system reduces {{the efficiency of the}} compressed air system. There are some large scale consumers of compressed air at Billerud, for example one function at PM 8 and the cleaning function of timber trucks. One idea for reducing electrical consumption is to replace compressed air with a high pressure fan at PM 8. In the report more suggestions for saving electrical energy regarding the other large scale consumers are presented...|$|E
50|$|<b>Register</b> <b>pressure</b> {{measures}} {{the availability of}} free registers {{at any point in}} time during the program execution. <b>Register</b> <b>pressure</b> is high when a large number of the available registers are in use; thus, the higher the <b>register</b> <b>pressure,</b> the more often the register contents must be spilled into memory. Increasing the number of registers in an architecture decreases <b>register</b> <b>pressure</b> but increases the cost.|$|R
40|$|Unroll-and-jam is an {{effective}} loop optimization that not only improves cache locality and instruction level parallelism (ILP) but also benefits other loop optimizations such as scalar replacement. However, unroll-and-jam increases <b>register</b> <b>pressure,</b> potentially resulting in performance degradation when the increase in <b>register</b> <b>pressure</b> causes <b>register</b> spilling. In this paper, we present a low cost method to predict the <b>register</b> <b>pressure</b> of a loop before applying unroll-and-jam on high-level source code with the consideration of the collaborative effects of scalar replacement, general scalar optimizations, software pipelining and register allocation. We also describe a performance model that utilizes prediction results to determine automatically the unroll vector, from a given unroll space, that achieves the best run-time performance. Our experiments show that the heuristic prediction algorithm predicts the floating point <b>register</b> <b>pressure</b> within 3 <b>registers</b> and the integer <b>register</b> <b>pressure</b> within 4 <b>registers.</b> With this algorithm, for the Polyhedron benchmark, our <b>register</b> <b>pressure</b> guided unroll-and-jam improves the overall performance about 2 % over the model in the industry-leading optimizing Open 64 backend for both the x 86 and x 86 - 64 architectures. 1...|$|R
50|$|While {{embedded}} instruction sets such as Thumb {{suffer from}} extremely high <b>register</b> <b>pressure</b> {{because they have}} small register sets, general-purpose RISC ISAs like MIPS and Alpha enjoy low <b>register</b> <b>pressure.</b> CISC ISAs like x86-64 offer low <b>register</b> <b>pressure</b> despite having smaller register sets. This {{is due to the}} many addressing modes and optimizations (such as sub-register addressing, memory operands in ALU instructions, absolute addressing, PC-relative addressing, and register-to-register spills) that CISC ISAs offer.|$|R
40|$|Instruction-level code parallelization {{increases}} the <b>register</b> <b>pressure</b> and renders the register allocation phase crucial. In {{the case of}} software pipelined loops, unrolling has to be performed when variables are alive during more than one iteration resulting in code size increases. Loop unrolling also influences the <b>register</b> <b>pressure.</b> LoRA is a package that implements several algorithms for trading the <b>register</b> <b>pressure</b> against code size. In LoRA either the <b>register</b> <b>pressure</b> or the unrolling degree can be constrained. We explain the different strategies used in LoRA and show experimental results on a large benchmark of loops. Our experiments show that in concrete cases the unrolling degree can be kept reasonable although the worst case is exponential {{in the number of}} registers thought...|$|R
40|$|The {{necessity}} of decreasing <b>register</b> <b>pressure</b> in compilers is discussed. Various approaches to decreasing <b>register</b> <b>pressure</b> in compilers are given, including different algorithms of regis-ter live range splitting, register rematerializa-tion, and <b>register</b> <b>pressure</b> sensitive instruction scheduling before register allocation. Some of the mentioned algorithms were tried and rejected. Implementation of the rest, in-cluding region based register live range split-ting and rematerialization {{driven by the}} regis-ter allocator, is in progress and probably {{will be part of}} GCC. The effects of discussed op-timizations will be reported. The possible di-rections of improving the register allocation in GCC will be given...|$|R
40|$|Redundancy {{elimination}} optimizations avoid repeated computation of {{the same}} value by computing the value once, saving it in a temporary, and reusing the value from the temporary when it is needed again. Examples of redundancy elimination optimizations include common subexpression elimination, loop invariant code motion and partial redundancy elimination. We demonstrate that the introduction of temporaries to save computed values {{can result in a}} significant increase in <b>register</b> <b>pressure.</b> An increase in <b>register</b> <b>pressure</b> may in turn trigger generation of spill code which can more than offset the gains derived from redundancy elimination. While current techniques minimize increases in <b>register</b> <b>pressure,</b> to avoid spill code generation it is instead necessary to ensure that <b>register</b> <b>pressure</b> does not exceed the number of available registers. In this paper we develop a redundancy elimination algorithm that is sensitive to register pressure: our novel technique first sets upper limits on al [...] ...|$|R
40|$|This paper {{shows how}} to {{software}} pipeline a loop for minimal <b>register</b> <b>pressure</b> without sacrificing the loop's minimum execution time. This novel bidirectional slack-scheduling method has been implemented in a FORTRAN compiler and tested on many scientific benchmarks. The empirical results [...] -when measured against an absolute lower bound on execution time, and against a novel schedule-independent absolute lower bound on <b>register</b> <b>pressure</b> [...] -indicate nearoptimal performance...|$|R
5000|$|... in {{a region}} with high <b>{{register}}</b> <b>pressure,</b> it may allow the register allocator to avoid spilling a register ...|$|R
40|$|Scalar {{replacement}} is {{an effective}} optimization for removing memory accesses. However, exposing all possible array reuse with scalars may cause {{a significant increase in}} <b>register</b> <b>pressure,</b> resulting in <b>register</b> spilling and performance degradation. In this paper, we present a low cost method to predict the <b>register</b> <b>pressure</b> of a loop before applying scalar replacement on high-level source code, called Pseudo-schedule Register Prediction (PRP), that takes into account the effects of both software pipelining and register allocation. PRP attempts to eliminate the possibility of degradation from scalar replacement due to register spilling while providing opportunities for a good speedup. PRP uses three approximation algorithms: one for constructing a data dependence graph, one for computing the recurrence constraints of a software pipelined loop, and one for building a pseudo-schedule. Our experiments show that PRP predicts the floating-point <b>register</b> <b>pressure</b> within 2 <b>registers</b> and the integer <b>register</b> <b>pressure</b> within 2. 7 registers on average with a time complexity of O(n 2) in practice. PRP achieves similar performance to the best previous approach, having O(n 3) complexity, with less than one-fourth of the compilation time on our test suite. 1...|$|R
40|$|Software {{pipelining}} is a scheduling {{technique that}} is used by some product compilers in order to expose more instruction level parallelism out of innermost loops. Modulo scheduling refers to a class of algorithms for software pipelining. Most previous research on modulo scheduling has focused on reducing the number of cycles between the initiation of consecutive iterations (which is termed II) but has not considered the effect of the <b>register</b> <b>pressure</b> of the produced schedules. The <b>register</b> <b>pressure</b> increases as the instruction level parallelism increases. When the register requirements of a schedule are higher than the available number of registers, the loop must be rescheduled perhaps with a higher II. Therefore, the <b>register</b> <b>pressure</b> has an important impact on the performance of a schedule. This paper presents a novel heuristic modulo scheduling strategy that tries to generate schedules with the lowest II, and, from all the possible schedules with such II, it tries to select [...] ...|$|R
40|$|The {{run-time}} {{performance of}} VLIW (very long instruction word) microprocessors depends {{heavily on the}} effectiveness of its associated optimizing compiler. Typical VLIW compiler phases include instruction scheduling, which maximizes instruction level parallelism (ILP), and register allocation, which minimizes data spills to external memory. If ILP is maximized without considering register constraints, high <b>register</b> <b>pressure</b> may result, leading to increased spill code and reduced run-time performance. In this paper, a new <b>register</b> <b>pressure</b> reduction technique for embedded VLIW processors is presented to control <b>register</b> <b>pressure</b> prior to instruction scheduling and register allocation. By modifying the relative ordering of operations, this technique restructures code to better reduce spills. Our technique has been implemented in Trimaran, an academic VLIW compiler, and evaluated using a series of VLIW benchmarks. Experimental results show that, on average, our algorithm reduces dynamic spills and improves overall cycle counts by 6 % for a VLIW architecture with 8 functional units and 32 registers versus previous spill code reduction techniques...|$|R
40|$|Current, {{state-of-the-art}} compilers use Briggs' graph coloring heuristic for register allocation. This heuristic {{provides an}} efficient mapping of program variables to machine registers. However, if a variable cannot be assigned a register the variable is spilled and referenced through memory. Each {{use of the}} variable is preceded by a load from memory and each definition {{is followed by a}} store to memory. The algorithm presented in this thesis is a method {{to reduce the amount of}} spill code added by a Briggs' allocator. Graph coloring maps the live range of a variable to a machine register. If no machine register is available for a live range, the variable is spilled. There are often areas in the live range where spill code is not needed. Our algorithm identifies there areas, known as low <b>register</b> <b>pressure</b> regions. Once low <b>register</b> <b>pressure</b> regions are found for a spilled live range, it is possible to limit the amount of spill code added to the low <b>register</b> <b>pressure</b> region. This is known [...] ...|$|R
50|$|Compilers {{need to be}} judicious {{about the}} number of temporaries created to hold values. An {{excessive}} number of temporary values creates <b>register</b> <b>pressure</b> possibly resulting in spilling registers to memory, which may take longer than simply recomputing an arithmetic result when it is needed.|$|R
50|$|However, if {{too many}} {{variables}} are created, {{there will be}} high <b>register</b> <b>pressure,</b> especially on processors with few registers, like the 32-bit x86. If the compiler runs out of registers, some variables will be spilled. To counteract this, the inverse optimization can be performed, rematerialization.|$|R
40|$|International audienceRegister {{allocation}} in loops {{is generally}} performed after {{or during the}} software pipelining process. This is because doing a conventional register allocation {{as a first step}} without assuming a schedule lacks the information of interferences between values live ranges. Thus, the register allocator may introduce an excessive amount of false dependences that dramatically reduce the ILP (Instruction Level Parallelism). We present a new theoretical framework for controlling the <b>register</b> <b>pressure</b> before software pipelining. This is based on inserting some anti-dependence edges (register reuse edges) labeled with reuse distances, directly on the data dependence graph. In this new graph, we are able to fix the <b>register</b> <b>pressure,</b> measured as the number of simultaneously alive variables in any schedule. The determination of register and distance reuse is parameterized by the desired minimum initiation interval (MII) {{as well as by the}} <b>register</b> <b>pressure</b> constraints - either can be minimized while the other one is fixed. After scheduling, register allocation is done on conventional register sets or on rotating register files. We give an optimal exact model, and an approximation that generalizes the Ning-Gao [22] buffer optimization method. We provide experimental results which show good improvement compared to [22]. Our theoretical model considers superscalar, VLIW and EPIC/IA 64 processors...|$|R
40|$|Modern {{compiler}} transformations that eliminate redundant computations or reorder instructions, such as partial redundancy elimination {{and instruction}} scheduling, are {{very effective in}} improving application performance but tend to create longer and potentially more complex live ranges. Typically the task {{of dealing with the}} increased <b>register</b> <b>pressure</b> is left to the register allocator. To avoid introduction of spill code which can reduce or completely eliminate the benefit of earlier optimizations, researchers have developed techniques such as live range splitting and rematerialization. This paper describes prematerialization (PM), a novel method for reducing <b>register</b> <b>pressure</b> for VLIW architectures with nop instructions. PM and rematerialization both select “never killed” live ranges and break them up by introducing one or more definitions close to the uses. However, while rematerialization is applied to live ranges selected for spilling during register allocation, PM relies on the availability of nop instructions and occurs prior to register allocation. PM simplifies register allocation by creating live ranges that are easier to color and less likely to spill. We have implemented prematerialization in HP-UX production compilers for the Intel ® Itanium ® architecture. Performance evaluation indicates that the proposed technique is effective in reducing <b>register</b> <b>pressure</b> inherent in highly optimized code...|$|R
40|$|Loop fusion is a {{reordering}} {{transformation that}} merges multiple loops {{into a single}} loop. It can increase data locality and the granularity of parallel loops, thus improving program performance. Previous approaches to this problem have looked at these two bene&quot;ts in isolation. In this work, we propose a new model which considers data locality, parallelism and <b>register</b> <b>pressure</b> together. We build a weighted directed acyclic graph in which the nodes represent program loops along with their <b>register</b> <b>pressure,</b> and the edges represent the amount of locality and parallelism present. The direction of an edge represents an execution order constraint. We then partition the graph into components such that {{the sum of the}} weights on the edges cut is minimized, subject to the constraint that the nodes in the same partition can be safely fused together, and the <b>register</b> <b>pressure</b> of the combined loop does not exceed the number of available registers. Previous work demonstrates that the general problem of &quot;nding optimal partitions is NP-hard. In restricted cases, we show {{that it is possible to}} arrive at the optimal solution. We give an algorithm for the restricted case and a heuristic for the general case. We demonstrate the effectiveness of fusion and our approach with experimental results. 1...|$|R
40|$|Communicated by Jean-Luc GAUDIOT Register {{allocation}} in loops {{is generally}} performed after {{or during the}} software pipelining process. This is because doing a conventional register allocation as a rst step without assuming a schedule lacks the information of interferences between values live ranges. Thus, the register allocator may introduce an excessive amount of false dependences that dramatically reduce the ILP (Instruction Level Parallelism). We present a new theoretical framework for controlling the <b>register</b> <b>pressure</b> before software pipelining. This is based on inserting some anti-dependence edges (register reuse edges) labeled with reuse distances, directly on the data dependence graph. In this new graph, {{we are able to}} x the <b>register</b> <b>pressure,</b> measured as the number of simultaneously alive variables in any schedule. The determination of register and distance reuse is parameterized by the desired minimum initiation interval (MII) {{as well as by the}} <b>register</b> <b>pressure</b> constraints- either can be minimized while the other one is xed. After scheduling, register allocation is done on conventional register sets or on rotating register les. We give an optimal exact model, and an approximation that generalizes the Ning-Gao [22] buffer optimization method. We provide experimental results which show good improvement compared to [22]. Our theoretical model considers superscalar, VLIW and EPIC/IA 64 processors...|$|R
50|$|On AMD Athlon XP and K8-based cores (i.e. Athlon 64), {{assembly}} programmers {{have noted}} {{that it is possible}} to combine 3DNow and SSE instructions to reduce <b>register</b> <b>pressure,</b> but in practice it is difficult to improve performance due to the instructions executing on shared functional units.|$|R
40|$|Moderate size {{register}} files {{can limit}} {{the performance of}} loop unrolling on multiple issue processors. With current scheduling heuristics, a breadth-first scheduling of iterations occurs, increasing <b>register</b> <b>pressure</b> and generating excessive spill code. A heuristic is proposed that causes a more depthfirst scheduling of unrolled iterations. This heuristic reduces the overlapping of the unrolled iterations and as a result, reduces <b>register</b> <b>pressure.</b> The experimental evaluation shows increased performance on processors with 32 or 64 registers. In addition, the performance of dependency removing optimizations is stabilized, so that applying additional optimizations {{is more likely to}} increase performance. 1 Introduction In multiple instruction issue processors, such as VLIW and superscalar processors, scheduling code for efficient usage of their function units requires many independent instruction sequences. Loop unrolling, combined with techniques to minimize or remove dependencies, has [...] ...|$|R
40|$|With GPU {{architectures}} {{becoming increasingly}} important {{due to their}} large number of parallel processors, NVIDIA’s CUDA environment is becoming widely used to support gen-eral purpose applications. To efficiently use the parallel pro-cessing power, programmers need to efficiently parallelize and map their algorithms. The difficulty of this task leads to the idea to investigate CUDA’s compiler. Part of the compiler in the CUDA tool-chain is entirely un-documented, as is its output. To draw conclusions on the behaviour of this compiler, the resulting object code is re-verse engineered. A visualization tool is introduced, analyz-ing the previously unknown compiler behaviour and proving helpful to improve the mapping process for the programmer. These improvements focus on the area of register allocation and instruction reordering. This paper describes an exten-sion to the CUDA tool-chain, providing programmers with a visualization of register life ranges. Also, the paper presents guidelines describing how to apply optimizations {{in order to obtain}} a lower <b>register</b> <b>pressure.</b> In a case-study example, performance increases by 33 % com-pared to already optimized CUDA code. This is achieved by optimizing the code {{with the help of the}} introduced visual-ization tool. Also, in 11 other case-study examples, <b>register</b> <b>pressure</b> is reduced by an average of 18 %. The presented guidelines could be added to the compiler to enable a simi-lar <b>register</b> <b>pressure</b> reduction to be achieved automatically at compile-time for new and existing CUDA programs...|$|R
40|$|Modern {{processors}} and compilers hide long memory latencies through non-blocking loads or explicit software prefetching instructions. Unfortunately, each mechanism has potential drawbacks. Non-blocking loads can signifi-cantly increase <b>register</b> <b>pressure</b> by extending the lifetimes of loads. Software prefetching increases {{the number of}} memory instructions in the loop body. For a loop whose exe-cution time is bound {{by the number of}} loads/stores that can be issued per cycle, software prefetching exacerbates this problem and increases the number of idle computational cy-cles in loops. In this paper, we show how compiler and architecture support for combining a load and a prefetch into one in-struction, called a prefetching load, can give lower regis-ter pressure like software prefetching and lower load/store-unit requirements like non-blocking loads. On a set of 106 Fortran loops we show that prefetching loads obtain a speedup of 1. 07 – 1. 53 over using just non-blocking loads and a speedup of 1. 04 – 1. 08 over using software prefetching. In addition, prefetching loads reduced floating-point regis-ter pressure by as much as a factor of 0. 4 and integer regis-ter pressure by as much as a factor of 0. 8 over non-blocking loads. Integer <b>register</b> <b>pressure</b> was also reduced by a fac-tor of 0. 97 over software prefetching, while floating-point <b>register</b> <b>pressure</b> was increased by a factor of 1. 02 versus software prefetching in the worst case. ...|$|R
40|$|Code {{optimizations}} {{and restructuring}} transformations are typically applied before scheduling {{to improve the}} quality of generated code. However, in some cases, the optimizations and transformations do not lead to a better schedule or may even adversely affect the schedule. In particular, optimizations for redundancy elimination and restructuring transformations for increasing parallelism are often accompanied with an increase in <b>register</b> <b>pressure.</b> Therefore their application in situations where <b>register</b> <b>pressure</b> is already too high may result in the generation of additional spill code. In this paper we present an integrated approach to scheduling that enables the selective application of optimizations and restructuring transformations by the scheduler when it determines their application to be beneficial. The integration is necessary because information that is used to determine the effects of optimizations and transformations on the schedule is only available during instruction sched [...] ...|$|R
40|$|This paper {{shows how}} to {{software}} pipeline a loop for minimal <b>register</b> <b>pressure</b> without sacrificing the loop's minimum execution time. This novel bidirectional slack-scheduling method has been implemented in a FORTRAN compiler and tested on many scientific benchmarks. The empirical results [...] -when measured against an absolute lower bound on execution time, and against a novel schedule-independent absolute lower bound on <b>register</b> <b>pressure</b> [...] -indicate nearoptimal performance. 1 Introduction Software pipelining increases a loop's throughput by overlapping the loop's iterations; that is, by initiating successive iterations before prior iterations complete. With sufficient overlap, a functional unit can be saturated, {{at which point}} the loop initiates iterations at the maximum possible rate. To find an overlapped schedule, a compiler must represent the complex resource constraints that can arise. Efficiently representing these constraints is especially difficult when adjacent iterations do n [...] ...|$|R
40|$|Using {{register}} renaming {{and physical}} registers, modern microprocessors eliminate false data dependences from reuse {{of the instruction}} set defined registers (logical registers). High performance processors that have longer pipelines and a greater capacity to exploit instruction-level parallelism have more instructions in-flight and require more physical registers. Simultaneous multithreading architectures further exacerbate this <b>register</b> <b>pressure...</b>|$|R
40|$|Abstract. Code {{optimizations}} {{and restructuring}} transformations are typically applied before scheduling {{to improve the}} quality of generated code. However, in some cases, the optimizations and transformations do not lead to a better schedule or may even adversely affect he schedule. In particular, optimizations for redundancy elimination and restructuring transformations for increasing parallelism axe often accompanied with an increase in <b>register</b> <b>pressure.</b> Therefore their application in situations where <b>register</b> <b>pressure</b> is already too high may result in the generation of additional spill code. In this paper we present an integrated approach to scheduling that enables the selective application of optimizations and restructuring transformations bythe scheduler when it determines their application to be beneficial. The integration is necessary because infor-mation that is used to determine the effects of optimizations and trans-formations on the schedule is only available during instruction schedul-ing. Our integrated scheduling approach is applicable to various type...|$|R
40|$|This paper {{presents}} UNRET (unrolling and retiming), a {{new approach}} for resourceconstrained loop pipelining. UNRET aims at finding a loop schedule with maximum throughput and minimum <b>register</b> <b>pressure.</b> UNRET is composed of two main phases. In the first phase, a schedule with maximum throughput is found for a given set of resource constraints. To do so, different unrolling degrees are explored in decreasing order of throughput. For each theoretical throughput, both the unrolling degree of the loop and the expected initiation interval of the schedule are analytically computed by using new and effective methods. In the second phase, the number of registers required by the schedule is reduced while maintining the throughput. The effectiveness of UNRET has been proven by presenting results on well-known benchmarks. The obtained results show that UNRET may obtain faster schedules than other approaches, also reducing the <b>register</b> <b>pressure.</b> 1 Introduction Software pipelining comprises a fami [...] ...|$|R
50|$|Matrix {{multiplication}} is {{like many}} other codes in {{that it can be}} limited by memory bandwidth, and that more registers can help the compiler and programmer reduce the need for memory bandwidth. This <b>register</b> <b>pressure</b> is why vendors of RISC CPUs, who intended to build machines more parallel than the general purpose x86 and 68000 CPUs, adopted 32-entry floating-point register files.|$|R
40|$|Abstract: This report makes {{a massive}} {{experimental}} study of an efficient heuristic for the SIRA framework [11]. The heuristic, called SIRALINA [4], bounds the register requirement of a data dependence graph before instruction scheduling under resource constraints. Our aim is to guarantee the absence of spilling before any instruction scheduling process, without hurting instruction level parallelism if possible. Our <b>register</b> <b>pressure</b> reduction methods are sensitive for both software pipelining (innermost loops) and acyclic scheduling (basic blocks and super-blocks). The SIRALINA method that we experiment in this report is shown efficient in terms of compilation times, in terms of register requirement reduction {{and in terms of}} shorted schedule increase. Our experiments are done on thousands standalone DDG extracted from FFMPEG, MEDIABENCH, SPEC 2000 and SPEC 2006 benchmarks. We consider processor architectures with multiple register type and we model delayed access times to <b>registers.</b> Our <b>register</b> <b>pressure</b> reduction method is distributed as a C independent library (SIRAlib. Key-words...|$|R
40|$|Compiler-controlled {{speculative}} execution {{has been}} shown to be e ective in increasing the available instruction level parallelism (ILP) found in non-numeric programs. An important problem with compiler-controlled speculative execution is to accurately report and handle exceptions caused by speculatively executed instructions. Previous solutions to this problem incur either excessive hardware overhead or extra <b>register</b> <b>pressure.</b> This paper introduces a new architecture scheme referred to as write-back suppression. This scheme systematically suppresses register le updates for subsequent speculative instructions after an exception condition is detected for a speculatively executed instruction. We show that with a modest amount of hardware, writeback suppression supports accurate reporting and handling of exceptions for compiler-controlled speculative execution without adding to the <b>register</b> <b>pressure.</b> Experiments based on a prototype compiler implementation and hardware simulation indicate that ensuring accurate handling of exceptions with write-back suppression incurs very little run-time performance overhead. Index terms- exception detection, exception recovery, scheduling, speculative execution, VLIW, superscalar 1...|$|R
40|$|This report makes {{a massive}} {{experimental}} study of an efficient heuristic for the SIRA framework sira 04. The heuristic, called SIRALINA siralina 07, bounds the register requirement of a data dependence graph before instruction scheduling under resource constraints. Our aim is to guarantee the absence of spilling before any instruction scheduling process, without hurting instruction level parallelism if possible. Our <b>register</b> <b>pressure</b> reduction methods are sensitive for both software pipelining (innermost loops) and acyclic scheduling (basic blocks and super-blocks). The SIRALINA method that we experiment in this report is shown efficient in terms of compilation times, in terms of register requirement reduction {{and in terms of}} shorted schedule increase. Our experiments are done on thousands standalone DDG extracted from FFMPEG, MEDIABENCH, SPEC 2000 and SPEC 2006 benchmarks. We consider processor architectures with multiple register type and we model delayed access times to <b>registers.</b> Our <b>register</b> <b>pressure</b> reduction method is distributed as a C independent library (SIRAlib...|$|R
30|$|Dataflow mini-graphs [13] {{are treated}} as atomic units by a processor. They have the {{interface}} of a single instruction, with intermediate variables alive only in the bypass network. In [14], architecturally visible ‘virtual registers’ are used to reduce <b>register</b> <b>pressure</b> through bypassing. In this method, a virtual register is only a tag marking data dependence between operations without having physical storage location in the RF.|$|R
40|$|Software {{pipelining}} is a scheduling {{technique that}} is used by some product compilers in order to expose more instruction level parallelism out of innermost loops. Module scheduling refers to a class of algorithms for software pipelining. Most previous research on module scheduling has focused on reducing the number of cycles between the initiation of consecutive iterations (which is termed II) but has not considered the effect of the <b>register</b> <b>pressure</b> of the produced schedules. The <b>register</b> <b>pressure</b> increases as the instruction level parallelism increases. When the register requirements of a schedule are higher than the available number of registers, the loop must be rescheduled perhaps with a higher II. Therefore, the <b>register</b> <b>pressure</b> has an important impact on the performance of a schedule. This paper presents a novel heuristic module scheduling strategy that tries to generate schedules with the lowest II, and, from all the possible schedules with such II, it tries to select that with the lowest register requirements. The proposed method has been implemented in an experimental compiler and has been tested for the Perfect Club benchmarks. The results show that the proposed method achieves an optimal II for at least 97. 5 percent of the loops and its compilation time is comparable to a conventional top-down approach, whereas the register requirements are lower. In addition, the proposed method is compared with some other existing methods. The results indicate that the proposed method performs better than other heuristic methods and almost as well as linear programming methods, which obtain optimal solutions but are impractical for product compilers because their computing cost grows exponentially with the number of operations in the loop body. Peer ReviewedPostprint (published version...|$|R
40|$|International audienceIntegrating {{register}} allocation {{and software}} pipelining of loops {{is an active}} research area. We focus on techniques that precondition the dependence graph before software pipelining {{in order to ensure}} that no register spill instructions are inserted by the register allocator in the software pipelined loop. If spilling is not necessary for the input code, preconditioning techniques insert dependence arcs so that the maximum <b>register</b> <b>pressure</b> MAXLIVE achieved by any loop schedule is below the number of available registers, without hurting the initiation interval if possible. When a solution exists, a spill-free software pipeline is guaranteed to exist. Existing preconditioning techniques consider one register type (register class) at a time [Deschinkel and Touati 2008]. In this article, we extend preconditioning techniques so that multiple register types are considered simultaneously. First, we generalize the existing theory of <b>register</b> <b>pressure</b> minimization for cyclic scheduling. Second, we implement ourmethod inside the production compiler of the ST 2 xx VLIWfamily, and we demonstrate its efficiency on industry benchmarks (FFMPEG, MEDIABENCH, SPEC 2000, SPEC 2006). We demonstrate a high spill reduction rate without a significant initiation interval loss...|$|R
