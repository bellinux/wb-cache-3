91|9|Public
50|$|Michael Clive Price has written: A <b>retrodiction</b> {{occurs when}} already {{gathered}} data is {{accounted for by}} a later theoretical advance in a more convincing fashion. The advantage of a <b>retrodiction</b> over a prediction is that the already gathered data {{is more likely to}} be free of experimenter bias. An example of a <b>retrodiction</b> is the perihelion shift of Mercury which Newtonian mechanics plus gravity was unable, totally, to account for whilst Einstein's general relativity made short work of it.|$|E
5000|$|... #Caption: Temporal {{representation}} of <b>retrodiction</b> or postdiction.|$|E
5000|$|... the <b>retrodiction,</b> postdiction and {{hindcasting}} of the (otherwise) indefinite and unknowable past; ...|$|E
40|$|We {{describe}} some {{properties of}} consistent sets of histories in the Gell-Mann [...] Hartle formalism, and {{give an example}} to illustrate that one cannot recover the standard predictions, <b>retrodictions</b> and inferences of quasiclassical physics using the criterion of consistency alone. Comment: 8 pages, TeX with Harvmac. Replaced with published version which contains fewer technical details and more discussion of physical implications. Title Correcte...|$|R
40|$|In the {{consistent}} histories formulation of quantum theory, the probabilistic predictions and <b>retrodictions</b> made from observed data {{depend on the}} choice of a consistent set. We show that this freedom allows the formalism to retrodict contrary propositions which correspond to orthogonal commuting projections and which each have probability one. We also show that the formalism makes contrary probability one predictions when applied to Gell-Mann and Hartle’s generalised time-neutral quantum mechanics...|$|R
40|$|Numerical {{models of}} mantle {{convection}} {{have become increasingly}} more sophisticated {{in the last two}} decades and are growing in complexity. Unfortunately, the increase in resolution and the incorporation of new features based on empirical relationships, parametrizations and long-range extrapolations limit the predictive power of these models, while at the same time allowing for an easy fit of individual geophysical and geological datasets. This calls for a more thorough testing of geodynamic models and a shift in their use, from scenario calculations to explicit modeling of Earth's dynamics. A promising pathway to test geodynamic models relies on geodynamic <b>retrodictions,</b> that is reconstructions of past mantle flow states obtained using presently available information. They link explicitly assumptions and inferences from various fields of the Earth Sciences in a comprehensive Earth model based on the physics of mantle convection, thus highlighting their interrelations. Moreover, reconstructing the past history of mantle convection allows for a test of the underlying model against the geological record. The emphasis on the cross-disciplinary testing of model results against observations marks the transition from numerical to observational geodynamics, of which this dissertation can be seen as a primer. Using the Atlantic realm as a case study, we collect a number of geophysical observations - from seismic structure to the history of plate motions, from epeirogenic movements to gravity anomalies - and bring them to bear. We first analyse them using theoretical considerations and analytical solutions, to gain some fundamental insight and formulate clear geophysical hypotheses. We then proceed to formally solve the geodynamic inverse problem, obtaining the first <b>retrodictions</b> of geodynamically plausible mantle flow in the Atlantic region...|$|R
5000|$|Given that <b>retrodiction</b> is {{a process}} in which [...] "past observations, events and data are used as {{evidence}} to infer the process(es) the produced them" [...] and that diagnosis [...] "involves going from visible effects such as symptoms, signs and the like to their prior causes" [...] the essential balance between prediction and <b>retrodiction</b> could be characterized as: ...|$|E
5000|$|In {{scientific}} method, {{the terms}} <b>retrodiction</b> or postdiction {{are used in}} several senses.|$|E
5000|$|<b>Retrodiction</b> (a.k.a. postdiction — {{although}} {{this should not}} be confused with the use of the term in criticisms of parapsychological research) is the act of making a [...] "prediction" [...] about the past.|$|E
40|$|Closed timelike curves (CTCs) are trajectories in spacetime that {{effectively}} travel backwards in time: a test particle following a CTC can interact with its former self in the past. A widely accepted quantum theory of CTCs was proposed by Deutsch. Here we analyze an alternative quantum formulation of CTCs based on teleportation and postselection, {{and show that}} it is inequivalent to Deutsch’s. The predictions or <b>retrodictions</b> of our theory can be simulated experimentally: we report {{the results of an}} experiment illustrating how in our particular theory the “grandfather paradox” is resolved. National Science Foundation (U. S.) Natural Sciences and Engineering Research Council of CanadaUnited States. Defense Advanced Research Projects AgencyUnited States. Office of Naval ResearchQuantumWorks CorporationCanadian Institute for Advanced ResearchNational Institute of Standards and Technology (U. S. ...|$|R
50|$|In 1949, {{physicist}} Max Born distinguished determination from causality. For him, determination {{meant that}} actual events are so linked by {{laws of nature}} that certainly reliable predictions and <b>retrodictions</b> {{can be made from}} sufficient present data about them. For him, {{there are two kinds of}} causation, which we may here call nomic or generic causation, and singular causation. Nomic causality means that cause and effect are linked by more or less certain or probabilistic general laws covering many possible or potential instances; we may recognize this as a probabilized version of criterion 3. of Hume mentioned just above. An occasion of singular causation is a particular occurrence of a definite complex of events that are physically linked by antecedence and contiguity, which we may here recognize as criteria 1. and 2. of Hume mentioned just above.|$|R
40|$|This paper {{addresses}} {{the question of}} how we should regard the probability distributions introduced into statistical mechanics. It will be argued that it is problematic to take them either as purely ontic, or purely epistemic. I will propose a third alternative: they are almost objective probabilities, or epistemic chances. The definition of such probabilities involves an interweaving of epistemic and physical considerations, and thus they cannot be classified as either purely epistemic or purely ontic. This conception, it will be argued, resolves some of the puzzles associated with statistical mechanical probabilities: it explains how probabilistic posits introduced on the basis of incomplete knowledge can yield testable predictions, and it also bypasses the problem of disastrous <b>retrodictions,</b> that is, the fact the standard equilibrium measures yield high probability of the system being in equilibrium in the recent past, even when we know otherwise. As the problem does not arise on the conception of probabilities considered here, {{there is no need to}} invoke a Past Hypothesis as a special posit to avoid it...|$|R
50|$|Backtesting is a {{term used}} in oceanography, {{meteorology}} and the financial industry to refer to testing a predictive model using existing historic data. Backtesting {{is a kind of}} <b>retrodiction,</b> and a special type of cross-validation applied to time series data.|$|E
50|$|The {{activity}} of <b>retrodiction</b> (or postdiction) involves moving backwards in time, step-by-step, {{in as many}} stages as are considered necessary, from the present into the speculated past to establish the ultimate cause of a specific event (e.g., reverse engineering and forensics).|$|E
50|$|The {{activity}} of <b>retrodiction</b> (or postdiction) involves moving backwards in time, step-by-step, {{in as many}} stages as are considered necessary, from the present into the speculated past to establish the ultimate cause of a specific event (for instance, {{in the case of}} reverse engineering, forensics, etc.).|$|E
40|$|This {{paper is}} {{concerned}} with private enforcement of EU competition law. It revisits the old and (increasingly) established concepts of a 'system of parallel competences' and a 'community right to damages', as established by the European Court of Justice in BRT v. SABAM (1974) and Courage v. Crehan (2001) and through subsequent interpretation by academic commentators and the European Commission. The analysis reveals that the current understanding of these concepts is based on 'teleological retrodictions,' i. e. ex post rationalisations of judgments that are aimed at 'desirable' or 'logical' results. Such <b>retrodictions</b> lead to a path dependency, whereby the seemingly unstoppable 'strengthening' of private enforcement tends to create conflicts with public enforcement. These conflicts ultimately threaten to harm {{both public and private}} enforcement. It is only through a deconstruction of the twin concepts that one can clear the way for an internally coherent, functional interpretation of the relationship between 'public' and 'private' enforcement of the rules as a single, integrated system. The paper contains a postscript, with a first impression of the European Commission's proposal for a directive on damages claims, which was published in June 2013, shortly after the conclusion of the original paper...|$|R
40|$|ABSTRACT: 19 th and 20 th century {{stratigraphy}} often concerned itself {{primarily with}} classification and nomenclature, during {{what can be}} termed the heroic and codex ages of stratigraphy. In contrast, 21 st century stratigraphy will fall within the post-modern age. In possession of agreed classification schemes, future stratigraphers will concentrate on (i) the reconstruction of earth environments and processes (including evolution) through time, (ii) the eficient location and recovery of useful earth resources, and (iii) the study of those geological hazards that can be understood within a stratigraphic context. The first objective- reconstructing environments through time- {{requires the use of}} a conceptual framework similar to the one that we term the geological time scale (GTS). The 21 st century GTS will be based on GSSP designations at the base of all geological Periods and, ultimately, Ages, i. e. it will comprise an internationally agreed chronologic hierarchy. Recognition of local chronologic schemes (as distinct from biostratigraphies based on Oppelzones) will thereafter serve no useful purpose and local “Ages ” will become redun-dant. Globally, recognition of a separate but completely parallel chronostratigraphic classification will also serve no useful purpose, and this hierarchy too will be abandoned. Correlation of events into the GTS will be undertaken using a wide variety of methods, including numeric dating, fossil occurrence, physical and chemical properties, tephrochronology and astrochronologic <b>retrodictions.</b> Biostrati-graphy, though remaining a vital tool, especially for Phanerozoic strata, will carry no necessary correlation primacy. Meeting the second and third objectives- locating and recovering earth resources, and studying hazards- requires first and fore-most the creation of detailed geological maps and stratigraphic columns. The lithostratigraphic hierarchy of Bed-Member-Forma...|$|R
40|$|A clear {{understanding}} of interactions between the arid Southwestern environment and that area's prehistoric inhabitants has been a goal of Southwestern archaeology. This research has reconstructed annual corn and dry bean crop yields for southwestern Colorado from A. D. 650 to 1968, {{as well as the}} amounts of those foods available for each of those years. Colorado's five southwestern county dry farming corn and dry bean crop records were combined to create two regional crop series. Modern technology's increasing influence was recognized as being present in the two series. This influence was felt to parallel Colorado's statewide fertilizer consumption and was removed using a multiple regression procedure. Two modern technology free regional crop series resulted. These two series, along with the original two historic crop series were calibrated against five Four Corners tree-ring chronologies from four localities. Both Douglas-fir and pinyon were employed in the calibration. The calibration process used multiple regression so that each series' current annual crop yield could be predicted using one or more of 25 separate dendrochronological predictors. The regression equation deemed most suitable for predicting each of the four crop series was utilized to reconstruct annual crop yield estimates for the A. D. 652 - 1968 period. Normal verification was impossible since additional independent crop data were lacking. The reconstructed crop yield series were evaluated statistically. Portions of them were compared against historically recorded events. These two types of testing suggested that the <b>retrodictions</b> were probably valid. The crop yield reconstructions provided the basic data for four sets of storage simulations that attempted to determine corn and dry bean availability for each year from A. D. 652 to 1968, given certain assumptions about the levels of storage technology available to the Anasazi of southwestern Colorado. A. E. Douglass' A. D. 1276 - 1299 "Great Drought" appears to be confirmed. A number of additional famines or food crises have also been recognized. In addition, periods when food was super abundant have been identified. It now appears that much of the Four Corners large public construction projects were undertaken during and perhaps because of these periods of excess surplus...|$|R
5000|$|The iron-sulfur world {{hypothesis}} {{is a set}} of proposals for the origin of life and the early evolution of life advanced {{in a series of articles}} between 1988 and 1992 by Günter Wächtershäuser, a Munich patent lawyer with a degree in chemistry, who had been encouraged and supported by philosopher Karl R. Popper to publish his ideas. The hypothesis proposes that early life may have formed on the surface of iron sulfide minerals, hence the name. [...] It was developed by <b>retrodiction</b> from extant biochemistry in conjunction with chemical experiments.|$|E
50|$|The two-state vector {{formalism}} is {{one example}} of a time-symmetric interpretation of quantum mechanics (see Minority interpretations of quantum mechanics). Time-symmetric interpretations of quantum mechanics were first suggested by Walter Schottky in 1921, and later by several other scientists. The two-state vector formalism was first developed by Satosi Watanabe in 1955, who named it the Double Inferential state-Vector Formalism (DIVF). Watanabe proposed that information given by forwards evolving quantum states is not complete; rather, both forwards and backwards evolving quantum states are required to describe a quantum state: a first state vector that evolves from the initial conditions towards the future, and a second state vector that evolves backwards in time from future boundary conditions. Past and future measurements, taken together, provide complete information about a quantum system. Watanabe's work was later rediscovered by Yakir Aharonov, Peter Bergmann and Joel Lebowitz in 1964, who later renamed it the Two-State Vector Formalism (TSVF). Conventional prediction, as well as <b>retrodiction,</b> can be obtained formally by separating out the initial conditions (or, conversely, the final conditions) by performing sequences of coherence-destroying operations, thereby cancelling out the influence of the two state vectors.|$|E
40|$|People {{must often}} infer {{what might have}} transpired {{in the past to}} bring about the present state of the world, a task called <b>retrodiction.</b> We hypothesize that <b>retrodiction</b> relies on similar {{cognitive}} mechanisms to prediction – inferring possible futures based on the present state of the world. Here we investigate how people perform on physical reasoning tasks that differ only in that people are asked to do either prediction or <b>retrodiction.</b> We find that average behavior is similar between tasks across a range of difficulty, though there was greater variability in <b>retrodiction</b> responses. We propose two ways in which prediction and <b>retrodiction</b> might be related; however, neither sufficiently explains the similarities and differences across tasks. We suggest that both tasks rely on similar cognitive processes, but that {{further research is needed to}} determine the exact relation...|$|E
40|$|Quantum <b>retrodiction</b> {{involves}} {{finding the}} probabilities for various preparation events given a measurement event. This {{theory has been}} studied for some time but mainly as an interesting concept associated with time asymmetry in quantum mechanics. Recent interest in quantum communications and cryptography, however, has provided <b>retrodiction</b> with a potential practical application. For this purpose quantum <b>retrodiction</b> in open systems should be more relevant than in closed systems isolated from the environment. In this paper we study <b>retrodiction</b> in open systems and develop a general master equation for the backward time evolution of the measured state, {{which can be used}} for calculating preparation probabilities. We solve the master equation, by way of example, for the driven two-level atom coupled to the electromagnetic field. Comment: 12 pages, no figure...|$|E
40|$|Building {{on recent}} work by Gammelmark et al. [Phys. Rev. Lett. 111, 160401 (2013) ] we develop a {{formalism}} for prediction and <b>retrodiction</b> of Gaussian quantum systems undergoing continuous measurements. We apply the resulting formalism {{to study the}} advantage of incorporating a full measurement record and <b>retrodiction</b> for impulse-like force detection and accelerometry...|$|E
40|$|We {{propose a}} quantum key {{distribution}} protocol based on a quantum <b>retrodiction</b> protocol, known as the Mean King problem. The protocol uses a two way quantum channel. We show security against coherent attacks in a transmission error free scenario, even if Eve is allowed to attack both transmissions. This establishes a connection between <b>retrodiction</b> and key distribution. Comment: 5 pages, 1 figur...|$|E
3000|$|... aWe {{prefer the}} term <b>retrodiction</b> to smoothing, as it {{combines}} {{the process of}} prediction and a retrospective view.|$|E
40|$|The <b>retrodiction</b> of spin {{measurements}} along a set {{of different}} axes is revisited in detail. The problem {{is presented in two}} different pictures, a geometric and a general algebraic one. Explicit measurement operators that allow the <b>retrodiction</b> are given for the case of three and four axes. For the Vaidman-Aharanov-Albert case of three orthogonal axes the quantum network is constructed for two different initial Bell states. Comment: 16 page...|$|E
40|$|Abstract – In this paper, {{we examine}} a <b>retrodiction</b> {{approach}} {{to handle the}} out-of-sequence measurement (OOSM) problem in active sonar, for both linear and nonlinear representations of target contact information. We find that the <b>retrodiction</b> approach performs well, even with multiple sensors and multi-lag out-of-sequence measurements. In addition, we {{examine the impact of}} the use of a ping-time reference for moving-platform sonar operations. Keywords: Multi-sensor target tracking, network-centric tracking, active sonar, out-of-sequence measurement (OOSM) problem. ...|$|E
40|$|We {{obtain a}} {{necessary}} and sufficient condition for perfect <b>retrodiction</b> {{of the outcome}} of a known generalised measurement, given the average final state, for an arbitrary initial state. From this, we deduce {{that it is impossible to}} perfectly retrodict the outcome of any fine-grained measurement other than one which is unitarily equivalent to a projective measurement. It also enables us to show that every POVM for which the number of outcomes does not exceed the Hilbert space dimension can be realised in such a way that perfect outcome <b>retrodiction</b> is possible for an arbitrary initial state. We then consider the situation where the initial state is not arbitrary, though it may be entangled, and describe the conditions under which unambiguous outcome <b>retrodiction</b> is possible for a fine-grained generalised measurement. We find that this is possible for some state if the Kraus operators are linearly independent. This condition is also necessary for finite-strength measurements. From this result, we deduce that every trace-preserving quantum operation is associated with a generalised measurement whose outcome is unambiguously retrodictable for some states, and also that a set of unitary operators can be unambiguously discriminated iff they are linearly independent. We then examine the issue of unambiguous outcome <b>retrodiction</b> without entanglement. This has important connections with the theory of locally linearly dependent and locally linearly independent operators...|$|E
40|$|From data in {{the present}} we can predict the future and retrodict the past. These {{predictions}} and retrodictions are for histories — most simply time sequences of events. Quantum mechanics gives probabilities for individual histories in a decoherent set of alternative histories. This paper discusses several issues connected with the distinction between prediction and <b>retrodiction</b> in quantum cosmology: the difference between classical and quantum <b>retrodiction,</b> the permanence of the past, why we predict the future but remember the past, the nature and utility of reconstructing the past(s), and information theoretic measures of the utility of history. Typeset using REVTE...|$|E
40|$|It {{has been}} {{suggested}} that prediction may be an organizing principle of the mind and/or the neocortex, with cognitive machinery specifically engineered to detect forward-looking temporal relationships, rather than merely associating temporally contiguous events. There is a remarkable absence of behavioral tests of this idea, however. To address this gap, subjects were shown sequences of shapes governed by stochastic Markov processes, and then asked to choose which shape reliably came after a probe shape (prediction test) or before it (<b>retrodiction</b> test). Prediction was never superior to <b>retrodiction,</b> even when subjects were forewarned of a forward-directional test...|$|E
40|$|It {{has been}} {{proposed}} that mentalising involves retrodicting as well as predicting behaviour, by inferring previous mental states of a target. This study investigated whether <b>retrodiction</b> is impaired in individuals with autism spectrum disorders (ASD). Participants watched videos of real people reacting to the researcher behaving in one of four possible ways. Their task was to decide which of these four "scenarios" each person responded to. Participants' eye movements were recorded. Participants with ASD were poorer than comparison participants at identifying the scenario to which people in the videos were responding. There were no group differences in time spent looking at the eyes or mouth. The findings imply those with ASD are impaired in using mentalising skills for <b>retrodiction...</b>|$|E
40|$|Quantum {{mechanics}} {{represents one}} of the greatest triumphs of human intellect and, undoubtedly, is the most successful physical theory we have to date. However, since its foundation about a century ago, it has been uninterruptedly the center of harsh debates ignited by the counterintuitive character of some of its predictions. The subject of one of these heated discussions is the so-called "retrodiction paradox", namely a deceptive inconsistency of quantum mechanics which is often associated with the "measurement paradox" and the "collapse of the wave function"; it comes from the apparent time-asymmetry between state preparation and measurement. Actually, in the literature one finds several versions of the <b>retrodiction</b> paradox; however, a particularly insightful one was presented by Sir Roger Penrose in his seminal book The Road to Reality. Here, we address the question to what degree Penrose's <b>retrodiction</b> paradox occurs in the classical and quantum domain. We achieve a twofold result. First, we show that Penrose's paradox manifests itself in some form also in classical optics. Second, we demonstrate that when information is correctly extracted from the measurements and the quantum-mechanical formalism is properly applied, Penrose's <b>retrodiction</b> paradox does not manifest itself in quantum optics. Comment: 18 pages, 4 figure...|$|E
40|$|It {{is shown}} that the “retrodiction paradox ” {{recently}} introduced by Peres arises {{not because of the}} fallacy of the time-symmetric approach as he claimed, but due to an inappropriate usage of <b>retrodiction.</b> 1 In a recent Letter 1 Peres claimed that our time-symmetric approach to quantum theory, 2, 3 in which retrodictions and predictions are on equal footing, leads to a paradox. We shall show that the paradox arises due to a particular usage of <b>retrodiction</b> by Peres, and no such paradox arises in our approach. A trivial time asymmetry of a quantum measurements is illustrated by the following example. Assume that the x component of the spin of a spin- 1 / 2 particle was measured at time t, and was found to be σx = 1. While there is a symmetry regarding prediction and <b>retrodiction</b> for the result of measuring σx after or before the time t (in both cases we are certain that σx = 1), there is an asymmetry regarding the results of measuring σy. We can predict equal probabilities for each outcome, σy = ± 1, of a measurement performed after the time t, but we cannot claim the same for the result of a measurement of σy performe...|$|E
40|$|If a {{generalised}} measurement {{is performed}} on a quantum system {{and we do}} not know the outcome, are we able to retrodict it with a second measurement? We obtain a necessary and sufficient condition for perfect <b>retrodiction</b> of the outcome of a known generalised measurement, given the final state, for an arbitrary initial state. From this, we deduce that, when the input and output Hilbert spaces have equal (finite) dimension, it is impossible to perfectly retrodict the outcome of any fine-grained measurement (where each POVM element corresponds to a single Kraus operator) for all initial states unless the measurement is unitarily equivalent to a projective measurement. It also enables us to show that every POVM can be realised {{in such a way that}} perfect outcome <b>retrodiction</b> is possible for an arbitrary initial state when the number of outcomes does not exceed the output Hilbert space dimension. We then consider the situation where the initial state is not arbitrary, though it may be entangled, and describe the conditions under which unambiguous outcome <b>retrodiction</b> is possible for a fine-grained generalised measurement. We find that this is possible for some state if the Kraus operators are linearly independent. This condition is also necessary when the Kraus operators are non-singular. From this, we deduce that every trace-preserving quantum operation is associated with a generalised measurement whose outcome is unambiguously retrodictable for some initial state, and also that a set of unitary operators can be unambiguously discriminated iff they are linearly independent. We then examine the issue of unambiguous outcome <b>retrodiction</b> without entanglement. This has important connections with the theory of locally linearly dependent and locally linearly independent operators. Comment: To appear in Physical Review...|$|E
40|$|In {{tracking}} and sensor data fusion applications, the full information on kinematic object properties accumulated over a certain discrete time window {{up to the}} present time is contained in the conditional joint probability density function of the kinematic state vectors referring to each time step in this window. This density is conditioned by the time series of all sensor data collected the present time and has accordingly been called an accumulated state density (ASD). ASDs provide a unified treatment of filtering and <b>retrodiction</b> insofar as by marginalizing them appropriately, the standard filtering and <b>retrodiction</b> densities are obtained. In addition, ASDs fully describe the posterior correlations between the states at different instants of time. We here provide an introduction into the notion of ASDs, derive closed formulae for calculating them, and discuss their relevance for problem solving in exact track-to-track fusion in distributed sensor networks...|$|E
40|$|We {{discuss the}} {{so-called}} mean king's problem, a <b>retrodiction</b> problem among non-commutative observables, {{in the context}} of error detection. Describing the king's measurement effectively by a single error operation, we give a solution of the mean king's problem using quantum error-correcting codes. The existence of a quantum error-correcting code from a solution is also presented. Comment: 7 pages, 2 table...|$|E
