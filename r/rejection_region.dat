87|50|Public
25|$|If δ > <b>Rejection</b> <b>Region,</b> {{the data}} point is an outlier.|$|E
25|$|The {{modified}} Thompson Tau test {{is used to}} {{find one}} outlier at a time (largest value of δ is removed if it is an outlier). Meaning, if a data point {{is found to be}} an outlier, it is removed from the data set and the test is applied again with a new average and <b>rejection</b> <b>region.</b> This process is continued until no outliers remain in a data set.|$|E
2500|$|First, a data set's {{average is}} determined. Next the {{absolute}} deviation between each data {{point and the}} average are determined. Thirdly, a <b>rejection</b> <b>region</b> is determined using the formula: where [...] is the critical value from the Student t distribution, n is the sample size, and s is the sample standard deviation.|$|E
40|$|Likelihood ratio {{tests for}} the one-sided multivariate problem have non-monotone <b>rejection</b> <b>regions</b> and non-monotone power {{functions}} when correlation is present. This paper proposes an alternative test which is cone order monotone {{with respect to}} the positive orthant. Multiple endpoints Multivariate normal distribution Likelihood ratio test...|$|R
40|$|We {{propose a}} {{confidence}} envelope for false discovery control when testing multiple hypotheses of association simultaneously. The method is valid under arbitrary and unknown dependence between the test statistics {{and allows for}} an exploratory approach when choosing suitable <b>rejection</b> <b>regions</b> while still retaining strong control over the proportion of false discoveries. © Board of the Foundation of the Scandinavian Journal of Statistics 2006...|$|R
40|$|The {{introduction}} of the false discovery rate (FDR) by Benjamini and Hochberg has spurred {{a great interest in}} developing methodologies to control the FDR in various settings. The majority of existing approaches, however, address the FDR control for the case where an appropriate univariate test statistic is available. Modern hypothesis testing and data integration applications, on the other hand, routinely involve multivariate test statistics. The goal, in such settings, is to combine the evidence for each hypothesis and achieve greater power, while controlling the number of false discoveries. This paper considers data-adaptive methods for constructing nested <b>rejection</b> <b>regions</b> based on multivariate test statistics (z-values). It is proved that the FDR can be controlled for appropriately constructed <b>rejection</b> <b>regions,</b> even when the regions depend on data and are hence random. This flexibility is then exploited to develop optimal multiple comparison procedures in higher dimensions, where the distribution of non-null z-values is unknown. Results are illustrated using simulated and real data. Comment: 33 pages, 5 figures, 3 table...|$|R
5000|$|How it works:First, a data set's {{average is}} determined. Next the {{absolute}} deviation between each data {{point and the}} average are determined. Thirdly, a <b>rejection</b> <b>region</b> is determined using the formula: where [...] is the critical value from the Student t distribution, n is the sample size, and s is the sample standard deviation.To determine if a value is an outlier:Calculate δ = |(X - mean(X)) / s|.If δ > <b>Rejection</b> <b>Region,</b> the data point is an outlier.If δ ≤ <b>Rejection</b> <b>Region,</b> the data point is not an outlier.|$|E
5000|$|Define the <b>rejection</b> <b>region</b> of {{the null}} {{hypothesis}} for the NP test as ...|$|E
5000|$|Any other {{test will}} have a {{different}} <b>rejection</b> <b>region</b> that we denote by [...] The probability of the data falling in region [...] given parameter [...] is ...|$|E
40|$|A {{class of}} nonparametric tests {{based on the}} third quad-rant layer ranks has {{recently}} been studied by Woodworth fl 31 {{in connection with the}} problem of testing for independence in a bivariate distribution. In the present work, exact one-sided <b>rejection</b> <b>regions</b> are tabulated for the normal score layer rank test which is asymptotically locally most powerful for positive dependence in the bivariate normal distribution. The cut-off points are tabulated for sample sizes n» 4 (l) 9 and significance levels a«. 10,. 05,. 025 and. 01. Normal and Rdgeworth approxi-mations for the significance probabilities are also given. A simplified version of the normal score test is proposed and its <b>rejection</b> <b>regions</b> are tabulated. These tests are compared with the correlation coefficient test, Kendall's t test and Spear-man's rank correlation test for independence by means of Monte Carlo evaluation of power employing 10, 000 trials from each of three different types of bivariate distributions. Also included is {{a brief description of the}} computing aspects of the problem that may prove useful in similar studies. (• 2...|$|R
40|$|Uniformly most {{powerful}} Bayesian tests (UMPBTs) are defined to be Bayesian tests that maximize {{the probability that}} the Bayes factor against a fixed null hypothesis exceeds a specified evidence threshold. Unfortunately, UMPBTs exist only in a relatively limited number of testing scenarios, and in particular they cannot be defined for most tests involving linear models. In this dissertation, I generalize the notion of UMPBTs by restricting the class of alternative hypotheses that are considered in the test of a given null hypothesis. I call the resulting class of Bayesian hypothesis tests restricted {{most powerful}} Bayesian tests (RMPBTs). I then derive RMPBTs for linear models by restricting the class of possible alternative hypotheses to g-priors. An important feature of the resulting class of tests is that their <b>rejection</b> <b>regions</b> coincide with the <b>rejection</b> <b>regions</b> of usual frequentist F-tests, provided that the evidence thresholds for the Bayesian tests are appropriately matched {{to the size of the}} classical tests. This correspondence leads to the definition of default Bayes factors for many common tests of linear hypotheses. I illustrate the use of RMPBTs in the special cases of ANOVA and one- and two-sample t-tests. I then use RMPBTs to develop a novel Bayesian variable selection method and compare its performance to other Bayesian tests based on g-priors in a sequence of numerical examples. Finally, a software package for R is detailed which implements the RMPBTs described herein as well as many of the UMPBTs that have been developed...|$|R
40|$|Abstract. Several copula goodness-of-fit {{approaches}} are examined, {{three of which}} are proposed in this paper. Results are presented from an extensive Monte Carlo study, where we {{examine the effect of}} dimension, sample size and strength of dependence on the nominal level and power of the different approaches. While no approach is always the best, some stand out and conclusions and recommendations are made. A novel study of p-value variation due to permuation order, for approaches based on Rosenblatt’s transformation is also carried out. Results show significant variation due to permutation order for some of the approaches based on this transform. However, when approaching <b>rejection</b> <b>regions,</b> the additional variation is negligible...|$|R
50|$|For example, when α {{is set to}} 5%, the {{conditional}} probability of a type I error, given that the null hypothesis is true, is 5%, and a statistically significant result is one where the observed p-value is less than 5%. When drawing data from a sample, {{this means that the}} <b>rejection</b> <b>region</b> comprises 5% of the sampling distribution. These 5% can be allocated {{to one side of the}} sampling distribution, as in a one-tailed test, or partitioned to both sides of the distribution as in a two-tailed test, with each tail (or <b>rejection</b> <b>region)</b> containing 2.5% of the distribution.|$|E
5000|$|... #Caption: In a two-tailed test, the <b>rejection</b> <b>region</b> for a {{significance}} level of α=0.05 is partitioned to {{both ends of}} the sampling distribution and makes up 5% of the area under the curve (white areas).|$|E
5000|$|... where S is the {{standard}} deviation of D, Φ is {{the standard}} normal cumulative distribution function, and δ = EY2 &minus; EY1 is the true effect of the treatment. The constant 1.64 is the 95th percentile of the standard normal distribution, which defines the <b>rejection</b> <b>region</b> of the test.|$|E
40|$|Abstract A {{goodness}} of fit test for the drift coefficient of an ergodic diffusion process is presented. The test {{is based on the}} score marked empirical process. The weak convergence of the proposed test statistic is studied under the null hypothesis and it is proved that the limit process is a continuous Gaussian process. The structure of its covariance function allows to calculate the limit distribution {{and it turns out that}} it is a function of a standard Brownian motion and so exact <b>rejection</b> <b>regions</b> can be constructed. The proposed test is asymptotically distribution free and it is consistent under any simple fixed alternative...|$|R
40|$|Estimation results {{obtained}} by parametric models may be seriously misleading when {{the model is}} misspecified or poorly approximates the true model. This study proposes a test that jointly tests the specifications of multiple response probabilities in unordered multinomial choice models. The test statistic is asymptotically chi-square distributed, consistent against a fixed alternative and able to detect a local alternative approaching to the null at a rate slower than the parametric rate. We show that <b>rejection</b> <b>regions</b> can be calculated by a simple parametric bootstrap procedure, when the sample size is small. The size {{and power of the}} tests are investigated by Monte Carlo experiments...|$|R
40|$|Our first {{attempts}} at the fabrication of long-wavelength infrared cut-off filters with extended transmission and <b>rejection</b> <b>regions</b> {{that are based}} {{on the use of the}} critical angle, the dispersion of refractive indices, and on thin-film interference were not very successful. The design of the filter consisted of layers placed at the interface between two high-index prisms. Using the available deposition equipment, the layers produced were porous and very rough. The pores adsorbed water vapor, which resulted in absorption. The roughness made the process of optical contacting very difficult. In this paper we describe the adjustments in the design and deposition processes that allowed us to obtain filters with a better and more stable performance. Peer reviewed: YesNRC publication: Ye...|$|R
50|$|The {{use of a}} {{one-tailed test}} is {{dependent}} on whether the research question or alternative hypothesis specifies a direction such as whether a group of objects is heavier or the performance of students on an assessment is better. A two-tailed test may still be used {{but it will be}} less powerful than a one-tailed test because the <b>rejection</b> <b>region</b> for a one-tailed test is concentrated {{on one end of the}} null distribution and is twice the size (5% vs. 2.5%) of each <b>rejection</b> <b>region</b> for a two-tailed test. As a result, the null hypothesis can be rejected with a less extreme result if a one-tailed test was used. The one-tailed test is only more powerful than a two-tailed test if the specified direction of the alternative hypothesis is correct. If it is wrong, however, then the one-tailed test has no power.|$|E
5000|$|A {{likelihood}} ratio test is any test with critical region (or <b>rejection</b> <b>region)</b> {{of the form}} [...] where [...] is any number satisfying [...] Many common test statistics such as the Z-test, the F-test, Pearson's chi-squared test and the G-test are tests for nested models and can be phrased as log-{{likelihood ratio}}s or approximations thereof.|$|E
50|$|The {{modified}} Thompson Tau test {{is used to}} {{find one}} outlier at a time (largest value of δ is removed if it is an outlier). Meaning, if a data point {{is found to be}} an outlier, it is removed from the data set and the test is applied again with a new average and <b>rejection</b> <b>region.</b> This process is continued until no outliers remain in a data set.|$|E
40|$|The mean {{residual}} life (MRL) {{measures the}} remaining life expectancy and {{is useful in}} actuarial studies, biological experiments and clinical trials. To assess the covariate effect, an additive MRL regression model has been proposed in the literature. In this paper, {{we focus on the}} topic of model checking. Specifically, we develop two goodness-of-fit tests to test the additive MRL model assumption. We explore the large sample properties of the test statistics and show that both of them are based on asymptotic Gaussian processes so that resampling approaches can be applied to find the <b>rejection</b> <b>regions.</b> Simulation studies indicate that our methods work reasonably well for sample sizes ranging from 50 to 200. Two empirical data sets are analyzed to illustrate the approaches. Department of Applied Mathematic...|$|R
40|$|This chapter proposes widely {{applicable}} resampling-based single-step and stepwise multiple {{testing procedures}} (MTP) for controlling a broad class of Type I error rates, in testing problems involving general data generating distributions (with arbitrary dependence structures among variables), null hypotheses, and test statistics (Dudoit and van der Laan, 2005; Dudoit et al., 2004 a,b; van der Laan et al., 2004 a,b; Pollard and van der Laan, 2004; Pollard et al., 2005). Procedures are provided to control Type I error rates defined as tail probabilities for arbitrary {{functions of the}} numbers of Type I errors, V_n, and rejected hypotheses, R_n. These error rates include: the generalized family-wise error rate, gFWER(k) = Pr(V_n 3 ̆e k), or chance of at least (k+ 1) false positives (the special case k= 0 corresponds to the usual family-wise error rate, FWER), and tail probabilities for the proportion of false positives among the rejected hypotheses, TPPFP(q) = Pr(V_n/R_n 3 ̆e q). Single-step and step-down common-cut-off (maxT) and common-quantile (minP) procedures, that {{take into account the}} joint distribution of the test statistics, are proposed to control the FWER. In addition, augmentation multiple testing procedures are provided to control the gFWER and TPPFP, based on any initial FWER-controlling procedure. The results of a multiple testing procedure can be summarized using <b>rejection</b> <b>regions</b> for the test statistics, confidence regions for the parameters of interest, or adjusted p-values. A key ingredient of our proposed MTPs is the test statistics null distribution (and consistent bootstrap estimator thereof) used to derive <b>rejection</b> <b>regions</b> and corresponding confidence regions and adjusted p-values. This chapter illustrates an implementation in SAS (Version 9) of the bootstrap-based single-step maxT procedure and of the gFWER- and TPPFP-controlling augmentation procedures. These multiple testing procedures are applied to an HIV- 1 sequence dataset to identify codon positions associated with viral replication capacity...|$|R
40|$|The Coalition Government’s <b>rejection</b> of <b>regions,</b> {{understood}} here as {{a spatial}} unit for managing sub-national development activity, remains politically and spatially ‘out of synch’ with EU regional policy. It is within this context that some important policy and delivery quandaries arise within and across the former English regions...|$|R
5000|$|This [...] is {{a random}} variable. A t {{distribution}} with a random number of {{degrees of freedom}} does not exist. Nevertheless, the Behrens-Fisher T can be compared with a corresponding quantile of Student's t distribution with these estimated number of degrees of freedom, , which is generally non-integer. In this way, the boundary between acceptance and <b>rejection</b> <b>region</b> of the test statistic T {{is calculated based on}} the empirical variances si2, {{in a way that is}} a smooth function of these.|$|E
3000|$|... −  1 respectively. The {{critical}} F-value on the F-distribution which {{marks the}} boundary between the lower 95  % (non <b>rejection</b> <b>region)</b> and the upper 5  % (<b>rejection</b> <b>region)</b> is determined using the F-table (or digitally) with chosen significance level (α), numerator degrees of freedom (df [...]...|$|E
40|$|This study {{offers a}} method for empirically testing {{theories}} operationalized {{in the form of}} multivariate statistical models. An innovation of the method is that it distinguishes testing into three separate forms, “effect testing,” “prediction testing,” and “theory testing,” where statistical significance plays a separate role in each one. In another innovation, the researcher specifies not only his or her desired level of statistical significance, but also his or her desired level of practical significance. Statistical significance and practical significance each serve as a dimension in a two-dimensional table that specifies the <b>rejection</b> <b>region</b> – the region where the researcher can justify the decision to reject the theory being tested. The boundary of the <b>rejection</b> <b>region</b> is the “validity frontier,” which ongoing research may advance so as {{to reduce the size of}} the <b>rejection</b> <b>region...</b>|$|E
40|$|The aim of {{the present}} paper is to {{estimate}} and control the Type I and Type II errors of a simple hypothesis testing problem of the drift/viscosity coefficient for stochastic fractional heat equation driven by additive noise. Assuming that one path of the first $N$ Fourier modes of the solution is observed continuously over a finite time interval $[0,T]$, we propose {{a new class of}} <b>rejection</b> <b>regions</b> and provide computable thresholds for $T$, and $N$, that guarantee that the statistical errors are smaller than a given upper bound. The considered tests are of likelihood ratio type. The main ideas, and the proofs, are based on sharp large deviation bounds. Finally, we illustrate the theoretical results by numerical simulations. Comment: Forthcoming in Stochastic Partial Differential Equations: Analysis and Computation...|$|R
40|$|Coefficient of {{variation}} is a reliability index. It {{is widely used}} in evaluation of reliability of existing structure, hospital statistics, insurance theory and so on. Hypothesis testing of the coefficient {{of variation}} is realistic significance. The sample of normal distribution is extracted, according {{to the relationship between}} sample mean X, sample standard deviation S and coefficient of variation *, the sample distribution of containing coefficient of variation * was given in this paper, at the same time its density function* dy is given. A way of hypothesis test of the coefficient of variation is established in small sample. Through using the sample distribution and null hypothesis, test statistics * is determined. Then a small probability events what makes alternative hypothes right is constructed, using this statistics. Thus <b>rejection</b> <b>regions</b> or <b>rejection</b> conditions are given. (* Indicates a formula, please see the full text...|$|R
40|$|The Bioconductor R package multtest {{implements}} widely applicable resampling-based single-step and stepwise multiple {{testing procedures}} (MTP) for controlling a broad class of Type I error rates, in testing problems involving general data generating distributions (with arbitrary dependence structures among variables), null hypotheses, and test statistics. The {{current version of}} multtest provides MTPs for tests concerning means, differences in means, and regression parameters in linear and Cox proportional hazards models. Procedures are provided to control Type I error rates defined as tail probabilities for arbitrary functions of the numbers of false positives and rejected hypotheses. These error rates include tail probabilities {{for the number of}} false positives (generalized family-wise error rate, gFWER) and the proportion of false positives among the rejected hypotheses (TPPFP). Single-step and step-down common-cut-off (maxT) and common-quantile (minP) procedures, that take into account the joint distribution of the test statistics, are proposed to control the family-wise error rate (FWER), or chance of at least one Type I error. In addition, augmentation multiple testing procedures are provided to control the gFWER and TPPFP, based on any initial FWER-controlling procedure. The results of a multiple testing procedure can be summarized using <b>rejection</b> <b>regions</b> for the test statistics, confidence regions for the parameters of interest, or adjusted p-values. A key ingredient of our proposed MTPs is the test statistics null distribution (and estimator thereof) used to derive <b>rejection</b> <b>regions</b> and corresponding confidence regions and adjusted p-values. Both bootstrap and permutation estimators of the test statistics null distribution are available. The S 4 class/method object-oriented programming approach was adopted to summarize the results of a MTP. The modular design of multtest allows interested users to readily extend the package 2 ̆ 7 s functionality. Typical testing scenarios are illustrated by applying various MTPs implemented in multtest to the Acute Lymphoblastic Leukemia (ALL) dataset of Chiaretti et al. (2004), with the aim of identifying genes whose expression measures are associated with (possibly censored) biological and clinical outcomes...|$|R
40|$|The {{use of a}} fixed <b>rejection</b> <b>region</b> for {{multiple}} hypothesis testing {{has been shown to}} outperform standard fixed error rate approaches when applied to control of the false discovery rate. In this work it is demonstrated that, if the original step-up procedure of Benjamini and Hochberg is modified to exercise adaptive control of the false discovery rate, its performance is virtually identical to that of the fixed <b>rejection</b> <b>region</b> approach. In addition, the dependence of both methods on the proportion of true null hypotheses is explored, with a focus on the difficulties that are involved in the estimation of this quantity. Copyright 2004 Royal Statistical Society. ...|$|E
3000|$|..., (i[*]=[*] 1,…, 8), {{indicating}} that H 0 i (i[*]=[*] 1,…, 8) {{falls in the}} <b>rejection</b> <b>region,</b> and all variables (x 1, x 2, x 3, x 4, x 5, x 6, x 7, x 8) have a significant linear impact on y.|$|E
40|$|As {{a rather}} expository article, {{an example of}} {{sequential}} inspection plan is dealt with. It is proposed to replace current double inspection plan {{for a kind of}} products. Some features of a special case of sequential test without <b>rejection</b> <b>region</b> are remarked. Some questions about practice of inspection are raised...|$|E
40|$|Let X 1 [...] . X, be n random variables, with {{cumulative}} distribution functions F 1, [...] ., F,. Define ¢i: = Fi(Xi) for all i, and let ~(1) ~< [...] . ~< ~(,) be the order statistics of the (~) ~. Let cq ~< [...] . ~< ~. be n {{numbers in the}} interval [0, 1]. We show that the probability of the event R: = {(") ~< ct ~ for all 1 ~< i ~< n} is at most min~n~Ji}. Moreover, this bound is exact: for any given n marginal distributions (F~) ~, there exists a joint distribution with these marginals such that the probability of R is exactly min~nct~/i}. This result is used in analyzing the significance level of multiple hypotheses testing. In particular, it implies that the ROger tests dominate all tests with <b>rejection</b> <b>regions</b> of type R as above. © 1997 Elsevier Science B. V...|$|R
40|$|Let X 1, [...] ., Xn be n random variables, with {{cumulative}} distribution functions F 1, [...] ., Fn. Define [xi]i: = Fi(Xi) for all i, and let [xi](1) [less-than-or-equals, slant] [...] . [less-than-or-equals, slant] [xi](n) be the order statistics of the ([xi]i) i. Let [alpha] 1 [less-than-or-equals, slant] [...] . [less-than-or-equals, slant] [alpha]n be n {{numbers in the}} interval [0, 1]. We show that the probability of the event R:= {[xi](i) [less-than-or-equals, slant] [alpha]i for all 1 [less-than-or-equals, slant] i [less-than-or-equals, slant] n} is at most minin[alpha]i/i}. Moreover, this bound is exact: for any given n marginal distributions (Fi) i, there exists a joint distribution with these marginals such that the probability of R is exactly minin[alpha]i/i}. This result is used in analyzing the significance level of multiple hypotheses testing. In particular, it implies that the Rüger tests dominate all tests with <b>rejection</b> <b>regions</b> of type R as above. Rüger tests Order statistics...|$|R
40|$|In an {{expected}} utility framework, assuming a decision maker operates under utility k([dot operator][theta]), for two risky alternatives X and Y with respective distribution functions F and G, alternative X {{is said to}} dominate alternative Y with respect to k([dot operator][theta]) if for all y. Utilizing the empirical distribution functions of F and G, a statistical test is presented to test the null hypothesis of indifference between X and Y given k([dot operator][theta]) against the hypothesis that X dominates Y with respect to k([dot operator][theta]). This is a large sample testing application of stochastic dominance {{with respect to a}} function. The asymptotic distribution of the test statistic associated with the null hypothesis given a sub-set of the utility function parameter space is developed. Based on large sample <b>rejection</b> <b>regions,</b> the hypothesis of preference of one alternative over another is demonstrated with an empirical example. ...|$|R
