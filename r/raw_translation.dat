12|26|Public
25|$|On August 4, Secretary of Defense McNamara gave President Johnson the <b>raw</b> <b>translation</b> of intercepted Korean {{transmissions}} {{directly from}} the NSA which, ostensibly, reported to DI McCone, rather than to McNamara. It was later determined that the transmission took place before the weapon discharges that night {{which leads to the}} conclusion that the transmission refers to the events of the attack the day before, and that, although Destroyers Maddox, and Turner Joy fired hundreds of shells at intermittent radar contacts, they were firing at false returns.|$|E
5000|$|The record's title {{comes from}} the <b>raw</b> <b>translation</b> of two phrases from the Icelandic and Turkish {{languages}} respectively: [...] "grey tickles" [...] refers to approaching middle age; [...] "black pressure" [...] {{comes from the}} Turkish word for nightmare. Grant stated {{that he wanted to}} get angrier and moodier on this record although he enjoyed the process of making this album more than the previous two. The album's trailer features Grant in what appears to be after a psychotic break, covered in blood and wielding a croquet mallet as a weapon. Grant described it as a fantasy of what he would like to do every time somebody calls him a faggot.|$|E
50|$|Bảo Ninh {{achieved}} {{prominence in}} Hanoi {{with the first}} version of the novel, Thân phận của tình yêu (English: The Destiny of Love), which was published in roneo form (similar to photocopying) before 1990. Soon afterwards Phan Thanh Hao translated it into English and took the manuscript to the British publishers Secker & Warburg. Geoffrey Mulligan, an editor there, commissioned Frank Palmos, an Australian journalist who had reported on the Vietnam War and written about it in his book Ridding the Devils (1990), to write an English version based on the <b>raw</b> <b>translation.</b> Bao Ninh had read Phan Thanh Hao's Vietnamese translation of Ridding the Devils and was willing to accept this arrangement. After several meetings with both the author and the translator, Hao, in Hanoi, and journeys throughout Vietnam to check details, Palmos wrote the English version over seven months. It was published in 1994 under the title The Sorrow of War.|$|E
5000|$|In {{the course}} of her career Eisenman worked on the {{subtitles}} of over 300 films. She speaks English, German, French, Italian, Portuguese and Spanish. She subtitled films shot in other languages as well, including Dutch, Danish, Chinese and Japanese, by editing the <b>raw</b> <b>translations</b> and turning them into subtitles.|$|R
40|$|CASMACAT is a modular, web-based {{translation}} workbench that offers ad-vanced functionalities for computer-aided translation {{and the scientific}} study of hu-man translation: automatic interaction with machine translation (MT) engines and translation memories (TM) to ob-tain <b>raw</b> <b>translations</b> or close TM matches for conventional post-editing; interactive translation prediction based on an MT en-gine’s search graph, detailed recording and replay of edit actions and translator’s gaze (the latter via eye-tracking), and the sup-port of e-pen as an alternative input device. The system is open source sofware and in-terfaces with multiple MT systems...|$|R
50|$|Translation {{memories}} are typically {{used in conjunction}} with a dedicated computer assisted translation (CAT) tool, word processing program, terminology management systems, multilingual dictionary, or even <b>raw</b> machine <b>translation</b> output.|$|R
40|$|In this paper, an {{objective}} qtumtitative quality mea-sure is proposed to evaluate tile performance of machiue translation systems. The proposed {{method is to}} compare the <b>raw</b> <b>translation</b> output of an MT system with the fi-nal revised version lor the customers, and then compute the editing efforts required to convert he <b>raw</b> <b>translation</b> to the final version. In contrast o the other prolx) sals, the evaluatiral process can he (lone quickly and auto-matically. Itence, it can provide a quick response on any system change. A system designer can thus quickly lind the advantages or faults of a particular performance-improving strategy aml improve system performance dy-namieally. Application of such a measure to improve the system performance on-line on a parameterized and feedback-controlled system will be demonstrated. Fur-thermore, because the revised versiou is used directly as a reference, tile perfoInunice lneasnre can reflect tile real quality gap between the system performance and customer expectation. A system designer can thus con-centrate on practically impo~ult opics rather than ml theoretically interesting issues. 1...|$|E
40|$|In this paper, we {{describe}} a system and methods for finding structural correspondences from the paired dependency structures of a source sentence and its translation in a target language. The system {{we have developed}} finds word correspondences first, then finds phrasal correspon(tences based on word correspondences. We have also developed a GUI system with which a user can check and correct tile correspondences retrieved by the system. These structural correspondences {{will be used as}} <b>raw</b> <b>translation</b> I) atterns in a corpus-based translation system. ...|$|E
40|$|This report {{describes}} {{our test}} on using statistical translation models for bilingual IR tasks in CLEF- 2001. These translation {{models have been}} trained {{on a set of}} parallel web pages automatically mined from the Web. Our goal is to compare the following approaches: - using the original parallel corpora or a cleaned corpora to train translation models; - using the <b>raw</b> <b>translation</b> probabilities to weigh query words or combine the probabilities with IDF; - using different cut-off probability values in the translation models (i. e. delete the translations lower than a threshold) ...|$|E
5000|$|Instantly move between <b>raw</b> {{sequence}} multi-frame <b>translation</b> and restriction maps ...|$|R
50|$|Post-editing is {{used when}} <b>raw</b> machine <b>{{translation}}</b> {{is not good}} enough and human translation not required. Industry advises post-editing to be used when it can at least double the productivity of manual translation, even fourfold it in the case of light post-editing.|$|R
40|$|The present paper {{evaluates the}} machine {{translation}} systems T 1 Professional 3. 0 and Personal Translator plus 98. First, the possible applications, the functions {{and the structure}} of the two systems are described. A comparison shows the functional differences. A general definition of the concept evaluation, an overview of the most important evaluation methods and a description of the nominal phrase serve as background information for the empirical investigation. In this investigation a test suite of 453 nominal phrases is translated by T 1 Professional 3. 0 and PT plus 98. The <b>raw</b> <b>translations</b> are checked for grammatical correctness and the most striking translation errors are analysed. The evaluation shows how the systems handle the translation of nominal phrases and which system does best. (orig.) SIGLEAvailable from TIB Hannover: RR 8958 (63) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|R
40|$|This paper {{presents}} an in-depth investigation on integrating neural language models in translation systems. Scaling neural language models {{is a difficult}} task, but crucial for real-world applications. This paper evaluates the impact on end-to-end MT quality of both new and existing scaling techniques. We show when explicitly normalising neural models is necessary and what optimisation tricks one should use in such scenarios. We also focus on scalable training algorithms and investigate noise contrastive estimation and diagonal contexts as sources for further speed improvements. We explore the trade-offs between neural models and back-off n-gram models and find that neural models make strong candidates for natural language applications in memory constrained environments, yet still lag behind traditional models in <b>raw</b> <b>translation</b> quality. We conclude {{with a set of}} recommendations one should follow to build a scalable neural language model for MT. Comment: NAACL 201...|$|E
40|$|In this paper, we {{describe}} a system and methods for finding structural correspondences from the paired dependency structures of a source sentence and its translation in a target language. The system {{we have developed}} finds word correspondences first, then finds phrasal correspondences based on word correspondences. We have also developed a GUI system with which a user can check and correct the correspondences retrieved by the system. These structural correspondences {{will be used as}} <b>raw</b> <b>translation</b> patterns in a corpus-based translation system. 1 Introduction So far, a number of methodologies and systems for machine translation using large corpora exist. They include example-based approaches [7, 8, 9, 12], pattern-based approaches [10, 11, 14], and statistical approaches. For instance, example-based approaches use a large set of translation patterns each of which is a pair of parsed structures of a source-language fragment and its target-language translation fragment. Figure 1 shows a [...] ...|$|E
40|$|In lilts paper, an {{objective}} qtumtitafive quality incasure is protxsed to evaluate tile performance of machiuc translation systems. The proposed methcu 3 {{is to compare}} the <b>raw</b> <b>translation</b> output of an MT system with the final revised version lbr the customers, and theu compute the editing efforts mquir to convert the mw translalion to the final version. lu contrast to the other prolx>sals, the evaluation process can be done quickly and automatically. lienee, it can provide a quick response on any system change. A systen tiesigner can thus quickly lind the advantages or faults of a particular performanceimproving strategy anti improve system performance dynamically. Application of such a measure to improve the systen performance on-line on a parameterized and feedback-controlled system will be demonstrated. Furtilermore, because the revised version is used directly as a reference, the peffollllauce nleaSUl-e caB reflect tile real quality gap between the system perfoonance and customer expectation. A system designer can thus concentra e on practically impostor topics ruther than on theoretically interesting issues...|$|E
40|$|Machine {{translations}} {{often have}} to be manually post-edited {{in order to meet}} quality demands. Since this is a labour-intensive task, it is desirable to find ways to automate (parts of) the post-editing process. This thesis presents a method for generation of rule sets for automatic post-editing of machine translations. The basic idea of the method is to generate a set of candidate rules from a parallel corpus of <b>raw</b> machine <b>translations</b> and manually post-edited translations, and to filter this set by measuring the effect of applying its individual rules to the <b>raw</b> machine <b>translations</b> of another corpus. As indicated by three frequently used evaluation metrics (BLEU, Meteor, and TER), rule sets created using this method are capable of increasing the translation quality of previously unseen translations from the same domain as the corpus used for filtering. Sammandrag Maskinöversättningar måste ofta efterbehandlas manuellt för att uppfylla uppställda kvalitetskrav. Eftersom detta är en arbetskrävande uppgift är de...|$|R
40|$|This paper {{describes}} Pa~lh'ans- a {{fully automatic}} production MT system de-signed for producing <b>raw</b> <b>translations</b> of patent texts fl'om English into Dan-ish. First {{we describe the}} backbone of tile system: the EUROTRA research project, and prototype. Then we give {{an overview of the}} trauslat, ion process and the basic flmetionality of Pa'I~'ans, and finally we describe some recent ex-tensions for improving processing effi-ciency and the translation quality of un-exl) ected input encountered in real-lit~ texts. 1 Introduct ion Pa]~'ans 1 is a fully-automatic machine transla-tion system designed for English-Danish transla-tion of patent, texts. It is based on the linguistic specifications and to some extent on the software of the EUROTRA project of the European Com-munity (Copeland et al., 1991 a; Copeland et al., 1991 b). Pa'IYans consists of a core grammar and translation module and a host of peripheral util-ities: terin databases, general databases, editors for pre- and postediting, document handling fa-cilities, facilities for creating and updating term databases. In this short presentation we will con-centrate on the grammar, lexicon and translation module and on some of the new features of Pa...|$|R
40|$|We {{participated in}} the English-Chinese CLQA task with the {{following}} procedures. An English question was first classified as to its answer category, and then rendered into Chinese in three ways: <b>raw</b> text <b>translation</b> by MT, extracted entity translation by our web-translation algorithm, and web-assisted question expansion followed by MT and entity web-translation. A combined Chinese question is formed that retrieves the top 100 sentences from the target collection. Candidate Chinese entities are extracted from the sentences and ranked for answer-hood based {{on a combination of}} five sources of evidence...|$|R
40|$|Swahili Language Manager (SALAMA) is a {{computational}} {{environment for}} managing written Swahili language and for developing {{various kinds of}} language applications. Having been subject to development since 1985, it currently (2004) contains the Standard Swahili lexicon as fully as possible. As it is a system for managing the language, it includes also the full morphological and morpho-phonological description of Swahili, a rule-based system for solving the word level ambiguities, a rule-based system for tagging text syntactically (including alternatively a shallow Constraint Grammar parsing or a deep Dependency Grammar parsing), a rule-based system for handling idiomatic expressions, proverbs and other non-standard clusters of words, and a semantic tagging and disambiguation system for defining correct semantic equivalents in English. SALAMA facilitates also a <b>raw</b> <b>translation</b> from Swahili to English, including the correct surface forms in English (e. g. verbs, nouns and adjectives) and transfer rules for the correct English word order. An essential part in developing and testing SALAMA is the Helsinki Corpus of Swahili, which has been under construction since 1988 and is currently globally available at the Language Bank of Finland (www. csc. fi). The paper discusses all these features in detail...|$|E
40|$|The {{standard}} {{design for a}} computer-assisted translation system consists of data entry of source text, machine translation, and revision of <b>raw</b> machine <b>translation.</b> This paper discusses this {{standard design}} and presents an alternative multi-level design consisting of integrated word process-ing, terminology aids, preprocessing aids and a link to an off- l ine machine translation system. Advantages of the new design are discussed. I THE STANDARD DESIGN FOR A COMPUTER-ASSISTED TRANSLATION SYSTEM. The standard design for a computer-assisted translation system consists of three phases: (A) data entry of the source text, (B) machin...|$|R
5000|$|Localization is {{the actual}} process of {{translating}} the language assets in a game into other languages. By localizing games, they increase their level of accessibility where games could help to expend the international markets effectively. Game localization is generally known as language translations yet a [...] "full localization" [...] of a game is a complex project. Different levels of translation range from: zero translation being {{that there is no}} translation to the product and all things are sent <b>raw,</b> basic <b>translation</b> where only a few text and subtitles are translated or even added, and a full translation where new voice overs and game material changes are added.|$|R
40|$|The {{concept of}} {{translational}} research, {{which aims to}} facilitate the application of basic scientific discoveries in clinical and community settings, is currently in vogue. While there are powerful forces driving this trend, support for translational research {{must be accompanied by}} a robust investment in basic science, which provides the essential <b>raw</b> material for <b>translation</b> and continues to represent humanity's best hope to meet a wide range of public health challenges...|$|R
40|$|We {{propose to}} use a {{statistical}} phrase-based machine translation system in a post-editing task: the system takes as in-put <b>raw</b> machine <b>translation</b> output (from a commercial rule-based MT system), and produces post-edited target-language text. We report on experiments that were per-formed on data collected in precisely such a setting: pairs of raw MT output and their manually post-edited versions. In our evaluation, the output of our automatic post-editing (APE) system is not only bet-ter quality than the rule-based MT (both {{in terms of the}} BLEU and TER metrics), it is also better than the output of a state-of-the-art phrase-based MT system used in standalone translation mode. These re-sults indicate that automatic post-editing constitutes a simple and efcient way of combining rule-based and statistical MT technologies. ...|$|R
40|$|Massive online {{collaboration}} {{could become}} a winning strategy {{to tear down the}} language barriers on the web, and in order for this to happen appropriate computer tools, like reliable machine translation systems and friendly postediting interfaces, should be widely available. However, community collaboration should not only involve the postediting of machine translations, but also the creation of the linguistic resources needed to improve the translation engines. In this paper we introduce Tradubi, a free/open-source web application for social translation, whose aim is, firstly, to build a platform for collaboratively customising and improving rule-based machine translation systems and, secondly, to offer an environment for the postediting and subsequent sharing of <b>raw</b> machine <b>translations.</b> Currently, Tradubi is built upon the free/open-source Apertium machine translation engine. The application can be accessed at tradubi. com or downloaded and installed on a different server. 1...|$|R
40|$|CLS Corporate Language Services AG {{recently}} began offering the rapid post-editing of <b>raw</b> machine <b>translation</b> output {{to meet the}} rising demand for this service among clients. What is meant by rapid post-editing is the rough correction of machine translated texts with emphasis on speed and denotative accuracy. In the preliminary phase of the project, CLS conducted a test among four inhouse translators. The objective was to gain practical experience, establish workflow requirements and set up efficient post-editing processes. Text samples were selected from several subject categories, and post-edited in English, German and French. The participants were given 10, 15 and 30 minutes per page to complete their tasks. This paper aims to present {{the results of the}} post-editing test at CLS Corporate Language Services AG, and to examine the conditions under which a rapid post-editing service is feasible in a commercial environment. ...|$|R
40|$|This master's {{thesis is}} related to human {{post-editing}} (PE) of <b>raw</b> machine <b>translation</b> (MT) output. It aims to identify the particular differences between post-edited versions with and without guidelines. An experiment with participants was carried out to obtain the relevant information. The test group post-edited the raw MT output with post-editing guidelines, while the control group post-editing without guidelines. A third group carried out a human post-editing evaluation. Different aspects were analysed and studied, for example, {{the time that the}} participants needed to perform the post-editing task and its relation with the quality of the output, the number and types of changes made during the post-editing phase in both groups and the post-editing effort. We use the PE guidelines proposed by Marian Flanagan and Tina Paulsen in their study of 2014 "Testing post-editing guidelines: how translation trainees interpret them and how to tailor them for translator training purposes"...|$|R
40|$|This thesis {{explores the}} {{correlations}} between statistical machine translation quality and post-editing activity of the English to Japanese language pair. Building on some previous research done at Autodesk Development Sàrl., and using a qualitative post-editing (PE) analysis method based on logical edits, we conducted a separate short research to determine the effort involved to post-edit machine translation (MT) stemming from different Moses configurations. We specially wanted to see whether it was establish correlations between MT quality, PE effort and productivity with the designed metric. Although, due to data scarcity, not all results are conclusive, this preliminary study has shows that carrying out a qualitative, logical-edits-based analysis of post-editing is informative as to areas of potential improvement in the <b>raw</b> machine <b>translation</b> output and post-editing activity in general. We suggested future work, in particular to determine the differences with post-editing analyses conducted with automated metrics...|$|R
40|$|This paper {{describes}} the submission of the AMU (Adam Mickiewicz University) {{team to the}} Automatic Post-Editing (APE) task of WMT 2016. We explore the application of neural translation models to the APE problem and achieve good results by treating different models as components in a log-linear model, allowing for multiple inputs (the MT-output and the source) that are decoded to the same target language (post-edited translations). A simple string-matching penalty integrated within the log-linear model is used to control for higher faithfulness {{with regard to the}} <b>raw</b> machine <b>translation</b> output. To overcome the problem of too little training data, we generate large amounts of artificial data. Our submission improves over the uncorrected baseline on the unseen test set by - 3. 2 % TER and + 5. 5 % BLEU and outperforms any other system submitted to the shared-task by a large margin. Comment: Submission to the WMT 2016 shared task on Automatic Post-Editin...|$|R
40|$|As {{the amount}} of {{available}} silicon resources on one chip increases, {{we have seen the}} advent of ever increasing parallel resources integrated on-chip. Many architectures use these resources as individually controllable, parallel processing elements. While such architectures excel at parallel applications, they seldom support legacy single-threaded applications. In this work, we propose using parallel resources to facilitate execution of legacy codes with acceptable performance on parallel architectures containing a drastically different instruction set through the use of an all software parallel dynamic binary translation engine. This engine spatially implements different portions of a superscalar processor across distinct parallel elements thus exploiting the pipeline parallelism inherent in a superscalar. This virtual microarchitecture facilitates changing the allocation of silicon resources between different superscalar units in software which is not possible when special purpose physical resources are built. We propose building dynamically reconfigurable architectures that inspect the current virtual machine configuration along with the dynamic instruction stream and change the configuration to best suit the program's needs at runtime. An x 86 to <b>Raw</b> parallel <b>translation</b> engine was built in which tiles dedicated to translation can be traded for tiles dedicated to the memory system as an example of dynamic reconfiguration...|$|R
40|$|Departament de Traducció i InterpretacióThe {{number of}} {{accessible}} audiovisual products {{and the pace}} at which audiovisual content is made accessible need to be increased, reducing costs whenever possible. The implementation of different technologies which are already available in the translation field, specifically machine translation technologies, could help reach this goal in audio description for the blind and partially sighted. Measuring machine translation quality is essential when selecting the most appropriate machine translation engine to be implemented in the audio description field for the English-Catalan language combination. Automatic metrics and human assessments are often {{used for this purpose}} in any specific domain and language pair. This article proposes a methodology based on both objective and subjective measures for the evaluation of five different and free online machine <b>translation</b> systems. Their <b>raw</b> machine <b>translation</b> outputs and the post-editing effort that is involved are assessed using eight different scores. Results show that there are clear quality differences among the systems assessed and that {{one of them is the}} best rated in six out of the eight evaluation measures used. This engine would therefore yield the best freely machine-translated audio descriptions in Catalan presumably reducing the audio description process turnaround and costs...|$|R
40|$|This paper {{describes}} {{a pilot study}} undertaken to propose {{a model for the}} analysis of the respective impact of translation memory (TM) use and full post-editing (PE) of <b>raw</b> machine <b>translation</b> (MT) output on the level of difficulty perceived and on the time needed by trainee translators. Six Italian MA-level translation students were asked to produce high-quality target texts when translating semi-specialised material from English into their native Italian. For this experiment, we proposed a model of data triangulation in which we measured the time taken to complete the tasks and we collected data on their translation with TM software and PE processes by means of think-aloud protocols (TAPs) and retrospective interviews. We studied {{the extent to which the}} number of translation solutions regarded as correct influenced, on the one hand, the perception of difficulty associated with the translation strategies employed and, on the other, the duration of the translation and PE tasks. Using a TM led to a reduction of the difficulty perceived and of the time employed by the participants as a result of the increased correct translation solutions provided. In contrast, a reduction was not observed when participants post-edited raw MT output. Further factors were assumed to influence the translation and PE processes of the students, especially their attitudes towards the translation technologies being use...|$|R
50|$|The {{traditional}} methods of producing protein arrays require the separate in vivo expression of {{hundreds or thousands of}} proteins, followed by separate purification and immobilization of the proteins on a solid surface. Cell-free protein array technology attempts to simplify protein microarray construction by bypassing the need to express the proteins in bacteria cells and the subsequent need to purify them. It takes advantage of available cell-free protein synthesis technology which has demonstrated that protein synthesis can occur without an intact cell as long as cell extracts containing the DNA template, transcription and <b>translation</b> <b>raw</b> materials and machinery are provided. Common sources of cell extracts used in cell-free protein array technology include wheat germ, Escherichia coli, and rabbit reticulocyte. Cell extracts from other sources such as hyperthermophiles, hybridomas, Xenopus oocytes, insect, mammalian and human cells have also been used.|$|R
40|$|The paper {{explains}} how an Optical Character Recognition system (OCR) works {{and how this}} system enables us in capturing {{an image of a}} text document. It also {{explains how}} OCR is more efficient and easier alternative to scanning a document using a scanner as the image captured using OCR is of exactly the same quality like its scanned copy, the only difference being that OCR is done {{with the help of a}} simple mobile phone camera whereas scanning is done using a bulky scanner. It then also explains the problems being faced by the developers in using OCR as a technology on a large scale and how that problem can be dealt with. The proposed OCR system provides many features that require no typing, editing <b>raw</b> data, quick <b>translation,</b> and memory utilization. In the end it also highlights the major emerging trends in the field of OCR and how OCR as a technology is evolving with every passing day. Keywords...|$|R
40|$|International audienceWe {{will explain}} and {{demonstrate}} iMAGs (interactive Multilingual Access Gateways), in particular on a scientific laboratory {{web site and}} on the Greater Grenoble (La Métro) web site. This bilingual presentation has been obtained using an iMAG. Presentation This presentation is an adaptation and update of an article presented as a demonstration only to TALN- 2010. The names of the files have been kept the same, although their contents are slightly different. The iMAG concept has been proposed by Ch. Boitet and V. Bellynck in 2006 (Boitet & al. 2008, Boitet & al. 2005), and reached prototype status in November 2008, with a first demonstration on the LIG laboratory Web site. It has been adapted to the DSR (Digital Silk Road) Web site in April 2009, and then to more than 50 other Web sites. These first prototypes are extensions of the SECTra_w (Huynh & al. 2008) online translation corpora support system. Since the beginning of 2011, we are operationalizing this software {{with a view to}} deploy it as a multilingual access infrastructure, {{in the context of the}} French ANR (National Agency for Research) Traouiero " emergence " project. An iMAG is an interactive Multilingual Access Gateway very much like Google Translate at first sight: one gives it a URL (starting Web site) and an access language and then navigates in that access language. When the cursor hovers over a segment (usually a sentence or a title), a palette shows the source segment and proposes to contribute by correcting the target segment, in effect post-editing an MT result. With Google Translate, the page does not change after contribution, and if another page contains the same segment, its translation is still the rough MT result, not the polished post-edited version. The more recent Google Translation Toolkit enables one to MT-translate and then post-edit online full Web pages from sites such as Wikipedia, but again the corrected segments don't appear when one later browses the Wikipedia page in the access language. By contrast, an iMAG is dedicated to an elected Web site, or rather to the elected sublanguage defined by one or more URLs and their textual content. It contains a translation memory (TM) and a specific, preterminological dictionary (pTD), both dedicated to the elected sublanguage. Segments are pretranslated not by a unique MT system, but by a (selectable) set of MT systems. Systran and Google are mainly used now, but specialized systems developed from the postedited part of the TM, and based on Moses, will be also used in the future. The powerful online contributive platforms SECTra_w and PIVAX (Nguyen & al. 2007) are used to support the TMs and pTDs. Translated pages are built with the best segment translations available so far. While reading a translated page, it is possible not only to contribute to the segment under the cursor, but also to seamlessly switch to SECTra_w online post-editing environment, equipped with proactive dictionary help and good filtering and search-and-replace functions, and then back to the reading context. A translation relay is being implemented to define the iMAGs or other translation gateways used by an elected Web site, select and parameterize the MT systems and translation routes used for various language pairs, and manage users, groups, projects (some contributions may be organized, other opportunistic), and access rights. Finally, MT systems tailored to the selected sublanguage can be built (by combinations of empirical and expert methods) from the TM and the pTD dedicated to a given elected Web site. That approach will inherently raise the linguistic and terminological quality of the MT results, hopefully converting them from rough into <b>raw</b> <b>translations.</b> The demonstration will use some iMAGs created by the AXiMAG startup for various Web sites, such as those of the LIG lab ([URL] and of La Metro (Greater Grenoble) web site ([URL] where access in Chinese and English was enabled in 2010 for the Shanghai Expo...|$|R
40|$|Luonnollinen kieli aiheuttaa tiedonhaulle ja kieltenväliselle tiedonhaulle monenlaisia ongelmia. Ongelmat ovat kieliriippuvaisia: esimerkiksi suomelle aiheuttaa ongelmia sanojen taipuminen ja yhdyssanat, kun taas englannissa fraasit (erikseen kirjoitetut yhdyssanat) ovat ongelmallisia. Tutkimuksen tarkoituksena on selvittää, miten sanojen normalisoinnilla, sanamuotojen generoinnilla ja sumeilla merkkijonojen täsmäytysmenetelmillä voidaan ratkaista tiedonhaun morfogisia ongelmia. Tutkimuksessa todettiin, että yhdyssanat aiheuttavat ongelmia kaksikieliselle tiedonhaulle, kun lähtökieli on fraasiorientoitunut kieli ja kohdekieli yhdyssanakieli. Yhdyssanojen pilkkominen indeksointivaiheessa parantaa hakutulosta huomattavasti. Tutkimuksen mukaan kaksikielisen tiedonhaun tulos taivutusmuotoindeksissä on huono ainakin silloin, kun kohdekieli on voimakkaasti taipuva kieli. Tämä johtuu siitä, että sanakirja antaa vain sanan perusmuodon, kun taas indeksissä esiintyy sanoja taipuneessa muodossa. Sanamuotojen generointi samoin kuin sumeat merkkijonojen täsmäytysmetelmät parantavat hakutulosta huomattavasti. Kaksikielistä tiedonhakua on perinteisesti testattu laboratoriotestein. Testien tuloksena on todettu, että käännetyt kyselyt antavat huomattavasti huonomman tuloksen kuin kohdekieliset kyselyt. Tässä tutkimuksessa suoritettiin käyttäjätestejä, joiden perusteella voidaan todeta, että kaksikielinen tiedonhaku on hyödyllistä tiedonhakijalle. Hyöty on sitä suurempaa, mitä heikompi kohdekielen taito henkilöllä on. Tämä koskee kuitenkin vain tilannetta, jossa kyselynkäännöksessä käytetään laadukasta sanakirjaa. Huonon sanakirjan antama käännös ei auta edes heikosti kieltä taitavaa tiedonhakijaa. The {{topics of}} the present thesis are {{linguistic}} and approximate string matching methods in monolingual, bilingual and multilingual information retrieval. The linguistic approaches applied in the studies are word normalization, translation and word form generation, while n-gramming and s-gramming represent approximate string matching techniques. The first contribution of this thesis is connected to compounds: we studied the importance of index decompounding in mono- and bilingual retrieval. The impact of decompounding, especially on bilingual retrieval, {{is not a very}} widely studied issue in IR literature. Index decompounding did not have any notable impact on monolingual retrieval. On the other hand, we found that in bilingual retrieval, index decompounding is vital, when the source language is phrase oriented while compounds are used in the target language. The second contribution deals with the quality of translation dictionaries. We found that the quality of a dictionary has an even larger effect on the bilingual retrieval result than has been supposed. We also performed user tests in bilingual retrieval utilizing dictionaries of various quality. We found that query translation is generally beneficial for users with moderate or poor language skills, but only if the translation dictionary is of good quality: a defective dictionary does not help even those with poor target language skills. The third contribution of this thesis is connected with bilingual user tests. In prior research, the performance of bilingual retrieval compared with monolingual retrieval has mostly been tested only in a laboratory environment. We found that query translation performed much better in user tests than it has performed in laboratory tests. The reason is that the target queries formulated by test persons (and in a real CLIR situation) are often defective, because they are formulated by people with only moderate or poor language skills, while laboratory tests utilize queries formulated by native language speakers. Our fourth contribution is connected to bilingual retrieval in an inflected index: many IR indexes are non-normalized, and thus, {{there is a need for}} a practical method to perform bilingual retrieval in an inflected word form index. There is not much research on the issue, however. We found that any kind of processing (approximate string matching, frequent case generation or their combination) improves the retrieval result compared with queries formulated directly from <b>raw</b> <b>translations.</b> This information may be important when developing systems utilizing bilingual retrieval. Fifth, we found that various normalization approaches in indexing and retrieval do not have any remarkable impact on the multilingual retrieval results, even if lemmatization seems to perform slightly better than stemming. Various result list merging approaches have only a minor impact on the result. On the other hand, there are not many systems utilizing separate indexes with result list merging. Thus, multilingual IR research should be directed towards systems with a merged index...|$|R

