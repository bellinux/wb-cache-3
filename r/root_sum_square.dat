25|6265|Public
50|$|The {{inability}} {{to achieve the}} required lateral navigation accuracy {{may be due to}} navigation errors related to aircraft tracking and positioning. The three main errors are path definition error (PDE), flight technical error (FTE) and navigation system error (NSE). The distribution of these errors is assumed to be independent, zero-mean and Gaussian. Therefore, the distribution of total system error (TSE) is also Gaussian with a standard deviation equal to the <b>root</b> <b>sum</b> <b>square</b> (RSS) of the standard deviations of these three errors.|$|E
50|$|Tolerance stackups or {{tolerance}} stacks {{are used}} to describe the problem-solving process in mechanical engineering of calculating the effects of the accumulated variation that is allowed by specified dimensions and tolerances. Typically these dimensions and tolerances are specified on an engineering drawing. Arithmetic tolerance stackups use the worst-case maximum or minimum values of dimensions and tolerances to calculate the maximum and minimum distance (clearance or interference) between two features or parts. Statistical tolerance stackups evaluate the maximum and minimum values based on the absolute arithmetic calculation combined with some method for establishing likelihood of obtaining the maximum and minimum values, such as <b>Root</b> <b>Sum</b> <b>Square</b> (RSS) or Monte-Carlo methods.|$|E
40|$|Abstract: Malaria {{represents}} {{major public}} health {{problems in the}} tropics. The harmful effects of malaria parasites to the human body cannot be underestimated. In this paper, a fuzzy expert system {{for the management of}} malaria (FESMM) was presented for providing decision support platform to malaria researchers, physicians and other healthcare practitioners in malaria endemic regions. The developed FESMM composed of four components which include the Knowledge base, the Fuzzification, the Inference engine and Defuzzification components. The fuzzy inference method employed in this research is the <b>Root</b> <b>Sum</b> <b>Square</b> (RSS). The <b>Root</b> <b>Sum</b> <b>Square</b> of drawing inference was employed to infer the data from the fuzzy rules developed. Triangular membership function was used to show the degree of participation of each input parameter and the defuzzification technique employed in this research is the Centre of Gravity (CoG). The fuzzy expert system was designed based on clinical observations, medical diagnosis and the expertâ€™s knowledge. We selected 35 patients with malaria and computed the results that were in the range of predefined limit by the domain experts...|$|E
50|$|Note that in Oja's {{original}} paper, , {{corresponding to}} quadrature (<b>root</b> <b>sum</b> of <b>squares),</b> {{which is the}} familiar Cartesian normalization rule. However, any type of normalization, even linear, will give the same result without loss of generality.|$|R
40|$|The {{trajectory}} of an orbiting spacecraft is determined from an orbit determination program. Two inputs to this program, among others, are {{the range and}} range rate relative to some known location. The arithmetic and measurement errors in the determinations of the range, range rate, and range differences were identified and evaluated. These uncertainties are tabulated for one way and two way systems. A comparison of the measurement error contributions illustrate the predominance of thermal noise effects under low power budget conditions, with the other error sources becoming relevent for the high power budget case. The evaluated uncertainties are summarized as <b>root</b> <b>sum</b> <b>squared</b> noise and bias errors...|$|R
2500|$|Radial {{acceleration}} {{is still}} equal to [...] Tangential acceleration {{is simply the}} derivative of the velocity at any given point: [...] This <b>root</b> <b>sum</b> of <b>squares</b> of separate radial and tangential accelerations is only correct for circular motion; for general motion within a plane with polar coordinates , the Coriolis term [...] should be added to , whereas radial acceleration then becomes [...]|$|R
40|$|In {{probabilistic}} {{design of}} multilevel systems, {{the challenge is}} to estimate uncertainty propagation since outputs of subsystems at lower levels constitute inputs of subsystems at higher levels. Three uncertainty propagation estimation techniques are compared in this paper in terms of numerical efficiency and accuracy: <b>root</b> <b>sum</b> <b>square</b> (linearization), distribution-based moment approximation, and Taguchi-based integration. When applied to simulation-based, multilevel system design optimization under uncertainty, it is investigated which type of applications each method is best suitable for. The probabilistic formulation of the analytical target cascading methodology is used to solve the multilevel problem. A hierarchical bi-level engine design problem is employed to investigate unique features of the presented techniques for uncertainty propagation. This study aims at helping potential users to identify appropriate techniques for their applications. 1...|$|E
40|$|The {{development}} of design load factors for aerospace and aircraft components and experiment support structures, which {{are subject to}} a simultaneous vehicle dynamic vibration (quasi-static) and acoustically generated random vibration, require {{the selection of a}} combination methodology. Typically, the procedure is to define the quasi-static and the random generated response separately, and arithmetically add or <b>root</b> <b>sum</b> <b>square</b> to get combined accelerations. Since the combination of a probabilistic and a deterministic function yield a probabilistic function, a viable alternate approach would be to determine the characteristics of the combined acceleration probability density function and select an appropriate percentile level for the combined acceleration. The following paper develops this mechanism and provides graphical data to select combined accelerations for most popular percentile levels...|$|E
40|$|The {{stringent}} attitude determination {{accuracy and}} faster slew maneuver requirements demanded by present-day spacecraft control systems motivate {{the development of}} recursive nonlinear filters for attitude estimation. This paper presents the second-order filter development for the estimation of attitude quaternion using three-axis gyro and star tracker measurement data. Performance comparisons {{have been made by}} computer simulation of system models and filter mechanization. It is shown that the second-order filter consistently performs better than the extended Kalman filter when the performance index of the <b>root</b> <b>sum</b> <b>square</b> estimation error of the quaternion vector is compared. The second-order filter identifies the gyro drift rates faster than the extended Kalman filter. The uniqueness of this algorithm is the online generation of the time-varying process and measurement noise covariance matrices, derived as a function or the process and measurement nonlinearity, respectively...|$|E
25|$|User {{equivalent}} range errors (UERE) {{are shown}} in the table. There is also a numerical error with an estimated value, , of about 1 meter. The standard deviations, , for the coarse/acquisition (C/A) and precise codes are also shown in the table. These standard deviations are computed by taking the <b>square</b> <b>root</b> of the <b>sum</b> of the <b>squares</b> of the individual components (i.e., RSS for <b>root</b> <b>sum</b> <b>squares).</b> To get the standard deviation of receiver position estimate, these range errors must be multiplied by the appropriate dilution of precision terms and then RSS'ed with the numerical error. Electronics errors are one of several accuracy-degrading effects outlined in the table above. When taken together, autonomous civilian GPS horizontal position fixes are typically accurate to about 15 meters (50ft). These effects also reduce the more precise P(Y) code's accuracy. However, the advancement of technology means that in the present, civilian GPS fixes under {{a clear view of}} the sky are on average accurate to about 5 meters (16ft) horizontally.|$|R
40|$|In {{this article}} we explore the general non-robustness of {{traditional}} <b>root</b> <b>sum</b> of <b>squares</b> statistical tolerancing and describe, in particular, how it can fail. These are [1] deficiencies in the functional model, [2] lower process capability in inputs that what is desired of outputs, [3] biases, [4] correlations, and [5] non-normality. We also show that statistical tolerancing is extremely non-robust to the first four types of causes. Moreover we provide examples of each type and discuss {{what to do about}} each...|$|R
40|$|Optical {{near-field}} {{technologies such}} as solid immersion lenses and hyperlenses are candidate solutions for high resolution and high throughput wafer inspection and metrology for the next technology nodes. Besides sub-diffraction limited optical performance, these concepts share the necessity of extreme proximity to the sample at distances that are measured in tens of nanometers. For the instrument this poses two major challenges: 1) how to measure {{the distance to the}} sample? and 2) how to position accurately and at high speed? For the first challenge near-field thermal radiation is proposed as a mechanism for an integrated distance sensor (patent pending). This sensor is realized by making a sensitive calorimeter (accuracy of 2 : 31 nW <b>root</b> <b>sum</b> <b>squared).</b> When used for distance measurement an equivalent uncertainty of 1 nm can be achieved for distances smaller than 100 nm. By scanning the distance sensor over the sample, thermal profilometry is realized, which can be used to inspect surfaces in a non-intrusive and non-contact way. This reduces wear of the probe and minimizes the likelihood of damaging the sample. Structural Optimization and Mechanic...|$|R
40|$|Abstractâ€”The {{high rate}} at which Africans die of {{syphilis}} yearly has been majorly attributed to the uneven ratio of the patients to competent medical practitioners who provide Medicare. This mortality rate has always drawn the attention of researchers and different approaches {{had been used to}} bring the rate down. This paper provides a software solution that personifies the expert-like way of providing diagnostic service to patients who suffer this disease. It is capable of making approximate diagnosis based on uncertainties. The system has been structured into five components: user interface, fuzzification, knowledge base, inference engine and defuzzification. The user interface uses a graphic user interface based method of human-computer interaction while the fuzzification component has transformed crisp quantities into fuzzy quantities using both interval-valued and S-curve membership functions. The reasoning has been achieved using <b>root</b> <b>sum</b> <b>square</b> (RSS) method and transformation of fuzzy values to scalar ones was through weighted average method. This system was tested and found effective...|$|E
40|$|AbstractA tide-surge-wave {{modelling}} system, called Kassandra, {{was developed}} for the Mediterranean Sea. It consists of a 3 -D finite element hydrodynamic model (SHYFEM), including a tidal model and a third generation finite element spectral wave model (WWMII) coupled to the hydrodynamic model. The numerical grid of the hydrodynamic and wave models covers the whole Mediterranean with variable resolution. The comparison with coastal tide gauge stations along the Italian peninsula results in a <b>root</b> <b>sum</b> <b>square</b> error for the main tidal components equal to 1. 44 cm. The operational implementation of the Kassandra storm surge system {{through the use of}} a high resolution meteorological model chain (GFS, BOLAM, MOLOCH) allows accurate forecast of total water level and wave characteristics. The root mean square error for the first day of forecast is 5 cm for the total water level and 22 cm for the significant wave height. Simulation results indicate that the use of a 3 -D approach with a depth-varying loading factor and the inclusion of the non-linear interaction between tides and surge improve significantly the model performance in the Italian coast...|$|E
40|$|Abstract: In {{order to}} study the {{vibration}} isolation performance of floating-slab track (FST), three track models are developed with different slab lengths. The ratio of <b>root</b> <b>sum</b> <b>square</b> of the force transmitted to the infrastructure to an assumed harmonic load on the rail is used as the criterion to evaluate vibration isolation performance for the FST. The {{results show that the}} FST has good ability to isolate the vibration transmitted from the track to the infrastructure, compared with the reference (ballasted) track. As expected, the lower the natural frequency of the slab-bearing system, the better vibration isolation performance. It is also found that the force transmitted to the infrastructure through the FST with short slab decays more rapidly along the track than [it does] through that with the long slab at low and higher frequencies. In addition, the perform-ance of the FST with medium length slab is greatly affected by the dynamic behaviour of the slab. Moreover, the FST shows different vibration isolation performance when the load acts at different positions relative to the slab...|$|E
40|$|While ANSI/ANS 3. 11 - 2000 {{does not}} specify {{a method for}} {{computing}} ÏƒÎ¸, it suggests one-pass methods in Appendix E, including the Yamartino method. For the suggested methods, it also recommends deriving the hourly value of ÏƒÎ¸ by computing the <b>Root</b> <b>Sum</b> <b>Squared</b> (RSS) of the 10 or 15 -minute averages {{in order to minimize}} inflation of the 60 -minute ÏƒÎ¸ due to the effects of plume meander. This inflation effect was observed while developing a utility to compute missing 60 -minute ÏƒÎ¸â€™s from partial data or to re-compute this value after portions of the underlying data had been edited. Re-computed ÏƒÎ¸â€™s generally are lower than the original values, frequently reducing the associated stability class to a more stable value. This presentation reviews ÏƒÎ¸ computation, then details the observed differences between 60 -minute ÏƒÎ¸â€™s computed from the original sensor data using the one-pass Yamartino method and values computed by RSS-ing the 15 -minute values. One year of actual observations and re-computations are analyzed with respect to differing wind conditions. Lastly, the differences in reported stability class for the two methods are presented...|$|R
40|$|Instantaneous {{signals from}} {{coherent}} random sound field are summed and time delayed to avoid introducing vectorial addition errors. Resultant statistically independent signals {{are applied to}} spectrometer. Displayed sound pressure level is proportional to <b>square</b> <b>root</b> of <b>sum</b> of <b>squares</b> of sound pressure levels taken over frequency range of interest...|$|R
5000|$|... where s is the {{standard}} deviation and n {{is the number of}} measurements. Type-B uncertainty is determined by estimating the upper and lower limits of uncertainty and selecting the type of uncertainty distribution. With the confidence interval, the type-B uncertainty can be determined. Overall uncertainty is the <b>root</b> <b>sum</b> of the <b>squares</b> of the type-A and type-B uncertainties.|$|R
40|$|In {{preparation}} for the fourth satellite in the CubeSat program at the Julius-Maximilians-UniversitÃ¤t in WÃ¼rzburg, a real-time orbit determination algorithm was developed. Due to strict power and volumetric constraints, {{the goal was to}} make use of sensors already existing onboard the third satellite in the program, called UWE- 3. The algorithm implemented is an Extended Kalman Filter (EKF) that makes use of magnetometer and sun sensor measurements in its update step. It is attitude independent as it uses only the norm of the magnetic field, and the cosine of the angle between the magnetic field and the sun vector. The propagation step models the satellite dynamics as a two-body problem with J 2 perturbations. The update step uses the International Geomagnetic Reference Field (IGRF) and a model of the earth's movement around the sun as references. The filter was first tested with simulated measurements based on the orbit of UWE- 3, followed by tests with real flight data from the satellite. Using the simulated measurements, the average <b>root</b> <b>sum</b> <b>square</b> (RSS) error of the absolute position was found to be 11. 56 km. When using real flight data, this value increased to 22. 24 km. Validerat; 20150901 (global_studentproject_submitter...|$|E
40|$|The present Space Shuttle's {{control system}} does not prevent the Orbiter's main engines from being in gimbal {{positions}} that are adverse to solid rocket booster separation. By eliminating the attitude error and attitude rate feedback just prior to solid rocket booster separation, the detrimental effects of the Orbiter's main engines can be reduced. In addition, if angular acceleration feedback is applied, the gimbal torques produced by the Orbiter's engines can reduce the detrimental effects of the aerodynamic torques. This paper develops these control techniques and compares the separation capability of the developed control systems. Currently with the worst case initial conditions and each Shuttle system dispersion aligned in the worst direction (which is more conservative than will be experienced in flight), the solid rocket booster has an interference with the Shuttle's external tank of 30 in. Elimination of the attitude error and attitude rate feedback reduces that interference to 19 in. Substitution of angular acceleration feedback reduces the interference to 6 in. The two latter interferences can be eliminated by atess conservative analysis techniques, that is, by using a <b>root</b> <b>sum</b> <b>square</b> of the system dispersions...|$|E
40|$|The Crew Return Vehicle (CRV) {{slated for}} use on the International Space Station (ISS) {{provides}} a safe return for up to seven crew members under various emergency conditions. One of the most demanding situations for executing the escape involves separating from a tumbling ISS Current requirements specify a maximum <b>Root</b> <b>Sum</b> <b>Square</b> (RSS) tumble rate of 2 degrees/second, with the additional requirement for an expedited departure from any ISS attitude. The design of a trajectory that ensures no re-contact with the ISS poses many challenges on the Guidance, Navigation, and Control (GN&C) system of the vehicle. To ensure no re-contact the trajectory design employs a two burn sequence, with the first burn preventing near-term collision and the second burn preventing far-field re-contact This presentation describes the approach used to design and to evaluate trajectories for CRV departure from the baselined location on the ISS Node 3 starboard. This approach involved performing a parametric search of selected control variables vital in escaping the tumbling ISS The presentation provides a candidate targeting methodology for escape using minimal information from available navigation devices, and presents the quantitative results from the analysis...|$|E
40|$|Often, {{the total}} {{responses}} experienced {{by a system}} are due to distinct and independent contributors. For example, during atmospheric flight, a launch vehicle and its spacecraft will experience loads from sources such as dynamic pressure, turbulence/gust, buffet, and thrust oscillation and vectoring. Because {{of the complexity of}} the phenomena, each contributor must be established in separate analyses. To obtain a total, the separate results must be combined. There are several combination equations, and three of these are assessed herein by means of Monte Carlo simulations and mathematical analysis. It will be demonstrated that the equation based on the envelope functions of Gaussian response time histories provides a reasonable bound, and that the form of the equation in which all contributors are <b>root</b> <b>sum</b> <b>squared</b> will frequently under predict the correct total. Nomenclature;, () x i jb t = base excitation to first SDOF system for ith LCE run and jth Monte Carlo draw;, () y i jb t = base excitation to second SDOF system for ith LCE run and jth Monte Carlo draw () tB = vector-valued function of buffet load time histories CLT = Central Limit Theorem based LCE ENV = envelope function based LCE f = natural frequencies of SDOF system in H...|$|R
40|$|Let Z 1, [...] ., Zn be i. i. d. {{standard}} normal variables, Mn {{the extreme}} among their absolute values, and Qn their <b>rooted</b> <b>sum</b> of <b>squares.</b> Here we study the ratio ?n =Mn /Qn. We show that ?(?n) = ?(Mn) /?(Qn) ~ bn / Vn ~ V 2 log(n) /n, where cn ~ dn denotes that cn /dn ? 1 for n??. Moreover, convergence {{happens in a}} stable manner, i. e. ?n ~ ?(?n) in probability. For low dimensions we also derive explicit expressions for ?(?n) and variance ? 2 (?n). These expressions are calculated by using an appealing geometrical interpretation of ?n. Values and TechnologyTechnology, Policy and Managemen...|$|R
50|$|When {{analyzing}} {{the response of}} materials to alternating electric fields (dielectric spectroscopy), in applications such as electrical impedance tomography, it is convenient to replace resistivity with a complex quantity called impeditivity (in analogy to electrical impedance). Impeditivity {{is the sum of}} a real component, the resistivity, and an imaginary component, the reactivity (in analogy to reactance). The magnitude of impeditivity is the <b>square</b> <b>root</b> of <b>sum</b> of <b>squares</b> of magnitudes of resistivity and reactivity.|$|R
40|$|AbstractGeometric {{dimensioning}} and Tolerancing (GDT) {{constitutes the}} dominant approach for design and manufacture of mechanical parts that control inevitable dimensional and geometrical deviations within appropriate limits. The stack up of tolerances and their redistribution without hampering the functionality {{is very important}} for cost optimization. This paper presents a methodology that aims towards the systematic solution of tolerance stack up problem involving geometric characteristics. Conventional tolerance stack up analysis is usually difficult as it involves numerous rule and conditions. The methodology presented i. e. generic capsule method is straightforward and easy to use for stack up of geometrical tolerances of components and their assembly using graphical approach. In the work presented in this paper, angularity tolerance has been considered for illustration of the methodology. Two approaches viz. Worst Case (WC) and <b>Root</b> <b>Sum</b> <b>Square</b> (RSS) have been used. An example of dovetail mounting mechanism has been taken for purpose of stack up of angularity. This assembly consists of two parts i. e. dovetail male and dovetail female. Tolerance stack up has been done both for the components and their assembly. Need for computerisation of methodology for geometrical tolerance stack up of large assemblies has emerged out as the limitation of the proposed method...|$|E
40|$|Ozone {{profiles}} {{from the}} surface to about 60 km are retrieved from Ozone Monitoring Instrument (OMI) ultraviolet radiances using the optimal estimation technique. OMI provides daily ozone profiles for the entire sunlit portion of the earth at a horizontal resolution of 13 km&times; 48 km for the nadir position. The retrieved profiles have sufficient accuracy in the troposphere to see ozone perturbations caused by convection, biomass burning and anthropogenic pollution, and to track their spatiotemporal transport. However, to achieve such accuracy it has been necessary to calibrate OMI radiances carefully (using two days of Aura/Microwave Limb Sounder data taken in the tropics). The retrieved profiles contain ~ 6 â€“ 7 Â° of freedom for signal, with 5 â€“ 7 in the stratosphere and 0 â€“ 1. 5 in the troposphere. Vertical resolution varies from 7 â€“ 11 km in the stratosphere to 10 â€“ 14 km in the troposphere. Retrieval precisions range from 1 % in the middle stratosphere to 10 % in the lower stratosphere and troposphere. Solution errors (i. e., <b>root</b> <b>sum</b> <b>square</b> of precisions and smoothing errors) vary from 1 â€“ 6 % in the middle stratosphere to 6 â€“ 35 % in the troposphere, and are dominated by smoothing errors. Total, stratospheric, and tropospheric ozone columns can be retrieved with solution errors typically in the few Dobson unit range at solar zenith angles less than 80 &deg;...|$|E
40|$|AbstractThis study {{compares the}} common {{harmonic}} constants of the O 1, K 1, P 1, Q 1, M 2, S 2, N 2, and K 2 tidal constituents from eight global and four regional tide models with harmonic constants from satellite altimeter and tide gauge {{data for the}} northern region of the Antarctic Peninsula (58 Â°Sâ€“ 66 Â°S, 53 Â°Wâ€“ 66 Â°W). To obtain a more representative comparison, the study area was divided into three zones with different physical characteristics but similar maximum tidal amplitude variations: Zone I (north of 62 Â°S), Zone II (south of 62 Â°S and west of the Antarctic Peninsula), and Zone III (between 62 Â°S and 64. 3 Â°S, and east of 58. 5 Â°W). <b>Root</b> <b>sum</b> <b>square</b> (RSS) values are {{less than or equal}} to 3. 0, 4. 2, and 8. 4 Â cm for zones I, II, and III, respectively. No single model shows superior performance in all zones. Because there are insufficient satellite altimetry observations in the vicinity of Matienzo Base (64. 9761 Â°S, 60. 0683 Â°W), this station was analyzed separately and presents the greatest values of both root mean square misfit and RSS. The maximum, minimum, and average amplitude values of the constituents that follow in importance after the eight common tidal constituents, and which have amplitudes greater than 1 Â cm, are also analyzed...|$|E
40|$|International audienceAn MR damper is {{a device}} that {{exhibits}} a high nonlinear and complex behavior with a hysteresis phenomenon. A comparison between different state-of-the-art and a Linear Parameter Varying (LPV) models for Magneto-Rheological (MR) dampers is presented. Several experimental datasets validate that Linear Parameter Varying (LPV) -based model outperforms the classical MR damper models for 51 % than any structures considering the Error to Signal Ratio index and 37 % better considering the <b>Squared</b> <b>root</b> of <b>Sum</b> of <b>Squared</b> Errors index...|$|R
40|$|This paper {{describes}} {{the results of}} the modal test planning and the pre-test analysis for the X- 33 vehicle. The pre-test analysis included the selection of the target modes, selection of the sensor and shaker locations and the development of an accurate Test Analysis Model (TAM). For target mode selection, four techniques were considered, one based on the Modal Cost technique, one based on Balanced Singular Value technique, a technique known as the <b>Root</b> <b>Sum</b> <b>Squared</b> (RSS) method, and a Modal Kinetic Energy (MKE) approach. For selecting sensor locations, four techniques were also considered; one based on the Weighted Average Kinetic Energy (WAKE), one based on Guyan Reduction (GR), one emphasizing engineering judgment, and one based on an optimum sensor selection technique using Genetic Algorithm (GA) search technique combined with a criteria based on Hankel Singular Values (HSV's). For selecting shaker locations, four techniques were also considered; one based on the Weighted Average Driving Point Residue (WADPR), one based on engineering judgment and accessibility considerations, a frequency response method, and an optimum shaker location selection based on a GA search technique combined with a criteria based on HSV's. To evaluate the effectiveness of the proposed sensor and shaker locations for exciting the target modes, extensive numerical simulations were performed. Multivariate Mode Indicator Function (MMIF) was used {{to evaluate the effectiveness of}} each sensor & shaker set with respect to modal parameter identification. Several TAM reduction techniques were considered including, Guyan, IRS, Modal, and Hybrid. Based on a pre-test cross-orthogonality checks using various reduction techniques, a Hybrid TAM reduction technique was selected and was used for all three vehicle fuel level configurations...|$|R
40|$|The {{design and}} {{analysis}} of many products is performed with imprecisely known parameters, relationships, and environmental conditions. This {{is especially true for}} wood products which exhibit greater variability than most materials. Fuzzy set theory applied to the design {{and analysis of}} wood products is regarded as a promising approach for modeling the geometric and mechanical property variability. A fuzzy mathematical model is used to analyze the design of a wood beam structure. The analysis is compared with a Monte-Carlo simulation and a <b>root</b> <b>sum</b> of <b>squares</b> analysis approach. The fuzzy set design approach compares favorably with these approaches and has several distinct advantages. It can model user preference as well as imprecision, it is computationally quick, and it better reduces the design space. Keywords: Engineering design; fuzzy analysis; fuzzy constraints; decision support tool. INTRODUCTION Structural design with wood presents complex problems because wood is a natural mater [...] ...|$|R
40|$|Abstract. Ozone {{profiles}} {{from the}} surface to about 60 km are retrieved from Ozone Monitoring Instrument (OMI) ultravi-olet radiances using the optimal estimation technique. OMI provides daily ozone profiles for the entire sunlit portion of the earth at a horizontal resolution of 13 kmÃ— 48 km for the nadir position. The retrieved profiles have sufficient accuracy in the troposphere to see ozone perturbations caused by con-vection, biomass burning and anthropogenic pollution, and to track their spatiotemporal transport. However, to achieve such accuracy it has been necessary to calibrate OMI radi-ances carefully (using two days of Aura/Microwave Limb Sounder data taken in the tropics). The retrieved profiles contain âˆ¼ 6 â€“ 7 degrees of freedom for signal, with 5 â€“ 7 in the stratosphere and 0 â€“ 1. 5 in the troposphere. Vertical res-olution varies from 7 â€“ 11 km in the stratosphere to 10 â€“ 14 km in the troposphere. Retrieval precisions range from 1 % in the middle stratosphere to 10 % in the lower stratosphere and troposphere. Solution errors (i. e., <b>root</b> <b>sum</b> <b>square</b> of preci-sions and smoothing errors) vary from 1 â€“ 6 % in the middle stratosphere to 6 â€“ 35 % in the troposphere, and are dominated by smoothing errors. Total, stratospheric, and tropospheric ozone columns can be retrieved with solution errors typically in the few Dobson unit range at solar zenith angles less than 80 â—¦. ...|$|E
40|$|Abstract: 2 Ì† 2 Universal {{interchangeability}} {{of parts}} or sub-assemblies {{is one of}} the goals of most designs. The knowledge of all possible variations in an assembly due to the specified tolerances is essential to ensure universal interchangeability. Tolerance zone, as defined in [1], is a virtual region formed around a true feature. Tolerance zone propagation can be effectively used to observe variations due to individual part tolerances in an assembly. Although the concept of tolerance zones is not explicitly used in most existing tolerance analysis methods, the underlying principles can be readily used to generate a tolerance zone. However, it is seen that tolerance zones generated by Worst Case or <b>Root</b> <b>Sum</b> <b>Square</b> (RSS) models do not encompass all possible variations inan assembly made of parts that are within tolerance specification, because the effect of non-worst case stacking situations is not considered. The new perspective on tolerance analysis, discussed in this paper, addresses the effect of non-worst case stacking situations by studying angular accumulation in addition to linear accumulation of tolerances. In a general plus/minus tolerance part there is a high probability that the part conforms to the specified tolerances with a surface that is not at the true angular position with respect to other features. Such parts when assembled together lead to angular stack-up. In this paper, angular accumulation is addressed using the concept of tolerance zones and a mathematical basis is developed for the representation and analysis of angular accumulation based on classical kinematic theories. Possible applications of this analysis are also discussed. 2 Ì†...|$|E
40|$|In February 2010, the Mertz Glacier Tongue (MGT) calved, {{releasing}} an 80 x 40 km iceberg. We {{have developed}} a high-resolution barotropic ocean model of the region to simulate the local circulation in response to tides and atmospheric forcing. We improved the coastline, grounding line position and built a new bathymetry using satellite imagery and older bathymetry data to derive the best available tidal model for the region. We compared this and other available models to seven different sea level observations available {{in the area and}} significantly improved the tidal solutions reaching a <b>root</b> <b>sum</b> <b>square</b> of 2. 3 cm. This model was then run in different bathymetric configurations, considering the ice draft of the major icebergs B 9 B and C 28, to simulate the circulation before, during, and after the calving event. The currents changed substantially in the neighborhood of the MGT and icebergs. The barotropic model with tidal and atmospheric forcing and the atmospheric wind fields allow us to evaluate the forces acting on the MGT. The sea surface slope force dominates the budget. Calving occurred when high tide and strong nontidal currents (due to atmospheric forcing) combined to lead to the monthly maximum forces exerted on the MGT (i. e., between 10 and 13 February 2010). While the forces are not unusually large at the calving time, the currents are largely enhanced in the rifting area. Therefore, processes related to these currents, like melting the ice melange inside the rifts, should be investigated to fully explain the final stage of the calving...|$|E
40|$|For {{practical}} purpose, buffeting {{response of}} cable-stayed bridges to wind excitation is usually analytically determined by single-mode-based method, {{and the resultant}} response is written as {{the composition of the}} resonant component and the background component by the <b>square</b> <b>root</b> of <b>sum</b> <b>squares</b> (SRSS) method. The background component is sometimes neglected for simplifying computations. In the present paper, numerical computations on four representative cable-stayed bridges in China indicate that the background component usually has a significant contribution to the buffeting response of long-span cable-stayed bridges. Parametric studies on the effects of structural parameters on the buffeting background components for these four bridges are also performed. A simplified method introduced in literatures for estimation of the background component of buffeting response is then briefly discussed. Finally an approximate method for estimating the first vertical bending mode-buffeting response of cable-stayed bridges is proposed. (C) 2002 Elsevier Science Ltd. All rights reserved...|$|R
40|$|Characterization of {{measurement}} uncertainty {{in terms of}} <b>root</b> <b>sums</b> of <b>squares</b> of both un-known systematic as well as random error components is given meaning {{in the sense of}} predic-tion intervals. Both types of errors are commonly encountered with industrial hygiene air monitoring of hazardous substances. Two extreme types {{of measurement}} methods are pre-sented for illustrating how confidence levels may be ascribed to prediction intervals defined by such uncertainty values. In the case of method calibration at each measurement, systematic error or bias may enter from a biased calibrant. At another extreme, a single initial method evaluation may leave residual bias owing to random error in the evaluation itself or to the use of a biased reference method. Analysis is simplified through new simple approximations to probabilistic limits (quantiles) on the magnitude of a non-central Student t-distributed ran-dom variable. Connection is established between traditional confidence limits, accuracy meas-ures in the case of bias minimization and an uncertainty measure...|$|R
40|$|A three {{dimensional}} {{general circulation}} model {{is used to}} simulate tides along the central western coast of U. S. The model, which is configured from the Regional Ocean Modeling System (ROMS), is three-level nested with the finest resolution of 1. 6 km in the Monterey Bay, California. Forced by tidal signal along the open boundaries in west, north and south directions, ROMS can simulate barotropic tides reasonably well in the region. The total discrepancy of the amplitudes of eight major tide constituents, as measured by <b>root</b> of <b>summed</b> <b>squares,</b> is 3. 5 cm in the open ocean compared with tide amplitudes estimated by Topex/POSEIDON along-track altimetry observation. Along the coastal region, the discrepancy of amplitudes is 5. 4 cm which is about 10 % of the amplitude of the most energetic M 2 constituent. For these major tide constituents, the phase error is generally much less than half hour. The simulated sea surface tidal current, which is heavily influenced by internal tide activity, shows sensitivity to stratification. 1...|$|R
