84|147|Public
30|$|Residual aging {{risks are}} {{uncontrollable}} by aging management strategies and {{may lead to}} safety incidents. To improve the stability and reliability of the safety digital control system, software attributes become more complex. Although stability and <b>reliability</b> <b>goals</b> promote software development, these factors increase software aging factors.|$|E
40|$|AbstractNetwork {{reliability}} {{models for}} determining optimal network topology {{have been presented}} and solved by many researchers. This paper presents some new types of topological optimization model for communication network with multiple <b>reliability</b> <b>goals.</b> A stochastic simulation-based genetic algorithm is also designed for solving the proposed models. Some numerical examples are finally presented to illustrate {{the effectiveness of the}} algorithm...|$|E
40|$|Presented is an advanced, {{fault-tolerant}} multiprocessor avionics architecture {{as could}} be employed in an advanced rotorcraft such as LHX. The processor structure is designed to interface with existing digital avionics systems and concepts including the Army Digital Avionics System (ADAS) cockpit/display system, navaid and communications suites, integrated sensing suite, and the Advanced Digital Optical Control System (ADOCS). The report defines mission, maintenance and safety-of-flight <b>reliability</b> <b>goals</b> {{as might be expected}} for an operational LHX aircraft. Based on use of a modular, compact (16 -bit) microprocessor card family, results of a preliminary study examining simplex, dual and standby-sparing architectures is presented. Given the stated constraints, it is shown that the dual architecture is best suited to meet <b>reliability</b> <b>goals</b> with minimum hardware and software overhead. The report presents hardware and software design considerations for realizing the architecture including redundancy management requirements and techniques as well as verification and validation needs and methods...|$|E
30|$|The {{proposed}} {{model was}} solved using pre-emptive goal programming approach. This {{enabled us to}} determine the bounds for the objective functions. We considered the technicians’ earned-valued goal as being a higher priority than the technicians’ <b>reliability</b> <b>goal.</b> However, some organisations may consider the technicians’ <b>reliability</b> <b>goal</b> as being a higher priority than the technicians’ earned-valued goal. To address priority determination, priority scored performance measurement can be used (Tarokh and Nazemi 2006). The minimum value of the expected reliability of the total scheduled technicians was 85  %. During the testing of the proposed model, the minimum acceptable reliability of the technicians was 60  %. The maximum acceptable reliability of the technicians was 95  %.|$|R
40|$|DVFS {{remains an}} {{important}} energy management technique for embedded systems. However, its {{negative impact on}} transient fault rates has been recently shown. In this paper, we propose the Generalized Shared Recovery (GSHR) technique to optimally use the DVFS technique {{in order to achieve}} a given <b>reliability</b> <b>goal</b> for real-time embedded applications. Our technique determines the optimal number of recoveries to deploy as well as task-level processing frequencies to minimize the energy consumption while achieving the <b>reliability</b> <b>goal</b> and meeting the timing constraints. The recoveries may be shared among tasks, improving the prospects of DVFS compared to existing reliability-aware power management frameworks. The experimental evaluation points to the close-to-optimal energy savings of our proposed technique...|$|R
40|$|Sampling distributions, {{constructed}} by Monte Carlo simulation {{are used in}} hardware development to establish a design <b>reliability</b> <b>goal,</b> to place a confidence coefficient on reliability estimates, and to determine whether sample stress/strength data demonstrate a specified reliability at a specified confidence level...|$|R
40|$|To {{increase}} {{the success rate}} of U. S. built Rocket Motors (SRM), the approach taken is: (1) set common <b>reliability</b> <b>goals</b> for nozzles, cases, bondline, propellant, and insulation; (2) build a common engineering data base to support standard industry-wide reliability assessment models; (3) structure or enhance existing industry/government/user term to develop the tools, methods needed, and the data to support them; and (4) areas where unreliabilities are found must be improved...|$|E
40|$|The {{article of}} record as {{published}} may be located at [URL] use of software reliability models {{as an aid}} to software maintenance, with applications to the Space Shuttle on-board software, will be described. In addition to supporting the maintenance function, the use of reliability models throughout the life of the software supports other functions such as reliability assessment, design feasibility assessment, and management of human and computer resources. By assessment we mean an evaluation of how well the software meets <b>reliability</b> <b>goals...</b>|$|E
40|$|Network {{reliability}} {{models for}} determining optimal network topology {{have been presented}} and solved by many researchers. This paper presents some new types of topological optimization model for communication network with multiple <b>reliability</b> <b>goals.</b> Astochastic simulation-based genetic algorithm is also designed for solving the proposed models. Some numerical examples are finally presented to illustrate {{the effectiveness of the}} algorithm. 数理解析研究所講究録 1205 のタイトル： 計算理論とアルゴリズムの新展開 : New Developments of Theory of Computation and Algoriffims 研究集会報告集 2001 年 1 月 29 日～ 1 月 31 日 研究代表者 加藤直樹(Naoki Katoh...|$|E
40|$|FlexRay {{is gaining}} wide {{acceptance}} {{as the next}} generation bus protocol for automotive networks. This has led to tremendous research interest in techniques for scheduling signals, which are generated by real-time applications, on the FlexRay bus. Signals are first packed together into frames at the application-level and the frames are then transmitted over the bus. To ensure reliability of frames {{in the presence of}} faults, frames must be retransmitted over the bus but this comes at the cost of higher bandwidth utilization. To address this issue, in this paper, we propose a novel frame packing method for FlexRay bus. Our method computes the required number of retransmissions of frames that ensures the specified <b>reliability</b> <b>goal.</b> The proposed frame packing method also ensures that none of the signals violates its deadline and that the desired <b>reliability</b> <b>goal</b> for guaranteeing fault-tolerance is met at the minimum bandwidth cost. Extensive experiments on synthetic as well as a industrial case study demonstrate the benefits of our method...|$|R
30|$|Taking {{the data}} in Ref. [24] as a reference, an example of {{reliability}} allocation is presented by using the method in section  4, and comparison is made between {{the results of the}} method proposed in this paper and that of the method in Ref. [24]. Target value of failure rate λobj[*]=[*] 1 /MTBFobj[*]=[*] 0.002, where, MTBFobj denotes the <b>reliability</b> <b>goal</b> of the overall CNC lathe in Ref. [24].|$|R
40|$|This {{paper will}} review the various philosophies (e. g., {{established}} reliability, Class S) used in developing the military and NASA specifications for {{the various types of}} electrical, electronic, and electromechanical parts. The paper will show how the specification requirements can be combined with applications guidelines, such as derating tables given in various NASA and military documents, to choose appropriate parts to meet the <b>reliability</b> <b>goal</b> of the particular space flight project...|$|R
40|$|In this {{work-in-progress}} {{paper we}} present how Com-ponent Based Software Engineering (CBSE) {{may be used}} to facilitate stochastic schedulability analysis of embedded real-time systems, by providing realistic models of execu-tion time distributions. We present our ongoing work regarding the usage of Ex-ecution Time Profiles (ETPs) to represent the timing be-haviour of real-time components. These ETPs are to be used in a tool for stochastic schedulability analysis of em-bedded real-time systems. The tool is intended for real-time engineers to make cost-reliability trade-offs by dimension-ing hardware resources in a cost efficient way to achieve the <b>reliability</b> <b>goals.</b> ...|$|E
40|$|The {{expended}} capabilities for Orbital Transfer Vehicles (OTV) {{which will}} be needed to meet increased payload requirements for transporting materials and men to geosynchronous orbit are discussed. The requirement to provide manrating offers challenges and opportunities to the propulsion system designers. The propulsion approaches utilized in previous manned space vehicles of the United States are reviewed. The principals of reliability analysis are applied to the Orbit Transfer Vehicle. Propulsion system options are characterized in terms of the test requirements to demonstrate <b>reliability</b> <b>goals</b> and are compared to earlier vehicle approaches...|$|E
40|$|Reliable data {{transport}} is {{an important}} facet of dependability and quality of service in wireless sensor networks. This paper gives {{an introduction to the}} reliable data transport problem and surveys protocols and approaches for this protocol, often developed for particular applications to reflect the application-specific dependability requirements. A joint characteristic of many of the discussed protocols is that they combine mechanisms from several layers to achieve their <b>reliability</b> <b>goals</b> while being energy-efficient. This very need to be energy-efficient precludes Internet-style approaches to reliability – handle it in the end system – and necessitates in-network solutions. I...|$|E
40|$|A human {{mission to}} Mars will require highly {{reliable}} {{life support systems}}. Mars life support systems may recycle water and oxygen using systems similar to those on the International Space Station (ISS). However, achieving sufficient reliability is less difficult for ISS than {{it will be for}} Mars. If an ISS system has a serious failure, it is possible to provide spare parts, or directly supply water or oxygen, or if necessary bring the crew back to Earth. Life support for Mars must be designed, tested, and improved as needed to achieve high demonstrated reliability. A quantitative <b>reliability</b> <b>goal</b> should be established and used to guide development t. The designers should select reliable components and minimize interface and integration problems. In theory a system can achieve the component-limited reliability, but testing often reveal unexpected failures due to design mistakes or flawed components. Testing should extend long enough to detect any unexpected failure modes and to verify the expected reliability. Iterated redesign and retest may be required to achieve the <b>reliability</b> <b>goal.</b> If the <b>reliability</b> is less than required, it may be improved by providing spare components or redundant systems. The number of spares required to achieve a given <b>reliability</b> <b>goal</b> depends on the component failure rate. If the failure rate is under estimated, the number of spares will be insufficient and the system may fail. If the design is likely to have undiscovered design or component problems, it is advisable to use dissimilar redundancy, even though this multiplies the design and development cost. In the ideal case, a human tended closed system operational test should be conducted to gain confidence in operations, maintenance, and repair. The difficulty in achieving high reliability in unproven complex systems may require the use of simpler, more mature, intrinsically higher reliability systems. The limitations of budget, schedule, and technology may suggest accepting lower and less certain expected reliability. A plan to develop reliable life support is needed to achieve the best possible reliability...|$|R
40|$|Areliability {{strategy}} {{is a set}} of softwareengineering practices defined for each project by combining different relia-bility achievement and assessment activi-ties and methods, according to the soft-ware <b>reliability</b> <b>goal</b> and project’s charac-teristics. In [1] is a description of a deci-sion-support system for reliability strategy selection based on a set of product, proj-ect, and resources decision factors. There are two main approaches to achieving high software reliability: 1. Avoiding defects in the final product. 2. Using fault tolerance methods. Fault avoidance can be achieved by using fault prevention and fault detection an...|$|R
40|$|Abstract—Software {{reliability}} allocation {{plays an}} important role during software product design phase, which has close relationship with software modeling and cost evaluation. We formulated an architecture-based approach for modeling software reliability optimization problem, on this basis a dynamic programming algorithm has been illustrated in this paper which can be used to allocate the reliability to each component so as to minimize the cost of designing software while meeting the desired <b>reliability</b> <b>goal.</b> The result of our experiment show an optimal or near optimal {{solution to the problem of}} selecting the component comprising the software can be obtained with lower cost. ...|$|R
40|$|Failure {{data from}} 16 {{commercial}} spacecraft were analyzed to evaluate failure trends, reliability growth, {{and effectiveness of}} tests. It was shown that the test programs were highly effective in ensuring {{a high level of}} in-orbit reliability. There was only a single catastrophic problem in 44 years of in-orbit operation on 12 spacecraft. The results also indicate that in-orbit failure rates are highly correlated with unit and systems test failure rates. The data suggest that test effectiveness estimates can be used to guide the content of a test program to ensure that in-orbit <b>reliability</b> <b>goals</b> are achieved...|$|E
40|$|This report {{describes}} {{a new approach}} to Domain Name Service (DNS) replication. The DNS sys-tem relies heavily on replication (based on zone file transfers) to achieve its <b>reliability</b> <b>goals,</b> but this form of replication typically requires cooperation from other DNS administrators. However, certain failures still occur in practice, and a decoupled, cen-tralized replica of DNS data faces scalability issues if it is based on zone transfers. Our proposed alternative, dubbed passive DNS replication, does not require cooperation from zone administrators and is able to recover from addi-tional failures. It automatically adapts to real-world DNS query patterns, but it does not aim a...|$|E
40|$|A {{technical}} {{management procedure}} that {{is directed to}} the design of a complex electronic system for space environment applications is described. The procedure was developed by the NASA Lewis Research Center and applied to the Centaur launch vehicle program. Specific controls used include a complete hierarchy of specifications, design ground rules, derating document, preferred parts list, worst-case design procedure, computer circuit analysis programs, and design reviews. The use of these rigorous design con-trols resulted in an electronic system capable of meeting its performance and <b>reliability</b> <b>goals</b> with a minimum of difficulty. Electronic circuit design Unclassified- unlimited Space vehicles *For sale by the Clearinghouse for Federal Scientific and Technical Informatio...|$|E
3000|$|... we find {{configurations}} toward <b>reliability</b> and availabilityimprovement <b>goals,</b> for finite, unbounded and infinite mission times; [...]...|$|R
40|$|Abstract. In this paper, {{reliability}} guarantee {{strategies for}} Hengqin were proposed based on reliability affecting factor system and Hengqin needs of high reliability power system and smart grid, and the reliability enhancing degree {{of these strategies}} were assessed. Firstly, the indices of reliability were analyzed, and the reliability affecting factor system was built up. Then, combined with the development need of Hengqin power system, four specific reliability guarantee strategies-network structure construction, advanced distribution automation, intelligent operation and maintenance center and the end-line monitoring system-were proposed and the reliability effects were quantitatively assessed. Finally, the reliability effect of the strategies was compared with the <b>reliability</b> <b>goal</b> of Hengqin power system, and the adequacy and completeness of the strategies were verified...|$|R
40|$|Confirmation of {{the general}} trends of a {{previously}} reported parametric study of plutonia-fueled thermionic generators in a detailed 100 -We generator design. The detailed design {{takes into account the}} additional weight of system-integration components and shows that design refinements of all aeroshell components are possible when a specific generator configuration is considered. An optimized 100 -We thermionic power supply design is presented, reflecting a 0. 98 <b>reliability</b> <b>goal</b> after five years of operation. The optimum multicell array consists of 28 isomite converters, each producing approximately 3. 6 We at end-of-life. The optimum arrangement of converters in the aeroshell is a four-column, seven-row stacking configuration connected electrically as a two-column, 14 -row array...|$|R
40|$|Seal, {{some of the}} {{statistical}} treatment of data has changed to more conservative models. In addition, some additional tests were run {{in order to meet}} the original <b>reliability</b> <b>goals</b> with the revised, more conservative, statistical treatment of the test data. Also enclosed is Westinghouse authorization letter CAW- 1 1 - 3084, (Enclosure 3) accompanying affidavit, Proprietary Information Notice, and Copyright Notice WCAP- 171 00 -P, Revision 1, contains information proprietary to Westinghouse Electric Company LLC; it is supported by an affidavit signed by Westinghouse, owner of the information. The affidavit sets forth the basis on which the information may be withheld from public disclosure by the Commission and addresse...|$|E
40|$|As {{technology}} {{scales and}} the energy of computation continually approaches thermal equilibrium [1, 2], parameter variations and noise levels will lead to larger error rates at various levels of the computation stack. The error rates would be especially high for post-CMOS and nanoelectronic systems {{as well as for}} probabilistic [3] and stochastic architectures [4]. N-modular redundancy (NMR) at the core-level has been proposed as a way to attain system <b>reliability</b> <b>goals</b> for multicore architectures. While core-level DMR and TMR {{have been shown to be}} effective when errors are rare, a large amount of core-level redundancy will be required for attaining system <b>reliability</b> <b>goals</b> in face of high error rates. This makes voting latency and bandwidth significant performance bottlenecks for such systems. In this paper, we present a scalable NMR framework for error prone chip multiprocessors(CMPs). The framework supports in-network fault tolerance where voting logic is integrated into routers to allow for truly distributed voting. The in-network fault tolerance router utilizes the expected redundancy in vote messages, to reduce some of the blocking overhead incurred at the leader, and also provide a mechanism to trade-off network bandwidth with latency. Our framework also supports proactive checkpoint deallocation which allows cores participating in voting to continue on with execution instead of waiting on notification from the voting logic. Finally, the framework supports dynamic constitution that allows an arbitrary core on this chip to be a part of an NMR group. This allows bypassing faulty cores as well as scheduling for performance. Our experiments show significant performance/bandwidth benefits from these optimizations...|$|E
40|$|Motivation is {{provided}} for a theorem that provides {{upper and lower}} bounds for the reliability of reconfigurable digital control systems. The <b>reliability</b> <b>goals</b> for these systems are too high to be established by natural life testing, which means the probability of system failure must be computed from mathematical models that capture the essential elements of fault occurence and system fault recovery. The upper and lower bound theorem shows that system recovery can be adequately described by its first two moments, provided component failure rate is low and system recovery is fast. This result greatly simplifies both the fault injection experiments that study system recovery and the numerical computations that estimate the probability of system failure from a mathematical model...|$|E
40|$|Abstract ⎯ This paper {{presents}} RANDREL, a simulator based trainer for reliability testing. Reliability {{testing is}} modeled as a random {{walk through the}} program execution state space into which an initial set of faults has been seeded. When a fault is encountered during the simulation, a failure is reported, the tester fixes the fault and resumes reliability testing. After each failure, the reliability growth model is updated and used {{to determine whether the}} <b>reliability</b> <b>goal</b> has been achieved. RANDREL provides a low-cost environment for learning reliability testing and modeling, and for exploring factors that contribute to the effectiveness of reliability testing. This paper describes the capabilities of RANDREL and the methodology being used to validate the model. Index Terms ⎯ simulation, software reliability, testing...|$|R
50|$|Providing an {{experienced}} {{head in the}} Western Bulldogs forward line, Giansiracusa’s <b>reliability</b> around <b>goals</b> was imperative in 2012. In the 17 games he goaled on all but one occasion, while contributing multiple majors on eight occasions. He finished the year as the Club’s leading goal scorer.|$|R
40|$|INTRODUCTION It is {{generally}} agreed that the performance assurance role involves two basic activities: engineering and product assurance. Engineering functions include reliability, quality assurance, and system safety. Product assurance consists of elements needed to establish confidence that the product is being designed and manufactured as intended to meet the <b>reliability</b> <b>goal.</b> In addition to these engineering and product assurance fundamentals, the Midcourse Space Experiment (MSX) Performance Assurance Program emphasized design integrity by specifying conformance to the APL Space Department's Engineering Notebook, which includes guidelines for part usage and test, software quality assurance, and design reviews. Figure 1 presents {{the organization of the}} MSX Performance Assurance Program, and shows that the performance assurance engineer reports directly to APL's Space Department management. T program. Complete hardware documentation, as well as integration and test records such a...|$|R
40|$|Payload {{benefits}} to {{be derived from}} refurbishment can be related to individual spacecraft programs directly and for planning purposes to the entire shuttle mission model. In the case of the large space telescope program, cost savings obtained through the use of the shuttle for maintenance operations have been estimated to be in the range from 30 to 40 %. This saving is realized over an operational lifetime of 15 years by reducing, through refurbishment on orbit, the number of flight units along with 'optimized' <b>reliability</b> <b>goals</b> commensurate with periodic maintenance revisits at one-year intervals. Shuttle-era payload implications are discussed together with a pressurized on-orbit maintenance configuration, an earth observation satellite, and some typical teleoperator-serviced spacecraft...|$|E
40|$|The Cassini mission {{requires}} extraordinary {{life and}} reliability from the linear servo-actuators which position the spacecraft's redundant rocket engines. Both commercial actuators and existing in-house actuator designs were studied for this application. Ultimately a device inherited from JPL's Mariner and Viking missions to Mars {{was selected because}} of its close match to functional requirements and its flight pedigree. However, several design improvements were necessary to meet life and <b>reliability</b> <b>goals.</b> Special attention was focused on reliability testing of the motor and mechanism at all stages of procurement and assembly because a brush type of DC motor was retained from the old design. These improvements and, in particular, efforts to develop new component sources are discussed in this paper...|$|E
40|$|Present-day {{practice}} is inadequate for developing justified confidence in software’s impact on system reliability. The inadequacies are especially obvious {{when dealing with}} systems of systems. As will be shown in this paper, there is {{a fair amount of}} uncertainty among system engineers about how to determine the impact of software on overall system reliability, and this uncertainty is especially clear when attempting to evaluate the impact of software on system of systems (SoS) reliability. This paper discusses the uncertainty that is evident today, based on presentations given at a reliability, availability, maintainability, and testability (RAM-T) summit for a large system of systems. Clearly, new approaches (or at least, better guides) are needed to deal adequately with software aspects of system and SoS reliability. A few suggestions are provided in this paper (the need for giving software failures consideration when doing system-level FME-CAs, 1 the need for specifying failure definitions and scoring criteria at the SoS level (not just at the constituent system, or platform, level), and the need for Software Reliability Improvement Programs undertaken during system design), but the main point {{is that it is not}} enough to simply formulate software <b>reliability</b> <b>goals</b> or to collect statistics on detected defects. Some Observations We start with a real life example. At a RAM-T Summit for a major DoD SoS, various contractors responsible for producing different constituents of the system briefed their approach and findings regarding system reliability, availability, and maintainability. 2 As part of the briefing template, each contractor was asked to discuss their approach to software reliability and its contribution to overall system <b>reliability</b> <b>goals.</b> There were a wide variety of statements in response to this requirement...|$|E
40|$|The {{demand for}} {{products}} with high reliability and low manufacturing costs is an ever increasing one in recent times. Inception {{of a product}} that beats competition {{in terms of both}} reliability and cost requires a design strategy that steers the engineering design process toward higher reliability from the very beginning. Engineering Design By Reliability (EDBR) is a methodology used to produce components that meet a certain <b>reliability</b> <b>goal</b> by designing <b>reliability</b> directly into the components. In this methodology, all design parameters are taken to be random variables. All parameters that define the failure governing stress acting on a component during its mission are taken to be distributed variables and all parameters defining the failure governing strength exhibited by the component during its mission are also taken as distributed. As a result...|$|R
40|$|A {{system to}} be {{designed}} and developed is composed of several sub-systems with complex configuration. The relationship between the sub-systems and the system cannot be fully expressed in analytical terms and has {{a high degree of}} uncertainty. Each sub-system can be designed and developed independently and is a subject of several possible measurable versions including both the cost of designing and creating the sub-system and its reliability. The problem is to assign reliability and cost requirements in the system design phase to all sub-systems, in order to:•achieve a specified <b>reliability</b> <b>goal</b> for the system, and•minimize the total costs of designing and creating of all the sub-systems. The corresponding dual problem is being solved as well. The third problem centers on optimizing the system’s structure in order to maximize the system’s utility by means of implementing local parametrical reliability and cost values...|$|R
40|$|Repairable systems {{reliability}} trend {{tests are}} reviewed, extensively tested and compared {{to evaluate their}} effectiveness over diverse data patterns. A repairable system is often modeled as a counting failure process. For a counting failure process, successive inter-arrival failure times will tend to become larger (smaller) for an improving (deteriorating) system. During testing and development of new systems, reliability trend analysis is needed to evaluate {{the progress of the}} design development and improvement process. Often a program of testing and modification, followed by more testing and modification, is required to achieve a desired system <b>reliability</b> <b>goal.</b> <b>Reliability</b> trend tests can be an important part of this program. The objective of system reliability trend tests is to determine whether and how the pattern of failures is significantly changing with time. This paper reviews the following four trend tests: (1) Crow/AMSAA Test, (2) PCNT (pairwise comparison nonparametric test), (3) Laplace Test, and (4) Lewis-Robinson Test. These tests are extensively tested, evaluated and compared for diverse repairable system reliability trends. Particular emphasis focused on comparisons with low sample sizes. Simulation models for trend tests are presented and discussed; and simulation results are summarized and compared. Based on these comparisons, it is concluded that the Crow/AMSAA test is the most robust trend test...|$|R
