2|5|Public
30|$|When the {{destination}} node receives a RD packet, {{it creates a}} route reply (<b>RR)</b> <b>packet</b> to send for the source node. As the <b>RR</b> <b>packet</b> passes through intermediate nodes, the routing tables of these nodes are updated accordingly, {{so that in the}} future, the messages can be routed through these nodes to {{the destination}}. The <b>RR</b> <b>packet</b> header includes the address and location of source node, address of destination node and shortest path length. The <b>RR</b> <b>packet</b> is forwarded based on best possible route and according to Table 2 the best possible route is I 6 ⇒ I 3 ⇒ I 4 ⇒ I 5 ⇒ I 1, as depicted in Figure 9. Also, it is possible for the RD originator to receive a <b>RR</b> <b>packet</b> from more than one node. In such cases, the RD originator will update its routing table with the most recent routing information, it uses the route with the greatest destination sequence number. We have used the node density on the road segments to measure the quality of routes. The source node starts sending data packets, when it receives <b>RR</b> <b>packet.</b>|$|E
40|$|Data Center {{switches}} need guarantee high throughput, resiliency and scalability {{for large-scale}} networks with constantly floating requirements. Multistage packet switches {{have been a}} pervasive solution to implement high-capacity Data Center Networks (DCNs) switches and routers. Yet, classical multistage switching architectures with their Space-Memory variants have shown limited performance. Most proposals prove either too complex to implement or not cost effective. In this paper, we present a highly scalable packet-switch for the DCN environment, in which we exploit the Network-on-Chip (NoC) design paradigm to replace the single-hop crossbars with multi-hop Switching Elements (SEs). In particular, we describe a three-stage switch with Output-Queued Unidirectional NoCs (OQ-UDN) in the central stage of the Clos-network. The design has several advantages over conventional multistage switches. First, it uses a simple Round-Robin (<b>RR)</b> <b>packet</b> dispatching scheme and avoids the need for complex and costly input modules. Besides, it offers better load balancing, a pipelined scheduling and more path-diversity. We assess {{the performance of the}} switch in terms of throughput, end-to-end latency and blocking probability using Markov chain analysis, and we propose an analytical model that integrates the various design parameters. Through extensive simulations, we show that the switching architecture achieves high performance under different types of traffic, and that both the analytical and experimental results correlate over wide range of evaluation settings...|$|E
5000|$|Feedback Target is a {{new type}} of member that has been firstly {{introduced}} by the Internet Draft draft-ietf-avt-rtcpssm-13 (see [...] ). The Hierarchical Aggregation method has extended its functionality. The function of this member is to receive Receiver Reports (RR) (see RTCP) and retransmit summarized <b>RR</b> <b>packets,</b> so-called Receiver Summary Information (RSI) to a sender (in case of single level hierarchy).|$|R
40|$|This {{document}} {{defines the}} Extended Report (XR) packet type for the RTP Control Protocol (RTCP), and defines how {{the use of}} XR packets can be signaled by an application if it employs the Session Description Protocol (SDP). XR packets are composed of report blocks, and seven block types are defined here. The purpose of the extended reporting format is to convey information that supplements the six statistics that are contained in the report blocks used by RTCP's Sender Report (SR) and Receiver Report (<b>RR)</b> <b>packets.</b> Some applications, such as multicast inference of network characteristics (MINC) or voice over IP (VoIP) monitoring, require other and more detailed statistics. In addition to the block types defined here, additional block types may be defined in the future by adhering to the framework that this document provides...|$|R
40|$|Multicast {{applications}} and network monitors can potentially {{benefit from the}} ability to infer the loss rates along links within a multicast tree. Estimators, known generically by minc, or multicast inference of network characteristics, {{have been developed to}} provide this ability. They consider multicast data packets to be probes, and conduct inference based upon reports of which probes reached each receiver. In practice, gathering reports from receivers in real time is a non-trivial task that presents scaling problems as the number of receivers increases. Prior work has led to an extension of the RTP data transport protocol to permit receivers to report per-probe information in packets known as RTCP XR packets. This paper demonstrates how minc inference can, in fact, be conducted using only a default RTP packet format known as RTCP <b>RR.</b> RTCP <b>RR</b> <b>packets</b> contain summary information rather than per-probe information. They thus offer bandwidth savings, although this comes at the expense of an increase in estimator convergence time. Furthermore, this technique can be used by the observer of any standard RTP session, whereas estimation based upon per-probe information is only possible when a session explicitly employs the extended reporting format...|$|R
30|$|The {{proposed}} MP packet scheduling {{algorithm is}} {{compared with the}} conventional MT, <b>RR,</b> and PF <b>packet</b> scheduling algorithms. Among the conventional three algorithms, the MT algorithm shows the best throughput and the RR algorithm the worst throughput. However, in terms of fairness, the RR algorithm achieves the best performance and the MT algorithm shows the worst performance. The worst fairness of the MT algorithm is attributed to the monopolization of spectrum resource by only a few UEs with good CQIs. On the other hand, UEs with poor CQIs can be given a higher priority in the PF algorithm by using a different metric from the MT algorithm as divided by the past average data rate. Therefore, in despite of the poor channel states, the UEs can precede other UEs having good channel conditions. Monopolizing UEs tend to be located near eNBs {{at the center of}} the cells. By applying the PF and RR algorithms, user throughput at the cell edge can be increased.|$|R

