142|573|Public
50|$|In CSMA/CA {{collision}} avoidance {{is used to}} improve the performance of CSMA. If the transmission medium is sensed busy before transmission, then the transmission is deferred for a <b>random</b> <b>interval.</b> This <b>random</b> <b>interval</b> reduces the likelihood that two or more nodes waiting to transmit will simultaneously begin transmission upon termination of the detected transmission, thus reducing the incidence of collision.|$|E
50|$|Here Prθ,φ {{indicates}} the probability distribution of X characterised by (θ, φ). An {{important part of}} this specification is that the <b>random</b> <b>interval</b> (u(X), v(X)) covers the unknown value θ with a high probability no matter what the true value of θ actually is.|$|E
5000|$|The {{time machine}} sends the {{traveller}} {{back in time}} by a <b>random</b> <b>interval.</b> Usually {{this is about a}} day but it may be as little as a few minutes or as much as a week. In the final episode of the series it is found that the length of time travelled back can be controlled by altering the length of the photon rods; this is discovered by the research company Webb Biotech, who have also invented a time machine.|$|E
40|$|A solid {{generator}} of <b>random</b> <b>intervals,</b> {{based on}} a beta ray emitter, is described. The instrument provides for independent control of the minimal interval between successive output plus and of the dispersion of the <b>random</b> <b>intervals.</b> It {{has been used for}} delivering sensory stimuli at <b>random</b> <b>intervals</b> or in <b>random</b> sequences. © 1971. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|<b>Random</b> <b>intervals</b> are {{increasingly}} useful in engineering modeling, but {{are difficult to}} measure and elicit from experts. We present a method for constructing <b>random</b> <b>intervals</b> by eliciting simple "multi-interval" and trace information from investigators. By eliciting in addition to "how high" and "how low", simply also "how high and low might the min and max themselves be", we generate an equivalence class of possibility distributions, and in turn a canonical member of an equivalence class of <b>random</b> <b>intervals...</b>|$|R
40|$|A large {{class of}} {{problems}} in sciences and engineering can be formulated as the general problem of constructing <b>random</b> <b>intervals</b> with pre-specified coverage probabilities for the mean. Wee propose a general approach for statistical inference of mean values based on accumulated observational data. We show that the construction of such <b>random</b> <b>intervals</b> {{can be accomplished by}} comparing the endpoints of <b>random</b> <b>intervals</b> with confidence sequences for the mean. Asymptotic results are obtained for such sequential methods. Comment: 75 pages, no figures. The main results of this paper appeared in Proceeding of SPIE Conference...|$|R
50|$|P2PRIV {{separates}} anonymization from {{user data}} transport. Before sending data, signalization tokens are forwarded over classical anonymous cascades towards formation of so-called cloning cascades (CC). The well-known anonymous techniques (i.e. Mix network and Crowds' Random walk algorithm) are utilized in hiding the initiator of the CC. Then, after a <b>random</b> <b>interval</b> of time, each CC member (i.e. group of clones {{and the true}} initiator) communicates directly and independently with destination nodes. A process of finding the true initiator among network nodes is hard to perform even for an adversary able to collude {{a significant part of}} overlay network.|$|E
50|$|As {{the atom}} {{came to be}} better understood, the nature of {{radioactivity}} became clearer. Some larger atomic nuclei are unstable, and so decay (release matter or energy) after a <b>random</b> <b>interval.</b> The three forms of radiation that Becquerel and the Curies discovered are also more fully understood. Alpha decay is when a nucleus releases an alpha particle, which is two protons and two neutrons, equivalent to a helium nucleus. Beta decay is {{the release of a}} beta particle, a high-energy electron. Gamma decay releases gamma rays, which unlike alpha and beta radiation are not matter but electromagnetic radiation of very high frequency, and therefore energy. This type of radiation is the most dangerous and most difficult to block. All three types of radiation occur naturally in certain elements.|$|E
50|$|Additional basic {{functions}} {{performed by the}} TCU's and PCU’s were generation of a cyclic-parity-check code vector and decoding of received packets for packet error-detection purposes, and generation of packet retransmissions using a simple <b>random</b> <b>interval</b> generator. If an acknowledgment was not received from the Menehune after the prescribed number of automatic retransmissions, a flashing light {{was used as an}} indicator to the human user. Also, since the TCU's and PCU’s did not send acknowledgments to the Menehune, a steady warning light was displayed to the human user when an error was detected in a received packet. Thus {{it can be seen that}} considerable simplification was incorporated into the initial design of the TCU as well as the PCU, making use of the fact that it was interfacing a human user into the network.|$|E
50|$|He {{also joined}} in with Mike Strickland and the Usual Unusual Clowns at <b>random</b> <b>intervals.</b>|$|R
5000|$|The Howler, male - a small, dirty {{bundle of}} rags who howls at <b>random</b> <b>intervals</b> ...|$|R
5000|$|At <b>random</b> <b>intervals</b> the {{authenticator}} sends a {{new challenge}} to the peer and repeats steps 1 through 3.|$|R
50|$|The first offered {{singulation}} protocol is the ALOHA protocol, originally used {{decades ago}} in ALOHAnet and {{very similar to}} CSMA/CD used by Ethernet. These protocols are mainly used in HF tags. In ALOHA, tags detect when a collision has occurred, and attempt to resend after waiting a <b>random</b> <b>interval.</b> The performance of such collide-and-resend protocols is approximately doubled if transmissions are synchronised to particular time-slots, and in this application time-slots for the tags are readily provided for by the reader. ALOHA does not leak information like the tree-walking protocol, and is much less vulnerable to blocker tags, which {{would need to be}} active devices with much higher power handling capabilities in order to work. However when the reader field is densely populated, ALOHA may make much less efficient use of available bandwidth than optimised versions of tree-walking. In the worst case, an ALOHA protocol network can reach a state of congestion collapse. The Auto-ID consortium is attempting to standardise a version of an ALOHA protocol which it calls Class 0 HF. This has a performance of up to 200 tags per second.|$|E
5000|$|... "In {{order to}} {{incorporate}} the nonlinear dynamics of biological neurons into neuron models to develop a prosthesis, {{it is first necessary}} to measure them accurately. We have developed and applied methods for quantifying the nonlinear dynamics of hippocampal neurons (Berger et al., 1988a,b, 1991, 1992, 1994; Dalal et al., 1997) using principles of nonlinear systems theory (Lee and Schetzen, 1965; Krausz, 1975;P. Z. Marmarelis and Marmarelis, 1978; Rugh, 1981; Sclabassi et al., 1988). In this approach, properties of neurons are assessed experimentally by applying a <b>random</b> <b>interval</b> train of electrical impulses as an input and electrophysiologically recordingthe evoked output of the target neuron during stimulation (figure 12.2A). The input train consists of a series of impulses (as many as 4064), with interimpulse intervals varying according to a Poisson process having a mean of 500 ms and a range of 0.2-5000 ms. Thus, the input is [...] "broadband" [...] and stimulates the neuron over most of its operating range; that is, the statistical properties of the random train are highly consistent with the known physiological properties of hippocampal neurons. Nonlinear response properties are expressed in terms of the relation between progressively higher-order temporal properties of a sequence of input events and the probability of neuronal output, and are modeled as the kernels of a functional power series." ...|$|E
40|$|A <b>random</b> <b>interval</b> graph of [...] . This paper {{characterizes the}} {{fluctuations}} {{of the independence}} number in <b>random</b> <b>interval</b> graphs. This characterization is obtained through {{the analysis of the}} greedy algorithm. We actually prove limit theorems (central limit theorem and large deviation principle) on the number of phases of this greedy algorithm. The proof relies on the analysis of first-passage-times through a random level...|$|E
5000|$|Brownian noise (Martin Gardner {{proposed}} {{this name}} for sound generated with <b>random</b> <b>intervals.</b> It is a pun on Brownian motion and white noise.) ...|$|R
40|$|In this paper, we have {{established}} a unified framework of multistage parameter estimation. We demonstrate that {{a wide variety of}} statistical problems such as fixed-sample-size interval estimation, point estimation with error control, bounded-width confidence intervals, interval estimation following hypothesis testing, construction of confidence sequences, can be cast into the general framework of constructing sequential <b>random</b> <b>intervals</b> with prescribed coverage probabilities. We have developed exact methods for the construction of such sequential <b>random</b> <b>intervals</b> in the context of multistage sampling. In particular, we {{have established}} inclusion principle and coverage tuning techniques to control and adjust the coverage probabilities of sequential <b>random</b> <b>intervals.</b> We have obtained concrete sampling schemes which are unprecedentedly efficient in terms of sampling effort as compared to existing procedures. Comment: 254 pages, no figure; added more references; main results appeared in Proceedings of SPIE, Orlando, Florida, USA, April 2010 and 201...|$|R
3000|$|RS. To {{estimate}} the compliance, the ventilator applies a 300 -ms pause maneuver {{at the end}} of inspiration at <b>random</b> <b>intervals</b> of four to 10 breaths [7]. P [...]...|$|R
40|$|In {{the setting}} of a discrete-time delayed renewal process,we study {{counting}} the number of renewals during a <b>random</b> <b>interval.</b> An exanple is the number of appearances of a specific pattern in a random number of repeated traials. We obtain closed-form mathematical expressions for the probability mass function and the binomial moments of this number for various distributions of the interrenewal times and the length of the <b>random</b> <b>interval.</b> Includes bibliographical reference...|$|E
40|$|AbstractThis article {{proposes a}} method for pricing a {{contingent}} claim with <b>random</b> <b>interval</b> and fuzzy random payoff. On introduction of the acceptability concept based on classical no-arbitrage argument, a price interval and a fuzzy price are obtained in <b>random</b> <b>interval</b> market and fuzzy random market, respectively. New definitions on replicative strategies, sub-replicative and sup-replicative ones, in two market setting are given. Some interesting results {{similar to those in}} the classical random market are presented...|$|E
40|$|We are {{interested}} in improving risk and reliability analysis of complex systems where our knowledge of system performance is provided by large simulation codes, and where moreover input parameters are known only imprecisely. Such imprecision lends itself to interval representations of parameter values, and thence to quantifying our uncertinay through Dempster-Shafer or Probability Bounds representations on the input space. In this context, the simulation code acts as a large "black box" function f,trans- forming one input Dempster-Shafer structure on the line (also known as a <b>random</b> <b>interval</b> A) into an output <b>random</b> <b>interval</b> f(A). Our quantification of output uncertainty is then based on this output <b>random</b> <b>interval.</b> If some properties of f (perhaps monotonicity or other analytical properties) are known, then some information about f(A) can be determined. But when f is a pure black box, we must resort to sampling approaches. In this paper, we present the basic formalism of a Monte Carlo approach to sampling a functionally propagated general random set, {{as opposed to a}} <b>random</b> <b>interval.</b> We show that the results of straightforward formal definitions are mathematically coherent, in the sense that bounding and convergence properties are achieved...|$|E
50|$|At <b>random</b> <b>intervals,</b> {{a player}} {{may be given}} a {{clearance}} or a sale at a store that does not currently have one. Other times, a player {{may have to pay}} an additional fee for the item.|$|R
40|$|In this paper, {{we develop}} a general theory on the {{coverage}} probability of <b>random</b> <b>intervals</b> {{defined in terms}} of discrete random variables with continuous parameter spaces. The theory shows that the minimum coverage probabilities of <b>random</b> <b>intervals</b> with respect to corresponding parameters are achieved at discrete finite sets and that the coverage probabilities are continuous and unimodal when parameters are varying in between interval endpoints. The theory applies to common important discrete random variables including binomial variable, Poisson variable, negative binomial variable and hypergeometrical random variable. The theory {{can be used to make}} relevant statistical inference more rigorous and less conservative. Comment: 21 pages, 2 figure, revised Theorem...|$|R
30|$|However, {{this may}} not be true all the time, as the packets arrive at <b>random</b> <b>intervals.</b> Hence BS needs a pairing {{algorithm}} to pair the MS in an efficient manner. There can be two ways of pairing the MS.|$|R
40|$|In this thesis, {{which is}} {{supervised}} by Dr. David Penman, we examine <b>random</b> <b>interval</b> graphs. Recall {{that such a}} graph is defined by letting X_ 1, [...] . X_n,Y_ 1, [...] . Y_n be 2 n independent random variables, with uniform distribution on [0, 1]. We then say that the ith of the n vertices is the interval [X_i,Y_i] if X_i<Y_i and the interval [Y_i,X_i] if Y_i<X_i. We then say that two vertices are adjacent {{if and only if}} the corresponding intervals intersect. We recall from our MA 902 essay that fact that in such a graph, each edge arises with probability 2 / 3, and use this fact to obtain {{estimates of the number of}} edges. Next, we turn to how these edges are spread out, seeing that (for example) the range of degrees for the vertices is much larger than classically, by use of an interesting geometrical lemma. We further investigate the maximum degree, showing it is always very close to the maximum possible value (n- 1), and the striking result that it is equal to (n- 1) with probability exactly 2 / 3. We also recall a result on the minimum degree, and contrast all these results with the much narrower range of values obtained in the alternative comparable model G(n, 2 / 3) (defined later). We then study clique numbers, chromatic numbers and independence numbers in the <b>Random</b> <b>Interval</b> Graphs, presenting (for example) a result on independence numbers which is proved by considering the largest chain in the associated interval order. Last, we make some brief remarks about other ways to define <b>random</b> <b>interval</b> graphs, and extensions of <b>random</b> <b>interval</b> graphs, including random dot product graphs and other ways to define <b>random</b> <b>interval</b> graphs. We also discuss some areas these ideas should be usable in. We close with a summary and some comments. Comment: M. Sc. thesis. October 200...|$|E
40|$|AbstractScale free graphs have {{attracted}} attention by their non-uniform structure {{that can be}} used as a model for various social and physical networks. In this paper, we propose a natural and simple random model for generating scale free interval graphs. The model generates a set of intervals randomly under a certain distribution, which defines a <b>random</b> <b>interval</b> graph. The main advantage of the model is its simpleness. The structure/properties of generated graphs are analyzable by relatively simple probabilistic and/or combinatorial arguments, which is different from many other models. Based on such arguments, we show for our <b>random</b> <b>interval</b> graph that its degree distribution follows a power law, and that it has a large average clustering coefficient...|$|E
40|$|In {{order to}} enhance the service performance, the {{preservation}} and increase of system dependability are researched and a system dependability self-tuning method is proposed based on autonomic computing. The self-tuning method attempts to achieve the sustained growth of system dependability by on-line evaluation, dynamic prediction and tuning of self-tuning scheme. There are four tuning methods <b>random</b> <b>interval,</b> settled interval, dependability threshold value and event trigger, which {{are discussed in the}} simulation experimentation. The tuning effects that affect system dependability increment are analyzed, and the optimal tuning opportunities for each tuning method are given. The result of simulation experiment shows that the tuning methods will ensure the positive increase of system dependability increment except <b>random</b> <b>interval...</b>|$|E
5000|$|At the Hammam Al Andalus, {{teams had}} to wash {{each other with}} a bar of soap until a marker saying [...] "Inquisition" [...] was {{revealed}} inside the bar of soap. At <b>random</b> <b>intervals,</b> they would be splashed with icy water.|$|R
30|$|The assumed {{continuous}} {{dependence of}} the probability density function (joint density function) on the random variable (variables) in an <b>interval</b> <b>random</b> variable (<b>interval</b> <b>random</b> variables) implies that the conditional probability density function is also continuous. This guarantees that the generalization of the conditional density function to the interval setting is always an interval.|$|R
30|$|We {{are now in}} a {{position}} to introduce the definition of <b>interval</b> <b>random</b> variables and <b>interval</b> stochastic processes.|$|R
40|$|Scale free graphs have {{attracted}} attention by their non-uniform structure {{that can be}} used as a model for various social and physical networks. In this paper, we propose a natural and simple random model for generating scale free interval graphs. The model generates a set of intervals randomly under a certain distribution, which defines a <b>random</b> <b>interval</b> graph. The main advantage of the model is its simpleness. The structure/properties of generated graphs are analyzable by relatively simple probabilistic and/or combinatorial arguments, which is different from many other models. Based on such arguments, we show for our <b>random</b> <b>interval</b> graph that its degree distribution follows a power law, and that it has a large average clustering coefficient...|$|E
3000|$|Jammalamadaka and Mangalam (2003) {{proposed}} a general censoring mechanism called the middle-censoring scheme in non-parametric {{set up and}} is differentiated from other censoring schemes. Middle-censoring occurs if a data point is not observable when it falls inside a <b>random</b> <b>interval.</b> Suppose T [...]...|$|E
40|$|In this paper, {{we propose}} a novel {{evolutionary}} <b>Random</b> <b>Interval</b> Fingerprint (RIF) for active RFID and ZigBee systems. This new approach can enable more secure multi-party communication since, if the wireless packets are forged by another wireless communication party, the interval fingerprint can provide {{another way to}} detect the spoofing packet. Moreover, the random evolutionary algorithms, both genetic and memetic, are also proposed {{as a means to}} generate the <b>random</b> <b>interval</b> fingerprint. Compared to the conventional random generator, our approach is flexible in generating uniform random and long cycle numbers, and more robust for the anti-cracking. It is difficult for the forged party to produce the fake random intervals. Finally, we provide an application example, a completed work survey, pseudo-code and analysis result to prove that our concept is feasible for the Wireless communication...|$|E
30|$|The described, {{remotely}} triggered trusted lifebeat procedure {{does not}} necessarily have to be executed at a fixed time interval but the control station can send requests at <b>random</b> <b>intervals.</b> It however should be ensured that these intervals do not exceed a previously configured maximum time.|$|R
3000|$|... (z), {{the random}} {{switching}} rule still hinders the covert/model-dependent attack described in Section 3.2. This {{follows from the}} simple fact that it is more difficult to synchronize the interference caused by the covert/model-dependent attacks with the controller states, which are switched at <b>random</b> <b>intervals.</b>|$|R
5000|$|Work {{sampling}} is {{a method}} in which the job is sampled at <b>random</b> <b>intervals</b> to determine the proportion of total time spent on a particular task. [...] It provides insight into how often workers are performing tasks which might cause strain on their bodies.|$|R
