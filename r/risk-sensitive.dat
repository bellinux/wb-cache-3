583|0|Public
5000|$|A {{particularly}} important example of subordinated bonds {{can be found}} in bonds issued by banks. Subordinated debt is issued periodically by most large banking corporations in the U.S. Subordinated debt can be expected to be especially <b>risk-sensitive</b> because subordinated debt holders have claims on bank assets only after senior debtholders and they lack the upside gain enjoyed by shareholders.|$|E
50|$|He {{investigated}} the capability issues of robust and adaptive control {{in dealing with}} uncertainty, and revealed that to capture the intrinsic limitations of adaptive control, {{it is necessary to}} use sup-types of transient and persistent performance, rather than limsup-types which reflect only asymptotic behavior of a system. This indicates that intimate interaction and inherent conflict between identification and control result in a certain performance lower bound which does not approach the nominal performance even when the system varies very slowly. For nonlinear hybrid stochastic systems with unknown jump-Markov parameters, he with co-authors used the Wonham nonlinear filter to estimate the unknown parameters and presented an estimation error bound, which is a basic tool and {{plays an important role in}} performance analysis of adaptive control of nonlinear hybrid stochastic systems. He also attacked a series of hard problems related on global output-feedback control of nonlinear stochastic systems with inverse dynamics, including practical output-feedback <b>risk-sensitive</b> control, robust adaptive stabilization, small-gain theorem of general nonlinear stochastic systems. Different from the existing literature, the systems considered in his work are so complicated that renders any control design for them is much difficult. He developed a set of predominant methods and obtained many innovative results. The work represents an accomplishment for both the field of stochastic nonlinear stabilization and the backstepping method.|$|E
40|$|In this paper, simple linear single-input-single output {{models of}} the reactor-regulating system have been considered, and <b>risk-sensitive</b> {{filtering}} and <b>risk-sensitive</b> parameter-estimation techniques {{have been used to}} obtain temporal-redundancy relations. While a <b>risk-sensitive</b> filter is used to provide a temporally redundant measurement of reactivity from an analytically redundant process parameter during a reactor start-up, a <b>risk-sensitive</b> parameter estimation technique is used to obtain temporally redundant measurements during steady state operation...|$|E
40|$|In {{this paper}} we derive <b>risk-sensitive</b> filters {{which can be}} used for both on-line and {{off-line}} identification of hidden Markov models (HMMs), The identification is achieved by taking <b>risk-sensitive</b> conditional mean {{estimates of the number of}} state transitions (jumps) smd occupation times and then using these values to estimate the parameters of the system. Furthermore we demonstrate that the <b>risk-sensitive</b> filters approach the existing rrsymptotically optimal (risk-neutral) filters in the limit of the <b>risk-sensitive</b> parameter. 1...|$|E
40|$|We define here <b>risk-sensitive</b> {{filtering}} as minimising {{the expected}} {{value of the}} exponential of an estimation error (quadratic) cost scaled by a <b>risk-sensitive</b> parameter. Such filtering is a generalization of standard risk-neutral filtering in that as the <b>risk-sensitive</b> parameter approaches zero, risk-neutral (minimum error variance) filtering is achieved. Also taking small noise limits, a differential game associated with H 1 filtering results. In this paper, the <b>risk-sensitive</b> nonlinear stochastic filtering problem is studied in both continuous and discrete-time for quite general finite-dimensional signal models, including also discrete state hidden Markov models (HMMs). The <b>risk-sensitive</b> estimates are {{expressed in terms of}} the so-called information state of the model given by the Zakai equation which is linear. In the linear Gaussian signal model case, the <b>risk-sensitive</b> (minimum exponential variance) estimates are identical to the minimum variance Kalman filter state estimates, and [...] ...|$|E
40|$|In this thesis, <b>risk-sensitive</b> {{estimation}} for Hidden Markov Models isstudied from a dynamical systems {{point of}} view. We show that <b>risk-sensitive</b> estimators {{belong to a}} broaderclass of product estimators in which risk-sensitivity willbe shown {{to be related to}} certain scaling functions. The product structureand the scaling functions perspective give us new insights into the underlying mechanism of <b>risk-sensitive</b> estimation. For the first time, in a series of theorems and examples, we relate risk-sensitivity to the dynamics of the underlying process and exposerelations among the transition probabilities, risk-sensitivity andthe decision regions. We introduce the <b>risk-sensitive</b> Maximum A Posterior Probability (MAP) criterion for HMM's with discrete rangeobservation. This criterion is the discrete time finite dimensionalversion of the classic <b>risk-sensitive</b> estimation problem for linear/quadratic partial observation case. The <b>risk-sensitive</b> filters take into account the"higher order" moments of the of the estimation error. In the context of <b>risk-sensitive</b> MAP for HMM's, we clarify and quantify the influence of risk-sensitivityon the behavior of the sample paths of the estimator; theproduct structure representationwill play an important role...|$|E
40|$|In this paper, {{we address}} the nite-dimensionality issues {{regarding}} discrete-time <b>risk-sensitive</b> estimation for stochastic nonlinear systems. We show {{that for a}} bilinear system with an unknown parameter, nite-dimensional <b>risk-sensitive</b> estimates can be obtained. A necessary condition is obtained for nonlinear systems with no process noise such that one can obtain nite-dimensional <b>risk-sensitive</b> estimates. 1...|$|E
40|$|The {{article is}} devoted to <b>risk-sensitive</b> {{optimality}} in Markov games. Attention is focused on Markov games evolving on communicating Markov chains with two-players with opposite aims. Considering <b>risk-sensitive</b> optimality criteria means that total reward generated by the game is evaluated by exponential utility function with a given <b>risk-sensitive</b> coefficient. In particular, the first player (resp. the secondplayer) tries to maximize (resp. minimize) the long-run risk sensitive average reward. Observe that if the second player is dummy, the problem is reduced to finding optimal policy of the Markov decision chain with the <b>risk-sensitive</b> optimality. Recall that for the risk sensitivity coefficient equal to zero we arrive at traditional optimality criteria. In this article, connections between <b>risk-sensitive</b> and risk-neutral Markov decisionchains and Markov games models are studied using discrepancy functions. Explicit formulae for bounds on the <b>risk-sensitive</b> average long-run reward are reported. Policy iteration algorithm for finding suboptimal policies of both players is suggested. The obtained results are illustrated on numerical example...|$|E
40|$|<b>Risk-sensitive</b> {{development}} {{is an essential}} component of building resilient communities. It provides an opportunity for sustaining development investment as well as reducing future risks at community level. Development plans should integrate disaster and climate risk information systematically, to overcome increasing challenges of disaster and climate risks and to optimise the use of resources for effective delivery of development outcomes. While development plans identify needs and priorities of communities, the process of formulating development plans itself intends to empower communities. Disaster Risk Reduction (DRR) and Climate Change Adaptation (CCA) integrated development strategies will enable state and non-state stakeholders to implement risk-informed actions in disaster prone areas. Formulation of <b>risk-sensitive</b> village and regional development plans has been promoted in the recent Community Resilience Framework of Sri Lanka. This paper presents an approach and process in developing <b>risk-sensitive</b> development plans in a pilot project in the Northern Sri Lanka moving from stand-alone DRR initiatives to <b>risk-sensitive</b> development. Key lessons from the pilot project include: involvement of local authorities from the outset of the <b>risk-sensitive</b> development planning process; formulating a system to monitor the complete <b>risk-sensitive</b> development planning process; and creating a community of practice to promote <b>risk-sensitive</b> development planning at divisional level for future upscaling...|$|E
40|$|We {{consider}} a <b>risk-sensitive</b> optimal control problem for hidden Markov models (HMM). Building upon recent results by Baras, James and Elliott, we investigate {{the structure of}} <b>risk-sensitive</b> controllers for HMM, via an examination of a popular benchmark problem. We obtain new results {{on the structure of}} the risk- sensitive controller by first proving concavity and piecewise linearity of the value function. Furthermore, we compare the structure of <b>risk-sensitive</b> and risk-neutral controllers...|$|E
40|$|We {{formulate}} {{and solve}} a <b>risk-sensitive</b> optimal control problem for quantum systems using dynamic programming techniques. The optimal control {{is given in}} terms of a new unnormalized conditional state, whose dynamics include the cost function used to specify the performance objective. The <b>risk-sensitive</b> conditional dynamic equation describes the evolution of our knowledge of the quantum system tempered by our purpose for the controlled quantum system. Feedback and robustness properties of <b>risk-sensitive</b> controllers are discussed...|$|E
40|$|Probabilistic {{planners}} {{can have}} various planning objectives: usually they either maximize {{the probability of}} goal achievement or minimize the expected execution cost of the plan. Researchers have largely ignored the problem how to incorporate <b>risk-sensitive</b> attitudes into their planning mechanisms. We discuss a <b>risk-sensitive</b> planning approach {{that is based on}} utility theory. Our key result is that this approach can, at least for risk-seeking attitudes, be implemented with any reactive planner that maximizes (or satisfices) the probability of goal achievement. First, the <b>risk-sensitive</b> planning problem is transformed into a different planning problem, that is then solved by the planner. The larger the probability of goal achievement of the resulting plan, the better its expected utility is for the original (<b>risk-sensitive)</b> planning problem. This approach extends the functionality of reactive planners that maximize the probability of goal achievement, since it allows one to use them (unchanged) for <b>risk-sensitive</b> planning...|$|E
40|$|The {{importance}} of feedback control is being increasingly appreciated in quantum physics and applications. This paper describes {{the use of}} optimal control methods {{in the design of}} quantum feedback control systems, and in particular the paper formulates and solves a <b>risk-sensitive</b> optimal control problem. The resulting <b>risk-sensitive</b> optimal control is given in terms of a new unnormalized conditional state, whose dynamics include the cost function used to specify the performance objective. The <b>risk-sensitive</b> conditional dynamic equation describes the evolution of our knowledge of the quantum system tempered by our purpose for the controlled quantum system. Robustness properties of <b>risk-sensitive</b> controllers are discussed, and an example is provided. Comment: 16 pages, revtex, submitted to Phys Rev...|$|E
40|$|In this paper, {{we develop}} new results {{concerning}} the <b>risk-sensitive</b> dual control problem for output feedback nonlinear systems, with unknown time-varying parameters. These {{results are not}} merely immediate specializations of known <b>risk-sensitive</b> control theory for nonlinear systems, but rather, are new formulations which are of interest in their own right. A dynamic programming equation solution is given to an optimal <b>risk-sensitive</b> dual control problem penalizing outputs, rather than the states, for a reasonably general class of nonlinear signal models. This equation, in contrast to earlier formulations in the literature, clearly shows the dual aspects of the <b>risk-sensitive</b> controller regarding control and estimation. The computational task to solve this equation, as has been seen for the risk-neutral dual control problem, suffers from the so-called ‘curse of dimensionality’. This motivates our study of the <b>risk-sensitive</b> version for a suboptimal risksensitive dual controller. Explicit controllers are derived for a minimum phase single-input, single-output auto-regressive model with exogenous input and unknown time-varying parameters. Also, simulation studies are carried out for an integrator with a time-varying gain. They show that the <b>risk-sensitive</b> suboptimal dual controller is more robust to uncertain noise environments compared with its risk-neutra...|$|E
40|$|Abstract. Social foragers obtain food {{through two}} tactics: ‘producer ’ {{searches}} for its food, and ‘scrounger ’ exploits food discovered by producer. In the recent literature, two alternative producer– scrounger (P-S) {{models have been}} proposed, one rate-maximizing, the other <b>risk-sensitive.</b> Their predictions diVer about the eVect of food clump density on the equilibrium proportional use of scrounger in a group. The rate-maximizing model predicts no eVect, whereas the <b>risk-sensitive</b> model predicts that the proportional use of scrounger should increase with food clump density. These predictions were tested using wild-caught European starlings, Sturnus vulgaris, in an indoor aviary. Increased food clump density resulted in significant increases in the proportional use of scrounger. Proportional use of scrounger was negatively related to food intake variance as assumed by the <b>risk-sensitive</b> model. Thus, scrounger is a risk-averse foraging tactic, and starlings used it in a <b>risk-sensitive</b> fashion. The <b>risk-sensitive</b> model was further challenged by testing its prediction concerning daily food requirement. When producer has a low competitive eYciency, as was found in these starlings, the <b>risk-sensitive</b> model predicts weakly positive eVects, if any, of increased requirement on proportional use of scrounger. Results were consistent with this prediction. A significant number of starlings showed consistently positive eVects of requirement on proportional use of scrounger, but th...|$|E
40|$|This thesis {{consists}} of three topics whose over-arching theme is based on risk sensitive stochastic control. In the �first topic (chapter 2), we study a problem on benchmark out-performance. We model this as a zero-sum <b>risk-sensitive</b> stochastic game between an investor who as a player wants to maximize the <b>risk-sensitive</b> criterion while the other player (a stochastic benchmark) tries to minimize this maximum <b>risk-sensitive</b> criterion. We obtain an explicit expression for the strategies for both these two players. In the second topic (chapter 3), we consider a finite horizon <b>risk-sensitive</b> asset management problem. We study {{it in the context}} of a zero-sum stochastic game between an investor and the second player called the "market world" which provides a probability measure. Via this game, we connect two (somewhat) disparate areas in stochastics; namely, stochastic stability and <b>risk-sensitive</b> stochastic control in mathematical finance. The connection is through the Follmer-Schweizer minimal martingale measure. We discuss the impact of this measure on the investor's optimal strategy. In the third topic (chapter 4), we study the sufficient stochastic maximum principle of semi-Markov modulated jump diffusion. We study its application in the context of a quadratic loss minimization problem. We also study the finite-horizon <b>risk-sensitive</b> optimization in relation to the underlying sufficient stochastic maximum principle of a semi-markov modulated diffusion...|$|E
40|$|Filtering {{problems}} with general exponential quadratic criteria are investigated for Gauss-Markov processes. In this setting, the Linear Exponential Gaussian and <b>Risk-Sensitive</b> filtering problems are solved {{and it is}} shown {{that they may have}} different solutions. Key words. Gauss-Markov process, optimal filtering, <b>risk-sensitive</b> filtering, exponential criteria, Riccati equatio...|$|E
40|$|We analyze <b>risk-sensitive,</b> incentive-compatible deposit {{insurance}} {{in the presence}} of private information and moral hazard. Without deposit-linked subsidies it is impossible to implement <b>risk-sensitive,</b> incentive- compatible {{deposit insurance}} pricing in a competitive, deregulared environment, except when the deposit insurer is the least risk averase agent in the economy. We establish this formally {{in the context of an}} insurance scheme in which privately informed depository institutions are offered deposit insurance premia contingent on reported capital; the result holds for alternative sorting instruments as well. This suggests a contradiction between deregulation and fairly priced, <b>risk-sensitive</b> deposit insurance. ...|$|E
40|$|We {{consider}} a <b>risk-sensitive</b> optimal control problem for hidden Markov models (HMM), i. e. controlled Markov chains where state information is only {{available to the}} controller via an output (message) process. Building upon recent results by Baras, James and Elliott, we report in this paper result of an investigation on the nature and structure of <b>risk-sensitive</b> controllers. The question we pose is: How does risk-sensitivity manifest itself {{in the structure of}} a controller? We present the dynamic programming equations for <b>risk-sensitive</b> control of HMMs and show a number of structural properties of the value function (e. g., concavity and piecewise linearity) and the optimal <b>risk-sensitive</b> controller, and compare these to the corresponding results for the risk- neutral case. Furthermore, we show that indeed the <b>risk-sensitive</b> controller and its corresponding information state converge to the known solutions for the risk-neutral situation, as the risk factor goes to zero. We also study the infinite and general risk aversion cases. In addition, we present a particular case study of a popular benchmark machine replacement problem...|$|E
40|$|A linear {{function}} approximation based reinforcement learning {{algorithm is proposed}} for Markov decision pro-cesses with infinite horizon <b>risk-sensitive</b> cost. Its convergence is proved using the ‘o. d. e. method ’ for stochastic approximation. The scheme is also extended to continuous state space processes. Key words: learning algorithm; <b>risk-sensitive</b> cost; function approximation; stochastic approximatio...|$|E
40|$|In {{this paper}} we use an information-state {{approach}} {{to obtain the}} solution to the linear <b>risk-sensitive</b> quadratic Gaussian control problem. With these methods the solution is obtained without appealing to a certainty equivalence principle. Specifically we consider the case of tracking a desired trajectory. The result gives some insight to more general information-state methods for nonlinear systems. Limit results are presented which demonstrate the link to standard linear quadratic Gaussian control. Also, a risksensitive filtering result is presentedwhich shows the relationship between tracking and filtering problems. Finally, simulation studies are presented to indicate some advantages gained via a <b>risk-sensitive</b> control approach. Keywords : <b>Risk-Sensitive</b> Control, LQG Control, Tracking 1 Introduction Recently there has been much interest in <b>risk-sensitive</b> control techniques. Such control policies lead to an optimal solution for which the controller's sensitivity to risk can be varied [...] . ...|$|E
40|$|This {{contribution}} {{is devoted to}} the <b>risk-sensitive</b> optimality criteria in finite state Markov Decision Processes. At first, we rederive necessary and sufficient conditions for average optimality of (classical) risk-neutral unichain models. This approach is then extended to the <b>risk-sensitive</b> case, i. e., when expectation of the stream of one-stage costs (or rewards) generated by a Markov chain is evaluated by an exponential utility function. We restrict ourselves on irreducible or unichain Markov models where <b>risk-sensitive</b> average optimality is independent of the starting state. As we show this problem is closely related to solution of (nonlinear) Poissonian equations and their connections with nonnegative matrices...|$|E
40|$|The authors analyze <b>risk-sensitive,</b> incentive-compatible deposit {{insurance}} {{in the presence}} of private information and moral hazard. Without deposit-linked subsidies, it is impossible to implement <b>risk-sensitive,</b> incentive-compatible {{deposit insurance}} pricing in a competitive, deregulated environment except when the deposit insurer is the least risk averse agent in the economy. The authors establish this formally {{in the context of an}} insurance scheme in which privately informed depository institutions are offered deposit insurance premia contingent on reported capital; the result holds for alternative sorting instruments as well. This suggests a contradiction between deregulation and fairly priced, <b>risk-sensitive</b> deposit insurance. Copyright 1992 by American Finance Association. ...|$|E
30|$|Ensure <b>risk-sensitive</b> {{investments}} through enhanced role of {{the science}} and technology community.|$|E
40|$|We {{deal with}} the <b>risk-sensitive</b> control, zero-sum and nonzero-sum game {{problems}} of stochastic functional differential equations. Using backward stochastic differential equations we show {{the existence of an}} optimal control and, a saddle-point and an equilibrium point for respectively the zero-sum and nonzero-sum games. Backward SDEs <b>Risk-sensitive</b> control Zero-sum game Nonzero-sum game Optimal control Saddle point Equilibrium point...|$|E
40|$|In this article, {{we study}} <b>risk-sensitive</b> control problem with {{controlled}} continuous time Markov chain state dynamics. Using multiplicative dynamic programming principle {{along with the}} atomic structure of the state dynamics, we prove the existence and a characterization of optimal <b>risk-sensitive</b> control under geometric ergodicity of the state dynamics along with a smallness condition on the running cost...|$|E
40|$|We uncover {{relations}} between robust MDPs and <b>risk-sensitive</b> MDPs. The objective of a robust MDP is to minimize a function, {{such as the}} expectation of cumulative cost, for the worst case when the parameters have uncertainties. The objective of a <b>risk-sensitive</b> MDP is to minimize a risk measure of the cumulative cost when the parameters are known. We show that a <b>risk-sensitive</b> MDP of minimizing the expected exponential utility is equivalent to a robust MDP of minimizing the worst-case expectation with a penalty for the deviation of the uncertain parameters from their nominal values, which is measured with the Kullback-Leibler divergence. We also show that a <b>risk-sensitive</b> MDP of minimizing an iterated risk measure that is composed of certain coherent risk measures is equivalent to a robust MDP of minimizing the worst-case expectation when the possible deviations of uncertain parameters from their nominal values are characterized with a concave function. ...|$|E
40|$|In this paper, {{we propose}} a <b>risk-sensitive</b> {{approach}} to parameter estimation for hidden Markov models (HMMs). The parameter estimation approach considered exploits estimation of various {{functions of the}} state, based on model estimates. We propose certain practical suboptimal <b>risk-sensitive</b> filters to estimate the various functions of the state during transients, rather than optimal risk-neutral filters as in earlier studies. The estimates are asymptotically optimal, if asymptotically risk neutral, and can give significantly improved transient performance, {{which is a very}} desirable objective for certain engineering applications. To demonstrate the improvement in estimation simulation studies are presented that compare parameter estimation based on <b>risk-sensitive</b> filters with estimation based on risk-neutral filters...|$|E
40|$|In {{this paper}} we {{formulate}} a <b>risk-sensitive</b> optimal control problem for continuously monitored open quantum systems modelled by quantum Langevin equations. The optimal controller {{is expressed in}} terms of a modified conditional state, which we call a <b>risk-sensitive</b> state, that represents measurement knowledge tempered by the control purpose. One of the two components of the optimal controller is dynamic, a filter that computes the <b>risk-sensitive</b> state. The second component is an optimal control feedback function that is found by solving the dynamic programming equation. The optimal controller can be implemented using classical electronics. The ideas are illustrated using an example of feedback control of a two-level atom...|$|E
40|$|The 'value' of {{infinite}} horizon <b>risk-sensitive</b> control {{is the principal}} eigenvalue of a certain positive operator. For the case of compact domain, Chang has built upon a nonlinear version of the Krein-Rutman theorem to give a 'min-max' characterization of this eigenvalue which {{may be viewed as}} a generalization of the classical Collatz-Wielandt formula for the Perron-Frobenius eigenvalue of a nonnegative irreducible matrix. We apply this formula to the Nisio semigroup associated with <b>risk-sensitive</b> control and derive a variational characterization of the optimal <b>risk-sensitive</b> cost. For the linear, i. e., uncontrolled case, this is seen to reduce to the celebrated Donsker-Varadhan formula for principal eigenvalue of a second-order elliptic operator...|$|E
40|$|The policy {{gradients}} of {{the expected}} return objective can react slowly to rare rewards. Yet, in some cases agents may wish to emphasize the low or high returns regardless of their probability. Borrowing from the economics and control literature, we review the <b>risk-sensitive</b> value function that arises from an exponential utility and illustrate its effects on an example. This <b>risk-sensitive</b> value function is not always applicable to reinforcement learning problems, so we introduce the particle value function defined by a particle filter over the distributions of an agent's experience, which bounds the <b>risk-sensitive</b> one. We illustrate {{the benefit of the}} policy gradients of this objective in Cliffworld...|$|E
40|$|A <b>risk-sensitive</b> {{generalization}} of the Maximum A Posterior Probability (MAP) estimationfor partially observed Markov chains is presented. Using {{a change of}} measure technique,a cascade filtering scheme for the risk-sensitivestate estimation is introduced. Structural results,the influence {{of the availability of}} information, mixing and non-mixingdynamics, and the connection with other <b>risk-sensitive</b> estimation methodsare considered. A qualitative analysis of the samplepaths clarifies the underlying mechanism...|$|E
40|$|Abstract. We {{extend the}} duality between {{exponential}} integrals and relative entropy to a variational formula for exponential integrals involving the Rényi divergence. This formula characterizes {{the dependence of}} <b>risk-sensitive</b> functionals to perturbations in the underlying distribution. It also shows that perturbations of related quantities determined by tail behavior, such as probabilities of rare events, can be bounded {{in terms of the}} Rényi divergence. The characterization gives rise to tight upper and lower bounds that are meaningful for all values of a large deviation scaling parameter, allowing one to quantify in explicit terms the robustness of <b>risk-sensitive</b> costs. As applications we consider problems of uncertainty quantification when aspects of the model are not fully known, as well their use in bounding tail properties of an intractable model in terms of a tractable one. Key words. Rényi divergence, <b>risk-sensitive</b> cost, rare events, large deviation, Laplace principle, robust bounds, <b>risk-sensitive</b> functional comparison bounds, logarithmic probability comparison bound...|$|E
40|$|In this {{technical}} note, we {{revisit the}} <b>risk-sensitive</b> optimal control problem for Markov jump linear systems (MJLSs). We first demonstrate the inherent difficulty {{in solving the}} <b>risk-sensitive</b> optimal control problem even if the system is linear and the cost function is quadratic. This {{is due to the}} nonlinear nature of the coupled set of Hamilton-Jacobi-Bellman (HJB) equations, stemming from the presence of the jump process. It thus follows that the standard quadratic form of the value function with a set of coupled Riccati differential equations cannot be a candidate solution to the coupled HJB equations. We subsequently show that there is no equivalence relationship between the problems of <b>risk-sensitive</b> control and H∞ control of MJLSs, which are shown to be equivalent {{in the absence of any}} jumps. Finally, we show that there does not exist a large deviation limit as well as a risk-neutral limit of the <b>risk-sensitive</b> optimal control problem due to the presence of a nonlinear coupling term in the HJB equations. clos...|$|E
40|$|Abstract. We {{discuss a}} class of <b>risk-sensitive</b> {{portfolio}} optimization problems. We consider the portfolio optimization model investigated by Nagai in 2003. The model by its nature can include fixed income securities {{as well in the}} portfolio. Under fairly general conditions, we prove the existence of optimal portfolio in both finite and infinite horizon problems. Key words. <b>Risk-sensitive</b> control, fixed income securities, non stationary optimal strategies...|$|E
40|$|The {{purpose of}} this paper is to {{describe}} some recent results concerning optimal feedback control of quantum systems using <b>risk-sensitive</b> performance criteria. We employ quantum stochastic models to describe an important class of quantum systems and define a <b>risk-sensitive</b> criterion for these models. A suitable information state is introduced to solve the optimal control problem using dynamic programming. The results are illustrated by examples...|$|E
