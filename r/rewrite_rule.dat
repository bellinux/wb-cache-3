262|2223|Public
5000|$|Not all XPs contain X&prime;s with adjuncts, so this <b>rewrite</b> <b>rule</b> is [...] "optional".|$|E
5000|$|Changes to ASTs can be {{accomplished}} by both procedural methods coded in PARLANSE and source-to-source tree transformations coded as rewrite rules using surface-syntax conditioned by any extracted program facts, using DMS's Rule Specification Language (RSL). The <b>rewrite</b> <b>rule</b> engine supporting RSL handles associative and commutative rules. A <b>rewrite</b> <b>rule</b> for C to replace a complex condition by the [...] operator be written as: ...|$|E
5000|$|... #Caption: Example for graph <b>rewrite</b> <b>rule</b> (optimization from {{compiler}} construction: multiplication with 2 {{replaced by}} addition) ...|$|E
40|$|In the {{rule-based}} equivalent transformation (RBET) paradigm, where computation {{is based}} on meaning-preserving transformation of declarative descriptions, a set of <b>rewriting</b> <b>rules</b> {{is regarded as a}} program. The syntax for a large class of <b>rewriting</b> <b>rules</b> is determined. The incorporation of meta-variables of two different kinds enables precise control of rewriting-rule instantiations. As a result, the applicability of <b>rewriting</b> <b>rules</b> and the results of rule applications can be rigorously specified. A theoretical basis for justifying the correctness of <b>rewriting</b> <b>rules</b> is established. Reverse transformation operation in the RBET framework is discussed, and it is shown that a correct <b>rewriting</b> <b>rule</b> is reversible, i. e., a correct <b>rewriting</b> <b>rule</b> can in general be constructed by syntactically reversing another correct <b>rewriting</b> <b>rule...</b>|$|R
30|$|The {{creation}} of the set of <b>rewrite</b> <b>rules</b> is an essential step in the reduction algorithm. With the <b>rewrite</b> <b>rules,</b> the original graph {{can be obtained from}} the reduced graph. Therefore, <b>rewrite</b> <b>rules</b> guarantee no loss of information, and so the reduction process is reversible.|$|R
5000|$|This {{simplification}} {{is normally}} done through <b>rewriting</b> <b>rules.</b> There are several classes of <b>rewriting</b> <b>rules</b> {{that have to}} be considered. The simplest consists in the <b>rewriting</b> <b>rules</b> that always reduce the size of the expression, like [...] or [...] They are systematically applied in the computer algebra systems.|$|R
50|$|In music, a <b>rewrite</b> <b>rule</b> is a {{recursive}} generative grammar, {{which creates}} a chord progression from another.|$|E
5000|$|A beta {{reduction}} is {{an application of}} the following <b>rewrite</b> <b>rule</b> to a beta redex contained in a term : ...|$|E
5000|$|... #Caption: Pic.1: Schematic {{triangle}} {{diagram of}} {{application of a}} <b>rewrite</b> <b>rule</b> [...] at position [...] in a term, with matching substitution ...|$|E
40|$|Context-dependent <b>rewrite</b> <b>rules</b> {{are used}} {{in many areas of}} natural {{language}} and speech processing. Work in computational phonology has demonstrated that, given certain conditions, such <b>rewrite</b> <b>rules</b> can be represented as finite-state transducers (FSTs). We describe a new algorithm for compiling <b>rewrite</b> <b>rules</b> into FSTs. We show the algorithm to be simpler and more efficient than existing algorithms. Further, man...|$|R
40|$|Unfailing {{completion}} is {{a commonly}} used technique for equational reasoning. For equational problems with associative and commutative functions, unfailing completion often generates {{a large number}} of <b>rewrite</b> <b>rules.</b> By comparing it with a ground completion procedure, we show that many of the <b>rewrite</b> <b>rules</b> generated are redundant. A set of consistency constraints is formulated to detect redundant <b>rewrite</b> <b>rules.</b> We propose a new completion algorithm, consistent unfailing completion, in which only consistent <b>rewrite</b> <b>rules</b> are used for critical pair generation and rewriting. Our approach does not need to use flattened terms. Thus it avoids the double exponential worst case complexity of AC unification. It also allows the use of more flexible termination orderings. We present some sufficient conditions for detecting inconsistent <b>rewrite</b> <b>rules.</b> The proposed algorithm is implemented in PROLOG. ...|$|R
40|$|Program {{transformation}} {{through the}} repeated application of simple <b>rewrite</b> <b>rules</b> {{is conducive to}} formal verification. However, when dealing with complex program structures, situations arise where data needs to be moved between two or more structurally unrelated portions of a program. In these cases it becomes necessary to construct a set of first-order <b>rewrite</b> <b>rules</b> that share data. Sharing of data often requires the construction of intermediate values such as lists, accompanying lookup functions, and rule parameterization. This increases the complexity of <b>rewrite</b> <b>rules</b> and their verification. In this article we explore the use of higherorder <b>rewrite</b> <b>rules</b> as the mechanism for moving data throughout a program structure. The effectiveness of higher-order <b>rewrite</b> <b>rules</b> is demonstrated by showing {{how they can be}} used to perform field distribution within the Java class loader. ...|$|R
50|$|And {{so forth}} for higher numbers of non-terminals {{in the right}} hand side of the <b>rewrite</b> <b>rule.</b> In general, if there are m non-terminals in the right hand side of a <b>rewrite</b> <b>rule,</b> the stack is {{partitioned}} m ways and distributed amongst the new non-terminals. Notice {{that there is a}} special case where a partition is empty, which effectively makes the rule a LIG rule. The Distributed Index languages are therefore a superset of the Linearly Indexed languages.|$|E
5000|$|... {{the only}} {{critical}} pair is ⟨g(x,z), f(x,z)⟩. Both {{of these terms}} {{can be derived from}} the term f(g(x,y),z) by applying a single <b>rewrite</b> <b>rule.</b>|$|E
5000|$|... #Caption: Triangle {{diagram of}} {{narrowing}} step s ~› t at position p in term s, with unifying substitution σ (bottom row), using a <b>rewrite</b> <b>rule</b> [...] (top row) ...|$|E
5000|$|... is {{a finite}} {{relation}} from [...] to [...] such that [...] The members of [...] {{are called the}} (<b>rewrite)</b> <b>rules</b> or productions of the grammar. There are three kinds of <b>rewrite</b> <b>rules.</b> For , [...] and ...|$|R
5000|$|Some <b>rewriting</b> <b>rules</b> {{sometimes}} {{increase and}} sometimes decrease {{the size of}} the expressions to which they are applied. This is the case of distributivity or trigonometric identities. For example, the distributivity law allows rewriting [...] and [...] As {{there is no way to}} make a good general choice of applying or not such a <b>rewriting</b> <b>rule,</b> such rewritings are done only when explicitly asked for by the user. For the distributivity, the computer function that apply this <b>rewriting</b> <b>rule</b> is generally called [...] "expand". The reverse <b>rewriting</b> <b>rule,</b> called [...] "factor", requires a non-trivial algorithm, which is thus a key function in computer algebra systems (see Polynomial factorization).|$|R
40|$|This paper defines and {{presents}} {{a method of}} inheritance for structures that are defined by <b>rewrite</b> <b>rules.</b> This method is natural {{in the sense that}} it can be easily and cleanly implemented in <b>rewrite</b> <b>rules</b> themselves. This framework of inheritance is not that of classical Object-Oriented Programming. It is shown that this inheritance has particular application to structures implemented in <b>rewrite</b> <b>rules</b> and, more generally, to symbolic computation. The treatment is practical, and examples are presented in Mathematica for concreteness. 1 Introduction An algebraic specification is a way of describing an abstract data type in an implementation independent way. Throughout this paper, an implementation of an algebraic specification or an abstract structure in terms of a system of <b>rewrite</b> <b>rules</b> will be called a symbolic specification. So a symbolic specification is a set of <b>rewrite</b> <b>rules</b> describing how to manipulate symbols in keeping with some algebraic specification or abstract structure [...] ...|$|R
5000|$|For example, [...] is a <b>rewrite</b> <b>rule,</b> {{commonly}} used to establish a normal form {{with respect to the}} associativity of [...]That rule can be applied at the numerator in the term [...] with the matching substitution , see picture 2.Applying that substitution to the rule's right hand side yields the term , and replacing the numerator by that term yields , which is the result term of applying the rewrite rule.Altogether, applying the <b>rewrite</b> <b>rule</b> has achieved what is called [...] "applying the associativity law for [...] to [...] " [...] in elementary algebra.Alternatively, the rule could have been applied to the denominator of the original term, yielding [...]|$|E
50|$|Each rule now {{fits the}} {{definition}} of an IG, {{in which all the}} non-terminals in the right hand side of a <b>rewrite</b> <b>rule</b> receive a copy of the rewritten symbol's stack. The indexed grammars are therefore able to describe all the languages that linearly indexed grammars can describe.|$|E
50|$|If Knuth-Bendix {{does not}} succeed, it will either run forever, or fail when it {{encounters}} an unorientable equation (i.e. an equation that it cannot {{turn into a}} <b>rewrite</b> <b>rule).</b> The enhanced completion without failure will not fail on unorientable equations and provides a semi-decision procedure for the word problem.|$|E
40|$|Planning by Rewriting (PbR) {{is a new}} {{paradigm}} for efficient high-quality planning that exploits plan <b>rewriting</b> <b>rules</b> and e#cient local search techniques to transform an easy-to-generate, but possibly suboptimal, initial plan into a high-quality plan. Despite the advantages of PbR in terms of scalability, plan quality, and anytime behavior, PbR requires the user to define a set of domain-specific plan <b>rewriting</b> <b>rules</b> which can be di#cult and time-consuming. This paper presents an approach to automatically learning the plan <b>rewriting</b> <b>rules</b> based on comparing initial and optimal plans. We report results for several planning domains showing that the learned rules are competitive with manually-specified ones, and in several cases the learning algorithm discovered novel <b>rewriting</b> <b>rules...</b>|$|R
40|$|Abstract. Deduction modulo is a {{framework}} in which theories are inte-grated into proof systems such as natural deduction or sequent calculus by presenting them using <b>rewriting</b> <b>rules.</b> When only terms are rewritten, cut admissibility in those systems {{is equivalent to the}} confluence of the rewriting system, as shown by Dowek, RTA 2003, LNCS 2706. This is no longer true when considering <b>rewriting</b> <b>rules</b> involving propositions. In this paper, we show that, {{in the same way that}} it is possible to recover confluence using Knuth-Bendix completion, one can regain cut admis-sibility in the general case using standard saturation techniques. This work relies on a view of proposition <b>rewriting</b> <b>rules</b> as oriented clauses, like term <b>rewriting</b> <b>rules</b> can be seen as oriented equations. This also leads us to introduce an extension of deduction modulo with conditional term <b>rewriting</b> <b>rules.</b> Whatever their origin, proofs rarely need to be search for without context: Program verification requires arithmetic, theories of lists or arrays, etc. Mathe...|$|R
3000|$|<b>Rewriting</b> <b>rules</b> simplify {{functions}} {{prior to}} their evaluation and speed up the search. <b>Rewriting</b> <b>rules</b> are rudimentary representations of DSP theorems. Unlike heuristics, they are not used by the genetic algorithm to favor combinations, but they do impact the search by [...]...|$|R
50|$|The {{formulation}} of the theorem is also given in a Lisp-like syntax: (prove-lemma commutativity-of-times (rewrite) (equal (times x z) (times z x)))Should the theorem prove to be true, it {{will be added to}} the knowledge basis of the system and {{can be used as a}} <b>rewrite</b> <b>rule</b> for future proofs.|$|E
5000|$|It is {{a family}} of {{declarative}} [...] "ultra high-level" [...] languages. It features abstract types, generic modules, subsorts (subtypes with multiple inheritance), pattern-matching modulo equations, E-strategies (user control over laziness), module expressions (for combining modules), theories and views (for describing module interfaces) for the massively parallel RRM (<b>rewrite</b> <b>rule</b> machine).|$|E
50|$|To {{make this}} rewrite theory {{a bit less}} morbid, we can alter some of our rewrite rules a bit, and make them {{conditional}} rewrite rules, which basically means they have to fulfill some criteria {{to be applied to}} the term (other than just matching the left hand side of the <b>rewrite</b> <b>rule).</b>|$|E
30|$|Axiomatizations {{can give}} rise to TRSs that are not weakly confluent, which can be {{remedied}} by Knuth–Bendix completion (Knuth and Bendix 1970). It determines overlaps in left hand sides of <b>rewrite</b> <b>rules,</b> and introduces extra <b>rewrite</b> <b>rules</b> to join the resulting right hand sides, which are called critical pairs.|$|R
40|$|Using finite-state automata for {{the text}} {{analysis}} component in a text-to-speech system is problematic in several respects: the <b>rewrite</b> <b>rules</b> {{from which the}} automata are compiled are difficult to write and maintain, and the resulting automata can become very large and therefore inefficient. Converting the knowledge represented explicitly in <b>rewrite</b> <b>rules</b> into a more efficient format is difficult. We take an indirect route, learning an efficient decision tree representation from data and tapping information contained in existing <b>rewrite</b> <b>rules,</b> which increases performance compared to learning exclusively from a pronunciation lexicon...|$|R
40|$|Relational OLAP {{tools and}} other {{database}} applications generate sequences of SQL statements that {{are sent to}} the database server as result of a single information request issued by a user. Coarse-Grained Optimization is a practical approach for the optimization of such statement sequences based on <b>rewrite</b> <b>rules.</b> In this demonstration we present the CHICAGO test and evaluation environment that allows to assess the effectiveness of <b>rewrite</b> <b>rules</b> and control strategies. It includes a lightweight heuristic optimizer that modifies a given statement sequence using a small and variable set of <b>rewrite</b> <b>rules.</b> 1...|$|R
5000|$|The basic rewrite {{operation}} of an LMG {{is very similar}} to that of a CFG, with the addition of [...] "arguments" [...] to the non-terminal symbols. Where a context-free <b>rewrite</b> <b>rule</b> obeys the general schema [...] for some non-terminal [...] and some string of terminals and/or non-terminals , an LMG <b>rewrite</b> <b>rule</b> obeys the general schema , where X is a non-terminal with arity n (called a predicate in LMG terminology), and [...] is a string of [...] "items", as defined below. The arguments [...] are strings of terminal symbols and/or variable symbols defining an argument pattern. In the case where an argument pattern has multiple adjacent variable symbols, the argument pattern will match any and all partitions of the actual value that unify. Thus, if the predicate is [...] and the actual pattern is , there are three valid matches: [...] In this way, a single rule is actually a family of alternatives.|$|E
50|$|In {{mathematical}} logic, {{a critical}} pair arises in term rewriting systems where rewrite rules overlap to yield two different terms. In more detail, (t1, t2) {{is a critical}} pair {{if there is a}} term t for which two different applications of a <b>rewrite</b> <b>rule</b> (either the same rule applied differently, or two different rules) yield the terms t1 and t2.|$|E
5000|$|... where f is any index symbol, [...] is any {{string of}} {{terminals}} and/or non-terminal symbols, and x is a terminal is a terminal symbol. Because occasionally a <b>rewrite</b> <b>rule</b> {{might need to}} be conditioned on the stack being in some sense empty, the symbol # is used as the bottom-most stack symbol, meaning an [...] "empty" [...] stack contains exactly one symbol, #.|$|E
40|$|Program {{transformation}} {{through the}} repeated application of simple <b>rewrite</b> <b>rules</b> {{is conducive to}} formal verification. In practice, program transformation oftentimes requires data to be moved throughout the program structure. This ar-ticle explores the use of higher-order <b>rewrite</b> <b>rules</b> as the mechanism for accomplishing such data movement. The effectiveness of higher-order <b>rewrite</b> <b>rules</b> is demonstrated by showing {{how they can be}} used to perform field distri-bution within a Java class loader. An approach to formal verification of a higher-order strategic implementation of a class loader is also briefly discussed...|$|R
40|$|International audienceThis paper {{provides}} a new {{presentation of the}} λΠ-calculus modulo where the addition of <b>rewrite</b> <b>rules</b> is made explicit. The λΠ-calculus modulo is {{a variant of the}} λ-calculus with dependent types where β-reduction is extended with user-defined <b>rewrite</b> <b>rules.</b> Its expressiveness makes it suitable to serve as an output language for theorem provers, certified development tools or proof assistants. Addition of <b>rewrite</b> <b>rules</b> becomes an iterative process and rules previously added can be used to type new rules. We also discuss the condition <b>rewrite</b> <b>rules</b> must satisfy in order to preserve the Subject Reduction property and we give a criterion weaker than the usual one. Finally we describe the new version of Dedukti, a type-checker for the λΠ-calculus modulo for which we assess its efficiency in comparison with Coq, Twelf and Maude...|$|R
40|$|AbstractSynchronization {{expressions}} {{are high}} level constructs used for specifying minimal synchronization constraints of parallel processes. Their semantics {{is defined by}} the corresponding synchronization language. The original definition of synchronization expressions [12, 13] forces the languages to be closed under <b>rewriting</b> <b>rules</b> that, for instance, do not preserve regularity. Here we propose an extension of the syntactic definition of synchronization expressions, and an appropriate modification of their semantics. The extended definition has the advantage that it allows us to eliminate the less well motivated transformations (<b>rewriting</b> <b>rules)</b> describing properties of synchronization languages. We show that the modified <b>rewriting</b> <b>rules</b> preserve regularity of the languages. Also, we obtain a characterization of finite synchronization languages as the family consisting of languages satisfying the start-termination property and closed under three types of simple <b>rewriting</b> <b>rules...</b>|$|R
