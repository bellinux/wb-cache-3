169|1232|Public
5000|$|The master {{observes the}} <b>round-trip</b> <b>time</b> (<b>RTT)</b> of the {{messages}} and estimates the time of each slave and its own.|$|E
50|$|End-to-end {{delay or}} one-way delay (OWD) {{refers to the}} time taken for a packet to be {{transmitted}} across a network from source to destination. It is a common term in IP network monitoring, and differs from <b>round-trip</b> <b>time</b> (<b>RTT).</b>|$|E
50|$|In telecommunications, the {{round-trip delay}} time (RTD) or <b>round-trip</b> <b>time</b> (<b>RTT)</b> is {{the length of}} time it takes for a signal to be sent plus {{the length of time}} it takes for an {{acknowledgment}} of that signal to be received. This time delay therefore consists of the propagation times between the two points of a signal.|$|E
30|$|Actually, {{many options}} can be {{proposed}} {{to implement the}} discovery of a CMP and the assignment of a DHoA. In this article, we assume the connection initiation process of ADA in BT mode will take two <b>Round-Trip</b> <b>Times</b> (<b>RTTs)</b> between the MN and the CMP.|$|R
30|$|The major {{disadvantage}} of CF-SIP is the long processing time. It involves exchanging six messages: BOOTP REQUEST, BOOTP REPLY, DHCP DISCOVERY, DHCP OFFER, DHCP REQUEST, and DHCP ACK. Thus, three <b>round-trip</b> <b>times</b> (<b>RTTs)</b> are required. Long processing time may preclude the MN from successfully obtaining an IP address before disconnect from the serving AP.|$|R
40|$|Abstract. We propose {{two methods}} to passively measure and monitor changes in <b>round-trip</b> <b>times</b> (<b>RTTs)</b> {{throughout}} {{the lifetime of}} a TCP connection. Our first method associates data segments with the acknowledgments (ACKs) that trigger them by leveraging the TCP timestamp option. Our second method infers TCP RTT by observing the repeating patterns of segment clusters where the pattern is caused by TCP selfclocking. We evaluate the two methods using both emulated and real Internet tests. ...|$|R
50|$|The {{maximum speed}} of a GPRS {{connection}} offered in 2003 was similar to a modem connection in an analog wire telephone network, about 32-40 kbit/s, depending on the phone used. Latency is very high; <b>round-trip</b> <b>time</b> (<b>RTT)</b> is typically about 600-700 ms and often reaches 1s. GPRS is typically prioritized lower than speech, and thus the quality of connection varies greatly.|$|E
50|$|Cristian's {{algorithm}} (introduced by Flaviu Cristian in 1989) is {{a method}} for clock synchronization {{which can be used}} in many fields of distributive computer science but is primarily used in low-latency intranets. Cristian observed that this simple algorithm is probabilistic, in that it only achieves synchronization if the <b>round-trip</b> <b>time</b> (<b>RTT)</b> of the request is short compared to required accuracy. It also suffers in implementations using a single server, making it unsuitable for many distributive applications where redundancy may be crucial.|$|E
50|$|TCP Vegas detects {{congestion}} at an incipient stage {{based on}} increasing <b>Round-Trip</b> <b>Time</b> (<b>RTT)</b> {{values of the}} packets in the connection unlike other flavors such as Reno, New Reno, etc., which detect congestion only after it has actually happened via packet loss. The algorithm depends heavily on accurate calculation of the Base RTT value. If it is too small then throughput of the connection will be less than the bandwidth available while if the value is too large then it will overrun the connection.|$|E
30|$|Choi et al. {{proposed}} a Wormhole Attack Prevention (WAP) algorithm which measured the <b>round-trip</b> <b>time</b> (<b>RTTs)</b> between neighbors, identifying that two neighbors {{which are not}} within each other’s communication range {{are supposed to be}} suffering from wormhole attack [14]. But, WAP algorithm could only be suitable for wireless sensor network applications with a lot of nodes. WAP algorithm could not detect false positive alarm while affected nodes only have few neighbor nodes due to lack of enough neighbor nodes’ information.|$|R
40|$|Current {{congestion}} control approaches {{that attempt to}} provide fair bandwidth allocation among competing ows primarily consider only data rate when making decisions on which packets to drop. However, responsive ows with high <b>round-trip</b> <b>times</b> (<b>RTTs)</b> can still receive significantly less bandwidth than responsive ows with low <b>round-trip</b> <b>times.</b> Better bandwidth fairness control can avoid expensive Content Distribution Network deployment cost because CDNs provide improved, uniform performance to all clients regardless of proximity and can improve utilization in same circumstances. This paper proposes an enhancement to AQM schemes called FIFA that addresses router unfairness in handling ows with significantly different RTTs. Usin...|$|R
40|$|Abstract — Knowledge about {{properties}} of network traffic can be beneficial when studying network protocols. It enables realistic models of network traffic {{to be created}} and evaluations of current protocols to take place. This study examines trends in <b>round-trip</b> <b>times</b> (<b>RTTs)</b> at a university Web server. <b>Round-trip</b> <b>time</b> is a particularly important characteristic of transport layer Internet traffic to measure because it impacts the throughput of TCP. In addition to examining trends of RTTs, this paper examines the relationship between <b>RTT</b> and the <b>time</b> between the SYNACK and ACK packets. The relationship between this heuristic for estimating RTT and actual measured RTTs is relevant for protocols such as TCP Vegas that need to estimate RTT early in a connection. Keywords: <b>Round-Trip</b> <b>Times,</b> TCP, Congestion Control I...|$|R
50|$|For an Internet packet, that {{delay is}} doubled before a reply is received. That is the {{theoretical}} minimum. Factoring in other normal delays from network sources gives a typical one-way connection latency of 500-700 ms from {{the user to}} the ISP, or about 1,000-1,400 ms latency for the total <b>round-trip</b> <b>time</b> (<b>RTT)</b> back to the user. This is more than most dial-up users experience at typically 150-200 ms total latency, and {{much higher than the}} typical 15-40 ms latency experienced by users of other high-speed Internet services, such as cable or VDSL.|$|E
50|$|High {{performance}} {{networks have}} very large BDPs. To give a practical example, two nodes communicating over a geostationary satellite link with a round-trip delay time (or <b>round-trip</b> <b>time,</b> <b>RTT)</b> of 0.5 seconds and a bandwidth of 10 Gbit/s can {{have up to}} 0.5&times;1010 bits, i.e., 5 Gbit = 625 MB of unacknowledged data in flight. Despite having much lower latencies than satellite links, even terrestrial fiber links can have very high BDPs because their link capacity is so large. Operating systems and protocols designed as recently as {{a few years ago}} when networks were slower were tuned for BDPs of orders of magnitude smaller, with implications for limited achievable performance.|$|E
50|$|To avoid {{congestive}} collapse, TCP uses a multi-faceted congestion-control strategy. For each connection, TCP {{maintains a}} congestion window, limiting {{the total number}} of unacknowledged packets that may be in transit end-to-end. This is somewhat analogous to TCP's sliding window used for flow control. TCP uses a mechanism called slow start to increase the congestion window after a connection is initialized or after a timeout. It starts with a window of two times the maximum segment size (MSS). Although the initial rate is low, the rate of increase is very rapid; for every packet acknowledged, the congestion window increases by 1 MSS so that the congestion window effectively doubles for every <b>round-trip</b> <b>time</b> (<b>RTT).</b>|$|E
40|$|This memo defines an Experimental Protocol for the Internet community. It {{does not}} specify an Internet {{standard}} of any kind. Discussion {{and suggestions for}} improvement are requested. Distribution of this memo is unlimited. IESG Note This RFC is not a candidate for any level of Internet Standard. It represents the consensus of the Delay Tolerant Networking (DTN) Research Group of the Internet Research Task Force (IRTF). See RFC 3932 for more information. This document describes the motivation {{for the development of}} the Licklider Transmission Protocol (LTP) designed to provide retransmission-based reliability over links characterized by extremely long message <b>round-trip</b> <b>times</b> (<b>RTTs)</b> and/or frequent interruptions in connectivity. Since communication acros...|$|R
40|$|Multihoming is {{increasingly}} being employed by large enterprises and data centers to extract good performance and reliability from their ISP connections. Multihomed end networks today can employ {{a variety of}} route control products to optimize their Internet access performance and reliability. However, {{little is known about}} the tangible benefits that such products can offer, the mechanisms they employ and their trade-offs. This paper makes two important contributions. First, we present a study of the potential improvements in Internet <b>round-trip</b> <b>times</b> (<b>RTTs)</b> and transfer speeds from employing multihoming route control. Our analysis shows that multihoming to three or more ISPs and cleverly scheduling traffic across the ISPs can improve Internet RTTs and throughputs by up to 25...|$|R
40|$|In this paper, {{we address}} the problem of {{determining}} whether a bottleneck router on a given network path is using an AQM or a drop-tail scheme. We assume that we are given a source-to-sink path of interest -along which a bottleneck router exists- and data regarding the <b>Round-Trip</b> <b>Times</b> (<b>RTT)</b> and Congestion Window (CWND) sizes with respect to this flow. We develop a reliable classification algorithm that solely uses RTT and CWND information pertaining to a single flow to classify the queuing scheme, Tail Drop or AQM, used by the bottleneck router. We evaluate our method and present results that demonstrate our algorithm's highly accurate classification ability across a wide array of complex network topologies and configurations...|$|R
5000|$|The minimum-pairs (or MP) is {{an active}} {{measurement}} protocol to estimate in real-time the smaller of the forward and reverse one-way network delays (OWDs). [...] It is designed to work in hostile environments, where a set of three network nodes can estimate an upper-bound OWDs between themselves and a fourth untrusted node. All four nodes must cooperate, though honest cooperation from the fourth node is not required. The objective is to conduct such estimates without involving the untrusted nodes in clock synchronization, and in a manner more accurate than simply half the <b>Round-Trip</b> <b>Time</b> (<b>RTT).</b> The MP protocol {{can be used in}} delay-sensitive applications (such as placing CDN replicas) or for secure Internet geolocation.|$|E
50|$|In {{recent years}} {{several types of}} traffic behavior, that can have {{significant}} impact on network performance, were discovered: long-range dependence, self-similarity and, more recently, multifractality.There are two major parameters generated by network traffic models: packet length distributions and packet inter-arrival distributions. Other parameters, such as routes, distribution of destinations, etc., are of less importance. Simulations that use traces generated by network traffic models usually examine a single node in the network, such as a router or switch; factors that depend on specific network topologies or routing information are specific to those topologies and simulations. The problem of packet size distribution is fairly well-understood today. Existing models of packet sizes {{have proven to be}} valid and simple. Most packet size models do not consider the problem of order in packet sizes. For example, a TCP datagram in one direction is likely to be followed by a tiny ACK in the other direction about half of one <b>Round-Trip</b> <b>Time</b> (<b>RTT)</b> later. The problem of packet inter-arrival distribution is much more difficult. Understanding of network traffic has evolved significantly over the years, leading to a series of evolutions in network traffic models.|$|E
30|$|In general, TCP {{faces the}} {{following}} problems: {{the effect of}} the <b>round-trip</b> <b>time</b> (<b>RTT)</b> and ACK, misjudgment on non-congestive losses, and slow reaction to congestion. This section discusses the necessity of decoupling congestion control from TCP in multi-hop wireless networks.|$|E
50|$|In {{computer}} networking, delay-gradient {{congestion control}} {{refers to a}} class of congestion control algorithms, which react to the differences in <b>round-trip</b> delay <b>time</b> (<b>RTT),</b> as opposed to classical congestion control methods, which react to packet loss or an RTT threshold being exceeded. Such algorithms include CAIA Delay-Gradient (CDG) and TIMELY.|$|R
40|$|In {{this study}} ICMP (Internet Control Message Protocol) packets were sent {{at high speed}} {{for a short period}} by the ping utility to various Internet {{addresses}} and their <b>round-trip</b> <b>times</b> (<b>RTTs)</b> were measured by ping and the tcpdump utility. The study has two purposes: to evaluate the accuracy of ping and tcpdump in terms of measuring packet wire <b>round-trip</b> <b>times</b> (WRTTs); and to identify short term high density ping traffic patterns and interpret them. A careful comparison was done of different software and hardware configurations for measuring the WRTTs, as well as the repeatability of measurements on similar configurations. The results show that ping's own RTT measurements can contain significant source processing delay and so distort the analysis of traffic patterns; running tcpdump to capture the packet wire times increases the accuracy of WRTT measurement; running tcpdump on separate measurement machines in single-user mode with output to the RAM disks can generate consistent WRTT measurements [...] . ...|$|R
40|$|Long network latency {{negatively}} impacts {{the performance}} of online multiplayer games. In this thesis, we propose a novel approach to reduce the network latency in online gaming. Our approach employs application level detour routing in which game-state update messages between two players can be forwarded through other intermediate relay nodes {{in order to reduce}} network latency. We present results from an extensive measurement study to show the potential benefits of detour routing in online games. We also present the design of a complete system to achieve the potential, which is called Indirect Relay System (IRS). The experimental and simulation results show that IRS: (i) significantly reduces end-to- end <b>round-trip</b> <b>times</b> (<b>RTTs)</b> among players, (ii) increases number of peers a player can connect to and maintain good gaming quality, (iii) imposes negligible network and processing overheads, and (iv) improves gaming quality and player performance...|$|R
30|$|The agents record {{measurements}} of physical properties such as pressure and temperature. In addition, the agents perform <b>round-trip</b> <b>time</b> (<b>RTT)</b> measurements to facilitate distance estimates to neighboring agents. Because of the strict energy limitations, {{there is no}} forwarding or transmission of any data aside from the RTT measurements.|$|E
40|$|Internet-Draft, ICN Research Group, draft-asaeda-icnrg-contrace- 01 This {{document}} {{describes the}} traceroute facility for Content-Centric Network (CCN), named "Contrace". Contrace investigates: 1) the forwarding path information per name prefix, device name, and function/application, 2) the <b>Round-Trip</b> <b>Time</b> (<b>RTT)</b> between content forwarder and consumer, and 3) {{the states of}} in-network cache per name prefix...|$|E
30|$|By {{evaluating}} the upper layer performance of deployed wireless networks, the variation of wireless link quality along a realistic HSR {{line can be}} revealed. In this context, the upper layer is considered as Internet Protocol (IP) layer of protocol stack, whose performance are normally evaluated by parameters of packet loss rate (PLR), <b>round-trip</b> <b>time</b> (<b>RTT).</b>|$|E
40|$|Abstract—Computer-centered {{services}} and broadband wire-less connectivity are enabling {{the delivery of}} multimedia-based entertainment from the Internet to in-house wireless devices and appliances. In this context, rich-media applications can be supported by different protocols that must share the same channel without affecting each other performances. Instead, with current systems, real-time applications (e. g., video stream-ing, online games) suffer from delays caused by the interference with elastic (e. g., TCP-based downloading sessions) ones. In ad-dition, elastic applications may also unfairly damage each other when featured with different <b>round-trip</b> <b>times</b> (<b>RTTs)</b> between clients and servers, even if sharing the same bottleneck. In this article we provide insight on these problems and show how a solution based on a smart access point may actually solve them, allowing a fair coexistence between heterogeneous flows, even when featured with different transport protocols and different RTTs...|$|R
40|$|Measuring network path {{capacity}} {{is an important}} capability to many Internet applications. But despite over ten years of effort, the capacity measurement problem {{is far from being}} completely solved. This paper addresses the problem of measuring network paths of asymmetric capacity without requiring the remote node’s control or overwhelming the bottleneck link. We first show through analysis and measurement that the current packet-dispersion methods, due to the packet size limitations, can only measure up to a certain degree of capacity asymmetry. Second, we propose TRIO that removes the limitation by using <b>round-trip</b> <b>times</b> (<b>RTTs).</b> TRIO cleverly exploits two types of probes to obtain three minimum RTTs to compute both forward and reverse capacities, and another minimum RTT for measurement validation. We validate TRIO’s accuracy and versatility on a testbed and the Internet, and develop a system to measure path capacity from the server or user side...|$|R
40|$|Existing {{approaches}} for multirate multicast congestion control are either friendly to TCP only over large time scales or introduce unfortunate side eects, such as signi cant control trac, wasted bandwidth, or {{the need for}} modi cations to existing routers. We advocate a layered multicast approach in which steady-state receiver reception rates emulate the classical TCP sawtooth derived from additive-increase, multiplicative decrease (AIMD) principles. Our approach introduces the concept of dynamic stair layers to simulate various rates of additive increase for receivers with heterogeneous <b>round-trip</b> <b>times</b> (<b>RTTs),</b> facilitated by a minimal amount of IGMP control trac. We employ a mix of cumulative and non-cumulative layering to minimize the amount of excess bandwidth consumed by receivers operating asynchronously behind a shared bottleneck. We integrate these techniques together into a congestion control scheme called STAIR which is amenable to those multicast applications which can make eective use of arbitrary and time-varying subscription levels. ...|$|R
40|$|In current IP based network TCP {{protocol}} {{is widely}} used as general purpose reliable data transfer protocol. While TCP with standard Tahoe and Renoe congestion control was flaw-lessly working for either slow networks or for fast networks with small <b>round-trip</b> <b>time</b> (<b>RTT)</b> it faces it’s limits when applied to current long distance high speed networks with high RTT...|$|E
30|$|In this paper, {{we explore}} a novel {{approach}} to end-to-end <b>round-trip</b> <b>time</b> (<b>RTT)</b> estimation using a machine-learning technique known as the experts framework. In our proposal, each of several ‘experts’ guesses a fixed value. The weighted average of these guesses estimates the RTT, with the weights updated after every RTT measurement based on {{the difference between the}} estimated and actual RTT.|$|E
40|$|For {{interactive}} networked applications like web browsing, every <b>round-trip</b> <b>time</b> (<b>RTT)</b> matters. We introduce ASAP, a new naming {{and transport}} protocol that reduces latency by shortcutting DNS requests and eliminating TCP’s three-way handshake, while ensuring the key security property of verifiable provenance of client requests. ASAP eliminates {{between one and}} two RTTs, cutting the delay of small requests by up to two-thirds. 1...|$|E
50|$|For {{the highest}} {{possible}} throughput, {{it is important that}} the transmitter is not forced to stop sending by the sliding window protocol earlier than one <b>round-trip</b> delay <b>time</b> (<b>RTT).</b> The limit on the amount of data that it can send before stopping to wait for an acknowledgment should be larger than the bandwidth-delay product of the communications link. If it is not, the protocol will limit the effective bandwidth of the link.|$|R
40|$|A {{number of}} designs have been {{proposed}} for complementing TCP’s treatment of packet loss as an implicit signal of congestion, with a signal derived from measurements of <b>round-trip</b> <b>times</b> (<b>RTT).</b> The premise of such delay-based congestion estimators (DBCEs) is that congestion is reflected in queueing delays that can be detected by measuring changes in RTT. We conduct a large-scale empirical analysis of real-world TCP connections {{to evaluate the effectiveness}} and limitations of five prominent DBCEs. Our findings are that none of the five perform well (correctly indicate congestion before a loss is experienced) for a large percentage of real-world TCP connections. They also often perform poorly by having high rates of false-positive and false-negative estimates of congestion. Further, we find that the connection characteristics that most influence the performance of these DBCEs are so diverse that designing an effective DBCE for all types of connections is still an open research problem. 1...|$|R
40|$|IP {{networks}} are increasingly carrying mission-critical applications with robust end-to-end network performance and reliability requirements. Network performance monitoring forms {{an essential component}} of critical IP network management functions such as troubleshooting, anomaly detection, and Service-Level-Agreement (SLA) compliance monitoring. However, privacy and security considerations are fueling the use of IP-level encryption techniques such as IPsec, which obscure important transport layer features that existing performance measurement techniques need. New techniques are therefore needed for monitoring performance of encrypted traffic. Towards this goal, in this paper we present a new technique for monitoring <b>round-trip</b> <b>times</b> (<b>RTT)</b> for IP-level encrypted communications. Our approach involves using network-level features like packet size and inter-packet timing to infer specific timing events, and aggregating measurements across short time intervals and related connections to derive final RTT estimates for network paths of interest. Extensive evaluations using traces from an enterprise and a broadband access network, demonstrate that the resulting RTT estimates are quite accurate...|$|R
