21|59|Public
40|$|This paper {{reports the}} design, implementation, and {{performance}} of a scalable and efficient tool to replicate Internet information services. Our tool targets replication degrees {{of tens of thousands}} of weakly-consistent replicas scattered throughout the Internet’s thousands of autonomously administered domains. The main goal of our <b>replication</b> <b>tool</b> is to make existing replication algorithms scale in today’s exponentially-growing, autonomouslymanaged internetworks. 1...|$|E
40|$|Replication {{has become}} a central element in modern {{information}} systems playing a dual role: increase availability and enhance scalability. Unfortunately, most existing protocols increase availability {{at the cost of}} scalability. This paper presents architecture, implementation and performance of a middleware based <b>replication</b> <b>tool</b> that provides both availability and better scalability than existing systems. Main characteristics are the usage of specialized broadcast primitives and efficient data propagation...|$|E
40|$|UDDI {{registries}} {{are intended}} to become the world-wide lookup mechanism for web-services. As such, the registry has to provide high throughput, low response times, high availability, and access to accurate data. Replication {{is often used to}} satisfy such requirements. Various replication strategies exist, favoring different subsets of the above performance metrics. In this paper, we have a closer look at two very different replication strategies. One strategy follows the UDDI speci£cation, the second uses a middleware based <b>replication</b> <b>tool.</b> In this paper, we provide a comparison of these two approaches focusing on performance and ease of integration with an existing UDDI implementation...|$|E
5000|$|Third-party tools, {{including}} GUI administrative <b>tools</b> and <b>replication</b> <b>tools</b> ...|$|R
40|$|Demoulding {{parts from}} <b>replication</b> <b>tools</b> is a {{critical}} stage of replication processes such as injection moulding and hot embossing. This challenge increases as part size decreases since components and associated replication cores become more fragile and liable to damage. Understanding interfacial characteristics between a polymer and the tool surface is critical to optimise the demoulding of such parts from <b>replication</b> <b>tools.</b> The strength of the polymer-tool interaction is characterised by the adhesion energy and is specific for a particular polymer-tool pair. It’s magnitude depends upon the tool material, the chemical structure of the polymer, the processing conditions and the surface roughness. Interfacial characteristics {{of a variety of}} polymer-tool steel surfaces are being studied by measuring contact angles of polymer droplets on the surfaces to predict the work of adhesion. The experimental set-up, selection of test parameters and main challenges faced to date are described and preliminary experimental results presented. In addition a description of how these results may be used to predict the force needed to demould parts from <b>replication</b> <b>tools</b> is discussed...|$|R
40|$|Friction between <b>replication</b> <b>tools</b> and {{replicated}} parts {{determines the}} force required to demould the part {{and also the}} stresses which develop in both the tool and the part during the demoulding process. Standardized equipment and procedures have been developed which strive to improve the repeatability and reproducibility of friction tests. Specific test standards, describing sled-type tests, include JIS K 7125, ISO 8295 and ASTM D 1894. However these tests do not produce results which {{are representative of the}} conditions typically found within <b>replication</b> <b>tools</b> such as injection moulds or embossing tools. This paper reviews how this challenge has been addressed by other researchers and describes the development of an apparatus to measure friction under typical replication conditions. Experimental results for the thermal characterization of the device are reported...|$|R
40|$|The GDMP {{client-server}} {{software system}} is a generic file <b>replication</b> <b>tool</b> that replicates files securely and efficiently from one site to another in a Data Grid environment using Globus Grid tools. In addition, it manages replica catalogue entries for file replicas and thus maintains a consistent view on names and locations of replicated files. Files to be transferred can be of any particular file format and GDMP treats them {{all in the same}} way. However, for Objectivity database files a particular plug-in exists. All files are assumed to be read-only. 17 Refs. [...] - 3 [...] - A...|$|E
40|$|Parallel file {{replication}} where a {{large file}} {{needs to be}} simultaneously replicated to multiple sites {{is an integral part}} of dataintensive grid environment. Current data transport mechanisms such as GridFTP is mainly created for point-to-point file transfer and not for parallel point-to-multipoint transfer (required in replication). This paper presents a Fast Parallel File <b>Replication</b> <b>tool</b> (FPRF) that creates multiple distribution trees by pipelining point-to-point transfer (e. g. GridFTP sessions) and optimizes the file replication time to multiple sites. Performance results from simulations and network-level deployment of the tool in Internet show a significant speed up of up to five times using the proposed tool, as compared to using point-topoint GridFTP. 1...|$|E
40|$|Magda is a {{distributed}} {{data manager}} prototype for grid-resident data. It {{makes use of}} the MySQL open source relational database, Perl, Java and C++ to provide file cataloging, retrieval and replication services. For data movement, gridFTP, bbftp and scp can be chosen depending on available protocols. Third party transfers are supported. Magda currently catalogs 321 K files with total size of 85. 8 TB. It was successfully used in the Data Challenge 1 production for the Atlas experiment. It {{has been used to}} replicate more than 7 TB of data between BNL and CERN mass stores. We present here the design and implementation of Magda, and how it {{has been used as a}} file catalog and <b>replication</b> <b>tool.</b> 1...|$|E
40|$|Demoulding {{components}} without {{damage to}} either the components or tool is critical to successful <b>replication</b> processes. During <b>tooling</b> development designers strive to optimize <b>replication</b> <b>tools</b> to minimize demoulding force and resultant stress on replicated parts. A critical element {{of this process is}} an accurate demoulding force prediction model. Various models have been proposed to predict demoulding forces, each showing limitations in its applicability. This paper reviews existing demoulding force models and parameters affecting demoulding force for micro polymer replication...|$|R
40|$|Polymer {{replication}} technique enables for {{low cost}} devices {{even in the}} case of aspheric or irregular shaped surfaces, submicron or other challenging structures. The use of UV-reaction moulding on semiconductors, glass or other inorganic substrates as the replication technique leads to a high degree of stability and allows for the simultaneous integration of optoelectronics or ion exchanged GRIN elements. Thin polymer layers on inorganic substrates show high flatness and lower wavefront deviations with respect to all?polymer elements. They show low lateral shrinkage during the UV-polymerisation, and the lateral thermal expansion is determined by the substrate. Furthermore, sensitive substrates can be used because the process does not involve high mechanical stress or elevated temperatures. Original structures for the replication masters are fabricated by different resist technologies. Subsequently, they are proportionally transferred by dry etching (RIE) into glass or silicon, or, the resist structure is transformed into a metal master by electroplating. The utilisation of UV-transparent <b>replication</b> <b>tools</b> allows for the use of opaque substrates (i. e. detectors). Locally UV-transparent <b>replication</b> <b>tools</b> enable a combination of replication and resist technology (leading to elements with new features) or can protect sensitive areas like bond pads from being coated with optical layers. The fabrication of isolated polymer elements on arbitrary substrates is an advantage of UV?reaction moulding against injection moulding or hot embossing...|$|R
50|$|In March 2013, Basho {{released}} {{portions of}} Riak CS code to open source. Basho also announced the commercial version of Riak CS Enterprise, adding multi-datacenter <b>replication,</b> monitoring <b>tools,</b> and 24x7 support.|$|R
40|$|Replication {{is widely}} used in {{application}} server products to tolerate faults. An important challenge is to correctly coordinate replication and transaction execution for stateful application servers. Many current solutions assume that a single client request generates exactly one transaction at the server. However, it is quite common that several client requests are encapsulated within one server transaction or that a single client request can initiate several server transactions. In this paper, we propose a <b>replication</b> <b>tool</b> that is able to handle these variations in request/transaction association. We have integrated our approach into the J 2 EE application server JBoss. Our evaluation using the ECPerf benchmark shows a low overhead of the approach. ...|$|E
40|$|Because {{of their}} {{increasing}} popularity, Internet information {{services such as}} the Web, Internet FTP archives, and Network News, replicate their servers to improve availability, response time, and fault tolerance. Traditional replication algorithms do not address the scale and administrative decentralization of today's internetworks. They manage a single group of replicas and rely on system administrators to hand configure the topologies over which updates travel. While this is appropriate for applications with {{a small number of}} replicas that operate within single administrative boundaries, it does not scale in wide-area, highly replicated services whose replicas spread throughout the Internet's thousands of autonomously administered domains. We have proposed and implemented a scalable and efficient tool to replicate widearea, autonomously managed services. We target replication degrees of thousands of weakly consistent replicas. The main goal of our <b>replication</b> <b>tool</b> is to make traditio [...] ...|$|E
40|$|This paper {{reports the}} design, implementation, and {{performance}} of a scalable and efficient tool to replicate Internet information services. Our tool targets replication degrees {{of tens of thousands}} of weakly-consistent replicas scattered throughout the Internet's thousands of autonomously administered domains. The main goal of our <b>replication</b> <b>tool</b> is to make existing replication algorithms scale in today's exponentially-growing, autonomouslymanaged internetworks. 1. Introduction Internet services provide large, rapidly evolving, highly accessed, autonomously managed information spaces. To achieve adequate performance, services such as WWW [1] will have to replicate their data in thousands of autonomous networks. As an example of a highly replicated service, take Internet news [5]. Although it manages a dynamic, flat, gigabyte database, it responds to queries in seconds. In contrast, popular WWW and FTP servers are constantly too overloaded to provide reasonable response time to users [...] ...|$|E
40|$|Beam {{shaping of}} {{incoherent}} light sources (LEDs, halogen lamps) for arbitrary target light distribution is obtained {{by a single}} free-shape mirror. Special design algorithm ensures continuous profile without abrupt changes and shadowing regions. The mirror is manufactured by single point diamond turning combined with Fast-Tool-Servo (FTS) for simultaneous figuring of base surface and fine structure (for redistributing the light energy). Lateral and axial resolution of the fine structure is determined by FTS and considered during the design and data transfer. Directly turned surfaces {{can be used as}} <b>replication</b> <b>tools</b> for polymer or glass moulding and embossing...|$|R
40|$|Demoulding {{components}} without {{damage to}} either the components or tool is critical to successful replication processes. Accurate demoulding force prediction prior to tool fabrication helps designers optimize <b>replication</b> <b>tools</b> to minimize the demoulding force and resultant stress on replicated parts. Various models have been proposed to predict demoulding forces. One such model, the stair-step model, was developed by Colton et al for stereolithographic moulding tools. This paper investigates applying the model to other periodic surfaces with validation using published experimental data. In addition validity of the model for application to micro mould surfaces produced by micro milling is discussed...|$|R
50|$|In 2008, with 10 employees, {{the company}} {{released}} Veeam Backup & <b>Replication,</b> a <b>tool</b> that provided VMware vSphere VMs with incremental backups and image-based replication, with built-in data deduplication and compression. Veeam Backup & Replication started supporting Microsoft Hyper-V in 2012.|$|R
40|$|This paper {{studies the}} usage of {{broadcast}} communication in distributed services. The approach taken is practical: all the algorithms are asynchronous, and tolerate realistic faults. We study four problems in a broadcast domain: clock synchronization, reliable and ordered broadcast, membership, and file replication. The clock synchronization algorithm shows {{for the first time}} how to utilize broadcast communication for synchronization. The master synchronizes any number of slaves while incurring a constant load. The approach taken in the file <b>replication</b> <b>tool</b> uses snooping in order to enhance the availability of file systems, at almost no cost. 1 Introduction This paper presents algorithms that use broadcast communication. The broadcast primitive enables the dissemination of messages to multiple destinations via a single transmission. The motivation behind this work is practical: most computer networks nowadays essentially provide a datagram broadcast service. Most transport protocols [...] ...|$|E
40|$|Cylindrical optics (lens arrays, mirrors) are {{typically}} used for beam shaping, beam homogenization {{as well as}} for live generation. Often aspherical profiles with high geometrical accuracy and pitches > 100 pm are required. This structures are machinable with diamond turning with a high flexibility. The cylindrical structures can be cut into the face or into the circumference of the workpiece. The bending of the structures - perpendicular to the cylinder profile - can be minimized by a great off-axis distance or is corrigible by a suitable optical design. In this paper the turning technologies are described considering as two examples: First, a <b>replication</b> <b>tool</b> (OHFC-Copper) for a cylindrical lens array with hyperbolic profile for an optical microphone and Second, a cylindrical mirror with asymmetric profile in OHFC-Copper. The achieved form accuracy and surface roughness are documented. The technological limits regarding minimum dimensions are discussed...|$|E
40|$|UDDI {{registries}} {{are intended}} to become the world-wide lookup mechanism for web services. As such, they have to provide low response time, high throughput, high availability, and access to accurate data. Data replication is a key technology to satisfy such requirements. However, replication requires proper coordination of updates. Various replication strategies favor different subsets of the performance metrics. In this thesis, we have {{a closer look at}} two different replication strategies. One follows the UDDI specification; the other uses a middleware-based <b>replication</b> <b>tool.</b> We have integrated both approaches into an existing UDDI registry in a modular way. The thesis provides a detailed comparison of these two strategies from different points of view. Performance is analyzed by the means of an analytical model evaluating the communication and database access overhead, and by performing experiments in both LAN and WAN environment. Implementation overhead, including modularity and reusability, is also analyzed. Furthermore, some core design issues, such as reliability, extensibility, etc., are discussed...|$|E
40|$|The most {{critical}} and {{important aspect of}} disaster recovery {{is to protect the}} data from application fail over, natural disasters and infrastructure failures. Taking frequent backups of the huge volumes of data and storing it is also {{an integral part of the}} disaster recovery plan. Various scenarios of database replication strategies and techniques are provided in this survey paper addressing the need for replication of data. A wide range of open source and commercial tools have evolved over a period of time to deal with the issues and challenges involved during the process of database replication. This paper describes the general characteristics of replication & disaster recovery. Later the features of open source and commercial <b>replication</b> <b>tools</b> are compared...|$|R
40|$|Data {{replication}} is {{an important}} aspect in a Data Grid for increasing fault tolerance and availability. Many Grid <b>replication</b> <b>tools</b> or middleware systems deal with read-only files which implies that replicated data items are always consistent. However, there are several applications that do require updates to existing data and the respective replicas. In this article we present a replica consistency service that allows for replica updates in a single-master scenario with lazy update synchronisation. The system allows for updates of (heterogeneous) relational databases, and {{it is designed to}} support flat files as well. It keeps remote replicas synchronised and partially (“lazily”) consistent. We report on the design and implementation of a novel “relaxed” replica consistency service and show its usefulness in a typical application use case...|$|R
40|$|For {{replication}} {{processes to}} be deemed successful it must be possible to remove the replicated parts from the tool after processing. With decreasing part and feature size the challenge of demoulding replicated parts increases since the resulting parts and <b>replication</b> <b>tooling</b> used are more delicate and can be easily damaged. Predictive demoulding force models {{can be used to}} optimise the part, tool and process parameters to maximise the likelihood of success. Developing accurate models for this process requires knowledge of the dominant interfacial contributions to friction and knowledge of the size scale at which the dominant contributions operate together with an understanding of how these might change as process parameters vary. This paper explains the dominant contributors to friction at the micro scale and reviews test methods which are available to isolate and quantify each of these contributors...|$|R
40|$|Data {{replication}} is a {{key issue}} in a Data Grid and can be managed in different ways and {{at different levels of}} granularity: for example, at the file level or object level. In the High Energy Physics community, Data Grids are being developed to support the distributed analysis of experimental data. We have produced a prototype data <b>replication</b> <b>tool,</b> the Grid Data Management Pilot (GDMP) that is in production use in one physics experiment, with middleware provided by the Globus Toolkit used for authentication, data movement, and other purposes. We present here a new, enhanced GDMP architecture and prototype implementation that uses Globus Data Grid tools for efficient file replication. We also explain how this architecture can address object replication issues in an object-oriented database management system. File transfer over wide-area networks requires specific performance tuning in order to gain optimal data transfer rates. We present performance results obtained with GridFTP, an enhanced version of FTP, and discuss tuning parameters...|$|E
40|$|Replicating data over {{a cluster}} of {{workstations}} is a powerful tool to increase performance, and provide fault-tolerance for demanding database applications. The big challenge in such systems is to combine replica control (keeping the copies consistent) with concurrency control. Most of the research so far has focused on providing the tra-ditional correctness criteria serializability. However, more and more database systems, e. g., Oracle and PostgreSQL, use multi-version concurrency control providing the iso-lation level snapshot isolation. In this paper, we present Postgres-R(SI), an extension of PostgreSQL offering trans-parent replication. Our <b>replication</b> <b>tool</b> is designed to work smoothly with PostgreSQL’s concurrency control provid-ing snapshot isolation for the entire replicated system. We present {{a detailed description of}} the replica control algo-rithm, and how it is combined with PostgreSQL’s concur-rency control component. Furthermore, we discuss some challenges we encountered when implementing the proto-col. Our performance analysis based on the TPC-W bench-mark shows that this approach exhibits excellent perfor-mance for real-life applications even if they are update in-tensive. 1...|$|E
40|$|Reservoir {{uncertainty}} {{analysis is}} targeted at obtaining assessments and predictions of reservoir performance, {{for the purpose}} of guiding development and operational decisions. However, accurately analyzing various reservoir uncertainty factors is a challenging issue due to the associated large-scale data manipulation and massive reservoir simulations which cannot be easily handled with the typical resources of a single institution. Security issues hinder effective collaborations between researchers interested in reservoir studies. We leverage Grid computing technologies to address these concerns. A data <b>replication</b> <b>tool</b> has been implemented for manipulating raw geological&geophysical (G&G) data, well logging data, and simulation results. A task farming framework has been developed for massive reservoir simulation executions. GSI (Grid Security Infrastructure) has been employed for security. This paper describes the design and implementation on these solutions. The case studies are introduced to verify our contributions. Our efforts also provide Grid solutions for other computing-intensive and data-intensive uncertainty analysis, such as coastal modeling. 1...|$|E
40|$|Wireless Sensor Network is the {{essential}} structure of a water eminence monitoring by means of wireless sensor network technology To scrutinize water quality greater than different sites as a synchronized application an estimable system structural design constituted by spread sensor nodes and a base station is suggested The nodes and base stations are linked using WSN technology like Zigbee Base stations are related via Ethernet. Design and execution of a prototype using WSN technology are the exigent work. Data are identified by means of dissimilar sensors at the node plane to compute the parameters like turbidity and oxygen quantity is transmitted via WSN to the support station Information unruffled from the distant location is capable of displayed in diagram setup {{as well as it}} is able to be calculated using dissimilar <b>replication</b> <b>tools</b> at the supporting station. The recent methods have benefits such as null amount carbon emission low power utilization more stretchy to put together at distant locations. Comment: 8 FIGURES AND 5 PAGE...|$|R
40|$|Abstract Background High-throughput cultivations in microtiter {{plates are}} {{the method of}} choice to express {{proteins}} from recombinant clone libraries. Such processes typically include several steps, whereby {{some of them are}} linked by replication steps: transformation, plating, colony picking, preculture, main culture and induction. In this study, the effects of conventional replication methods and <b>replication</b> <b>tools</b> (8 -channel pipette, 96 -pin replicators: steel replicator with fixed or spring-loaded pins, plastic replicator with fixed pins) on growth kinetics of Escherichia coli SCS 1 pQE- 30 pSE 111 were observed. Growth was monitored with the BioLector, an on-line monitoring technique for microtiter plates. Furthermore, the influence of these effects on product formation of Escherichia coli pRhotHi- 2 -EcFbFP was investigated. Finally, a high-throughput cultivation process was simulated with Corynebacterium glutamicum pEKEx 2 -phoD-GFP, beginning at the colony picking step. Results Applying different <b>replication</b> <b>tools</b> and methods for one single strain resulted in high time differences of growth of the slowest and fastest growing culture. The shortest time difference (0. 3 h) was evaluated for the 96 cultures that were transferred with an 8 -channel pipette from a thawed and mixed cryoculture and the longest time difference (6. 9 h) for cultures that were transferred with a steel replicator with fixed pins from a frozen cryoculture. The on-line monitoring of a simulated high-throughput cultivation process revealed strong variances in growth kinetics and a twofold difference in product formation. Another experiment showed that varying growth kinetics, caused by varying initial biomass concentrations (OD 600 of 0. 0125 to 0. 2) led to strongly varying product formation upon induction at a defined point of time. Conclusions To improve the reproducibility of high-throughput cultivation processes and the comparability between different applied cultures, it is strongly recommended to use automated or manual liquid handling stations or, alternatively, multi-channel pipettes. Because of their higher transfer volume and hence precision in comparison to pin replicators, they reduce the variance of initial biomass concentrations. With respect to the results obtained, other methods to increase the comparability between parallel cultivations by compensating differences in biomass concentrations are required, such as using autoinduction media, fed-batch operation of precultures or on-line monitoring in microtiter plates combined with automated liquid handling. </p...|$|R
40|$|This {{research}} paper outlines the research activity {{being carried out}} at Industrial Research Institute Swinburne (IRIS) on the evaluation studies of different samples prepared using hot embossing technique. The objective {{of this research is}} to investigate microtribology aspects of electroformed shims meant for replication using hot embossing for Micro electromechanical systems (MEMS) applications. Micro hot embossing {{has been one of the}} most simple and cost effective route of replication of many MEMS components [...] -using electroformed shim with the features on it to replicate these structures in plastics. There is a need to increase the lifetime of these electroformed shims as this has been recognised as one of major obstacles. This problem can be solved during shim fabrication (by altering electroforming conditions) and also by deposition of wear resistant materials TiN and CrN to improve wear properties of <b>replication</b> <b>tools.</b> As a first step in this direction, we have started work on evaluating the electroformed shim structures and the results of these studies are presented in this paper...|$|R
40|$|A {{replication}} technique {{allowing for}} the wafer scale integration of microoptical elements is presented and illustrated by various examples. The technique is based on polymer UV reaction moulding using a modified contact mask aligned where mask and wafer are replaced by the <b>replication</b> <b>tool</b> and an arbitrary substrate, respectively. The technology {{takes advantage of the}} high precision and adjustment accuracy of photolithography equipment. The replication masters are nickel shims, etched Silicon wafers or uv-transparent fused silica tools. The latter ones allow for replication on opaque substrates. Additionally, polymer elements with unique properties can be obtained by the combination of replication and resist technology using partially transparent replication tools. Wafer scale hybrid integration of microoptical subsystems is accomplished by replication of polymer elements like lenses, lens arrays, micro prisms etc. onto semiconductor wafers containing detectors or VCSELs, or by combini ng microoptical elements on both sides of a glass wafer. The use of thin layers of uv cured (crosslinked) polymers on inorganic substrates results in good thermal and mechanical stability compared to all-polymer devices...|$|E
40|$|Cluster based {{replication}} {{solutions are}} an attractive mechanism to provide both high-availability and scalability for the database backend within the multi-tier information systems of service-oriented businesses. An important {{issue that has}} not yet received sufficient attention is how database replicas that have failed can be reintegrated into the system or how completely new replicas can be added in order to increase the capacity of the system. Ideally, recovery takes place online, i. e, while transaction processing continues at the replicas that are already running. In this paper we present a complete online recovery solution for database clusters. One important issue is to find an efficient way to transfer the data the joining replica needs. In this paper, we present two data transfer strategies. The first transfers the latest copy of each data item, the second transfers the updates a rejoining replica has missed during its downtime. A second challenge is to coordinate this transfer with ongoing transaction processing such that the joining node does not miss any updates. We present a coordination protocol that can be used with Postgres-R, a <b>replication</b> <b>tool</b> which uses a group communication system for replica control. We have implemented and compared our transfer solutions against a set of parameters, and present heuristics which allow an automatic selection of the optimal strategy for a given configuration. 1...|$|E
40|$|Published online : 02 August 2013 Microinjection {{moulding}} {{is one of}} {{the most}} efficient replication methods for polymeric components in microsystems. The manufacturing of moulding blocks for complex geometries is resorting increasingly to the techniques of rapid prototyping. This development on the use of additive microtechnologies can promote the massification of microsystems within a shorter tooling development cycle time. However, the microinjection moulding process itself has mechanical and thermal demands that must be addressed and require specific consideration of the selection of the tool material. This constrains the selection of the best-suited additive manufacturing process. The current state of the art of additive manufacturing technologies at the micrometric scale favours laser sources to process layer by layer the media contained in a vat. The media type, the laser power and the laser spot size are parameters that can influence the <b>replication</b> <b>tool</b> tolerances and physical properties. This work explores the possibilities of two additive technology tooling approaches for microinjection moulding, using different materials. The research parameters included replication detailing onto the plastic part, surface roughness, microtool integrity and wear. The evaluation of these parameters was carried out using both optical and hybrid microscopy, a laser perthometer as a non-contact solution for surface roughness evaluation, scanning electron microscopy and X-ray spectroscopy. The results of this research work showed that the processed material and technology play an important role both on surface quality and tool life, enabling criteria definition for technology selection...|$|E
40|$|Recent {{results on}} {{waveguide}} device fabrication by replication of inorganic copolymers (ORMOCERs) are presented. The use of optimized ORMOCER resins offers advantages over conventional organic polymers. The organic {{as well as}} inorganic crosslinking is responsible to high thermal and chemical stability and thus an improved stability of the waveguide devices. Fluorination of ORMOCER side chains reduces the NIR absorption to < 0. 1 dB/cm at 1. 55 mu m and < 0. 3 dB/cm at 1. 3 mu m. Furthermore, the synthesis of purely inorganically crosslinking CH-free ORMOCER is possible. The refractive index can be turned so that highly fluorinated core material can be combined with low-cost unfluorinated cladding material. The influence of the sidewall roughness of <b>replication</b> <b>tools</b> on scattering losses is investigated, and methods to fabricate smooth original structures have been developed leading to an additional scattering loss <O. 1 dB/cm in single-mode strip waveguides even at visible wavelengths. Furthe rmore, an improved deforming behaviour is achieved. UV-patterning by uv-induced crosslinking is a second waveguide fabrication method used in ORMOCERs in thermooptical switching nodes are discussed...|$|R
40|$|AbstractThis paper {{investigates the}} effect that a novel {{texturing}} of <b>replication</b> <b>tools</b> by applying amorphous hydrogenated carbon (aC:H) coating has on the processing conditions in micro injection moulding. Texturing usually increases the surface area of tools leading to higher demoulding forces acting on the component during the ejection stage of the process. As a consequence of this the ejection forces can cause stress marks, deformation, fracture and stretching of the polymer micro features. Therefore, this research studies {{the effect that}} a textured aC:H coating with nano scale structures has on the resulting demoulding forces in comparison to an untreated tooling surface. The obtained results demonstrate the beneficial effect of the aC:H surface coating on demoulding forces in replicating nano-scale surface structures. Especially, nano bead-like texturing and nano pillars on the tools' surfaces did not increase the demoulding forces to the levels witnessed on uncoated tooling surfaces, and the aC:H coatings remained a dominant factor in determining the tool performance. The carried out proof of concept study showed that the applied surface texturing method {{can be considered as}} an alternative to existing techniques for surface structuring {{and at the same time}} to reduce demoulding forces...|$|R
40|$|In {{this paper}} {{we present a}} first {{distributed}} REal-time COsmic Ray Database (RECORD). The aim of the project {{is to develop a}} unified database with data from different neutron monitors collected together, in unified format and to provide a user with several commonly used data access methods. The database contains not only original cosmic ray data but also auxiliary data necessary for scientific data analysis. Currently the database includes Lomn. Stit, Moscow, Oulu; Tixie Bay, Yakutsk stations. The main database server is located in IKFIA SB RAS (Yakutsk) but there will be several mirrors of the database. The database and all its mirrors are updated on the nearly real-time (1 hour) basis. The data access software includes WWW-interface, Perl scripts and C library, which may be linked to a user program. Most of frequently used functions are implemented to make it operable to users without SQL language knowledge. A draft of the data rep-resentation standard is suggested, based on common practice of neutron monitor community. The database engine is freely distributed open-sourced PostgreSQL server coupled with a set of <b>replication</b> <b>tools</b> developed at Bioengineering division of the IRCCS E. Medea, Italy. 1...|$|R
