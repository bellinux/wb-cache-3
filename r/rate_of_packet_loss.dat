19|10000|Public
30|$|Inequality (4) {{reveals the}} {{probabilistic}} characterization of packet losses by counting {{the number of}} observed packet losses. It indicates that the limit of the probability of the rate of packet losses greater than ρ ^* is zero. In other words, when the time is long enough, the <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> should have an upper bound with probability one.|$|E
40|$|The sending rate of {{commonly}} used TCP protocols is tightly coupled to packet loss within the network: a high <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> {{will cause a}} sender to slow down, thereby reducing the network load and decreasing subsequent packet loss rates. In this paper, we combine a widely verified source rate TCP model with an Optical Burst Switching (OBS) loss model, to find fixed-point input loads and loss rates for an OBS link carrying TCP traffic. In doing so, we show that if OBS networks are to be efficiently used to carry TCP traffic, many wavelengths with full wavelength conversion are required...|$|E
40|$|When a {{wireless}} link forms {{a part of}} a network, the <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> due to link noise may be considerably higher than observed in a modern terrestrial network. This paper studies TCP performance over a range of link environments and highlights the advantage of recent modifications to TCP (e. g. SACK, New-Reno) for wireless communications. It also identifies two key issues which impact the performance of TCP over error prone links: TCP’s reliance on timers to recover from a failed retransmission cycle, and TCP’s inability to separate congestion packet loss from other types of packet loss. A solution to the first issue is identified and analysed by simulation, and the factors affecting the second issue are outlined. ...|$|E
30|$|Measuring {{accurately}} the <b>rate</b> <b>of</b> <b>packet</b> <b>losses</b> {{caused by}} wireless errors is almostnot possible at transport layer. Thus, we will estimate the <b>packet</b> <b>loss</b> rate bychecking how often FRRs/RTOs are triggered since TCP invokes FRRs/RTOs wheneverpackets are lost. Although our estimation includes the <b>rate</b> <b>of</b> <b>packet</b> <b>losses</b> causedby congestion, {{it is useful}} since cwnd needs to be smaller even whenpackets are lost due to congestion.|$|R
40|$|Disclosed is {{a system}} for {{dynamically}} suppressing Fast Retransmission and Recovery (FRR) on high-latency Transport Control Protocol (TCP) connections with low ongoing <b>packet</b> <b>loss.</b> This system measures the relative <b>rate</b> <b>of</b> recent <b>packet</b> <b>loss</b> and adjusts the suppression of FRR {{based on the measured}} rate. Provided that the <b>rate</b> <b>of</b> actual <b>packet</b> <b>loss</b> is low, high-latency TCP connections can benefit significantly from suppressing FRR...|$|R
40|$|In {{this report}} we {{investigate}} the impact <b>of</b> randomised <b>packet</b> <b>loss</b> on TCP transfers using FreeBSD 8. 2. We then evaluate these outcomes {{with respect to}} web interactivity and responsiveness. We find that even small <b>rates</b> <b>of</b> <b>packet</b> <b>loss</b> have a significant detrimental impact on perceivable performance of a website, and that avoiding <b>packet</b> <b>loss</b> {{is likely to be}} a better strategy than increasing bandwidth. We also investigate the effect of delay, bandwidth bottlenecks and queue size to compare with <b>packet</b> <b>loss...</b>|$|R
40|$|Virtual Private Network (VPN) is a {{technology}} implemented {{as a solution}} to connect head and branch offices through a network. VPN enables all offices connected to be treated as a single broadcast domain or a single network, providing a private connection. VPN can be implemented over several protocols: Point-To-Point Tunneling Protocol (PPTP) and Ethernet over Internet Protocol (EoIP). This research conducted through implementation of both protocols on a site-to site VPN and measuring each protocol 2 ̆ 7 s performance using throughput, packet loss and delay parameters obtained from real topology. Overall result shows that EoIP performs better than PPTP. Within six days of observation, obtained data shows that EoIP has better throughput and less delay than PPTP, while PPTP has a smaller <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> than EoIP...|$|E
30|$|In {{order to}} achieve our aims in the experiment, we used {{different}} scenarios of non-congestion events under three different network conditions. First condition is designed to check the throughput of random loss detection according to the <b>rate</b> <b>of</b> <b>packet</b> <b>loss,</b> bandwidth, delay, number of hops, and variation of cwnd size. Thus, in this condition, all packet losses are caused by transmission errors. The second condition aims to cause random loss and packet reordering according to the rate of delay, bandwidth, packet reordering rate, packet loss rate, and percentage of unneccssary retransmissions. Finally, in third condition, we planned to observe the throughput in terms of congestion loss, random loss, and packet reordering according to the rate of queue size, bandwidth, packet loss, delay, and number of hops in order to confirm that TCP NCE is efficient in the co-existence of congestion and non-congestion events.|$|E
40|$|Vehicular Ad-hoc Networks (VANETs) are {{currently}} in everyone's mouth when talking about future technologies that will be implemented in the automotive industry. In the last years the IEEE group has {{been working in the}} development of a standard for vehicular communications, this standard is the 802. 11 p. Most research work in this area has focused on vehicle-to-vehicle communication architecture, thus, more research is still necessary on the vehicle-to-infrastructure communication architecture. In this paper we present a performance study of the 802. 11 p technology for the development of applications in VANETs. This work simulates the IEEE 802. 11 p technology in a vehicular scenario. Results show that the IEEE 802. 11 p is an adequate technology for the development of several vehicular applications in terms of <b>rate</b> <b>of</b> <b>packet</b> <b>loss,</b> average end-to-end delay, and throughput. Peer ReviewedPostprint (published version...|$|E
50|$|The {{original}} {{definition of}} OLSR {{does not include}} any provisions for sensing of link quality; it simply assumes that a link is up if a number <b>of</b> hello <b>packets</b> have been received recently. This assumes that links are bi-modal (either working or failed), which {{is not necessarily the}} case on wireless networks, where links often exhibit intermediate <b>rates</b> <b>of</b> <b>packet</b> <b>loss.</b> Implementations such as the open source OLSRd (commonly used on Linux-based mesh routers) have been extended (as of v. 0.4.8) with link quality sensing.|$|R
40|$|A {{mechanism}} is devised for performing handoff in mobile networks. It {{is based on}} the micro-mobility concept and packet forwarding strategy. With a comparably small signaling overhead, the mechanism provides the smooth handoff when mobile nodes change the points of their attachment. The routing is based on a flat routing table look-up with caching the binding information on current location of mobile nodes. The simulation results show a lower <b>rate</b> <b>of</b> <b>packet</b> <b>losses</b> and high throughput than that encountered for Mobile IP and Cellular IP...|$|R
40|$|AODV (Ad hoc On-demand Distance Vector routing), DSDV (Destination-Sequenced Distance-Vector routing), DSR (Dynamic Source Routing), and OLSR (Optimized Link State Routing protocol) are {{protocols}} {{used for}} routing management in ad-hoc networks. In a specific sensor data network application, nodes need {{information about the}} network topology, i. e. the network nodes and the connections between them. OLSR provides nodes with this information, while the three other protocols do not. This thesis investigates how OLSR compares to AODV, DSDV,and DSR in a low bandwidth network scenario. Two cases were analyzed: One where AODV, DSDV, and DSR distribute topology information in the application layer and one where they do not. The sensor data application was not finished when this thesis project started. Instead, a simplified traffic model of the application was used. In addition to a protocol comparison, this thesis investigates if traffic generated from the model results in high <b>rates</b> <b>of</b> <b>packet</b> <b>loss,</b> assuming low bandwidth conditions. The ns- 3 network simulator was used for these investigations. This thesis shows that AODV outperforms the three other protocols regardless of whether AODV, DSDV, and DSR distribute topology information in the application layer or not. Furthermore, it is shown that running the traffic model in the low bandwidth environment is not possible without high <b>rates</b> <b>of</b> <b>packet</b> <b>loss...</b>|$|R
40|$|Problem statement: Next-generation mobile {{networks}} are evolving towards network architectures relying entirely on IP. Approach: These networks {{had to be}} scalable {{in order to support}} future IP traffic, namely new multimedia services and real time applications, while providing an effective mobility management mechanism to cope with increasingly mobile users. In addition to global connectivity, next-generation mobile networks will have to offer quality of service guarantees such as assured bandwidth, low <b>rate</b> <b>of</b> <b>packet</b> <b>loss,</b> low delay and jitter. Results: In this study, we proposed an MPLS-based architecture for mobility management and end-to-end quality of service support in fourth-generation all-IP mobile networks (MAFI). Conclusion/Recommendations: Our scheme aimed to reduce handoff latency by implementing the fast handover technique and to increase the robustness and flexibility of the mobile system. The results obtained confirm the efficiency of MAFI when compared to FHMIPv 6 and others schemes well-known in the literature...|$|E
40|$|P 2 P based live {{streaming}} applications {{are growing up}} rapidly. However, when extending them to WLANs, the bandwidth bottleneck and the high <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> are usually the major stumbling blocks. To overcome this issue, a new wireless multicast agent mechanism (WiMA) based on the IP multicast scheme for buffer management and scheduling is proposed. First of all, a wireless agent selection method is presented to choose an appropriate agent for WiMA. Then this agent gains media data by interacting with wired neighbor peers as a common P 2 P node, and transmits these data to other wireless peers in the WLAN by means of multicast pushing and multicast patching. A normal wireless peer requests data according to the strategy of "emergent ones first". Experimental {{results show that the}} approach proposed can significantly save bandwidth in WLANs with acceptable start delay and satisfied playing continuity. 1...|$|E
40|$|We {{present an}} {{innovative}} totally ordered multicast protocol {{that is based}} on reservation of buffers at the destinations and intermediate network bridges, rather than on an acknowledgment strategy. By introducing timestamps into the packets and by using a buffer reservation retract scheme, our protocol not only produces a global total order of packets but also solves the deadlock and starvation problems to which reservation-based protocols are vulnerable. A discrete event simulation demonstrates the high throughput and low latency of the protocol. 1. Introduction Modern communication networks offer very high speeds and also very high reliability, particularly when reinforced by an error-correcting code. The primary cause of packet loss in a modern high-speed network is not corruption of the packets on the communication medium, but rather lack of buffer space at the destinations and intermediate network bridges [12]. It has been shown that, even when the <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> at each node [...] ...|$|E
40|$|Abstract — Delivering {{multicast}} data using so-called overlay networks {{offers many}} advantages. Overlay networks only {{consisting of a}} multicast group’s members that are connected by means of transport links, non-members (especially routers) {{no longer need to}} bother about multicast routing and keeping a group’s state information. While existing application layer multicast protocols mainly were designed for the fixed Internet, first attempts to adapt such protocols for mobile ad-hoc networks start emerging. Because these adaptions however still suffer from a relatively high <b>rate</b> <b>of</b> <b>packet</b> <b>losses,</b> this paper outlines generic mechanisms that improve the overall delivery ratio for application layer multicast protocols. Although the proposed mechanisms are illustrated at the example of the NICE-MAN protocol (which is an adaption of the NICE protocol, originating from the Internet), they may be applied to arbitrary overlays. Furthermore, this paper shows how overlay networks combined with the developed mechanisms can be used, to significantly improve delivery ratios for existing multicast protocols (like ODMRP, M-AODV) that reside on the network layer. I...|$|R
40|$|The SSH {{protocol}} provides many invaluable {{network features}} over encrypted channels. In version 4. 3 of the OpenSSH implementation, VPN functionality is also supported, where actual IP packets from other applications are captured and tunneled via OpenSSH to the remote location. OpenSSH is using TCP consistently {{for all its}} network connections and thus for its VPN feature. This causes the VPN feature to tunnel one TCP connection within another TCP connection. Many sources say that TCP in TCP tunneling, under realistic conditions, can give rise to conflicts between the two TCP implementations and that TCP in TCP should be avoided. Many SSH and SSL VPN solutions use this functionality anyway {{and it seems to}} work. To see whether a UDP based solution would perform better than a TCP based solution on links experiencing <b>packet</b> <b>loss,</b> we have modified the OpenSSH implementation by adding support for a UDP base connection to its VPN functionality. The modification was tested and compared to the original implementation using a test network, in which <b>packet</b> <b>loss</b> was emulated. The performance of the implementations is compared in terms of bandwidth for different <b>rates</b> <b>of</b> <b>packet</b> <b>loss.</b> We have shown that a UDP based solution performs slightly better than a TCP based solution. The most gain in performance, from using a UDP base connection, was detected when ACKs belonging to the tunneled connection where lost...|$|R
40|$|Current {{congestion}} control algorithms treat <b>packet</b> <b>loss</b> {{as an indication}} of network congestion, under the assumption that most losses are caused by router queues overflowing. In response to losses (congestion), a sender reduces its sending rate in an effort to reduce contention for shared network resources. In network paths where a non-negligible portion of loss is caused by packet corruption, performance can suffer due to needless reductions <b>of</b> the sending <b>rate</b> (in response to "perceived congestion" that is not really happening). This paper explores a technique, called Cumulative Explicit Transport Error Notification (CETEN), that uses information provided by the network to bring the transport's long-term average sending rate closer to that dictated by only congestionbased losses. We discuss several ways that information about the cumulative <b>rates</b> <b>of</b> <b>packet</b> <b>loss</b> due to congestion and corruption might be obtained from the network or through fairly generic transport layer instrumentation. We then explore two ways to use this information to develop a more appropriate {{congestion control}} response (CETEN). The work in this paper is done in terms of TCP. Since numerous transport protocols use TCP-like congestion control schemes, the CETEN techniques we present are applicable to other transports as well. In this paper, we present early simulation results that show CETEN to be a promising technique. In addition, this paper discusses a number of practical and thorny implementation issues associated with CETEN...|$|R
40|$|Abstract: Problem statement: Next-generation mobile {{networks}} are evolving towards network architectures relying entirely on IP. Approach: These networks {{had to be}} scalable {{in order to support}} future IP traffic, namely new multimedia services and real time applications, while providing an effective mobility management mechanism to cope with increasingly mobile users. In addition to global connectivity, next-generation mobile networks will have to offer quality of service guarantees such as assured bandwidth, low <b>rate</b> <b>of</b> <b>packet</b> <b>loss,</b> low delay and jitter. Results: In this study, we proposed an MPLS-based architecture for mobility management and end-to-end quality of service support in fourth-generation all-IP mobile networks (MAFI). Conclusion/Recommendations: Our scheme aimed to reduce handoff latency by implementing the fast handover technique and to increase the robustness and flexibility of the mobile system. The results obtained confirm the efficiency of MAFI when compared to FHMIPv 6 and others schemes well-known in the literature. Key words: Mobile IP, mobility management, QoS, 4...|$|E
30|$|With {{the rapid}} growth of the {{deployment}} of WiFi [1] devices, mobile users can easily access Internet resources. Since handoff is indispensable to a mobile user changing location, it is imperative to achieve seamless handoff so that the connection is maintained. Seamless handoff requires minimizing the time to process handoff and the <b>rate</b> <b>of</b> <b>packet</b> <b>loss.</b> To address packet loss, several schemes [2, 3] have been proposed that the corresponding node duplicates the data packets among relevant APs. However, these duplicated packets may overload network devices. Therefore, a better approach is to reduce the time spent in handoffs. Handoffs occur across several layers. For example, the handoff in the network layer deals with network address re-allocation, whereas the data link layer determines a target access point (AP). In order to reduce the time in processing a handoff, its operations must be integrated across layers. Even though lower-layer protocols involved in handoff are simplex, integration with various application layer protocols is not trivial. Even though an application layer handoff approach, proactive and adaptive handover system [4], was proposed using session initiation protocol (SIP) [5], some network and data link layer operations can be integrated, for example an IP address pre-fetching and link layer call admission.|$|E
40|$|Due to {{enormous}} {{growth of}} the Internet, demands for access from multiple users and request for new services for its applications have also increased significantly. In a result there is a rise in packet loss rates and drop in network efficiency. In addition, the inability to support new services has severely hindered the widespread deployment of bandwidth-sensitive applications. So the success of TCP / IP depends {{on its ability to}} deliver services in time of extremely high demand and hence various congestion control mechanisms ensure this ability to prosper. The idea behind TCP congestion control is to control network load by having sources adjust their rates according to the level of congestion in the network. This paper focuses on how congestion control and queue management techniques have evolved in due course of time and being modified to minimize the <b>rate</b> <b>of</b> <b>packet</b> <b>loss.</b> Considering RED being most important of all we have optimized the algorithm by challenging the linearity of marking/dropping probability. We conduct a survey by applying different possible functions in contrary to the linear behavior of dropping probability for evaluating their performance in comparison to RED. We implement the optimized RED by simulating a multicast network for TCP flows...|$|E
40|$|In {{the last}} few years, the Vehicular Ad-hoc Network (VANET) {{has come to be}} an {{important}} area of research. Significant research has been conducted to improve the performance of VANETS. One output of further research conducted on VANET is the Vehicular Delay Tolerant Network (VDTN). It is an application of the mobile DTN where nodes relay messages in the network using a store-carry-forward approach. Due to its high mobility, it suffers frequent disconnections and also congestions at nodes which leads to message drops. To minimize the <b>rate</b> <b>of</b> message drops and so optimize the probability of message delivery so that drivers are increasingly aware of the situation of the road, we propose a congestion control mechanism: Congestion Aware Spray and Wait (CASaW) protocol in this work so as to optimize the <b>rate</b> <b>of</b> message delivery to its destination and so increase the awareness of drivers in the vehicular environment thereby improve road safety. The results have shown that our proposition performed better than other classical VDTN protocols in terms of message delivery probability and <b>rate</b> <b>of</b> <b>packet</b> drops performance measures. We used the Opportunistic Networking Environment (ONE) simulator to implement the classical VDTN protocols: the PROPHET protocol, the Epidemic protocol, the MaxProp protocol and the Spray and Wait Protocol. The simulation scenarios shows a better performance for the congestion control mechanism we propose as it maintains a good message delivery rate as well as minimize the <b>rate</b> <b>of</b> <b>packet</b> <b>losses</b> thereby optimizing the chances of messages getting to their destinations and so improve road safety. Comment: 13 pages, 9 figure...|$|R
30|$|To {{validate}} {{that the}} proposed analytical model is consistent with real random access procedure, we compare the analytical results obtained using the SMM model with the simulation results produced based on the protocol implementation. The number <b>of</b> aggregated <b>packets</b> N is set to 1 and 2 to represent the regular random access and random access with packet aggregation. Here, we compare preamble collision <b>rate</b> instead <b>of</b> <b>packet</b> <b>loss</b> <b>rate.</b> The reason is that in some cases, the <b>packet</b> <b>loss</b> rate is very small, e.g., it {{is very close to}} 0 when λ= 1 / 300,N= 2, and the number of UE is less than 1500. Therefore, the difference between simulated results and analytical results might not be clearly seen when comparing.|$|R
40|$|Wireless {{transfer}} of energy through directed radio frequency waves {{has the potential}} to realize perennially operating sensor nodes by replenishing the energy contained in the limited on-board battery. However, the high power energy transfer from energy transmitters (ETs) interferes with data communication, limiting the coexistence of these functions. This paper provides the first experimental study to quantify the <b>rate</b> <b>of</b> charging, <b>packet</b> <b>loss</b> due to interference, and suitable ranges for charging and data communication of the ETs. It also explores how the placement and relative distances of multiple ETs affect the charging process, demonstrating constructive and destructive energy aggregation at the sensor nodes. Finally, we investigate the impact of the separation in frequency between data and energy transmissions, as well as among multiple concurrent energy transmissions. Our results aim at providing insights on radio frequency-based energy harvesting wireless sensor networks for enhanced protocol design and network planning...|$|R
40|$|Recent {{years have}} seen a growing {{interest}} in underwater communication and some {{progress has been made}} in this area. However, underwater communication is still immature compared with terrestrial communication. A prime reason for this is that the underwater environment is intrinsically not suitable for propagation of electric waves. Instead, ultrasonic waves are mainly used for underwater communication. Since ultrasonic waves cannot provide sufficient communication speed or capacity, they cannot use existing network technologies, which assume use of radio waves. In particular, communication in shallow water is still an uncharted territory. Few communication technologies are employed in environments where people enjoy scuba diving. This paper addresses problems faced by recreational scuba divers. It proposes constructing an ad hoc mesh-shaped network between divers within a group and use ultrasonic waves as transmission media in order to enable the detection of a stray diver. It also proposes a communication protocol in which messages are relayed in multiple hops, and a message collision avoidance method, which is intended to reduce the <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> caused by message propagation delay. We have implemented the proposed methods in a network simulator, and compared them with an existing communication method that has no message collision avoidance function, in terms of the packet loss rate, the stray driver detection rate, and the rate of the ability to communicate in multiple hops...|$|E
40|$|The {{cellular}} {{networks are}} increasingly facing {{the challenge of}} data explosion due high demands of data by users. Several forecasts and analysis indicates that, {{in the near future}} the technology cannot cater for the users’ data demands. Many attempts to upgrade the technology resulted into inefficient or expensive solution. Cellular data offloading to Wi-Fi is the most promising solution. The two main strategies for cellular data offloading are delay-tolerance and on-the-spot. The on-the-spot offloads less significant percentage of the traffic while the delay strategy achieves higher offloading percentage but with high <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> and high latency which affect the performance of real-time services. This research proposed an enhancement over the existing delay-algorithm. On receiving the user data request the strategy checks the availability and signal strengths of both the Wi-Fi and cellular and then classified the applications into real-time and non-real-time. The strategy always connects to Wi-Fi network if available. But when the Wi-Fi signal falls below the minimum threshold during the transfer, the strategy will complete the transfer using cellular immediately for real-time applications and wait till the end of the delay deadline in case of nonreal- time applications before it switch to cellular. The simulation result shows the enhanced algorithm achieved 59 % of offloading efficiency similarly to the Wiffier delay-algorithm but with 28 % reduction in packet loss and 30 % less completion time for real-time traffics compares to original delay-algorithm...|$|E
30|$|When {{the train}} is running within the speed range of 300 – 350 [*]km/h, the single output of the four modules’ {{downlink}} and uplink packets are tested respectively. When the ground sends data packets to the train, the number of data packets successfully received by the vehicle test platform is instantaneous after the train passes the ground test platform. According to the test results, the number of data packets sent successfully decreases as {{the speed of the}} train increases, and the number of data packets sent successfully by the communication module based on ZigBee technology is the largest. When the train sends data packets to the ground, the number of data packets successfully received by the ground test platform is instantaneous after the train passes the ground test platform. According to the test results, the number of data packets sent by the communication module based on ZigBee technology is also the largest. Through several tests, the average packet loss rate of uplink and downlink of each communication module is calculated. According to the test results, when the communication module based on RFID technology is set to 250 [*]kbps at the air speed and the baud rate is 9600, the <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> in both uplink and downlink is the lowest. The packet loss rate of communication module based on ZigBee technology is relatively high. By adding the delay of the uplink and the delay of the downlink, the problem of two laptops’ time asynchrony can be eliminated and the more accurate round-trip delay of the packet transmission can be obtained.|$|E
40|$|In recent years, video {{streaming}} services over TCP, such as YouTube, {{have become more}} and more popular. TCP NewReno, the current TCP standard, performs greedy congestion control, which increases the congestion window size until <b>packet</b> <b>loss</b> occurs. Therefore, because TCP transmits data at a much higher rate than the video playback <b>rate,</b> the probability <b>of</b> <b>packet</b> <b>loss</b> in the network increases, which in turn takes bandwidth from other network traffic. In this paper, we propose a new transport-layer protocol, called TCP Stream, that solves the problem of TCP in {{video streaming}}. TCP Stream performs a hybrid congestion control that combines the loss-based congestion control, which uses <b>packet</b> <b>loss</b> as an index of congestion, and the delay-based congestion control, which uses delay as an index of congestion. Simulation and experimental results show that TCP Stream transmits data at the adjusted rate, unlike TCP NewReno, and does not steal bandwidth from of other network traffic...|$|R
40|$|Abstract — The {{quality of}} the audio in IP {{telephony}} is significantly influenced by various factors, such as type of encoder, distance, delay variation, <b>rate</b> and distribution <b>of</b> <b>packet</b> <b>loss,</b> type <b>of</b> error concealment, and others. Hence, the performance of any IP telephony system is highly dependent on understanding the contribution of these factors on audio quality, {{and their impact on}} adaptive transport mechanisms such as error and buffer control. We conducted a large-scale audio transmission experiment over the Internet in a 12 -month period in order to evaluate the effects and the correlation of such parameters on audio transmission over IP. As a part of studying and analyzing the collected data, we have made a number of new observations on the correlation of loss and RTT variation, and various RTT measurement mechanisms that are significant for adaptive audio transmission over IP networks. Keywords—packet audio; Internet experiments; IP telephony; VoIP...|$|R
40|$|Consider {{a network}} with an {{arbitrary}} topology and arbitrary communication delays, in which congestion control {{is based on}} additive [...] increase and multiplicative [...] decrease. We show that the source rates tend to be distributed {{in order to maximize}} an objective function called F_A^h ("F_A^h fairness`). We derive this result under the assumption <b>of</b> <b>rate</b> proportional negative feedback and for the regime of rare negative feedback. This applies to TCP in moderately loaded networks, and to those TCP implementations that are designed to interpret multiple <b>packet</b> <b>losses</b> within one RTT as a single congestion indication and do not rely on re-transmission timeout. This result provides some insight into the distribution <b>of</b> <b>rates,</b> and hence <b>of</b> <b>packet</b> <b>loss</b> ratios, which can be expected in a given network with a number of competing TCP or TCP-friendly sources. We validate our findings by analyzing the parking lot scenario, and comparing with previous results floyd- 91 -b,mathis- 97 -a, and an extensive numerical simulation with realistic parameter settings. We apply F_A^h fairness to gain a more accurate understanding of the bias of TCP against long round trip times...|$|R
40|$|Wireless {{networks}} {{have become increasingly}} popular in recent times {{and it has become}} a pressing need to ensure that the various applications using it get the necessary Quality of service. Wireless networks being inherently different from wired networks and pose a unique set of challenges. Quality of Service(QoS) is dened as the performance oered by a network to its users in terms of providing resource assurance and service dierentiation to dierent kinds of trac ows. Due to scarcity of bandwidth and high <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> in wireless networks providing QoS to time critical applications is a challeng- ing task. In this thesis we attempt to study the QoS management strategies applied by the wireless networks at the MAC layer. The most common QoS provisioning strategy is to prioritize the dierent classes of trac and make sure that the high priority trac gets preferential access to the channel. In this thesis,a study of the binary exponential back-o algorithm which is used by the wireless MAC protocols has been done and an improvement has been proposed in which the Contention Window(CW) is varied in a non-uniform manner for dierent access categories with an aim to improve the performance parameters. The CW denes the range[0,CW] from which a random no of slots are chosen by a station in case of a failure in transmission for backing o before attempt- ing to transmit again. To demonstrate the eect of the modied contention window variation scheme simulations have been carried out using the Qualnet Simulator designed by Scalable Network Technologies, Inc. After implementing the proposed modication a performance comparison has been carried out for parameters such as packet delivery ratio, throughput and jitter...|$|E
40|$|In {{this thesis}} we look into network {{performance}} bottlenecks and how end-to-end delivery of data {{is affected by}} the performance of the network. The last years, the buzzword: &# 147;the bufferbloat issue&# 147; has gotten much attention in the network community. Bufferbloat is used to describe problems with high congestion on the Internet. The &# 147;common wisdom&# 148; is that congested links and bottlenecks are usually in the last-mile of the network, out to the consumer. This thesis puts this "common wisdom&# 148; to the test by discovering losses and delays inside the network. A stream of UDP packets were used to measure the end-to-end performance, while the traceroute&# 146; like tool MTR is used to identify where in the network loss and delay occurs. The experiments were run in a testbed called PlanetLab. PlanetLab is a network of computers distributed across the word. In this work access was gained to servers in most European countries, throughout USA, Argentina, Ecuador, South Korea, Japan, China, Thailand, New Zealand and more. No servers were available in the Middle East, India or Africa. The work is done by designing several Python scripts witch uses MTR and socket programming for sending UDP packet streams. This is done to measure delay and loss in the Internet. The python scripts were deployed and successfully run between over 250 intercontinental pair's servers for one week. The measurements were carefully logged and data was analysed. For the MTR trace-logs, borders between the first- and last-mile networks were established, making it possible to quantify loss and delay occurring in between the identified first-mile hop and the last-mile hop(the transport network). The results from the analysis gave no indication of disproving the common knowledge. Only a low <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> within the transport-network was discovered. Increased delays, due to congestion, took for the most part place in the Last-mile of the network. </p...|$|E
40|$|Context. Cloud {{computing}} (CC) {{is developed}} as a Human-centered computing model to facilitate its users to access resources anywhere on the globe. The resources can be shared among any cloud user which mainly questions the security in cloud computing. There are Denial of Service and Distributed Denial of Service attacks which are generated by the attackers to challenge the security of CC. The Next-Generation Intrusion Prevention Systems (sometimes referred as Non-Traditional Intrusion Prevention Systems (NGIPS) are {{being used as a}} measure to protect users against these attacks. This research is concerned with the NGIPS techniques that are implemented in the cloud computing environment and their evaluation. Objectives. In this study, the main objective is to investigate the existing techniques of the NGIPS that can be deployed in the cloud environment and to provide an empirical comparison of source mode and destination mode in Snort IPS technique based on the metrics used for evaluation of the IPS systems. Methods. In this study, a systematic literature review is used to identify the existing NGIPS techniques. The library databases used to search the literature are Inspec, IEEE Xplore, ACM Digital Library, Wiley, Scopus and Google scholar. The articles are selected based on an inclusion and exclusion criteria. The experiment is selected as a research method for the empirical comparison of Source mode and destination mode of Snort NGIPS found through literature review. The testbed is designed and implemented with the Snort filter techniques deployed in the virtual machine. Results. Snort is one of the mostly used NGIPS against DoS and DDoS attacks in the cloud environment. Some common metrics used for evaluating the NGIPS techniques are CPU load, Memory usage, bandwidth availability, throughput, true positive rate, false positive rate, true negative rate, false negative rate, and accuracy. From the experiment, it was found that Destination mode performs better than source mode in Snort. When compared with the CPU load, Bandwidth, Latency, Memory Utilization and <b>rate</b> <b>of</b> <b>packet</b> <b>loss</b> metrics. Conclusions. It was concluded that many NGIPS of the cloud computing model are related to each other and use similar techniques to prevent the DoS and DDoS attacks. The author also concludes that using of source based and destination based intrusion detection modes in Snort has some difference in the performance measures...|$|E
40|$|QoS for VoIP applications. The primary aims of {{the study}} {{reported}} in the paper are {{to carry out a}} fundamental investigation of the impact <b>of</b> <b>packet</b> <b>loss</b> and talkers on perceived speech quality using an objective method to provide the basis for developing an artificial neural network (ANN) model to predict speech quality for VoIP. The impact <b>of</b> <b>packet</b> <b>loss</b> (e. g. loss burstiness, <b>loss</b> patterns and <b>packet</b> size) and different talkers on speech quality was investigated for three modern codecs (G. 729, G. 723. 1 and AMR) using the new ITU PESQ algorithm. Results show that <b>packet</b> <b>loss</b> burstiness, loss locations/patterns and the gender of talkers have an impact on perceived speech quality. Packet size has, in general, no obvious influence on perceived speech quality for the same network conditions, but the deviation in speech quality depends on packet size and codec. Based on the investigation, we used talkspurt-based conditional and unconditional <b>packet</b> <b>loss</b> <b>rates</b> (instead <b>of</b> network <b>packet</b> <b>loss</b> <b>rates</b> because they are perceptually more relevant), codec type and the gender of the talker (extracted from decoder) as inputs to an ANN model to predict speech quality directly from network parameters. Results show that high prediction accuracy was obtained from the ANN model (correlation coefficients for the test and validation datasets were 0. 952 and 0. 946 respectively). This work should help to develop efficient, non-intrusive QoS monitoring and control strategies for VoIP applications...|$|R
40|$|The {{quality of}} audio in IP {{telephony}} is significantly influenced by various factors, including type of encoder, delay, delay variation, <b>rate</b> and distribution <b>of</b> <b>packet</b> <b>loss,</b> and type <b>of</b> error concealment. Hence, {{the performance of}} IP telephony systems is highly dependent on understanding the contribution of these factors to audio quality, {{and their impact on}} adaptive transport mechanisms such as error and buffer control. We conducted a large-scale audio transmission experiment over the Internet in a 12 -month period in order to evaluate the effects and the correlation of such parameters on audio transmission over IP. We have noticed that the correlation of loss and delay is not linear, but stronger correlation is observed as the delay approaches certain thresholds. We have made a number of new observations on various delay thresholds that are significant for loss prediction for adaptive audio transmission over IP networks. We also have made new observations to assess the audio quality of PCM µ-Law and G. 728 codecs under different loss and delay conditions. The paper provides a number of recommendations for implementing efficient adaptive FEC mechanisms based on our measurement observations and analysis...|$|R
40|$|SUMMARY We {{proposed}} and evaluated a speech <b>packet</b> <b>loss</b> concealment method which predicts lost segments from speech included in packets either before, or {{both before and}} after the lost packet. The lost segments are predicted recursively by using linear prediction both in the forward direction from the <b>packet</b> preceding the <b>loss,</b> and in the backward direction from the packet succeeding the lost segment. Predicted samples in each direction are smoothed by averaging using linear weights to obtain the final interpolated signal. The adjacent segments are also smoothed extensively to significantly reduce the speech quality disconti-nuity between the interpolated signal and the received speech signal. Subjective quality comparisons between the proposed method and the the <b>packet</b> <b>loss</b> concealment algorithm described in the ITU standard G. 711 Appendix I showed similar scores up to about 10 % <b>packet</b> <b>loss.</b> However, the proposed method showed higher scores above this loss rate, with Mean Opinion Score rating exceeding 2. 4, even at an extremely high <b>packet</b> <b>loss</b> <b>rate</b> <b>of</b> 30 %. <b>Packet</b> <b>loss</b> concealment <b>of</b> speech degraded with G. 729 coding, and babble noise mixed speech showed similar trends, with the proposed method showing higher qualities at high loss rates. We plan to further improve the performance by using adaptive LPC prediction order depending on the estimated pitch, and adaptive LPC bandwidth expansion depending on the consecutive num-ber of repetitive prediction, among many other improvements. We also plan to investigate complexity reduction using gradient LPC coefficient updates, and processing delay reduction using adaptive forward/bidirectional prediction modes depending on the measured <b>packet</b> <b>loss</b> ratio. key words: speech <b>packets,</b> <b>packet</b> <b>loss</b> concealment, linear pre-diction, segment smoothing, subjective speech quality evaluations 1...|$|R
