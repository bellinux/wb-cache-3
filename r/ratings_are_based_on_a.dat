12|10000|Public
25|$|Users can submit {{reviews and}} ratings for apps and digital content {{distributed}} through Google Play, which are displayed publicly. <b>Ratings</b> <b>are</b> <b>based</b> <b>on</b> <b>a</b> 5-point scale. App developers {{can respond to}} reviews using the Google Play Developer Console.|$|E
50|$|At the University of Colima's <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> <b>a</b> {{scale from}} 0.0 to 10.0. The maximum score is 10.0, and 6.0 is the minimum passing grade.|$|E
50|$|Users can submit {{reviews and}} ratings for apps and digital content {{distributed}} through Google Play, which are displayed publicly. <b>Ratings</b> <b>are</b> <b>based</b> <b>on</b> <b>a</b> 5-point scale. App developers {{can respond to}} reviews using the Google Play Developer Console.|$|E
50|$|<b>Ratings</b> <b>are</b> <b>based</b> <b>on</b> FCAT scores.|$|R
50|$|University <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> facilities, accommodation, security, a school's {{quality of}} education, research, and innovation. For lecturers, <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> attendance, quality of {{teaching}}, student engagement/communication, teaching methods, {{and knowledge of}} the curriculum. Users who cannot find lecturers on the website can manually add them thereto.|$|R
5000|$|Note: All <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> the AGB Nielsen Media Research ...|$|R
5000|$|Lack of {{comparability}} {{over time}} and space: For example, the WGI “Control of Corruption” for Eastern Europe and Central Asia has 23 different combinations of sources, but only four pair of countries <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> <b>a</b> common set of sources.|$|E
5000|$|Both <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> <b>a</b> {{probabilistic}} iterative-fitting model. In the Performance rating, point {{margins are}} converted into probabilities {{based on the}} standard deviation of a team's performance from its [...] "mean". In this case, a probabilistic model gives greater weight to points score in close games. For the Elo rating, probabilistic outcomes of one and zero are assigned to wins and losses, respectively. An iterative method has the distinct advantage when dealing with only wins and losses that a best fit short of infinity can be found for undefeated and winless teams. The Matrix-Elo {{was inspired by the}} Chess Elo rating system.|$|E
40|$|This study determines empirically the {{relationship}} between college teachers ' classroom performance and their involvement in research. The study {{is based on a}} national sample of approximately 5, 000 faculty members in 16 colleges. Ratings of classroom performance were derived from published course critiques and scholarship <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> <b>a</b> weighted publication score or citation score. Findings show that {{there is little or no}} correlation between teaching ratings and scholarly activities and, because of this, that universities shculd recruit faculty who are strong in both areas. Further investigation found that (1) professors teaching upper division and smaller enrollment courses receive better evaluations than colleagues in lower division and larger courses; (2) teachers in the languages received highest teacher ratings, followed by humanities, other social sciences, professional schools, physical an...|$|E
5000|$|Before 1 April 2003 the <b>ratings</b> <b>were</b> <b>based</b> <b>on</b> § 6 and 7 JÖSchG (Gesetz zum Schutze der Jugend in der Öffentlichkeit, law for {{protecting}} youth in public). Differences were: ...|$|R
50|$|After sanctioned tournaments are completed, the Tournament Organizer uploads {{the results}} of each match to POP. The results of each match are used to {{calculate}} a player's rating. POP <b>Ratings</b> <b>are</b> <b>based</b> <b>on</b> the Elo rating system.|$|R
5000|$|<b>Ratings</b> <b>are</b> <b>based</b> <b>on</b> the Live {{airing of}} 우리동네 예체능 on KBS2 on Tuesday 11.10pm kst. (Cool Kiz {{on the block}} which airs the English subbed version on KBSWorld TV on Tuesday 11.15pm airs 2 episodes late) ...|$|R
40|$|Stresses {{exceeding}} the absolute maximum ratings may damage the device. The device may not function or be opera-ble above the recommended operating conditions and stressing the parts to these levels is not recommended. In addi-tion, extended exposure to stresses above the recommended operating conditions may affect device reliability. The absolute maximum ratings are stress ratings only. Values are at TA = 25 °C unless otherwise noted. Note: 1. These ratings are limiting values above which the serviceability of the diode may be impaired. These <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> <b>a</b> maximum junction temperature of 200 °C. These are steady state limits. The factory should be consulted on applications involving pulsed or {{low duty cycle}} operations. Thermal Characteristics(2) Note: 2. Jedec Standard 51 - 3 method (PCB Board size 76 * 114 * 0. 6 Tmm 3...|$|E
30|$|Subsequent to the {{different}} ‘sustainability’ comprehensions, {{it makes sense to}} look at the investor groups’ assessments of how ecological, social, ethical, or sustainable actions affect the stock price of a company, in the long run. The respondents <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> <b>a</b> 5 -point Likert scale anchored by 1  = ‘negative’ and 5  = ‘positive’. Especially in the empirical sciences “it has become common practice to assume that Likert-type categories constitute interval-level rather than ordinal-level measurement” (Blaikie (2003)) and therefore to report mean values and t-test 9 results for the comparison of two independent samples. Knowing that this might be discussable and produce impreciseness due to the originally rather ordinal data measure, we additionally report the medians as well as the ranges and besides used the Wilcoxon test. This non-parametric alternative test-approach avoids the use of mean values which cannot adequately describe the location of a non-continuous distribution. The test results are generally quite robust: there are differences in significances only on rare occasions. Therefore, we primarily discuss mean values and t-test results and additionally allude to relevant divergences between the parametric and non-parametric tests.|$|E
40|$|The Prescribed Burn Risk Assessment Tool (BRAT) aims {{to improve}} the {{planning}} and conduct of prescribed burns. It provides the fire manager with a means to assess {{the risk of the}} fire escaping (likelihood of impact), the potential to do damage if it does escape (consequence), the effects of escape mitigation strategies in reducing the probability of escapes, and the potential benefits of the operation in meeting fire management objectives (benefits). This tool uses the concepts outlined in the Australian Standard for Risk Management (AS/NZS 4360 : 2004), a Standard applicable {{to a wide range of}} industries and situations. This standard provides a framework for establishing the risk management context and methods of analysis, evaluation, treatment, monitoring and communication of risk. The practitioner enters a ”low”, “moderate ” or “high ” rating for each of the escape risk factors, potential impact factors and the potential risk reduction benefit of the burn. These <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> <b>a</b> defined range of conditions for each factor. The spreadsheet then calculates the risk score for that criterion and combines them for all factors to produce an overall risk rating for the likelihood of the fire escaping, the risk of causing damage and the level of benefit to be potentially gained by...|$|E
50|$|<b>Ratings</b> <b>are</b> <b>based</b> <b>on</b> {{the average}} of the total ratings for Australian {{mainland}} capital cities.This episode was a one-hour series premiere.This episode aired half an hour later at 7pm due to a Seven News special in its regular timeslot.|$|R
50|$|<b>Ratings</b> <b>are</b> <b>based</b> <b>on</b> {{the quality}} and {{comprehensiveness}} of the features and benefits it offers. Defaqto rate individual propositions, not the provider of the product, across more than 60 categories - including banking, general insurance, life and protection, and pensions and investments.|$|R
2500|$|The Texas Education Agency (TEA) has {{awarded the}} District [...] "Superior" [...] ratings in the Financial Integrity Rating System of Texas (FIRST) {{for eight years}} in a row (2003–2010). [...] These <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> {{criteria}} including low administrative spending, low student-teacher ratios, and more.|$|R
40|$|Recommender systems provide {{consumers}} with ratings of items. These <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> <b>a</b> set of ratings that {{were obtained from}} a wide scope of users. Predicting the ratings can be formulated as a regression problem. Ensemble regression methods are effective tools that improve the results of simple regression algorithms by iteratively applying the simple algorithm to a diverse set of inputs. The present paper describes a simple and effective ensemble regressor for the prediction of missing ratings in recommender systems. The ensemble method is an adaptation of the AdaBoost regression algorithm for recommendation tasks. In all iterations, interpolation weights for all nearest neighbors are simultaneously derived by minimizing the root mean squared error. From iteration to iteration instances {{that are hard to}} predict are reinforced by manipulating their weights in the goal function that needs to be minimized. The experimental evaluation demonstrates that the ensemble methodology significantly improves the predictive performance of single neighborhood-based collaborative filtering. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specifi...|$|E
40|$|The AODP Global Climate Index {{was first}} {{published}} in 2012 and provided stakeholders with a ranking and rating to indicate how each major asset owner performs in managing their exposure to climate risk. The objective of the survey is to facilitate incorporation of climate change capability in the pension and superannuation industry and throughout the wider investment sector. The launch of AODP's fourth global survey comes ahead of the critical 2015 Paris Climate Conference in December, which will see nations thrash out a legally binding and universal agreement on climate. AODP sends survey invitations to the world's largest long-term investors (pension funds, insurers, sovereign wealth funds, foundations and endowments) with at least USD 2 billion assets under management. The survey comprises approximately 40 multiple-choice questions covering the following three key areas assessing the asset owner's capability in managing portfolio climate risk: Engagement / The degree to which asset owners transparently disclose information to and actively engage with the general public and the investment chain: i. e. their members and stakeholders, investment consultants, asset managers and investee companies. Portfolio Carbon Risk Management / How effectively asset owners are measuring, monitoring and managing climate change risks within their portfolios. Hedging & Low- carbon investment / The extent of any low-carbon investments held by the asset owner. An asset owner's ranking within each of these categories will be provided back to each asset owner, highlighting where they need to improve and how. The <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> <b>a</b> mixture of publicly available information and asset owner disclosures. Survey responses are used to rank and rate the asset owners to create the AODP Global Climate Index, to be released in April 2016. The top 500 asset owners (by AUM) that decline the invitation to participate are researched by our team of analysts and assessed using publicly available information or information provided to us by their members or stakeholders. Asset owners are rated from AAA through to D grade, with an additional X category for those asset owners that appear to be doing absolutely nothing to manage climate risk. Disclosure / Points awarded for making the survey response public. Performance / Points awarded for implementing elements of climate change best practic...|$|E
40|$|Financial {{instruments}} today {{often are}} issued along with assessments of their quality by credit rating agencies (“CRAs”). The assessments {{are in the}} form of ratings (A, B+, B, etc.). These <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> (<b>a)</b> the risk that the issuer of an instrument will default; and (b) the effectiveness of debt collection conditional on default. The effectiveness of debt collection, in turn, is a function of (c) the quality of the law that will be applied to assess the parties’ rights and obligations; and (d) the efficiency of the legal system in which the instrument will be enforced. The higher is the rating, the lower is the interest rate the issuer must pay. Professor du Marais and his colleagues analyze the way CRAs condition their ratings on the effectiveness of debt collection. Three such agencies are studied: Standard and Poor, Moody’s and Fitch. The method used was to conduct interviews of “stakeholders”, the CRAs, “top managers of all kinds of issuers”, and staff of the regulators. All of these interviews were conducted in France. The paper does not distinguish clearly between the quality of law to be applied and the efficiency of the collection system. It is unclear whether the CRAs make this distinction clearly themselves. In any event, the paper has two positive conclusions: (a) CRAs prefer statutes to cases. That is, they give greater weight to a desirable legal rule that is contained in a statute than to the same rule that is the product of high court opinions; and (b) CRAs give greater weight to instruments that will be controlled by and enforced in the legal systems of England and the US than to the French legal system and systems similar to it. The CRAs’ preferences are consequential, amounting to several interest rate points for an issue. The paper claims that the CRAs are making a mistake. In the authors’ view, CRAs are using “doubtful indicators”, and their preferences reflect “unscientifically based biases”. As a consequence of these deficiencies, CRAs “are undervaluing the bonds and securities issued in markets belonging to the less preferred legal traditions”. This paper is in the line of papers that make serious studies of private institutions that affect the law and markets. These institutions have not received sufficient scrutiny, so this paper is welcome. In my view, the paper’s positive findings are valuable but its normative critique needs more work. Thus, this Comment should be taken as a request for further research. My remarks are in three categories: market responses; ratings criteria; and data issues...|$|E
50|$|J.D. Power and Associates' {{marketing}} research consists primarily of consumer surveys. J.D. Power <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> the survey responses of randomly selected and/or specifically targeted consumers. J.D. Power relies on consumer reporting for study results {{as well as}} in-house vehicle testing for opinion based reviews in blogs.|$|R
5000|$|The [...] "initial hypothesis" [...] for the <b>ratings</b> <b>is</b> <b>based</b> <b>on</b> six core metrics, {{for which}} {{institutions}} receive a double-positive flag, a positive flag, no flag, a negative flag or a double-negative flag, {{depending on whether}} they exceed or fall short of their benchmark by certain thresholds. These are: ...|$|R
50|$|The goal of {{the council}} was to provide {{objective}} content ratings for computer games, similar to the earlier formed Videogame Rating Council (VRC) and later Entertainment Software Rating Board (ESRB). The RSAC <b>ratings</b> <b>were</b> <b>based</b> <b>on</b> the research of Dr. Donald F. Roberts of Stanford University who studied media {{and its effect on}} children.|$|R
50|$|<b>Ratings</b> shown <b>were</b> <b>based</b> <b>on</b> {{the latest}} {{statistics}} as of 24 March 2015.|$|R
50|$|In 2001 a {{research}} paper said that US News <b>ratings</b> <b>were</b> <b>based</b> <b>on</b> medical school assessments, counts of research publications, student opinion surveys, and counts of faculty. The paper {{noted that the}} rankings were broadly accepted, cited, and used to make decisions by all sorts of stakeholders. The public image of the rankings {{was that they were}} unbiased.|$|R
2500|$|In 2007, {{the city}} was {{named one of the}} top four [...] "places to watch" [...] in the United States by the American Association of Retired Persons (AARP). The <b>ratings</b> <b>were</b> <b>based</b> <b>on</b> what <b>was</b> {{perceived}} as ideal qualities for older residents. Criteria included the factors that make a community livable: new urbanism, smart growth, mixed-use development, and easy-living standards.|$|R
50|$|The DBRS {{short-term}} debt rating scale provides {{an opinion on}} the risk that an issuer will not meet its short-term financial obligations in a timely manner. <b>Ratings</b> <b>are</b> <b>based</b> <b>on</b> quantitative and qualitative considerations relevant to the issuer and the relative ranking of claims. The R-1 and R-2 rating categories are further denoted by the subcategories “(high)”, “(middle)”, and “(low)”.|$|R
50|$|Pearl High School is {{currently}} rated a 5, {{which is the}} highest education level a school can reach in our Nation's Standard as set down by the No Child Left Behind Act, signed by President George W. Bush. Schools <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> the Mississippi Curriculum Tests, which are issued every year to determine a school's effectiveness on its students.|$|R
5000|$|In 2007, {{the city}} was {{named one of the}} top four [...] "places to watch" [...] in the United States by the American Association of Retired Persons (AARP). The <b>ratings</b> <b>were</b> <b>based</b> <b>on</b> what <b>was</b> {{perceived}} as ideal qualities for older residents. Criteria included the factors that make a community livable: new urbanism, smart growth, mixed-use development, and easy-living standards.|$|R
5000|$|The second {{division}} of FAB <b>is</b> the FAB <b>Ratings</b> System. Originally developed by Elayne Blythe in four categories ("L", [...] "V", [...] "N" [...] and [...] "S", for (respectively) Language, Violence, Nudity and Sex), {{the present system}} was developed in 1988 {{at the request of}} independent film makers and distributors {{as an alternative to the}} Motion Picture Association of America film rating system. The FAB <b>ratings</b> system <b>is</b> intended to be less costly and more informative than the MPAA's system. The <b>ratings</b> fee <b>is</b> <b>based</b> <b>on</b> the film's running time instead of negative cost, and the <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> the level of maturity of the material's intended audience, rather than the film's content.|$|R
50|$|Angie's List members grade {{companies}} using a report-card-style scale, which {{ranges from}} A to F; these <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> the following criteria: price, quality, responsiveness, punctuality and professionalism. Each company {{has its own}} page, which is composed of a description of its business along with the customer reviews. The aggregate grade is drawn from the combined reviews and grades given to the businesses from the consumers.|$|R
5000|$|FIDE updates its ratings list at the {{beginning}} of each month. In contrast, the unofficial [...] "Live ratings" [...] calculate the change in players' ratings after every game. These Live <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> the previously published FIDE ratings, so a player's Live rating is intended to correspond to what the FIDE rating would be if FIDE were to issue a new list that day.|$|R
50|$|The film {{received}} generally positive reviews. <b>Ratings</b> shown <b>were</b> <b>based</b> <b>on</b> {{the latest}} statistics as of 28 March 2015.|$|R
30|$|Another {{direction}} of using results is compounding of ranking of regional innovation activity. Typically, these <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> performance-related research activities and economic potential. Innovation network variable is not considered, since {{the creation of}} relevant indicators {{that can be used}} for inter-regional comparisons, is a nontrivial task. Instead researchers use different ratings of the institutional environment. In my opinion, the use of the indicator directly related to the commercialization of innovation is more productive.|$|R
5000|$|As a top-five {{finisher}} for {{the third}} consecutive year, Perot Systems was named to the Fortune magazine “Most Admired Companies in America” list for IT Services in 2008. Company <b>ratings</b> <b>are</b> <b>based</b> <b>on</b> eight criteria, ranging from investment value and quality of products/services to innovation and quality of management. According to a survey Dell Services (the successor of Perot Systems) was ranked #1 as an IT provider in the US healthcare market ...|$|R
