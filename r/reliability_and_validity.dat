8707|10000|Public
5|$|The then-General Accounting Office (GAO) {{has issued}} reports since VA started {{gathering}} data in 2000 on veterans' wait {{times to be}} scheduled for an appointment and these GAO reports have called into question the <b>reliability,</b> <b>and</b> <b>validity,</b> of VA's wait time data.|$|E
5|$|The National Institute of Neurological and Communicative Disorders and Stroke (NINCDS) and the Alzheimer's Disease and Related Disorders Association (ADRDA, {{now known}} as the Alzheimer's Association) {{established}} the most commonly used NINCDS-ADRDA Alzheimer's Criteria for diagnosis in 1984, extensively updated in 2007. These criteria require that the presence of cognitive impairment, and a suspected dementia syndrome, be confirmed by neuropsychological testing for a clinical diagnosis of possible or probable AD. A histopathologic confirmation including a microscopic examination of brain tissue is required for a definitive diagnosis. Good statistical <b>reliability</b> <b>and</b> <b>validity</b> have been shown between the diagnostic criteria and definitive histopathological confirmation. Eight cognitive domains are most commonly impaired in AD—memory, language, perceptual skills, attention, constructive abilities, orientation, problem solving and functional abilities. These domains are equivalent to the NINCDS-ADRDA Alzheimer's Criteria as listed in the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV-TR) published by the American Psychiatric Association.|$|E
5|$|The {{variety of}} {{positivism}} that remains dominant today is termed instrumental positivism. This approach eschews epistemological and metaphysical concerns (such as {{the nature of}} social facts) in favour of methodological clarity, replicability, <b>reliability</b> <b>and</b> <b>validity.</b> This positivism {{is more or less}} synonymous with quantitative research, and so only resembles older positivism in practice. Since it carries no explicit philosophical commitment, its practitioners may not belong to any particular school of thought. Modern sociology of this type is often credited to Paul Lazarsfeld, who pioneered large-scale survey studies and developed statistical techniques for analysing them. This approach lends itself to what Robert K. Merton called middle-range theory: abstract statements that generalize from segregated hypotheses and empirical regularities rather than starting with an abstract idea of a social whole.|$|E
5000|$|Research {{should be}} tested for <b>reliability,</b> generalizability, <b>and</b> <b>validity.</b>|$|R
5000|$|One study {{provided}} some {{evidence for the}} test-retest <b>reliability</b> <b>and</b> predictive <b>validity.</b>|$|R
40|$|This {{research}} was conducted to help counseling psychologists be able to better understand Asian international students’ unique acculturative and adaptive experiences. Because the current literature lacks a specific acculturation scale for Asian international students, developing a proper acculturation scale that represented these students was the significant contribution of this study. Confirmatory factor analysis (CFA) with 259 participants {{was used to test}} the four factor structure of the 33 -item Acculturation Scale for Asian International Students (ASAIS), which was based on Berry’s (1984, 1990) theory. <b>Reliabilities</b> <b>and</b> <b>validities</b> estimates were also examined. Cluster analysis and Multivariate Analysis of Variance (MANOVA) were used to explore acculturation status differences on perceived gain and loss, and coping. The results indicated that the ASAIS had good internal consistency <b>and</b> acceptable <b>reliabilities</b> <b>and</b> <b>validities.</b> In addition, results indicated that there were significant group differences in Reflective and Reactive coping styles. ...|$|R
25|$|Both {{invasive}} and non-invasive {{approaches are}} used. The <b>reliability</b> <b>and</b> <b>validity</b> of the non-invasive approach has gained some acceptance, {{although there is}} not complete agreement on this point. The clinical use of this approach in the diagnosis, prognosis and therapy {{of a variety of}} diseases continues.|$|E
25|$|Key {{concepts}} in classical test theory are <b>reliability</b> <b>and</b> <b>validity.</b> A reliable measure {{is one that}} measures a construct consistently across time, individuals, and situations. A valid measure is one that measures what {{it is intended to}} measure. Reliability is necessary, but not sufficient, for validity.|$|E
25|$|Industrial and {{organizational}} psychologists consider innovation, {{more often than}} not, a variable of less importance and often a counter-productive one to include in conducting job performance appraisals when irrelevant to the major job functions for which a given job exists. Nonetheless, I/O psychologists see the value of that variable where its consideration would, were its <b>reliability</b> <b>and</b> <b>validity</b> questioned, achieve a statistically significant probability that its results are not due to chance, and {{that it can be}} replicated reliably with a statistically significant ratio of reliability, and that were a court to raise a question on its <b>reliability</b> <b>and</b> <b>validity</b> testing, the I/O psychologist behind its use would be able to defend it before a court of justice with the belief that it will stand before such a court as reliable, and valid.|$|E
40|$|BACKGROUND AND PURPOSE: Women {{use their}} {{cumulative}} breastfeeding experiences, {{in combination with}} other factors, to make their infant feeding decisions. This pilot study assessed the <b>reliability</b> <b>and</b> predictive <b>validity</b> of the revised Beginning Breastfeeding Survey-Cumulative (BBS-C). METHODS: 25 women were recruited prenatally from a university hospital. The BBS-C was completed before hospital discharge. Infant feeding outcomes were measured at 1 and 3 months postpartum. RESULTS: Participants were 17 - 40 years old, mostly married, Whites, and well-educated. Coefficient alpha was. 92 -. 94. The BBS-C predicted an infant not receiving breast milk, not feeding from the breast, and receiving infant formula feedings. CONCLUSIONS: In this sample, the BBS-C had strong <b>reliability</b> <b>and</b> predictive <b>validity.</b> Further testing should assess <b>reliability</b> <b>and</b> predictive <b>validity</b> in a wider range of populations and settings...|$|R
40|$|BACKGROUND: Clinical sub-groups of schizophrenia, namely drug related, traumatic, {{anxiety and}} stress {{sensitivity}} sub-types, {{have been proposed}} for use in research, training and practice. They were developed {{on the basis of}} clinical observation but have not yet been used in research or clinical practice to any great extent. AIMS: To develop a semi-structured clinical interview for psychosis sub-groups (SCIPS) and determine the best diagnostic criteria with the highest inter-rater <b>reliability,</b> test-retest <b>reliability</b> <b>and</b> concurrent <b>validity</b> for sub-grouping patients with schizophrenia according to a newly developed classification scheme. METHODS: The SCIPS was developed based upon discussion with the clinician researchers who had developed and were using the sub-groups. Kappa coefficients were calculated between two independent diagnostic assessments with the SCIPS (for inter-rater <b>reliability</b> <b>and</b> test-retest <b>reliability,</b> n = 20) and between the SCIPS diagnosis and the sub-groupings as determined independently with highest achievable validity (for concurrent validity, n = 21) for patients with schizophrenia. These inter-rater <b>reliability</b> <b>and</b> concurrent <b>validity</b> were compared among five different sets of diagnostic criteria to determine which was most reliable and valid. RESULTS: A set of diagnostic criteria with the highest inter-rater <b>reliability</b> <b>and</b> concurrent <b>validity</b> was determined. Kappa coefficients (95 % confidence interval) for the inter-rater <b>reliability</b> <b>and</b> concurrent <b>validity</b> were 0. 93 (0. 66 - 1. 20) and 0. 73 (0. 47 - 1. 00), respectively, with these diagnostic criteria. CONCLUSIONS: The SCIPS is a promising tool with which to sub-group patients with schizophrenia according to this recently developed classification scheme. The semi-structured interview achieves acceptable inter-rater <b>and</b> test-retest <b>reliability</b> <b>and</b> concurrent <b>validity...</b>|$|R
30|$|The {{purpose of}} this study was to assess the Thai version of the SRS- 22 and to {{determine}} its <b>reliability</b> <b>and</b> concurrent <b>validity.</b>|$|R
25|$|Those {{psychological}} {{researchers who}} prefer qualitative research argue that statistically based research has limitations {{because it is}} less able {{to take into consideration}} the context of behaviour. Qualitative researchers have developed their own criteria for assessing <b>reliability</b> <b>and</b> <b>validity.</b> The work of Yvonna Lincoln and Egon Guba is an example of this.|$|E
25|$|The VADRS is {{a fairly}} new {{instrument}} with incomplete data on <b>reliability</b> <b>and</b> <b>validity,</b> and consequently, its use in a clinical population has not been fully analyzed. Additionally, normative data has only been collected in a localized population and only for the teacher version. Relating to the measure itself, its comorbidity subscales are not based on the DSM-IV {{like the rest of}} the measure, and the current incarnation of the VADRS has not been adapted for DSM-5 criteria.|$|E
25|$|There are two {{versions}} available: a parent form that contains 55 questions, {{and a teacher}} form that contains 43 questions. Shorter follow-up versions of the VADRS are also available for parents and teachers and consists of 26 questions with an additional 12 side effect measures. Comparing scores from the {{different versions of the}} VADRS with other psychological measures have suggested the scores have good but limited <b>reliability</b> <b>and</b> <b>validity</b> across multiple samples. The VADRS has only been recently developed, however, so clinical application of the measure is limited.|$|E
40|$|Objectives: To {{examine the}} <b>validity</b> <b>and</b> <b>reliability</b> of a {{modified}} Sedentary Behavior Strategy Self-Management Scale (SBSMS) {{in a sample}} of breast cancer survivors. Methods: A total of 291 African-American (AA) breast cancer survivors completed the SBSMS, which was subjected to tests of <b>reliability,</b> structural <b>validity,</b> <b>and</b> tests of measurement equivalence/invariance (ME/I). Results: A revised measurement model fit the data <b>and</b> demonstrated internal <b>reliability</b> <b>and</b> structural <b>validity.</b> Tests for ME/I revealed that the revised model had appropriate levels of invariance among weight status, educational, and years out from diagnosis groups, but not among age groups. Conclusion: The <b>reliability</b> <b>and</b> structural <b>validity</b> of the instrument was supported overall; however, revisions may be needed to support its validity in older AA breast cancer survivors...|$|R
5000|$|Marks (1995) {{published}} {{a new version}} of the VVIQ, the VVIQ2. This questionnaire consists of twice the number of items and reverses the rating scale so that higher scores reflect higher vividness. Campos and Pérez-Fabello (2009) evaluated the <b>reliability</b> <b>and</b> construct <b>validity</b> of the VVIQ and the VVIQ2. Cronbach a reliabilities for both the VVIQ and the VVIQ-2 were found to be high. Estimates of internal consistency <b>reliability</b> <b>and</b> construct <b>validity</b> were found to be similar for the two versions.|$|R
30|$|SOMS- 5 {{does have}} {{sufficient}} <b>reliability</b> <b>and</b> factor <b>validity.</b> Because of its frequent usage in recent years, its Japanese version {{can be used}} without difficulty.|$|R
25|$|Ligand binding assays {{provide a}} measure of the {{interactions}} that occur between two molecules, such as protein-bindings, as well as the degree of affinity (weak, strong, or no connection) for which the reactants bind together. Essential aspects of binding assays include, but are not limited to, the concentration level of reactants or products (see radioactive section), maintaining the equilibrium constant of reactants throughout the assay, and the <b>reliability</b> <b>and</b> <b>validity</b> of linked reactions. Although binding assays are simple, they fail to provide information on whether or not the compound being tested affects the target's function.|$|E
25|$|The Test to Measure Upper Limb Apraxia (TULIA) is {{one method}} of {{determining}} upper limb apraxia through the {{qualitative and quantitative}} assessment of gesture production. In contrast to previous publications on apraxic assessment, the <b>reliability</b> <b>and</b> <b>validity</b> of TULIA was thoroughly investigated. The TULIA consists of subtests for the imitation and pantomime of non-symbolic (“put your index finger {{on top of your}} nose”), intransitive (“wave goodbye”) and transitive (“show me how to use a hammer”) gestures. Discrimination (differentiating between well- and poorly performed tasks) and recognition (indicating which object corresponds to a pantomimed gesture) tasks are also often tested for a full apraxia evaluation.|$|E
25|$|There {{are many}} self-report {{measures}} of EI, including the EQ-i, the Swinburne University Emotional Intelligence Test (SUEIT), and the Schutte EI model. None of these assess intelligence, abilities, or skills (as their authors often claim), but rather, they are limited measures of trait emotional intelligence. The {{most widely used}} and widely researched measure of self-report or self-schema (as it is currently referred to) emotional intelligence is the EQ-i 2.0. Originally known as the BarOn EQ-i, {{it was the first}} self-report measure of emotional intelligence available, the only measure predating Goleman's best-selling book. There are over 200 studies that have used the EQ-i or EQ-i 2.0. It has the best norms, <b>reliability,</b> <b>and</b> <b>validity</b> of any self-report instrument and was the first one reviewed in Buros Mental Measures Book. The EQ-i 2.0 is available in many different languages as it is used worldwide.|$|E
40|$|Nutritional studies {{often use}} the terms <b>reliability,</b> {{reproducibility}} <b>and</b> <b>validity</b> {{to indicate the}} correctness of the study. These terms {{do not appear to}} have a universal meaning to all researchers. The components of a dietary study are the input, the data collection instrument and the compiled data. Frequently the data collection questionnaire/tooVinstrument is tested for reliability, reproducibility or validity. The data collection questionnaire/tooVinstrument is simply a structure, a vehicle for gathering data. An argument is presented that demonstrates the reasons that such a structure cannot be tested for reliability, reproducibility or validity. The logical approach {{to the use of the}} terms <b>reliability,</b> reproducibility <b>and</b> <b>validity</b> is presented. <b>Reliability</b> refers to the input component of the study, reproducibility may or may not lead to strengthening the study <b>and</b> <b>validity</b> refers to the truthfulness of the database generated. Validity must be derived from reliable and reproducible data. Frequently, nutritional studies use the terms <b>reliability,</b> reproducibility <b>and</b> <b>validity</b> of dietary questionnaires as a measure of the correctness of the study...|$|R
40|$|Italian {{guidelines}} {{require a}} 4 -level in hospital triage {{based on an}} acuity scale measurement, but they don’t suggest common guidelines neither which triage models to adopt. Thus each hospital developed own triage guidelines based on consensus. But, to our knowledge, there aren’t data on the <b>reliability</b> <b>and</b> predictive <b>validity</b> of triage systems adopted by Italian Emergency Department. Also in the ED of Imola, a triage working group developed Guidelines on triage in 2001. In this study we measured the <b>reliability</b> <b>and</b> predictive <b>validity</b> of the Imola Triage Guidelines (LGTI) ...|$|R
40|$|Although the {{measurement}} of self-leadership (RSLQ) has been developed and validated with samples from the US with promising <b>reliability</b> <b>and</b> construct <b>validity,</b> its generalizability to other non-western context is problematic. In order to enhance the generalizability of self-leadership theory to the Chinese context, {{the authors of this}} study extend the breadth of self-leadership dimensions and refine its measurement based on the cross-cultural theory about self-concept differences between individualism <b>and</b> collectivism. The <b>reliability</b> <b>and</b> construct <b>validity</b> of this refined self-leadership scale are explored using exploratory (EFA) and confirmatory factor analysis (CFA). 3 page(s...|$|R
25|$|The Child PTSD Symptom Scale (CPSS) {{is a free}} {{checklist}} {{designed for}} children and adolescents to report traumatic events and symptoms that they might feel afterward. The items cover the symptoms of posttraumatic stress disorder (PTSD), specifically, the symptoms and clusters used in the DSM-IV. Although relatively new, {{there has been a}} fair amount of research on the CPSS due to the frequency of traumatic events involving children. The CPSS is usually administered to school children within school boundaries, or in an off-site location to assess symptoms of trauma. Some, but not all, people experience symptoms after a traumatic event, and in serious cases, these people may not get better on their own. Early and accurate identification, especially in children, of experiencing distress following a trauma could help with early interventions. The CPSS {{is one of a handful}} of promising measures that has accrued good evidence for <b>reliability</b> <b>and</b> <b>validity,</b> along with low cost, giving it good clinical utility as it addresses a public health need for better and larger scale assessment.|$|E
2500|$|Boyd EA, Goudreau L, O'Riain MD, et al.: A {{radiological}} {{measure of}} shoulder subluxation in hemiplegia: its <b>reliability</b> <b>and</b> <b>validity.</b> Arch Phys Med Rehabil 1993 Feb; 74(2): 188-93 ...|$|E
2500|$|Both <b>reliability</b> <b>and</b> <b>validity</b> can be {{assessed}} statistically. Consistency over repeated measures of the same test can {{be assessed}} with the Pearson correlation coefficient, and is often called test-retest reliability. [...] Similarly, [...] the equivalence of {{different versions of the}} same measure can be indexed by a Pearson correlation, and is called equivalent forms reliability or a similar term.|$|E
40|$|Cataloged from PDF {{version of}} article. This study {{examined}} the relationship between face <b>validity</b> <b>and</b> relatively more objective measures of tests, such as <b>reliability</b> <b>and</b> predictive <b>validity.</b> The study also examined the face <b>validity,</b> <b>reliability</b> <b>and</b> predictive <b>validity</b> of the achievement tests administered at Zonguldak Karaelmas University Preparatory School. The instruments employed in this study were two questionnaires and C- (beginner) level students’ test scores. First, instructors and students were given questionnaires to define the degree of face <b>validity</b> <b>and</b> <b>reliability</b> of the achievement tests. Second, the correlations between students’ first term averages, second term averages, cumulative averages and the end-of-course assessment scores were examined to find the degree of predictive validity. Analysis of data revealed that face validity does not contradict with more objective measures of tests, such as <b>reliability</b> <b>and</b> predictive <b>validity.</b> However, face <b>validity</b> <b>and</b> <b>reliability</b> analyses revealed some important weaknesses in the local testing system. These weaknesses would not have been revealed if the researcher had looked at only face validity, or only reliability, or only predictive validity of the tests. Therefore, {{it is very important to}} look at tests from multiple perspectives, and get information from a variety of sources. Additionally, it has been found that the face <b>validity,</b> <b>reliability</b> <b>and</b> predictive <b>validity</b> of the achievement tests administered at Zonguldak Karaelmas University Preparatory School are high in spite of the weaknesses that were revealed in the analysis. Küçük, FundaM. S...|$|R
40|$|The aim of {{this study}} was to {{determine}} the internal consistency, test-retest <b>reliability</b> <b>and</b> concurrent <b>validity</b> of the RSI QuickScan, a newly developed questionnaire that aims to identify the presumed risk factors for neck, shoulder and arm symptoms in a population of computer workers. The internal consistency was calculated using item analysis. The test-retest <b>reliability</b> <b>and</b> concurrent <b>validity</b> were analysed by calculating the percentage of agreement, Cohen's Kappa and the Ppositive and Pnegative. The concurrent validity was also tested by comparing the results from the new questionnaire with those from the original questionnaires that the current questionnaire was based on, on-site expert observations and direct measurements. The results indicate that the RSI QuickScan is a measurement tool with acceptable internal consistency, <b>reliability</b> <b>and</b> concurrent <b>validity.</b> The questionnaire can be used as a means to rapidly collect data on a large population of office workers and at low cost. © 2009 Taylor & Francis...|$|R
40|$|This study {{developed}} a scale to measure customer psychological empowerment. Focus group and in-depth interviews {{were used to}} generate items. Three separate studies were undertaken with different sampling methods in different service industries to refine the scale. Exploratory and confirmatory factor analyses were performed to identify and confirm the factor structure. Convergent, discriminant, nomological, <b>and</b> criterion <b>validities</b> were reported prior to testing internal <b>and</b> external <b>validities.</b> The customer psychological empowerment scale {{was determined to be}} a second-order factor model consisting of three subdimensions: service choice, information attainment, and impact. The scale generates high <b>reliability</b> <b>and</b> <b>validities...</b>|$|R
2500|$|In Research on Aging, Idler {{and other}} working group members {{reported}} results of in-depth analyses {{of data from}} administering the BMMRS in the 1998 General Social Survey. The various BMMRS questions [...] "had the expected relationships with other measures of [...] concepts. Overall, the instrument has the appropriate characteristics of <b>reliability</b> <b>and</b> <b>validity</b> {{to be used in}} further research." [...] (p.356). Another analysis of the same data suggested that the BMMRS [...] "is useful for ...|$|E
2500|$|Of all the {{questions}} on the scale, Sell considered those assessing sexual attraction {{to be the most}} important as sexual attraction is a better reflection of the concept of sexual orientation which he defined as [...] "extent of sexual attractions toward members of the other, same, both sexes or neither" [...] than either sexual identity or sexual behavior. Identity and behavior are measured as supplemental information because they are both closely tied to sexual attraction and sexual orientation. Major criticisms of the SASO have not been established, but a concern is that the <b>reliability</b> <b>and</b> <b>validity</b> remains largely unexamined.|$|E
2500|$|An {{assessment}} protocol {{has been}} developed by the U.S. National Registry of Evidence-Based Practices and Programs (NREPP). Evaluation under this protocol occurs only if an intervention has already had one or more positive outcomes, with a probability of less than [...]05, reported, if these {{have been published in}} a peer-reviewed journal or an evaluation report, and if documentation such as training materials has been made available. The NREPP evaluation, which assigns quality ratings from 0 to 4 to certain criteria, examines <b>reliability</b> <b>and</b> <b>validity</b> of outcome measures used in the research, evidence for intervention fidelity (predictable use of the treatment in the same way every time), levels of missing data and attrition, potential confounding variables, and the appropriateness of statistical handling, including sample size.|$|E
40|$|The Health Information Orientation Scale (HIOS) was {{developed}} from {{a need to}} briefly assess information orientation in a health context and underlying reasons for information seeking or avoidance. Using data from a larger longitudinal study of informal cancer caregivers, this study examines {{psychometric properties of the}} HIOS, including confirmatory factor analysis (CFA), <b>reliability</b> <b>and</b> construct <b>validity</b> through associations with information competence, coping and distress. CFA supported two conceptually unique factors: Information Engagement and Information Apprehension. Each factor demonstrated adequate <b>reliability</b> <b>and</b> construct <b>validity,</b> providing promising findings regarding Information Engagement and Information Apprehension, specific to a health context...|$|R
50|$|Thombs, B., Bernstein, D. P., Lobbestael, J., & Arntz, A. (2009). A {{validation}} {{study of the}} Dutch Childhood Trauma Questionnaire-Short Form: factor structure, <b>reliability,</b> <b>and</b> known-groups <b>validity.</b> Child Abuse <b>and</b> Neglect, 33, 518-523.|$|R
40|$|This article {{describes}} the development, the <b>reliability,</b> <b>and</b> the <b>validity</b> of the Personality Functioning Scale (PFS), an instrument based on the conceptual and empirical works of McGlashan and Miller (1982) and McGlashan (1984). The PFS consists of 31 items grouped into 8 domains: developmental level, aspects of the self, object relatedness, reality acceptance, fullness of experience, coping mechanisms, integrative capacity and self analytic functions. Two clinical samples (borderline personality disorder = 69, schizophrenia = 34) were {{used to evaluate the}} <b>reliability</b> <b>and</b> the <b>validity</b> of the PFS. The scale showed high internal consistency (. 97), test-retest <b>reliability</b> (. 90), <b>and</b> criterion <b>validity</b> (. 96;. 94;. 98;. 94;. 97). The construct validity of the scale was confirmed by the results of the factor analysis. The PFS is proposed for use both in the dynamic evaluation of personality (diagnostic area) and in the evaluation of the results of psychotherapy...|$|R
