18|213|Public
40|$|The ISO/IEC MPEG- 2 Audio NBC (Non Backwards Compatible) audio coding {{work was}} started to provide MPEG- 2 {{with the best}} audio quality at low data rates without any {{restrictions}} due to compatibility requirements. This paper describes the main features of the NBC advanced coding system (CD 13818 - 7). NBC combines the coding efficiency of a high <b>resolution</b> <b>filter</b> bank, prediction techniques and Huffmann coding with additional functionalities aimed to deliver broadcast quality at very low data rates (64 kb/s per channel) ...|$|E
40|$|In the past, it {{has often}} been assumed that when a high {{frequency}} <b>resolution</b> <b>filter</b> bank was used in a coding system, no easy access to the signal's temporal fine structure was possible. This paper presents the general framework for accessing and manipulation the temporal structure of signals by using the dual of the standard "LPC" paradigm, i. e. predicting in frequency instead of time. Examples for the application of this principle are given including the Temporal Noise Shaping (TNS) technique of the ISO/MPEG- 2 Advanced Audio Coding system...|$|E
40|$|The paper {{presents}} a critical comparison of some spectrum analyzer-based measurement techniques {{for the evaluation}} of the environmental electromagnetic field intensity. The goal is both to show when a given technique can be more efficiently exploited and to suggest practical hints for improving accuracy and measurement time. To this aim, suitable experimental examples provided on some real-life telecommunication signals are proposed. The examples show that better results can be easily achieved by following some simple guidelines on the choice of analyzer parameters such as the <b>resolution</b> <b>filter</b> bandwidth, the frequency span and the number of sweeps...|$|E
40|$|Silicon {{microspheres}} can be {{used for}} free space optical communication applications in the THz communication bands. The morphology dependent resonances of the microsphere have quality factors of 100000, which provide the narrow linewidths for high <b>resolution</b> <b>filtering,</b> Raman lasers, modulators, and CMOS compatible detectors...|$|R
40|$|Liquid Crystal Arrayed Microcavities (LCAM) {{is a new}} {{technology}} for ultra-narrow optical filtering (FWHM ~ 0. 1 nm) that uses pico-liter volume Fabry-Perot type optical cavities filled with liquid crystal for tuning. LCAMs are sub-nm spectral <b>resolution</b> <b>filters,</b> which utilize well-established laser writing, thin film deposition, and wafer manufacturing techniques. These filters are compact, robust, and inexpensive. Compact, high-resolution optical filters have applications including biomedical imaging, chemical detection, and environmental monitoring. Here we describe the LCAM design and initial performance metrics...|$|R
40|$|When a {{hazardous}} substance is diffused, {{it is necessary}} to identify the pollutant source and respond immediately. However, there are many cases in which damage is caused without a clear understanding of where the pollutant source is located. There are three groups of identifying pollutant source information (Liu and Zhai, 2007) : the probability method, forward method, and backward method. In our previous study, we proposed reverse simulation, which is categorized as a backward method (Abe and Kato, 2011). Numerical instability by negative diffusion is a principal problem in the backward method. In order to improve the problem, we applied a low-pass filter operation to the concentration flux in the RANS analysis. The simulation secured the numerical stability. However, reverse simulation accuracy is expected to depend on the grid <b>resolution</b> and <b>filter</b> width. In this paper, we introduce reverse simulation results in cavity flow. In particular, we survey the dependence of reverse simulation accuracy on the grid <b>resolution</b> and <b>filter</b> width. Moreover, we discuss the dependence of reverse simulation on the grid <b>resolution</b> and <b>filter</b> width with a one-dimensional diffusion equation. As a result, we found that the simulated negative diffusion varies greatly among the grid <b>resolution</b> and <b>filter</b> width...|$|R
40|$|An optimal use of shared-earth {{modeling}} is {{hampered by}} the fact that simulating a migrated image that can be compared directly to the real migrated image is time-consuming. The key to enable iterative testing of different geological scenarios is to filter a shared-earth model by a spatial <b>resolution</b> <b>filter</b> to simulate a migrated image. The shared-earth model that describes a target-zone is decoupled from the macro-velocity model that is used to compute the spatial <b>resolution</b> <b>filter</b> and thus enabling iterative testing of different geological scenarios. Synthetic geological models are used to validate that simulated migrated and inverted impedance data can be compared directly to the migrated and inverted impedance real data. An iterative shared-earth modeling approach of the Early Jurassic Cook Formation (Oseberg Field) is used to enhance the reservoir characterization of the Cook Formation (Oseberg Field, Offshore Norway). In the iterative shared-earth modeling approach two different geological scenarios are tested. Relevant wire-line data of the Cook Formation are assigned to the different facies in the earth-model. In order to obtain a closer fit, {{the size and shape of}} the facies elements of the geological model are manually varied within the ranges (uncertainties) obtained from a modern-analogue study. Comparison of the simulated migrated and impedance data and real data sets led to the conclusion that east-west migrating channels and tidal sand-bars in an estuarine environment produce the best fitting geological model. Civil Engineering and Geoscience...|$|E
40|$|In {{this paper}} we {{evaluate}} {{the performance of}} two reduced <b>resolution</b> <b>filter</b> approaches to data assimilation. The main distinction between these approaches is in the manner they propagate error covariances. Both account for error covariances in a space with dimension m smaller than the model's state vector dimension n. In the first approach the m dimensional error covariance matrix is interpolated to the n-dimensional space and propagated with the n-dimensional dynamics. In the second approach the low-dimensional error covariance matrix is propagated by a dynamical operator generated in the m-dimensional space. Our experiments indicate that the first approach provides a more reliable simplified scheme for error covariance propagation than the second approach...|$|E
40|$|The edge {{technique}} utilizes {{the edge}} of a high spectral <b>resolution</b> <b>filter</b> for high accuracy wind measurement using direct detection lidar. The signal is split between an edge filter channel and a broadband energy monitor channel. The energy monitor channel is used for signal normalization. The edge measurement is made as a differential frequency measurement between the outgoing laser signal and the atmospheric backscattered return for each pulse. As a result, the measurement is insensitive to laser and edge filter frequency jitter and drift at a level less than a few parts in 10 (exp 10). We will discuss the methodology of the technique in detail, present a broad range of simulation results, and provide preprints of a journal article currently in press...|$|E
40|$|Color {{versions}} of the highest resolution Voyager images of Io were produced by combining the low resolution color images with the high <b>resolution,</b> clear <b>filter</b> images. High <b>resolution</b> {{versions of}} the orange, blue, and violet filter images are produced by: orange = high-res clear * low-res orange / low-res clear blue = high-res clear * low-res blue / low-res clear violet = high-res clear * low-res violet / low-res clear. The spectral responses of {{the high and low}} <b>resolution</b> clear <b>filter</b> images cancel, leaving the color, while the spatial frequencies of the two low resolution images cancel, leaving the high resolution...|$|R
50|$|The Lightweight Directory Access Protocol LDAP uses default {{attributes}} flagged for ambiguous name <b>resolution</b> to <b>filter</b> {{results of an}} input query. In Microsoft Active Directory the searchFlags attribute is a bit flag that defines special properties related to searching with the attribute.|$|R
40|$|Abstract: The {{shafting}} {{torsional vibration}} mode of generator sets reflects dynamic {{process of the}} power grid. This paper proposes a novel real-time algorithm for shafting torsional vibration mode decomposition of generator sets, which has excellent time-frequency resolution. The algorithm realizes the signal frequency <b>resolution</b> <b>filtering</b> based on classic infinite impulse response (IIR) filtering. At the same time, the inertia of the narrow-band filtering algorithm is eliminated through multi-period rotation IIR filtering and the time-frequency dynamic resolution of the modal decomposition is realized. PSCAD-based simulation verifies that the algorithm has the frequency anti-aliasing performance, and can fully reserve the time-frequency variation characteristics and can realize the multi-mode real-time decomposition of the torsional vibration perfectly. The algorithm {{can also be used}} for the time-frequency analysis in other fields...|$|R
40|$|Ground-based {{spectral}} line {{measurements of the}} 22. 2 GHz atmospheric water vapor line in emission were made at the JPL {{in order to obtain}} data in a dry climate, and to confirm similar measurements made at the Haystack Observatory. The results obtained from March 1984 to July 1984 and from December 1984 to May 1985, were based on data recorded by a HP 9816 microcomputer. The instrument spectrometer was a 64 channel, 62. 5 kHz <b>resolution</b> <b>filter</b> bank. Data indicates the existence of a seasonal variation in the abundance of water vapor in the upper mesosphere, with mixing ratios higher in summer than in spring. This is consistent with recent theoretical and observational results. In the area of semiannual oscillation, Haystack data are more consistent than those of JPL, indicating an annual cycle with abundances at maximum in summer and minimum in winter...|$|E
40|$|Two {{suboptimal}} data assimilation {{schemes for}} stable and unstable dynamics are introduced. The first scheme, the partial singular value decomposition filter, {{is based on}} the most dominant singular modes of the tangent linear propagator. The second scheme, the partial eigendecomposition filter, {{is based on the}} most dominant eigenmodes of the propagated analysis error covariance matrix. Both schemes rely on iterative procedures like the Lanczos algorithm to compute the relevant modes. The performance of these schemes is evaluated for a shallow [...] water model linearized about an unstable Bickley jet. The results are contrasted against those of a reduced <b>resolution</b> <b>filter,</b> in which the gains used to update the state vector are calculated from a lower [...] dimensional dynamics than the dynamics that evolve the state itself. The results are also contrasted against the exact results given by the Kalman filter. These schemes are validated for the case of stable dynamics as well. The two new approxima [...] ...|$|E
40|$|A {{rigorous}} {{mathematical analysis}} and a {{comparative study of}} carrier-frequency modulation (CFM) techniques for the conducted electromagnetic interference (EMI) suppression in pulsewidth-modulated converters is presented. CFM techniques dither the switching period with a small amplitude variation around the nominal value, so that the harmonic power is redistributed over the spectrum of concern. Two types of dithering signals, including the periodic and random signals, are investigated in this paper. The operational characteristics {{as well as the}} input and output power spectra of the converters with the two modulating signals are compared. In particular, their characteristics in the low- and high-frequency harmonic power redistribution will be depicted. It is shown that random CFM (RCFM) gives a more effective way to disperse the harmonics around the switching frequency than the periodic CFM (PCFM) with the same frequency deviation. However, RCFM introduces higher low-frequency harmonics than the PCFM at the converter output. Furthermore, effects of the <b>resolution</b> <b>filter</b> bandwidth in the electromagnetic compatibility analyzer on conducted EMI measurement is discussed. The validity of the analyses is confirmed experimentally by using a dc/dc buck converter operating in continuous conduction mode. link_to_subscribed_fulltex...|$|E
40|$|Much of {{the signal}} energy due to speckle in {{ultrasound}} images is shown to be of higher spatial frequency than the intrinsic pulse shape limited resolution in B-scan ultrasound images. A significant increase in {{signal to noise ratio}} can therefore be obtained by <b>resolution</b> limited spatial <b>filtering</b> which selectively removes energy of higher spatial frequency than the pulse envelope reso-lution limit. The concept is illustrated by <b>resolution</b> limited <b>filtering</b> ECG gated B-scan echocardio-graphic images. Signal to noise improvement is illustrated by comparing time-motion displays gen-erated from both processed and unprocessed images. Key words: B-scan, filtering; resolution; speckle; ultrasound I...|$|R
5000|$|... 24.2 {{megapixel}} {{image sensor}} with 12-bit <b>resolution.</b> Optical low-pass <b>filter</b> removed (OLPF, anti-aliasing (AA) filter) at 5 Frames per second ...|$|R
40|$|AbstractWe {{define the}} notion of a minimal <b>filtered</b> free <b>resolution</b> for a <b>filtered</b> module over the ring D(h), a {{homogenization}} of the ring D of analytic differential operators. This provides us with analytic invariants attached to a (bi) filtered D-module. We also give an effective argument using a generalization of the division theorem in D(h) due to Assi et al. (J. Pure. Appl. Algebra 164 (2001) 3 – 21), by which we obtain an upper bound for the length of minimal <b>filtered</b> <b>resolutions...</b>|$|R
40|$|Abstract—A {{rigorous}} {{mathematical analysis}} and a {{comparative study of}} carrier-frequency modulation (CFM) techniques for the conducted electromagnetic interference (EMI) suppression in pulsewidth-modulated converters is presented. CFM techniques dither the switching period with a small amplitude variation around the nominal value, so that the harmonic power is redistributed over the spectrum of concern. Two types of dithering signals, including the periodic and random signals, are investigated in this paper. The operational characteristics {{as well as the}} input and output power spectra of the converters with the two modulating signals are compared. In particular, their characteristics in the low- and high-frequency harmonic power redistribution will be depicted. It is shown that random CFM (RCFM) gives a more effective way to disperse the harmonics around the switching frequency than the periodic CFM (PCFM) with the same frequency deviation. However, RCFM introduces higher low-frequency harmonics than the PCFM at the converter output. Furthermore, effects of the <b>resolution</b> <b>filter</b> bandwidth in the electromagnetic compatibility analyzer on conducted EMI measurement is discussed. The validity of the analyses is confirmed experimentally by using a dc/dc buck converter operating in continuous conduction mode. Index Terms—DC–DC power conversion, power electronics, pulsewidth modulation, random switching techniques, switching circuits. I...|$|E
40|$|Consider two uniform {{samplers}} operating simultaneously on a signal, {{with sample}} spacings MT and NT where M and N are coprime integers, and T has time or space dimension. It {{can be shown}} that the difference coarray of this pair of sampling arrays has elements at all integer multiples of T, regardless of how large M and N are. This implies that any application which depends only on second order statistics, such as angle of arrival estimation, beamforming, and multiple frequency detection, {{can be carried out}} at high resolution with the help of sparse sampling arrays. One manifestation is that two sensor arrays withM and N sensors can actually identify O(MN) independent sources. This paper extends these results to the case of multidimensional signals. The multidimensional sampling arrays operate on a lattice geometry. The coarray of such a system is studied. Even though the two lattice arrays are sparse (with respect to the integer grid), the coarray contains all integer vectors. It is also shown how to achieve the effect of a high resolution multidimensional DFT filter bank by combining coprime low <b>resolution</b> <b>filter</b> banks...|$|E
40|$|In {{order to}} {{effectively}} use iris patterns in biometric recognition, there is value in knowing how bit errors in iris codes are distributed. In this work, the iris is considered in a part-based framework as rings and sectors. A mean normalised bit error {{is defined as}} the bit error averaged over the entire part and over an ensemble of images. The distribution of this error for genuine comparisons is investigated as a function of radius (ring) and angle (sector) for a range of factors more comprehensively than previous studies of consistency of iris codes. Two iris recognition systems and three data sets are used. The effect of residual segmentation errors after automated segmentation is checked, and masks are manually refined to obtain segmentation error free data for further investigation. The effect of factors such as capture sensor, resampling, input iris image <b>resolution,</b> <b>filter</b> type and encoding scheme, and changes in pupil size is systematically investigated. Results confirm the finding in previous works that the pupillary and limbic boundaries are more error-prone than the middle region of the iris. This study further confirms that this V-shaped radial trend is not significantly disturbed by any of the above factors other than pupil size changes. Both pupil dilation and constriction result in increased bit errors which no longer show a dip in the middle region of the iris. The distribution of errors as a function of angle is approximately uniform regardless of the factor investigated but shows a small decrease towards the sectors near the eye corners...|$|E
40|$|Graduation date: 2017 This {{dissertation}} {{focuses on}} extending the application scope of surface enhanced {{infrared absorption spectroscopy}} to gas sensing. The method we propose is incorporating plasmonic nanostructures with nano-composite material, metalorganic framework, which can selectively preconcentrate certain gas molecules into the nanopores. The preconcentrating property is first demonstrated by applying metal-organic framework to optical fiber based sensor. Then two different metalorganic framework integrated surface enhanced infrared absorption gas sensors fabricated on bulk substrate and nano-membrane are investigated, and the high enhancement factors demonstrated for the first time. Lastly, an on-chip spectrometer using high <b>resolution</b> plasmonic <b>filter</b> array is proposed and experimentally demonstrated for resolving CO 2 absorption spectrum at 2. 0 μm with 10 12 nm <b>resolution.</b> This <b>filter</b> array spectrometer is simple and low-cost, which can be potentially used for portable gas spectroscopy system...|$|R
40|$|The {{theory of}} double edge lidar {{techniques}} {{for measuring the}} atmospheric wind using aerosol and molecular backscatter is described. Two high spectral <b>resolution</b> <b>filters</b> with opposite slopes are located about the laser frequency for the aerosol based measurement or in {{the wings of the}} Rayleigh - Brillouin profile for the molecular measurement. This doubles the signal change per unit Doppler shift and improves the measurement accuracy by nearly a factor of 2 relative to the single edge technique. For the aerosol based measurement, the use of two high <b>resolution</b> edge <b>filters</b> reduces the effects of background, Rayleigh scattering, by as much as an order of magnitude and substantially improves the measurement accuracy. Also, we describe a method that allows the Rayleigh and aerosol components of the signal to be independently determined. A measurement accuracy of 1. 2 m/s can be obtained for a signal level of 1000 detected photons which corresponds to signal levels in the boundary layer. For the molecular based measurement, we describe the use of a crossover region where the sensitivity of a molecular and aerosol-based measurement are equal. This desensitizes the molecular measurement to the effects of aerosol scattering and greatly simplifies the measurement. Simulations using a conical scanning spaceborne lidar at 355 nm give an accuracy of 2 - 3 m/s for altitudes of 2 - 15 km for a 1 km vertical resolution, a satellite altitude of 400 km, and a 200 km x 200 km spatial...|$|R
40|$|A new {{technique}} for {{the generation of}} fundamental dark soliton trains with uniform intensity background is described. The signal emitted by a multigigahertz repetition rate mode-locked laser source is temporally shaped by high <b>resolution</b> spectral <b>filtering.</b> The proposed shaping device is all-optical and passive. The emitted dark pulses are shown to propagate soliton-like over distances compatible with telecommunication applications. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|Graph-structured data {{appears in}} many modern {{applications}} like social networks, sensor networks, transportation networks and computer graphics. These applications {{are defined by}} an underlying graph (e. g. a social graph) with associated nodal attributes (e. g. number of ad-clicks by an individual). A simple model for such data {{is that of a}} graph signal [...] a function mapping every node to a scalar real value. Our aim is to develop signal processing tools for analysis of such signals de- fined over irregular graph-structured domains, analogous to classical Fourier and Wavelet analysis defined for regular structures like discrete-time sequences and two-dimensional grids. In this work, we start by reviewing the notion of a Graph Fourier Transform (GFT), which has been defined in the literature for graph signals. We examine the spatial and spectral features of circulant graphs, which accommodate linear shift-invariant operations. We describe fundamental operations such as shifting, sampling, graph-reconnection and linear filtering for signals on circulant graphs and derive associated sampling and graph-reconnection theorems. We also develop wavelet filter bank structures for multi resolution analysis of large-scale graphs. We present a method to decompose an arbitrary graph into a linear combination of circulant graphs. This helps extend fundamental operations such as sampling, filtering and multi <b>resolution</b> <b>filter</b> banks to general graphs. We present an application in the area of graph semi-supervised learning where some of the existing algorithms can be viewed as suitably designed filters defined in the GFT domain. We propose a wavelet regularized learning algorithm and evaluate the performance on some real-world datasets...|$|E
40|$|Over {{the last}} decade of {{geophysical}} research the concepts of hotspots and plumes have taken a central role in discussions of the interior structure of the Earth and global geodynamic plate and convection models. In this study, I focus on the ability of thermal and/or thermochemical plumes to reproduce global and regional seismic observations at hotspot locations on Earth. In order to make meaningful interpretations of seismic images from global tomographic images I begin with an investigation into the physical meaning of seismic reference models and a full exploration of the temperature and compositional sensitivities of mantle seismic velocities, utilising a fully consistent forward modelling approach with up-to-date mineral physics parameters and associated uncertainties. I determine that, despite three-dimensional complexity of the mantle, averaged seismic structure reflects the average radial physical structure of the mantle except near phase boundaries and within thermal boundary layers. In {{the second half of the}} study I produce synthetic plume signatures by converting the thermo-chemical strutures of a range of plausible dynamic whole mantle plumes into seismic velocities-including the effect of seismic resolution in global tomographic models by convolution of the seismic structures with a <b>resolution</b> <b>filter</b> for the global model S 40 RTS. Quantitative comparison of synthetic signatures with global seismic observations beneath a number of hotspots indicates that more than half of all studied locations are underlain by low-velocity anomalies with widths and magnitudes compatible with thermal plumes. Other locations, e. g. Iceland, require plumes with time-dependent morphologies, modified by chemistry or phase buoyancy forces. I next forward model the predicted transition zone seismic structure for a number for thermal and thermochemical whole mantle plume scenarios, before commenting on suitability of using transition zone thickness beneath hotspots as a proxy for temperature. Lastly, I finish with a discussion of how such an analysis might be extended to other terrestrial planets, such as Mars. EThOS - Electronic Theses Online ServiceScience and Technology Facilities Council (STFC) GBUnited Kingdo...|$|E
40|$|Radiometrically {{accurate}} {{observations of}} the earth's emission spectrum from 3. 8 to 16. 6 microns have been made using the High-resolution Interferometer Sounder (HIS) to look downward from the NASA U 2 /ER 2 aircraft or upward from the ground. These observations {{have been used to}} demonstrate the substantially improved vertical resolution of temperature and water vapor soundings derived from high resolution spectra (resolving power from 1800 to 3800), as compared to soundings from the low <b>resolution</b> <b>filter</b> radiometer observations used in current satellite sounders. The HIS observations have also demonstrated that Fourier Transform Infrared (FTIR) instruments are especially well suited to absolute emission measurements of broad spectral bands at high resolution. A fundamental advantage of FTIR instruments for accurate calibration is wavelength integrity, the same property which has made FTIR the standard for very high resolution absorption measurements. The long wavelength part of a HIS downwelling radiance spectrum is compared to a calculated spectrum. The calculation uses the AFGL HITRAN/ 86 line file and FASCOD 2 line-by-line program with atmospheric state data from in situ measurements. In general, agreement between HIS and FASCOD 2 spectra is remarkably good, a tribute to the current state of spectral line files and line-by-line codes. Reproducible differences between HIS observations and FASCOD 2 line-by-line calculations lead to the following conclusions: (1) The FASCOD 2 water vapor continuum in the longwave window region from 10 to 13 microns (750 to 1000 cm(exp - 1)) gives reasonable agreement with radiance observations; (2) The model H 2 O continuum from 7 to 8 microns (1250 to 1425 cm(exp - 2)) needs adjustment to reduce its contribution by about 60 percent; (3) CO 2 absorption in the region from 13. 1 to 14. 3 microns (700 to 760 cm(exp - 1)) is too small in the model; and (4) Water vapor line strengths in the region from 8. 1 to 9. 1 microns (1100 to 1230 cm(exp - 1)) need to be increased about 30 percent...|$|E
40|$|We have {{constructed}} solid Fabry-Perot narrow-band filters {{that can}} be used in systems having one arc second or better <b>resolution.</b> Our <b>filters</b> operate at H-alpha, have a three-inch aperture, and typical transmission of 70 per cent. However, the same technology can be applied to construction of filters as narrow as 0. 05 A at any wavelength from 4200 to 11000 A...|$|R
40|$|In {{this paper}} we propose a {{biometric}} sclera recognition and validation system. Here the sclera segmentation is performed by a time-adaptive active contour-based region growing technique. The sclera vessels are not prominent so image enhancement is required and hence a bank of 2 D decomposition Haar wavelet multi-resolution filters is used to enhance the vessels pattern for better accuracy. For feature extraction, Dense Scale Invariant Feature Transform (D-SIFT) is used. D-SIFT patch descriptors of each training image are used to form bag of features by using k-means clustering and a spatial pyramid model, which is used to produce the training model. Support Vector Machines (SVMs) are used for classification. The UBIRIS version 1 dataset is used here for experimentation. An encouraging Equal Error Rate (EER) of 0. 66 % is attained in the experiments presented. Keywords: Biometric; Sclera vessel patterns; D-SIFT; SVM; Bag of features, k-means, Bank of 2 D decomposition Haar multi- <b>resolution</b> <b>filters</b> wavelet.. Griffith Sciences, School of Information and Communication TechnologyNo Full Tex...|$|R
5000|$|... which {{corresponds}} to 6.1 nm&minus;1 on the CM300. Contributions with a spatial frequency {{higher than the}} point <b>resolution</b> can be <b>filtered</b> out with an appropriate aperture leading to easily interpretable images {{at the cost of}} a lot of information lost.|$|R
40|$|Attenuation {{correction}} (AC) of cerebral PET data {{acquired in}} hybrid MR/PET scanners {{is still a}} challenge. To overcome this problem we previously proposed a correction method by obtaining template-based attenuation maps (AM) using MR and ECAT EXACT HR+ transmission scans. In the present study we investigated (a) the basic difference between template-based and CT-based AC methods and (b) their influence on reconstructed PET images. The data of 11 subjects undergoing 18 FDG imaging in the Siemens 3 T MR-BrainPET scanner were used. Additionally, from all participants a CT scan of the whole head was acquired at the same day. These CT images were transformed to CT-based AMs. They were filtered by a 3 D Gaussian kernel with 3 mm (BrainPET <b>resolution)</b> <b>filter</b> width, which was considered as reference. Comparisons between both AMs (CT-based and template-based) were performed by estimating the Dice coefficients D and calculating the numbers of true positive, true negative and false negative voxels. The BrainPET emission data were reconstructed with both AMs (AMCT 3 mm and AMTemplate). All reconstructed PET images were scaled to standardized uptake values (SUVs) and normalized to the MNI brain for using the AAL-VOI Atlas analysis. Correlation plots with regression equation, coefficients of determination R 2 and relative differences (RD) between AMCT 3 mm and the AMTemplate were derived. The fraction of the overall true positive voxels averaged over the 11 subjects was 80. 4 ± 7. 5 % for AMTemplate compared to AMCT 3 mm (Dbone = 0. 63 ± 0. 08; Dsoft - tissue = 0. 85 ± 0. 08; Dair = 0. 79 ± 0. 04). A misclassification of bone as soft tissue and vice versa {{was evident in the}} comparison. The correlation plot of all VOIs considered (1, 276 values) showed a mean R 2 of 0. 964 and a slope of 1. 02. A mean RD of 1. 33 ± 0. 95 % (min = - 0. 12 %, max = 2. 85 %) was found. The template-based AC method proposed by our group shows considerable differences in comparison to the higher resolution CT-based AM with respect to the Dice coefficients, in particular in the classification of bone and soft tissue. However, this has no major influence on the reconstructed 18 FDG PET data...|$|E
40|$|Aerosol and {{molecular}} based {{versions of the}} double-edge technique {{can be used for}} direct detection Doppler lidar spaceborne wind measurement. The edge technique utilizes the edge of a high spectral <b>resolution</b> <b>filter</b> for high accuracy wind measurement using direct detection lidar. The signal is split between an edge filter channel and a broadband energy monitor channel. The energy monitor channel is used for signal normalization. The edge measurement is made as a differential frequency measurement between the outgoing laser signal and the atmospheric backscattered return for each pulse. As a result the measurement is insensitive to laser and edge filter frequency jitter and drift at a level less than a few parts in 10 (exp 10). We have developed double edge versions of the edge technique for aerosol {{and molecular}}-based lidar measurement of the wind. Aerosol-based wind measurements have been made at Goddard Space Flight Center and molecular-based wind measurements at the University of Geneva. We have demonstrated atmospheric measurements using these techniques for altitudes from 1 to more than 10 km. Measurement accuracies of better than 1. 25 m/s have been obtained with integration times from 5 to 30 seconds. The measurements can be scaled to space and agree, within a factor of two, with satellite-based simulations of performance based on Poisson statistics. The theory of the double edge aerosol technique is described by a generalized formulation which substantially extends the capabilities of the edge technique. It uses two edges with opposite slopes located about the laser frequency at approximately the half-width of each edge filter. This doubles the signal change for a given Doppler shift and yields a factor of 1. 6 improvement in the measurement accuracy compared to the single edge technique. The use of two high resolution edge filters substantially reduces the effects of Rayleigh scattering on the measurement, as much as order of magnitude, and allows the signal to noise ratio to be substantially improved in areas of low aerosol backscatter. We describe a method that allows the Rayleigh and aerosol components of the signal to be independently determined using the two edge channels and an energy monitor channel. The effects of Rayleigh scattering may then subtracted from the measurement and we show that the correction process does not significantly increase the measurement noise for Rayleigh to aerosol ratios up to 10. We show that for small Doppler shifts a measurement accuracy of 0. 4 m/s can be obtained for 5000 detected photon, 1. 2 m/s for 1000 detected photons, and 3. 7 m/s for 50 detected photons for a Rayleigh to aerosol ratio of 5. Methods for increasing the dynamic range of the aerosol-based system to more than +/- 100 m/s are given...|$|E
40|$|Airborne LiDAR {{data have}} been {{collected}} {{for the city of}} Istanbul using Riegl laser scanner Q 680 i with 400  kHz and an average flight height of 600  m. The flight campaign was performed by a helicopter and covers an area of 5400  km 2. According to a flight speed of 80 knot a point density of more than 16 points/m 2 and a laser footprint size of 30  cm could be achieved. As a result of bundle adjustment, in total, approximately 17, 000 LAS files with the file size of 500  m by 700  m have been generated for the whole city. The main object classes Ground, Building, Vegetation (medium, high) were derived from these LAS files using the macros in Terrasolid software. The forest area under investigation is located northwest of the city of Istanbul, main tree species occurring in the test site are pine (pinus pinaster), oak (quercus) and beech (fagus). In total, 120 LAS tiles covering the investigation area have been analysed using the software IMPACT of Joanneum Research Forschungsgesellschaft, Graz, Austria. First of all, the digital terrain model (DTM) and the digital surface models (DSM) were imported and converted into a raster file from the original laser point clouds with a spatial resolution of 50  cm. Then, a normalized digital surface model (nDSM) was derived as the difference between DSM and the DTM. Tree top detection was performed by multi – <b>resolution</b> <b>filter</b> operations and tree crowns were segmented by a region growing algorithms develop specifically for this purpose. Breast Height Diameter (BHD) was calculated on the base of tree height and crown areas derived from image segmentation applying allometric functions found in literature. The assessment of stem volume was then calculated as a function of tree height and BHD. A comparison of timber volume estimated from the LiDAR data and field plots measured by the Forest Department of Istanbul showed R 2 of 0. 46. The low correlation might arise either from the low quality of the field plots or from the inadequacy of the allometric functions used for BHD and stem volume modelling. Further investigations therefore will concentrate both on improving the quality of field measurements and the adoption of the allometric functions to the specific site condition of the forests under investigation. Finally stand boundaries of the forest area made available by the forest department of Istanbul were superimposed to the LiDAR data and the single tree measurements aggregated to the stand level. Aside from the LiDAR data, a Pleiades multispectral image characterized by four spectral bands (blue, green, red and near infrared) and a GSD of 2. 8  m has been used for the classification of different tree species. For this purpose the near infrared band covering the spectral range of 0. 75  μm to 0. 90  μm has been utilized and the IMPACT software used...|$|E
40|$|A {{loudspeaker}} system with an endfire array {{of three or}} more loudspeakers (Z n, n = 3, 4, [...] N) arranged on a line. The system has a set of filters (F n, n = 3, 4, [...] N), each loudspeaker (Z n) being connected to one corresponding filter (F n). The filters (F n) are super <b>resolution</b> beamforming <b>filters</b> such as to provide the endfire array with a pre-designed directivity index (DI) and a pre-designed noise sensitivity (NS) ...|$|R
40|$|Frequency warping using allpass {{structures}} or Laguerre filters {{has found}} increasingly applications in audio signal processing due to good match with the auditory frequency <b>resolution.</b> Kautz <b>filters</b> are an extension where the frequency warping and related resolution {{can have more}} freedom. In this paper we discuss the properties of Kautz filters and how they meet typical requirements found in modeling and equalization of audio systems. Case studies include transfer function modeling of the guitar body and loudspeaker response equalization...|$|R
40|$|We {{present a}} {{comparison}} between the peculiar velocity fields measured from the SFI all-sky Sbc-Sc Tully-Fisher catalog and that derived from the 1. 2 Jy redshift survey galaxy distribution. The analysis {{is based on the}} expansion of these data in redshift space using smooth orthonormal functions and is performed using low and high resolution expansions, with an effective smoothing scale which increases almost linearly with redshift. The effective smoothing scales at 3000 are 1500 and 1000 for the low and high <b>resolution</b> <b>filters.</b> The agreement between the high and low resolution SFI velocity maps is excellent. The general features in the filtered SFI and velocity fields agree remarkably well within 6000. This good agreement between the fields allows us to determine the parameter β=Ω^ 0. 6 /b, where Ω is the cosmological density parameter and b is the linear biasing factor. From a likelihood analysis on the SFI and modes we find that β= 0. 6 ± 0. 1 independently of the resolution of the modal expansion. For this value of within 6000. Most remarkable is the lack of any coherent, redshift dependent dipole flow in the residual field...|$|R
