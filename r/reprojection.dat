510|16|Public
500|$|In 1935, Vladimir Fock {{showed that}} the quantum {{mechanical}} bound Kepler problem {{is equivalent to the}} problem of a free particle confined to a three-dimensional unit sphere in four-dimensional space. [...] Specifically, Fock {{showed that the}} Schrödinger wavefunction in the momentum space for the Kepler problem was the stereographic projection of the spherical harmonics on the sphere. [...] Rotation of the sphere and <b>reprojection</b> results in a continuous mapping of the elliptical orbits without changing the energy; quantum mechanically, this corresponds to a mixing of all orbitals of the same energy quantum number n. [...] Valentine Bargmann noted subsequently that the Poisson brackets for the angular momentum vector L and the scaled LRL vector D formed the Lie algebra for SO(4). [...] Simply put, the six quantities D and L correspond to the six conserved angular momenta in four dimensions, associated with the six possible simple rotations in that space (there are six ways of choosing two axes from four). [...] This conclusion does not imply that our universe is a three-dimensional sphere; it merely means that this particular physics problem (the two-body problem for inverse-square central forces) is mathematically equivalent to a free particle on a three-dimensional sphere.|$|E
5000|$|Minimizing the <b>reprojection</b> error can be {{used for}} {{estimating}} the error from point correspondences between two images. Suppose we are given 2D to 2D point imperfect correspondences [...] We wish to find a homography [...] and pairs of perfectly matched points [...] and , i.e. points that satisfy [...] that minimize the <b>reprojection</b> error function given bySo the correspondences can be interpreted as imperfect images of a world point and the <b>reprojection</b> error quantifies their deviation from the true image projections ...|$|E
5000|$|... 1998: UMN MapServer 2.0, Added <b>reprojection</b> support (PROJ.4).|$|E
40|$|In {{this paper}} {{we show that}} given two {{homography}} matrices for two planes in space, there is a linear algorithm for the rotation and translation between the two cameras, the focal lengths of the two cameras and the plane equations in the space. Using the estimates as an initial guess, we can further optimize the solution by minimizing the difference between observations and <b>reprojections.</b> Experimental results are shown. We also provide {{a discussion about the}} relationship between this approach and the Kruppa equation. ...|$|R
40|$|In {{this paper}} we {{address the problem of}} {{recovering}} range information from a pair of images obtained from camera viewpoints whose relative poses are known (stereo vision). The images we deal with are cylindrical <b>reprojections</b> of images captured by an omnidirectional vision sensor. Images obtained by such a device have a relatively low spatial resolution in comparison to standard camera images. We analyze the sensitivity of range estimation from image correspondences with respect to errors caused by discretization. The analysis reveals the significance of obtaining subpixel accuracy for range estimation. We present our method and experimental results. The results indicate that high accuracy range estimates can be obtained using our method...|$|R
5000|$|Spatial {{databases}} {{are usually}} object relational databases enhanced with geographic data types, methods and properties. They are necessary whenever a web mapping application {{has to deal}} with dynamic data (that changes frequently) or with huge amount of geographic data. Spatial databases allow spatial queries, sub selects, <b>reprojections,</b> and geometry manipulations and offer various import and export formats. PostGIS is a prominent example; it is open source. MySQL also implements some spatial features. Oracle Spatial, Microsoft SQL Server (with the spatial extensions), and IBM DB2 are the commercial alternatives. The Open Geospacial Consortium's (OGC) specification [...] "Simple Features" [...] is a standard geometry data model and operator set for spatial databases. Part 2 of the specification defines an implementation using SQL.|$|R
5000|$|... 1998-07: MapServer 2.0 {{released}} as final ForNET deliverable; added <b>reprojection</b> support (PROJ.4).|$|E
5000|$|Yi Ma, Stefano Soatto, Jana Kosecka, and Shankar Sastry, Euclidean Reconstruction and <b>Reprojection</b> up to Subgroups ...|$|E
5000|$|Geoprocessing: buffer, intersection, clip, dissolve, union, convex hull, difference, merge, spatial join, XY shift, <b>reprojection,</b> Sextante geoprocessing.|$|E
40|$|We {{present a}} new hybrid {{rendering}} method for interactive walkthroughs in photometrically complex environments. The display process starts from some approximation {{of the scene}} rendered at high frame rates using graphics hardware. Additional computation power is used to correct this rendering towards a high quality ray tracing solution during the walkthrough. This is achieved by applying corrective textures to scene objects or entire object groups. These corrective textures contain a sampled representation {{of the differences between}} the hardware generated and the high quality solution. By reusing the textures, frameto -frame coherence is exploited and explicit <b>reprojections</b> of point samples are avoided. Finally, we describe our implementation, which can display interactive walkthroughs of fairly complex scenes including high quality global illumination features. 1 Introduction Photorealistic rendering has a major drawback: its performance is far from interactive. In contra [...] ...|$|R
40|$|This paper proposes an {{efficient}} method for tracking a 3 D surface model, which utilises an accurate neighbourhood motion prior to regularize the solution. Typical 3 D motion trackers only estimate the local translations at each {{point on the}} surface model, which means that enforcing smooth motion between neighbouring surface points can be difficult when undergoing rigid body motion. This paper uses a patch-based representation of the scene surface so that both translations and rotations can be estimated on the surface, leading to smooth neighbouring scene flows under local rigid body motions. Since the translation and rotation motions are estimated at each patch using a variational approach, the proposed tracker is efficient with relatively few <b>reprojections</b> required at each frame. The proposed method is demonstrated on a real-world multi-camera sequence, and the scene-flow is accurately estimated over ninety frames. 1...|$|R
30|$|Given {{the current}} state of SPT, {{accurate}} classification of noisy subtomograms with a missing wedge remains one of the biggest challenges. The missing wedge, as well as missing information between tilts, can make accurate classification statistically impossible in specific cases. Popular techniques used in cryoEM SPA such as multivariate statistical analysis (MSA) (Van Heel and Frank 1981; Frank et al. 1982; Van Heel 1984) can be tricky to apply to SPT, because the missing wedge, which is often the strongest feature, is difficult to exclude when the particles have already been rotated for alignment. A classification technique for subtomograms based on 2 D <b>reprojections</b> has been proposed to overcome the uncertainties in classification introduced by the missing wedge (Yu et al. 2010, 2013). While this method would still be, in principle, subject to the degeneracy problem that arises in SPA cryoEM (Fig.  1), it may allow for fast, initial 2 D classification of particles from cellular tomograms without the concern of overlapping densities.|$|R
5000|$|... 1993: Xerox PARC Map Viewer, The first mapserver {{based on}} CGI/Perl, allowed <b>reprojection</b> styling and {{definition}} of map extent.|$|E
5000|$|The <b>reprojection</b> {{error is}} a {{geometric}} error {{corresponding to the}} image distance between a projected point and a measured one. It is used to quantify how closely an estimate of a 3D point [...] recreates the point's true projection [...] More precisely, let [...] be the projection matrix of a camera and [...] be the image projection of , i.e[...] The <b>reprojection</b> error of [...] is given by , where [...] denotes the Euclidean distance between the image points represented by vectors [...] and [...]|$|E
5000|$|GPS: internal/external GPS connection, <b>reprojection</b> to UTM, {{simulated}} NMEA frames, waypoints, tracklog in GPX and CSV formats, {{center on}} view, signal parameters, satellites used, calculate {{the distance between}} current location and the destination location.|$|E
40|$|Typical monocular {{localization}} schemes {{involve a}} search for matches between reprojected 3 D world points and 2 D image features in order to estimate the absolute scale transformation between the camera and the world. Successfully calculating such transformation implies {{the existence of a}} good number of 3 D points uniformly distributed as reprojected pixels around the image plane. This paper presents a method to control the march of a humanoid robot towards directions that are favorable for visual based localization. To this end, orthogonal diagonalization is performed on the covariance matrices of both sets of 3 D world points and their 2 D image <b>reprojections.</b> Experiments with the NAO humanoid platform show that our method provides persistence of localization, as the robot tends to walk towards directions that are desirable for successful localization. Additional tests demonstrate how the proposed approach can be incorporated into a control scheme that considers reaching a target position...|$|R
40|$|Interactive {{walkthrough}} applications require rendering an observed {{scene from}} a continuous range of target viewpoints. Toward this end, a novel approach is introduced that processes a set of input images to produce photorealistic scene <b>reprojections</b> {{over a wide range}} of viewpoints. This is achieved by (1) acquiring calibrated input images that are distributed throughout a target range of viewpoints to be modeled, and (2) computing a 3 D reconstruction that is consistent in projection with all of the input images. The method avoids image correspondence problems by working in a discretized scene space whose voxels are traversed in a fixed visibility ordering. This strategy takes full account of occlusions and enables reconstructions of panoramic scenes. Promising initial results are presented for a room walkthrough. 1 Introduction The topic of creating scene "walkthroughs" and "flybys " from images has achieved much recent interest in the research community, {{due in part to the}} popularit [...] ...|$|R
40|$|SummaryWe {{present the}} codimensional {{principal}} component analysis (PCA), a novel and straightforward method for resolving sample heterogeneity within a set of cryo-EM 2 D projection images of macromolecular assemblies. The method employs PCA of resampled 3 D structures computed using subsets of 2 D data obtained with a novel hypergeometric sampling scheme. PCA provides us with a small subset of dominating “eigenvolumes” of the system, whose <b>reprojections</b> are compared with experimental projection data to yield their factorial coordinates constructed in a common framework of the 3 D space of the macromolecule. Codimensional PCA is unique in the dramatic reduction of dimensionality of the problem, which facilitates rapid determination of both the plausible number of conformers in the sample and their 3 D structures. We applied the codimensional PCA to a complex data set of Thermus thermophilus 70 S ribosome, and we identified four major conformational states and visualized high mobility of the stalk base region...|$|R
50|$|The {{forthcoming}} WCS Coordinate System Extension allows {{to retrieve}} coverages in Coordinate Reference Systems (CRSs) {{different from the}} Native CRS in which the coverage is stored on the server - in other words, it allows <b>reprojection.</b>|$|E
50|$|In 2005 LizardTech began adding {{tools to}} its basic {{compression}} product {{with the aim}} of supporting geospatial users from a workflow standpoint, such as <b>reprojection,</b> area-of-interest encoding and color balancing. That year the company also released Spatial Express, an API and set of tools for storing and retrieving wavelet-compressed imagery in an Oracle database.|$|E
5000|$|A common way {{to reduce}} the {{perceived}} latency or compensate for a lower frame rate, is to take an (older) rendered frame and morph it {{according to the most recent}} head tracking data just before presenting the image on the screens. This is called asynchronous <b>reprojection</b> or [...] "asynchronous time warp" [...] in Oculus jargon.|$|E
40|$|We {{describe}} a calibration procedure for a multi-camera rig. Consider {{a large number}} of synchronized cameras arranged in some space, for example, on the walls of a room looking inwards. It is not necessary for all the cameras to have a common field of view, as long as every camera is connected to every other camera through common fields of view. Switching off the lights and waving a wand with an LED at the end of it, we can capture a very large set of point correspondences (corresponding points are captured at the same time stamp). The correspondences are then used in a large, nonlinear eigenvalue minimization routine whose basis is the epipolar constraint. The eigenvalue matrix encapsulates all points correspondences between every pair of cameras in a way that minimizing the smallest eigenvalue results in the projection matrices, to within a single perspective transformation. In a second step, given additional data from waving a rod with two LEDs (one at each end) the full projection matrices are calculated. The method is extremely accurate—the <b>reprojections</b> of the reconstructed points were within a pixel...|$|R
40|$|The Nano-ESI TOF MS {{spectrum}} of the B-Raf – H-C-K complex confirms that the stoichiometry observed in the Cdk 4 – H-C-K complex {{is not unique to}} that kinase. The highest molecular weight species observed in the gas phase is a complex of the dimer of Hsp 90, a monomer of Cdc 37 and a monomer of B-Raf catalytic domain. The two peak series observed for this complex represent two charged states for this species. The calculated mass for B-Raf catalytic domain is 34490 Da. Figure S 2. (A) Examples of filtered, masked and centred raw particles, and their corresponding class averages before 3 D reconstruction and therefore without model bias, shown alongside corresponding <b>reprojections</b> and surface views of the final reconstruction. (B) Euler angle plot for class sums (generated by projection matching of the raw data) from the final model. Each class is represented by a cross on the sphere. Although there is a hole in one region of space there are sufficient views around the horizontal axis to fill in 3 D-space. Generated by IMAGIC (van Heel et al. ...|$|R
40|$|We improve data {{extrapolation}} for truncated {{computed tomography}} (CT) projections by using Helgason-Ludwig (HL) consistency conditions that mathematically describe the overlap of information between projections. First, we theoretically derive a 2 D Fourier {{representation of the}} HL consistency conditions from their original formulation (projection moment theorem), for both parallel-beam and fan-beam imaging geometry. The derivation result indicates {{that there is a}} zero energy region forming a double-wedge shape in 2 D Fourier domain. This observation is also referred to as the Fourier property of a sinogram in the previous literature. The major benefit of this representation is that the consistency conditions can be efficiently evaluated via 2 D fast Fourier transform (FFT). Then, we suggest a method that extrapolates the truncated projections with data from a uniform ellipse of which the parameters are determined by optimizing these consistency conditions. The forward projection of the optimized ellipse can be used to complete the truncation data. The proposed algorithm is evaluated using simulated data and <b>reprojections</b> of clinical data. Results show that the root mean square error (RMSE) is reduced substantially, compared to a state-of-the-art extrapolation method...|$|R
5000|$|... where [...] is {{the number}} of null {{singular}} values in [...] and each [...] is the corresponding right singular vector of [...] [...] can range from 1 to 4. After calculating the initial coefficients , the Gauss-Newton algorithm is used to refine them. The [...] and [...] matrices that minimize the <b>reprojection</b> error of the world reference points, , and their corresponding actual image points , are then calculated.|$|E
50|$|For a human, {{the eyes}} change their angle {{according}} to {{the distance to the}} observed object. To a computer this represents significant extra complexity in the geometrical calculations (epipolar geometry). In fact the simplest geometrical case is when the camera image planes are on the same plane. The images may alternatively be converted by <b>reprojection</b> through a linear transformation {{to be on the same}} image plane. This is called image rectification.|$|E
5000|$|Third, {{through an}} {{equivalent}} operation, {{we can find}} H' [...] to rectify the second image (column 2 of 2D image set). Note that H'1 should rotate the second image's optical axis to be parallel with the transformed optical axis of the first image. One strategy is to pick a plane parallel to the line where the two original optical axes intersect to minimize distortion from the <b>reprojection</b> process. In this example, we simply define H' [...] using the rotation matrix R and initial projective transformation H as [...]|$|E
40|$|The general {{allometric}} equations for the logarithmic helicospiral can fit many extraconical shapes, but the isometric conditions traditionally used limit study only to conical growth. We present {{evidence to}} show that in real gastropod shells, the logarithmic helicospiral equations fit the suture. Poor location of the coiling axis and/or an inappropriate pole for the logarithmic helicospiral has often led to the rejection of this model. The differences between the errors associated with measurement or previously available models are discussed. Two methods, based on suture trace measurements, are proposed to locate the coiling axis both in apical and lateral views. The first is a graphical method based on an elementary property of the logarithmic spiral. The second is a computational method based on iterative <b>reprojections</b> of the suture. It is shown that the protoconch and the teleoconch must be treated separately. The precision of the new methods (especially the computing method) enables deviations from logarithmic helicospiral trajectory to be identified and differentiated from irregularities of the shell and sequential growth phases. Application of these methods may be useful not only for other gastropod morphological features, but also for other taxa such as brachiopods and other mollusks. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|While many recent hand pose {{estimation}} methods critically {{rely on a}} training set of labelled frames, the creation of such a dataset is a challenging task that has been overlooked so far. As a result, existing datasets are limited to a few sequences and individuals, with limited accuracy, and this prevents these methods from delivering their full potential. We propose a semi-automated method for efficiently and accurately labeling each frame of a hand depth video with the corresponding 3 D locations of the joints: The user is asked to provide only {{an estimate of the}} 2 D <b>reprojections</b> of the visible joints in some reference frames, which are automatically selected to minimize the labeling work by efficiently optimizing a sub-modular loss function. We then exploit spatial, temporal, and appearance constraints to retrieve the full 3 D poses of the hand over the complete sequence. We show that this data can be used to train a recent state-of-the-art hand pose estimation method, leading to increased accuracy. The code and dataset can be found on our website [URL] added link to source [URL] Appears in Proc. of CVPR 201...|$|R
40|$|AbstractWe have {{developed}} an algorithm known as the Z-buffer segmentation (ZBS) algorithm for segmenting vascular structures from 3 D MRA images. Previously we evaluated {{the accuracy of the}} ZBS algorithm on a voxel level in terms of inclusion and exclusion of vascular and background voxels. In this paper we evaluate the diagnostic fidelity of the ZBS algorithm. By diagnostic fidelity we mean that the data preserves the structural information necessary for diagnostic evaluation. This evaluation is necessary to establish the potential usefulness of the segmentation for improved image display, or whether the segmented data could form the basis of a computerized analysis tool. We assessed diagnostic fidelity by measuring how well human observers could detect aneurysms in the segmented data sets. ZBS segmentation of 30 MRA cases containing 29 aneurysms was performed. Image display used densitometric <b>reprojections</b> with shaded surface highlighting that were generated from the segmented data. Three neuroradiologists independently reviewed the generated ZBS images for aneurysms. The observers had 80 % sensitivity (90 % for aneurysms larger than 2 mm) with 0. 13 false positives per image. Good agreement with the gold standard for describing aneurysm size and orientation was shown. These preliminary results suggest that the segmentation has diagnostic fidelity with the original data and may be useful for improved visualization or automated analysis of the vasculature...|$|R
50|$|In September 2015 it was {{revealed}} the headset would have three rendering modes for developers to choose from: native 90 Hz, native 120 Hz, and a mode where gameplay running at 60 Hz would be displayed at 120 Hz using a motion interpolation technique called asynchronous <b>reprojection.</b> The interpolation would be achieved with little system resources and a small latency of under 18 milliseconds. The technique would also be utilised in the native 120 Hz mode to ensure consistent framerate. According to a Sony representative the company expects the interpolated 120 Hz mode to be a popular choice for games.|$|E
5000|$|Bundle {{adjustment}} {{amounts to}} jointly refining {{a set of}} initial camera and structure parameter estimates for finding the set of parameters that most accurately predict {{the locations of the}} observed points in the set of available images. More formally, assume that [...] 3D points are seen in [...] views and let [...] be the projection of the th point on image [...] Let [...] denote the binary variables that equal 1 if point [...] is visible in image [...] and 0 otherwise. Assume also that each camera [...] is parameterized by a vector [...] and each 3D point [...] by a vector [...] Bundle adjustment minimizes the total <b>reprojection</b> error with respect to all 3D point and camera parameters, specifically ...|$|E
50|$|Bundle {{adjustment}} {{boils down}} to minimizing the <b>reprojection</b> error between the image locations of observed and predicted image points, which is expressed as the sum of squares {{of a large number}} of nonlinear, real-valued functions. Thus, the minimization is achieved using nonlinear least-squares algorithms. Of these, Levenberg-Marquardt has proven to be one of the most successful due to its ease of implementation and its use of an effective damping strategy that lends it the ability to converge quickly from a wide range of initial guesses. By iteratively linearizing the function to be minimized in the neighborhood of the current estimate, the Levenberg-Marquardt algorithm involves the solution of linear systems termed the normal equations. When solving the minimization problems arising in the framework ofbundle adjustment, the normal equations have a sparse block structure owing to the lack of interaction among parameters for different 3D points and cameras. This can be exploited to gain tremendous computational benefits by employing a sparse variant of the Levenberg-Marquardt algorithm which explicitly takes advantage of the normal equations zeros pattern, avoiding storing and operating on zero-elements.|$|E
40|$|This thesis {{introduces}} a novel geometry processing pipeline based on unconstrained spherical parameterization and normal remeshing. We claim three main contributions: First we show how {{to increase the}} stability of Normal Mesh construction, while speeding it up by decomposing the process into two stages: parameterization and remeshing. We show that the remeshing step {{can be seen as}} resampling under a small perturbation of the given parameterization. Based on this observation we describe a novel algorithm for efficient and stable (interpolatory) normal mesh construction via parameterization perturbation. Our second contribution is the introduction of Variational Normal Meshes. We describe a novel algorithm for encoding these meshes, and use our implementation to argue that variational normal meshes have a higher approximation quality than interpolating normal meshes, as expected. In particular we demonstrate that interpolating normal meshes have about 60 percent higher Hausdorff approximation error for the same number of vertices than our novel variational normal meshes. We also show that variational normal meshes have less aliasing artifacts than interpolatory normal meshes. The third contribution is on creating parameterizations for unstructured genus zero meshes. Previous approaches could only avoid collapses by introducing artificial constraints or continuous <b>reprojections,</b> which are avoided by our method. The key idea is to define upper bound energies that are still good approximations. We achieve this by dividing classical planar triangle energies by the minimum distance to the sphere center. We prove that these simple modifaction provides the desired upper bounds and are good approximations in the finite element sense. We have implemented all algorithms and provide example results and statistical data supporting our theoretical observations...|$|R
5000|$|In 1935, Vladimir Fock {{showed that}} the quantum {{mechanical}} bound Kepler problem {{is equivalent to the}} problem of a free particle confined to a three-dimensional unit sphere in four-dimensional space. [...] Specifically, Fock {{showed that the}} Schrödinger wavefunction in the momentum space for the Kepler problem was the stereographic projection of the spherical harmonics on the sphere. Rotation of the sphere and <b>reprojection</b> results in a continuous mapping of the elliptical orbits without changing the energy; quantum mechanically, this corresponds to a mixing of all orbitals of the same energy quantum number n. Valentine Bargmann noted subsequently that the Poisson brackets for the angular momentum vector L and the scaled LRL vector D formed the Lie algebra for SO(4). [...] Simply put, the six quantities D and L correspond to the six conserved angular momenta in four dimensions, associated with the six possible simple rotations in that space (there are six ways of choosing two axes from four). This conclusion does not imply that our universe is a three-dimensional sphere; it merely means that this particular physics problem (the two-body problem for inverse-square central forces) is mathematically equivalent to a free particle on a three-dimensional sphere.|$|E
40|$|Fourier-based <b>reprojection</b> {{methods have}} the {{potential}} to reduce the computation time in iterative tomographic image reconstruction. Interpolation errors are a limitation of Fourier-based <b>reprojection</b> methods. We apply a min-max interpolation method for the nonuniform fast Fourier transform (NUFFT) to minimize the interpolation errors. Numerical results show that the min-max NUFFT approach provides substantially lower approximation errors in tomographic <b>reprojection</b> and backprojection than conventional interpolation methods...|$|E
