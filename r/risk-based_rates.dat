6|7|Public
5000|$|Frank Nutter, the {{president}} of the Reinsurance Associate of America, suggested pursuing a plan of keeping the scheduled insurance premium increases, but targeting the homeowners that are [...] "most in need, while maintaining the benefits of <b>risk-based</b> <b>rates</b> and incentivizing community and individual mitigation." ...|$|E
5000|$|The Institute's {{flagship}} publication, initiated {{while still}} {{a part of}} Heartland, is an annual Insurance Regulation Report Card, a state-by-state study of the U.S. insurance regulatory system, examining which states are doing the best job of regulating insurance through limited, effective and efficient government. The 2012 report card measured states on 14 variables, including the concentration of home and auto insurance markets and relative size of residual markets; the effectiveness of state solvency and fraud regulation; the transparency and politicization of insurance regulation; the tax and fee burden placed on insurance markets {{and the proportion of}} fees used to support insurance regulation; and the relative freedom granted to insurers to set <b>risk-based</b> <b>rates,</b> including through the use of credit and territorial information. Vermont was judged to have the best environment for insurance regulation, while Florida, the lone state to earn an F grade, was judged to have the worst.|$|E
40|$|Background: Asthma is {{prevalent}} but treatable: {{adherence to}} evidence-based treatment lessens impairment and lowers {{the risk of}} future exacerbations. Objective: This report details recent trends in asthma prevalence, health care use, and mortality since 2001 and presents an overview of trends since 1980. Methods: Asthma prevalence estimates {{were obtained from the}} National Health Interview Survey (2001 - 2010). Physician office visit data were obtained from the National Ambulatory Medical Care Survey, hospital outpatient department and emergency department (ED) visit data from the National Hospital Ambulatory Medical Care Survey, hospitalization data from the National Hospital Discharge Survey, and death data from the National Vital Statistics System (2001 - 2009). Two types of rates were calculated: population-based rates based on the total population and <b>risk-based</b> <b>rates</b> based on the population with asthma. Results: Current asthma prevalence increased from 2001 to 2010. There were no significant changes in rates for hospital outpatient department visits, ED visits, or hospitalizations, whereas <b>risk-based</b> <b>rates</b> for private physician office visits declined. Asthma death rates decreased from 2001 to 2009. Over the long term, asthma prevalence rose more slowly after 2001 than during 1980 - 1996, asthma hospitalizations declined since 1984 and deaths declined since 1999. Disparities by race and sex for adverse outcomes remained high despite these declines. Conclusion: Since 2001, asthma prevalence increased, <b>risk-based</b> <b>rates</b> for visits to private physician offices and deaths declined, and <b>risk-based</b> <b>rates</b> for other types of ambulatory visits and for hospitalizations showed no clear trend. by Jeanne E. Moorman, Lara J. Akinbami, Cathy M. Bailey, Hatice S. Zahran, Michael E. King, Carol A. Johnson, and Xiang Liu. "November 2012. "CS 234447. Includes bibliographical references...|$|E
40|$|The needed of big fund {{inspired}} the companies {{to sell a}} part of its {{shares in the capital}} market. One of methods that used is to be a public company (Go-Public). However, for Islamic banking to be a public company is not main choice. At present, Islamic banking that was listing its shares in Indonesian Stock Exchange is one Islamic banking only. In this research described the comparison financial soundness of Islamic banking pre- Go-Public with post- Go-Public. The used of the analysis was the analysis of financial ratios of components contained in RBBR (<b>Risk-based</b> Bank <b>Rating).</b> Comparing between a financial soundness of Islamic banking pre go-public and post go-public used comparison test Paired-sample t test. The financial soundness condition of Islamic banking pre- and post- Go-Public overall changed to a better level. However, based on the result of further tests, showed that Go-Public policy only influenced to capital factor. DOI: 10. 15408 /etk. v 15 i 1. 2410 </a...|$|R
5000|$|Car finance arose {{because the}} price of cars {{was out of the}} reach of {{individual}} purchasers without borrowing the money. The funding for personal car finance is provided either by a retail bank or a specialist car financing company. Some car manufacturers own their own car financing arms, such as Ford with the Ford Motor Credit Company and General Motors with its GMAC Financial Services arm, which has now been renamed and rebranded as Ally Financial. Indirect auto lenders may set <b>risk-based</b> interest <b>rate,</b> or “buy rate,” that it conveys to auto dealers. Car companies may then allow their auto dealers to charge a higher interest rate when they finalize the deal with the consumer. This is typically called “dealer markup.” [...] Markups can generate compensation for dealers and some (those of GM's Ally and Honda) have been found to use the discretion to charge consumers different rates regardless of consumer creditworthiness.|$|R
50|$|On December 1, 2008, the New York State Unified Court System began sending notices to borrowers {{in default}} who have high cost {{mortgages}}, whose mortgages were being foreclosed prior to September 1, 2008, offering voluntary settlement conferences. Borrowers with high cost mortgages whose mortgages entered or are entering into foreclosure from September 2008 on, {{will be required}} to attend a mandatory settlement conference prior to foreclosure proceedings. High cost loans are considered to have excessive fees, <b>risk-based</b> sub-prime percentage <b>rates,</b> negative amortizing payment options, and other features {{which may or may not}} be considered predatory lending practices.|$|R
40|$|There {{is often}} tension between setting {{insurance}} premiums that reflect risk {{and dealing with}} equity/affordability issues. The National Flood Insurance Program in the United States recently moved toward elimination of certain premium discounts, but this raised issues {{with respect to the}} affordability of coverage for homeowners in flood-prone areas. Ultimately, Congress reversed course and reinstated discounted rates for certain classes of policyholders. We examine the tension between <b>risk-based</b> <b>rates</b> and affordability through a case study of Ocean County, New Jersey, an area heavily damaged by Hurricane Sandy. We argue that the NFIP must address affordability, but that this should not be done through discounted premiums. Instead, we propose a means-tested voucher program coupled with a loan program for investments in hazard mitigation...|$|E
40|$|A {{letter report}} {{issued by the}} Government Accountability Office with an {{abstract}} that begins "Questions about the financial status of the National Flood Insurance Program (NFIP) have increased since the 2005 hurricanes, which left the program with an unprecedented $ 17. 4 billion deficit [...] a debt that resulted in GAO placing NFIP on its high-risk list in March 2006. Among the concerns are the subsidized rates NFIP must provide for about 25 percent of the policies, mostly for older buildings in high-risk flood zones. And although fully <b>risk-based</b> <b>rates</b> are supposed to reflect actual flood risk, concerns have been raised that they do not. This report evaluates (1) the Federal Emergency Management Agency's (FEMA) process for setting full-risk rates {{to determine whether it}} produces rates that accurately reflect the risk of flooding and (2) the process that FEMA uses to set subsidized rates and their effect on the financial condition of NFIP. To do this work, GAO evaluated the NFIP rate model, examined data from FEMA, surveyed relevant literature, and interviewed other relevant agencies and risk-modeling firms. ...|$|E
40|$|Abstract This paper explores {{options for}} {{programs}} {{to be put}} in place prior to a disaster to avoid large and often poorly-managed expenditures following a catastrophe and to provide appropriate protection against the risk of those large losses which do occur. The lack of interest in insurance protection and mitigation by property owners and by public sector agencies prior to a disaster often creates major problems following a catastrophic event for victims and the government. Property owners who suffer severe damage may not have the financial resources easily at hand to rebuild their property and hence will demand relief. The government is then likely to respond with costly but poorly targeted disaster assistance. To avoid these large and often uneven ex post expenditures, we consider the option of mandatory comprehensive private disaster insurance with <b>risk-based</b> <b>rates.</b> It may be more efficient to have an ex ante public program to ensure coverage of catastrophic losses and to subsidize low income residents who cannot afford coverage rather than the current largely ex post public disaster relief program...|$|E
40|$|Information {{advantage}} and entry deterrence incentives are investigated as they affect lending outcomes and competitive {{structure of the}} U. S. residential mortgage market. In the model, when assessing a loan applicant, the incumbent monopoly lender employs a proprietary screening technology to produce a privately observed estimate of loan credit quality. When faced with potential competitive entry, the incumbent signals poor credit quality by charging high prices to higher quality borrowers. Market structure and loan pricing strategy are derived endogenously, where the incumbent deters entry by first segmenting consumers into prime and sub-prime loan markets and second by charging prime market borrowers a uniform rate that {{is higher than the}} <b>risk-based</b> monopoly <b>rate.</b> Empirical implications of the model are identified, and evidence is presented that is consistent with predictions. 1 The U. S. residential mortgage market represents close to 30 percent of the nation’s total credit market. The structure of this market has received considerable attention in recent years, with much of the focus on Fannie Mae and Freddie Mac. Over the years these two Government Sponsore...|$|R
40|$|Subprime credit, a {{relatively}} new method of risk-based pricing, has been hailed {{as a way to}} open up markets and provide access to credit to those who would otherwise be excluded. Evidence suggests that subprime mortgage segmentation increases rather than reduces exclusionary practices in lending. Furthermore, what is unclear is how lenders determine who qualifies as a subprime borrower. This concern became manifested when studies demonstrated that minority borrowers, regardless of creditworthiness, are more likely to receive expensive, sub-prime loans. The disparity is properly attributed to lenders’ credit pricing policies which included discretionary increases despite the objectively-determined <b>risk-based</b> interest <b>rate</b> as well as minority borrowers’ search costs and asymmetric information about prices in this market. This Article reviews the theory and history of credit scoring in mortgage lending and argues that lenders’ practices arguably justified by 2 ̆ 2 legitimate business need 2 ̆ 2 as well as lenders’ credit scoring models exacerbate lending disparities. It argues that the failure of competitive forces to disallow these unjustified and illegal increases also speaks to regulatory failure. It proposes that lenders operating in noncompetitive subprime mortgage markets address how their practices interact with lending disparities even apart from their complicity in creating conditions that worsen economic disadvantage...|$|R
40|$|The use of {{technology}} by firms is changing the way insurance and lending markets function. I study the financial technology, or "fin-tech'', industry, which {{is characterized by a}} growing number of online lenders who use data on educational, employment, and financial outcomes to quickly assess the risk of prospective borrowers and offer individualized loan terms. In many ways, their financial "innovations'' {{can be thought of as}} movements towards more personalized products: interest rates that better reflect individuals' risk, payment plans that are tailored to individuals' monthly income and expenditures, and user-friendly interfaces that make financial decisions more intuitive and uncomplicated. On an individual level, as firms expand and customize product offerings, there is the potential for large efficiency gains. These innovations could also have wider implications for market structure; for example, if more accurate risk-based pricing creates clear winners and losers, it will change the distribution of consumer surplus. Advances in data-driven underwriting have both efficiency and equity implications for consumer lending markets where private and public credit options coexist. In the $ 1 trillion student loan market, private lenders now offer a growing distribution of <b>risk-based</b> interest <b>rates,</b> while the federally-run loan program sets a break-even, uniform interest rate. In my first chapter, I measure the overall gains in consumer surplus from such risk-based pricing and quantify the redistributional consequences of low-risk types refinancing out of the government pool into the private market. The empirical analysis is based on a unique applicant-level dataset from an online refinancing firm that contains information on loan terms, household balance sheets, and <b>risk-based</b> interest <b>rates.</b> I first leverage a series of firm-conducted interest rate experiments to estimate the sensitivity of borrowers' maturity and refinancing choices to interest rates. Using the maturity response, I then estimate a structural model of borrowers' repayment preferences. Using the estimated model, I show that comprehensive risk-based pricing generates large absolute gains in welfare of $ 480 per borrower relative to a break-even uniform price, and $ 400 relative to a coarser method of FICO-based pricing. If the federal pool conducts breakeven pricing, these efficiency gains come at a direct equity cost [...] low risk surplus will increase on average by $ 2, 300, while high risk surplus will fall by $ 2, 100. In order to maintain access to the current uniform rate, the government would have to transition from break-even pricing to an average net subsidy of $ 2, 080 per borrower. In the second chapter, I empirically analyze the fixed and variable rate decisions of borrowers who are financing large personal loans, and are given the option to switch rate types at any point. Many online lending firms now offer financial products that are more flexible and personalized than traditional loans; however, little is known about how consumers will interact with these more complete, but also more complex, contracts. Over my sample time period, the market index interest rate for the fixed and variable rate loans changed considerably. I first present reduced form evidence on the determinants of borrowers' initial rate decisions and the presence of switching costs, and then estimate a structural model that maps these findings to the coefficient of absolute risk aversion and a switching cost parameter. I compare the active and inactive rate choices of borrowers in different interest rate environments to separately identify switching costs from risk preferences. I show that while initial rate choices are very responsive to the prevailing interest rate environment, very few borrowers ever take advantage of the option to switch rate types even when interest rates increase. Specifically, I estimate a risk aversion parameter of. 0564, which implies that borrowers are very risk averse, and lower and upper bounds on switching costs from $ 166 to $ 1, 185. I also show that both the initial probability of choosing a variable rate loan and the probability of never switching are positively correlated with borrower liquidity constraints, which suggests that these borrowers are more focused on current monthly payments than future interest rate risk...|$|R
40|$|The 2007 - 2009 {{financial}} crisis has {{shed light on}} the importance of contagion and systemic risk, and revealed the lack of adequate indicators for measuring and monitoring them. This dissertation addresses these issues and leads to several recommendations for the design of an improved assessment of systemic importance, improved rating methods for structured finance securities, and their use by investors and risk managers. Using a complete data set of all mutual exposures and capital levels of financial institutions in Brazil in 2007 and 2008, we explore in chapter 2 the structure and dynamics of the Brazilian financial system. We show that the Brazilian financial system exhibits a complex network structure characterized by a strong degree of heterogeneity in connectivity and exposure sizes across institutions, which is qualitatively and quantitatively similar to the statistical features observed in other financial systems. We find that the Brazilian financial network is well represented by a directed scale-free network, rather than a small world network. Based on these observations, we propose a stochastic model for the structure of banking networks, representing them as a directed weighted scale free network with power law distributions for in-degree and out-degree of nodes, Pareto distribution for exposures. This model may then be used for simulation studies of contagion and systemic risk in networks. We propose in chapter 3 a quantitative methodology for assessing contagion and systemic risk in a network of interlinked institutions. We introduce the Contagion Index as a metric of the systemic importance of a single institution or a set of institutions, that combines the effects of both common market shocks to portfolios and contagion through counterparty exposures. Using a directed scale-free graph simulation of the financial system, we study the sensitivity of contagion to a change in aggregate network parameters: connectivity, concentration of exposures, heterogeneity in degree distribution and network size. More concentrated and more heterogeneous networks are found to be more resilient to contagion. The impact of connectivity is more controversial: in well-capitalized networks, increasing connectivity improves the resilience to contagion when the initial level of connectivity is high, but increases contagion when the initial level of connectivity is low. In undercapitalized networks, increasing connectivity tends to increase the severity of contagion. We also study the sensitivity of contagion to local measures of connectivity and concentration across counterparties [...] the counterparty susceptibility and local network frailty [...] that are found to have a monotonically increasing relationship with the systemic risk of an institution. Requiring a minimum (aggregate) capital ratio is shown to reduce the systemic impact of defaults of large institutions; we show that the same effect may be achieved with less capital by imposing such capital requirements only on systemically important institutions and those exposed to them. In chapter 4, we apply this methodology {{to the study of the}} Brazilian financial system. Using the Contagion Index, we study the potential for default contagion and systemic risk in the Brazilian system and analyze the contribution of balance sheet size and network structure to systemic risk. Our study reveals that, aside from balance sheet size, the network-based local measures of connectivity and concentration of exposures across counterparties introduced in chapter 3, the counterparty susceptibility and local network frailty, contribute significantly to the systemic importance of an institution in the Brazilian network. Thus, imposing an upper bound on these variables could help reducing contagion. We examine the impact of various capital requirements on the extent of contagion in the Brazilian financial system, and show that targeted capital requirements achieve the same reduction in systemic risk with lower requirements in capital for financial institutions. The methodology we proposed in chapter 3 for estimating contagion and systemic risk requires visibility on the entire network structure. Reconstructing bilateral exposures from balance sheets data is then a question of interest in a financial system where bilateral exposures are not disclosed. We propose in chapter 5 two methods to derive a distribution of bilateral exposures matrices. The first method attempts to recover the balance sheet assets and liabilities "sample by sample". Each sample of the bilateral exposures matrix is solution of a relative entropy minimization problem subject to the balance sheet constraints. However, a solution to this problem does not always exist when dealing with sparse sample matrices. Thus, we propose a second method that attempts to recover the assets and liabilities "in the mean". This approach is the analogue of the Weighted Monte Carlo method introduced by Avellaneda et al. (2001). We first simulate independent samples of the bilateral exposures matrix from a relevant prior distribution on the network structure, then we compute posterior probabilities by maximizing the entropy under the constraints that the balance sheet assets and liabilities are recovered in the mean. We discuss the pros and cons of each approach and explain how it could be used to detect systemically important institutions in the financial system. The recent crisis has also raised many questions regarding the meaning of structured finance credit ratings issued by rating agencies and the methodology behind them. Chapter 6 aims at clarifying some misconceptions related to structured finance ratings and how they are commonly interpreted: we discuss the comparability of structured finance ratings with bond ratings, the interaction between the rating procedure and the tranching procedure and its consequences for the stability of structured finance ratings in time. These insights are illustrated in a factor model by simulating rating transitions for CDO tranches using a nested Monte Carlo method. In particular, we show that the downgrade risk of a CDO tranche can be quite different from a bond with same initial rating. Structured finance ratings follow path-dependent dynamics that cannot be adequately described, as usually done, by a matrix of transition probabilities. Therefore, a simple labeling via default probability or expected loss does not discriminate sufficiently their downgrade risk. We propose to supplement ratings with indicators of downgrade risk. To overcome some of the drawbacks of existing rating methods, we suggest a <b>risk-based</b> <b>rating</b> procedure for structured products. Finally, we formulate a series of recommendations regarding the use of credit ratings for CDOs and other structured credit instruments...|$|R

