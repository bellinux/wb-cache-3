4821|1826|Public
25|$|Standard {{deviation}} {{is often}} used to compare <b>real-world</b> <b>data</b> against a model to test the model.|$|E
25|$|While these {{algorithms}} are asymptotically efficient on random data, {{for practical}} efficiency on <b>real-world</b> <b>data</b> various modifications are used. First, the overhead of these algorithms becomes significant on smaller data, so often a hybrid algorithm is used, commonly switching to insertion sort once {{the data is}} small enough. Second, the algorithms often perform poorly on already sorted data or almost sorted data – these are common in <b>real-world</b> <b>data,</b> and can be sorted in O(n) time by appropriate algorithms. Finally, {{they may also be}} unstable, and stability is often a desirable property in a sort. Thus more sophisticated algorithms are often employed, such as Timsort (based on merge sort) or introsort (based on quicksort, falling back to heap sort).|$|E
25|$|This {{brings with}} it the benefit {{of being able to}} {{simulate}} changes to business processes based on <b>real-world</b> <b>data</b> (not just on assumed knowledge). Also, the coupling of BPM to industry methodologies allows users to continually streamline and optimize the process to ensure that it is tuned to its market need.|$|E
50|$|Differences in <b>real-world</b> {{measured}} <b>data</b> {{from the}} true values come about from by multiple factors affecting the measurement.|$|R
30|$|It is {{important}} that occupancy forecast errors are realistic; thus, we propose a method to systematically introduce realistic occupancy errors into MPC predictions using <b>real-world</b> occupancy <b>data.</b>|$|R
30|$|Thus, <b>real-world</b> {{clinical}} <b>data</b> {{demonstrates that}} when generic alendronate {{is compared to}} brand alendronate there are significant differences in persistence to therapy, effectiveness (bone mineral density) and safety (AEs).|$|R
500|$|The {{method is}} said to benefit from {{continuing}} improvements in modeling techniques of computer science and increased computer capabilities. [...] Issues include those common to experimental economics in general and by comparison and to development of a common framework for empirical validation and resolving open questions in agent-based modeling. • Fagiolo, Giorgio, Alessio Moneta, and Paul Windrum (2007). [...] "A Critical Guide to Empirical Validation of Agent-Based Models in Economics: Methodologies, Procedures, and Open Problems", Computational Economics, 30, pp. –226. The ultimate scientific objective of the method {{has been described as}} [...] "test theoretical findings against <b>real-world</b> <b>data</b> in ways that permit empirically supported theories to cumulate over time, with each researcher's work building appropriately on the work that has gone before." [...] • Judd, Kenneth L. (2006). [...] "Computationally Intensive Analyses in Economics", Handbook of Computational Economics, v. 2, ch. 17, pp. [...] 893. Pre-pub [...] • Tesfatsion, Leigh, and Kenneth L. Judd, ed. (2006). Handbook of Computational Economics, v. 2. [...] & and chapter-preview ...|$|E
2500|$|Kurzweil says Alan Turing's 1950 paper Computing Machinery and Intelligence {{launched}} {{the field of}} artificial intelligence. He admits that early progress in the field led to wild predictions of future successes which did not materialize. Kurzweil feels intelligence is the [...] "ability to use optimally limited resources" [...] to achieve goals. He contrasts recursive solutions with neural nets, he likes both but specifically mentions how valuable neural nets are since they destroy information during processing, which if done selectively is essential to making sense of <b>real-world</b> <b>data.</b> A neuron either fires or not [...] "reducing the babble of its inputs to a single bit". He also greatly admires genetic algorithms which mimic biological evolution to great effect.|$|E
2500|$|At the time, {{there was}} a general belief in the {{stability}} of natural systems. However, cracks started to appear when a study was made of the predator-prey relationship of wolf and elks. It was found that wild population swings had occurred over centuries. Other studies then found huge variations, and a significant lack of homeostasis in natural systems. George Van Dyne then tried to build a computer model to try to simulate a complete ecosystem based on extensive <b>real-world</b> <b>data,</b> to show how the stability of natural systems actually worked. To his surprise, the computer model did not stabilize like the Odums' electrical model had. The reason for this lack of stabilization was that he had used extensive data which more accurately reflected reality, whereas the Odums and other ecologists had [...] "ruthlessly simplified nature." [...] The scientific idea had thus been shown to fail, but the popular idea remained in currency, and even grew as it apparently offered the possibility of a new egalitarian world order.|$|E
40|$|Background-—As implantable cardioverter-defibrillator {{technology}} evolves, clinicians {{and patients}} need reliable performance data on current transvenous implantable cardioverter-defibrillator systems. In addition, <b>real-world</b> reliability <b>data</b> could inform postmarket surveillance strategies directed by regulators and manufacturers...|$|R
30|$|The {{proposed}} algorithm involves two random graph generation {{models and}} four schemes. Two authentic score functions are {{proposed for the}} PA Model. With the first experiment, we study the performance of different combinations using <b>real-world</b> graph <b>data.</b>|$|R
5000|$|RealStream <b>Real-World</b> Challenges for <b>Data</b> Stream Mining Workshop-Discussion at the ECML PKDD 2013, Prague, Czech Republic.|$|R
2500|$|Puglsey left Bristol in 1968 and Severn was {{appointed}} his successor as professor {{and head of}} department, a move that was viewed with surprise by some contemporaries owing to Severn's youth – he was 38 years-old {{at the time of}} his appointment. [...] Severn continued his focus on the effects of earthquakes upon dams, particularly embankment dams which were widespread in the hydro-electric power stations being constructed during this period and outnumbered the previously dominant arch dams by ten to one in new construction. [...] The accurate modelling of embankment dams is difficult due to their mix of rocks and soil and little work had been carried out previously on their reaction to dynamic loading, such as was exerted by earthquakes. [...] Severn was a proponent of the use of finite element analysis in the modelling of such dams and pioneered the application of early digital computers to this task. [...] In the late 1970s Severn installed a 2m by 1m shaking table at Bristol and used it to derive a set of guidelines for the design of earthquake resistance in embankment dams, they were the first of their kind in the world. [...] Severn's table was computer controlled and used a series of eccentricly-mounted weights to exert forces upon embankment dam models that he constructed of sand and wax. [...] He refined his models using <b>real-world</b> <b>data</b> collected from a dam in Wales. [...] Under Severn's direction Bristol's Department of Civil Engineering became the top-rated such department in the world and his Earthquake Engineering Research Centre, the largest institution of its kind in the UK, was internationally renowned.|$|E
5000|$|Oracles. A {{crucial feature}} for most contracts, whether encoded as text or as code, {{is the ability}} to refer to values from the outside {{environment}} and <b>real-world</b> <b>data.</b> The æternity Oracle Machine provides <b>real-world</b> <b>data</b> to the smart-contracts in way that is closely integrated into the Blockchain.|$|E
50|$|High-order pattern {{discovery}} {{facilitate the}} capture of high-order (polythetic) patterns or event associations that are intrinsic to complex <b>real-world</b> <b>data.</b>|$|E
40|$|In {{this paper}} {{we focus on}} a multi-case case-based {{reasoning}} system to support users during collaborative search tasks. In particular we describe how repositories of search experiences/knowledge can be recommended to users at search time. These recommendations are evaluated using <b>real-world</b> search <b>data...</b>|$|R
30|$|In {{this study}} {{a range of}} stereo imagery is used for {{evaluation}} including that from the Middlebury Stereo Collection [6], virtual automotive stereo sequences [7] and also two sets of <b>real-world</b> stereo <b>data</b> originating both from this study and the prior independent study of [9].|$|R
40|$|Our institute’s {{scope is}} put on the {{integration}} of content-based and semantic technologies into multimedia applications. We therefore highlight the current state-of-the-art {{in dealing with the}} Semantic Gap and present our approach based on the experience gained from projects focusing on <b>real-world</b> media <b>data...</b>|$|R
50|$|Applied {{econometrics}} uses theoretical econometrics and <b>real-world</b> <b>data</b> {{for assessing}} economic theories, developing econometric models, analyzing economic history, and forecasting.|$|E
50|$|Below {{are several}} sample WebQL scripts. While scripts to perform <b>real-world</b> <b>data</b> {{integration}} tasks are generally much larger, these scripts give a sense the language’s capabilities.|$|E
50|$|Meaning any data {{outside the}} {{blockchain}} {{can be translated}} into a deterministic value {{that can be used}} in æternity smart contracts, making <b>real-world</b> <b>data</b> easily accessible and actionable.|$|E
30|$|ThermalSim {{requires}} <b>real-world</b> occupancy <b>data</b> {{to generate}} an error matrix. We leveraged an existing deployment from our university campus and gathered occupancy data (along with other information) {{from more than}} fifty volunteers – including students, faculty, and the staff members every 30 seconds for a year.|$|R
30|$|The rest of {{the paper}} is {{organized}} as follows. We review the related work in Sect.  2 and present the critical techniques of Bus-OLAP in Sect.  3. In Sect.  4, we report a systematic empirical study using <b>real-world</b> bus <b>data</b> and we conclude the paper in Sect.  5.|$|R
40|$|In this articie，we {{will talk}} on some {{algorithmic}} developments for KnapsackProblem，Set-Covering／Set-Partitioning Problem. Then，we propose that finding an optimal／near optimal solution {{for a given}} <b>Real-World</b> input <b>data</b> of a NP-Complete／NP-Hard integer programming problem is great enough because any algorithm for such a problem shows exponential and heavy data dependentcomputing time...|$|R
50|$|Timsort was {{designed}} {{to take advantage of}} runs of consecutive ordered elements that already exist in most <b>real-world</b> <b>data,</b> natural runs. It iterates over the data collecting elements into runs, and concurrently merging those runs together.|$|E
5000|$|... "Serious games can be {{powerful}} educational tools, allowing users to experiment, {{learn from their}} mistakes and safely experience risky or dangerous situations.... Examples of serious games include IndustryPlayer, a business simulation based on <b>real-world</b> <b>data</b> ..." ...|$|E
50|$|Normal {{distributions}} are symmetrical, bell-shaped distributions {{that are}} useful in describing <b>real-world</b> <b>data.</b> The standard normal distribution, represented by the letter Z, is the normal distribution having a mean of 0 and {{a standard deviation of}} 1.|$|E
40|$|Convolutional neural {{networks}} (CNN) represent a state-of-the-art approach to non-trivial image processing tasks, including compression artifacts reduction and image super-resolution. As some research groups nowadays show, these networks {{can also be}} leveraged to perform such tasks on <b>real-world</b> video <b>data,</b> resulting in video spatial super-resolution and more. The main goal of this work is to determine whether these nets can be adjusted to perform temporal super-resolution of <b>real-world</b> video <b>data.</b> I utilize the aforementioned neural net architectures in this paper to do so. As I show, given that the input videos are of reasonable quality, these nets are capable of double-image interpolation {{up to a certain}} level, where the output image is usable for temporal upsampling. Although the presented results are promising, I encourage more research to be done on this topic...|$|R
50|$|In June 2012, SwiftKey {{released}} a specialized {{version of its}} keyboard called SwiftKey Healthcare. It is a virtual keyboard for iOS, Android, Windows Phone and BlackBerry devices that offers next-word predictions based on <b>real-world</b> clinical <b>data.</b> In October 2012 SwiftKey Healthcare won the Appsters Award for Best Enterprise App 2012.|$|R
40|$|In this paper, {{we propose}} a new {{learning}} algorithm for non-stationary Dynamic Bayesian Networks is proposed. Although {{a number of}} effective learning algorithms for non-stationary DBNs have previously been proposed and applied in Signal Pro- cessing and Computational Biology, those algorithms are based on batch learning algorithms that {{cannot be applied to}} online time-series data. Therefore, we propose a learning algorithm based on a Particle Filtering approach so that we can apply that algorithm to online time-series data. To evaluate our algorithm, we apply it to the simulated data set and the <b>real-world</b> financial <b>data</b> set. The result on the simulated data set shows that our algorithm performs accurately makes estimation and detects change. The result applying our algorithm to the <b>real-world</b> financial <b>data</b> set shows several features, which are suggested in previous research that also implies the effectiveness of our algorithm. Thesi...|$|R
5000|$|The normal {{distribution}} is NOT assumed nor {{required in the}} calculation of control limits. Thus making the IndX/mR chart a very robust tool. This is demonstrated by Wheeler using <b>real-world</b> <b>data,</b> [...] and {{for a number of}} highly non-normal probability distributions.|$|E
50|$|While these {{algorithms}} are asymptotically efficient on random data, {{for practical}} efficiency on <b>real-world</b> <b>data</b> various modifications are used. First, the overhead of these algorithms becomes significant on smaller data, so often a hybrid algorithm is used, commonly switching to insertion sort once {{the data is}} small enough. Second, the algorithms often perform poorly on already sorted data or almost sorted data - these are common in <b>real-world</b> <b>data,</b> and can be sorted in O(n) time by appropriate algorithms. Finally, {{they may also be}} unstable, and stability is often a desirable property in a sort. Thus more sophisticated algorithms are often employed, such as Timsort (based on merge sort) or introsort (based on quicksort, falling back to heap sort).|$|E
50|$|Crowd {{analysis}} and tracking provide <b>real-world</b> <b>data</b> {{to evaluate and}} improve simulation techniques, and real crowd data-sets can share crowd monitoring and anomaly detection methods with simulated crowds. A robust noise-resistant method is necessary to compare simulated scenarios with real crowd tracking data meaningfully.|$|E
30|$|As {{with many}} tomographic {{reconstruction}} algorithms, several practical issues arise when applying the SIRT-FBP method on <b>real-world</b> tomographic <b>data.</b> In this section, we discuss implementation details {{that are important}} for real-world application of SIRT-FBP. To demonstrate the impact {{of some of these}} details, we give reconstruction results for simulated data in the “Results and discussion” section.|$|R
50|$|As a basic comparison, mainframe-class tape drives, such as Oracle's Sun StorageTek T10000B, {{are priced}} at {{approximately}} US$37,000 each, excluding tape libraries. (IBM's TS1130 is also representative of this storage class.) At any single {{moment in time}} each T10000C tape drive can read or write (or both read and write) to one tape cartridge which can contain up to 5TB of uncompressed <b>data.</b> <b>Real-world</b> sequential <b>data</b> transfer speeds are high (sustained 240MB/second for the T10000C and 160MB/second for the TS1130) compared to disk. However, PC-class hard disks are priced below $200 for 3TB. One mainframe-class hard disk still has a much lower price than one mainframe-class tape drive, so the economics might favor disk.|$|R
30|$|The {{data used}} for this work consist of Automatic Identification System (AIS), which is a {{broadcast}} system used for large ships; Automatic Dependent Surveillance-Broadcast (ADS-B), which is a broadcast system used for commercial aircrafts; GPS logs; and <b>real-world</b> radar <b>data.</b> The classes for this work are typical classes for coastal surveillance, e.g., large ships, birds, and small boats.|$|R
