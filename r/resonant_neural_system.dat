0|6863|Public
40|$|An evolvable {{synthetic}} <b>neural</b> <b>system</b> {{includes an}} evolvable neural interface operably coupled {{to at least}} one neural basis function. Each neural basis function includes an evolvable neural interface operably coupled to a heuristic <b>neural</b> <b>system</b> to perform high-level functions and an autonomic <b>neural</b> <b>system</b> to perform low-level functions. In some embodiments, the evolvable synthetic <b>neural</b> <b>system</b> is operably coupled to one or more evolvable synthetic <b>neural</b> <b>systems</b> in a hierarchy...|$|R
50|$|The International Journal of <b>Neural</b> <b>Systems</b> is a {{bimonthly}} peer-reviewed scientific journal {{founded in}} 1989. It {{is published by}} World Scientific and covers information processing in natural and artificial <b>neural</b> <b>systems.</b>|$|R
50|$|The {{gestures}} in Indian classical dance have {{an impact}} on the <b>neural</b> <b>system</b> of human body. It is said it increases oxygen flow, controls the <b>neural</b> <b>system,</b> and thereby cures certain diseases.|$|R
40|$|Abstract Biological data {{suggests}} that activity patterns emerging in small- and large-scale <b>neural</b> <b>systems</b> may {{play an important}} role in performing the functions of the <b>neural</b> <b>system,</b> and in particular, neural computations. It is proposed in this paper that <b>neural</b> <b>systems</b> can be understood in terms of pattern computation and abstract communication systems theory. It is shown that analysing high-resolution surface EEG data, it is possible to determine abstract probabilistic rules that describe how emerging activity patterns follow earlier activity patterns. The results indicate the applicability of the proposed approach for understanding the working of complex <b>neural</b> <b>systems.</b> ...|$|R
40|$|The Evolvable <b>Neural</b> Software <b>System</b> (ENSS) is {{composed}} of sets of Neural Basis Functions (NBFs), which can be totally autonomously created and removed according to the changing needs and requirements of the software system. The resulting structure is both hierarchical and self-similar in that a given set of NBFs may have a ruler NBF, which in turn communicates with other sets of NBFs. These sets of NBFs may function as nodes to a ruler node, which are also NBF constructs. In this manner, the synthetic <b>neural</b> <b>system</b> can exhibit the complexity, three-dimensional connectivity, and adaptability of biological <b>neural</b> <b>systems.</b> An added advantage of ENSS over a natural <b>neural</b> <b>system</b> {{is its ability to}} modify its core genetic code in response to environmental changes as reflected in needs and requirements. The <b>neural</b> <b>system</b> is fully adaptive and evolvable and is trainable before release. It continues to rewire itself while on the job. The NBF is a unique, bilevel intelligence <b>neural</b> <b>system</b> composed of a higher-level heuristic <b>neural</b> <b>system</b> (HNS) and a lower-level, autonomic <b>neural</b> <b>system</b> (ANS). Taken together, the HNS and the ANS give each NBF the complete capabilities of a biological <b>neural</b> <b>system</b> to match sensory inputs to actions. Another feature of the NBF is the Evolvable Neural Interface (ENI), which links the HNS and ANS. The ENI solves the interface problem between these two systems by actively adapting and evolving from a primitive initial state (a Neural Thread) to a complicated, operational ENI and successfully adapting to a training sequence of sensory input. This simulates the adaptation of a biological <b>neural</b> <b>system</b> in a developmental phase. Within the greater multi-NBF and multi-node ENSS, self-similar ENI s provide the basis for inter-NBF and inter-node connectivity...|$|R
25|$|Theoretical and {{computational}} neuroscience {{is concerned}} with the theoretical analysis and the computational modeling of biological <b>neural</b> <b>systems.</b> Since <b>neural</b> <b>systems</b> attempt to reflect cognitive processes and behavior, the field is closely related to cognitive and behavioral modeling.|$|R
40|$|<b>Neural</b> <b>systems</b> {{of organisms}} derive their {{functionality}} {{largely from the}} numerous and intricate connections between individual components. These connections are costly and have been refined via evolutionary pressure that acts to maximize their functionality while minimizing the associated cost. This tradeoff can be formulated as a constrained optimization problem. In this paper, we use simulated annealing, implemented through Gibbs sampling, to investigate the minimal cost placement of individual components in <b>neural</b> <b>systems.</b> We show that given the constraints and the presumed cost function associated with the neural interconnections, we can find the configuration corresponding to the minimal cost. We restrict the mechanisms considered to those involving incremental improvement through local interactions since real <b>neural</b> <b>systems</b> {{are likely to be}} subject to such constraints. By adjusting the cost function and comparing with the actual configuration in <b>neural</b> <b>systems,</b> we can infer the actual cost function associated with the connections used by nature. This provides a powerful tool to biologists for investigating the configurations of <b>neural</b> <b>systems...</b>|$|R
50|$|Recently, Fiske {{has been}} {{involved}} in the field of social cognitive neuroscience. This emerging field examines how <b>neural</b> <b>systems</b> are involved in social processes, such as person perception. Fiske's own work has examined <b>neural</b> <b>systems</b> involved in stereotyping, intergroup hostility, and impression formation.|$|R
50|$|Gail Carpenter is a {{cognitive}} scientist, neuroscientist and mathematician. She is a Professor of Cognitive and <b>Neural</b> <b>Systems</b> and a Professor of Mathematics at Boston University, {{and the director}} of the Department of Cognitive and <b>Neural</b> <b>Systems</b> (CNS) Technology Lab at Boston University.|$|R
40|$|A {{survey of}} Artificial <b>Neural</b> <b>Systems</b> {{in support of}} NASA's (Johnson Space Center) Automatic Perception for Mission Planning and Flight Control Research Program was conducted. Several of the world's leading {{researchers}} contributed papers containing their most recent results on artificial <b>neural</b> <b>systems.</b> These papers were broken into categories and descriptive accounts of the results make up {{a large part of}} this report. Also included is material on sources of information on artificial <b>neural</b> <b>systems</b> such as books, technical reports, software tools, etc...|$|R
40|$|This chapter {{provides}} {{an introduction to}} the field of hybrid <b>neural</b> <b>systems.</b> Hybrid <b>neural</b> <b>systems</b> are computational systems which are based mainly on artificial neural networks but also allow a symbolic interpretation, or interaction with symbolic components. In this overview, we will describe recent results of hybrid <b>neural</b> <b>systems.</b> We will give a brief overview of the main methods used, outline the work that is presented here, and provide additional references. We will also highlight some important general issues and trends...|$|R
40|$|Synthetic <b>neural</b> <b>systems</b> {{that operate}} {{in real time}} have been {{fabricated}} using analog complementary metal-oxide- semiconductor (CMOS) very large scale integration (VLSI) technology. The analog silicon system surpasses the computational power of a general-purpose digital computer because, from device physics to circuit architecture, its form parallels the functional organization of the <b>neural</b> <b>system.</b> Because the CMOS circuit represents neural processing directly in hardware, {{it is not simply}} a simulation tool but rather an analog <b>neural</b> <b>system</b> that is embedded in, and interacts with, the real world...|$|R
5000|$|IEEE Transactions on <b>Neural</b> <b>Systems</b> and Rehabilitation Engineering ...|$|R
5000|$|... 1988-2004 Associate Editor, International Journal of <b>Neural</b> <b>Systems.</b>|$|R
40|$|A {{model is}} {{proposed}} of the {{pulse frequency modulation}} process in those <b>neural</b> <b>systems</b> where the neuron discharge is random. The model is characterized by one property, namely input-invariance of the output random process after a time transformation, which, on the one hand, greatly simplifies its analytical treatment, {{and on the other}} hand, gives a tool to determine experimentally whether the model describes the external behavior of a given <b>neural</b> <b>system.</b> The main dynamical properties of the model are studied, and the relevance of the results to information transmission by <b>neural</b> <b>systems</b> is discussed...|$|R
40|$|<b>Neural</b> <b>systems</b> {{can present}} {{various types of}} {{nonlinear}} input-output relationships, such as harmonic, subharmonic, and/or intermodulation coupling. This paper aims to introduce a general framework in frequency domain for detecting and characterizing nonlinear coupling in <b>neural</b> <b>systems,</b> called the cross-frequency coherence framework (CFCF). CFCF {{is an extension of}} classic coherence based on higher-order statistics. We demonstrate an application of CFCF for identifying nonlinear interactions in human motion control. Our results indicate that CFCF can effectively characterize nonlinear properties of the afferent sensory pathway. We conclude that CFCF contributes to identifying nonlinear transfer in <b>neural</b> <b>systems...</b>|$|R
50|$|Neurorobotics, a {{combined}} study of neuroscience, robotics, and artificial intelligence, is {{the science and}} technology of embodied autonomous <b>neural</b> <b>systems.</b> <b>Neural</b> <b>systems</b> include brain-inspired algorithms (e.g. connectionist networks), computational models of biological neural networks (e.g. artificial spiking neural networks, large-scale simulations of neural microcircuits) and actual biological systems (e.g. in vivo and in vitro neural nets). Such <b>neural</b> <b>systems</b> can be embodied in machines with mechanic or any other forms of physical actuation. This includes robots, prosthetic or wearable systems but at also, at smaller scale, micro-machines and, at the larger scales, furniture and infrastructures.|$|R
40|$|The {{analysis}} of <b>neural</b> <b>systems</b> leverages tools {{from many different}} fields. Drawing on techniques {{from the study of}} critical phenomena in statistical mechanics, several studies have reported signatures of criticality in <b>neural</b> <b>systems,</b> including power-law distributions, shape collapses, and optimized quantities under tuning. Independently, neural complexity - an information theoretic measure - has been introduced in an effort to quantify the strength of correlations across multiple scales in a <b>neural</b> <b>system.</b> This measure represents an important tool in complex systems research because it allows for the quantification of the complexity of a <b>neural</b> <b>system.</b> In this analysis, we studied the relationships between neural complexity and criticality in neural culture data. We analyzed neural avalanches in 435 recordings from dissociated hippocampal cultures produced from rats, as well as neural avalanches from a cortical branching model. We utilized recently developed maximum likelihood estimation power-law fitting methods that account for doubly truncated power-laws, an automated shape collapse algorithm, and neural complexity and branching ratio calculation methods that account for sub-sampling, all of which are implemented in the freely available Neural Complexity and Criticality MATLAB toolbox. We found evidence that <b>neural</b> <b>systems</b> operate at or near a critical point and that neural complexity is optimized in these <b>neural</b> <b>systems</b> at or near the critical point. Surprisingly, we found evidence that complexity in <b>neural</b> <b>systems</b> is dependent upon avalanche profiles and neuron firing rate, but not precise spiking relationships between neurons. In order to facilitate future research, we made all of the culture data utilized in this analysis freely available online...|$|R
5000|$|The Kavli <b>Neural</b> <b>Systems</b> Institute at The Rockefeller University ...|$|R
30|$|Finally, we {{remark that}} there is {{evidence}} of metastable states in <b>neural</b> <b>systems</b> (e.g. [36 – 38]) that are supportive of the presence of approximate robust heteroclinic cycles. There are also suggestions that heteroclinic cycles may facilitate certain computational properties of <b>neural</b> <b>systems</b> - see for example [7, 39, 40].|$|R
5000|$|... 2. Analyzing actual <b>neural</b> <b>system</b> in {{response}} to natural images ...|$|R
5000|$|The M1 muscarinic receptors (...) {{are located}} in the <b>neural</b> <b>system.</b>|$|R
5000|$|... 1987-89 - Chair, University Interdisciplinary Committee on Adaptive <b>Neural</b> <b>Systems</b> ...|$|R
40|$|In {{this article}} we {{proposed}} a method for optimizing {{the structure of a}} fuzzy artifi cial neural networks (FANN) through genetic algorithms. This genetic algorithm (GA) is used to optimize the number of weight connections in a neural network structure, by evolutionary calculating the fi tness function of those structures as individuals in a population. This fuzzy neural is then applied as the pattern recognition in our developed odor recognition system. Experimental results show that the optimized <b>neural</b> <b>system</b> provides higher recognition capability compare with that of unoptimized <b>neural</b> <b>system.</b> Recognition rate of the unoptimized neural structure is 70. 4 % and could be increased up to 85. 2 % in the optimized <b>neural</b> <b>system.</b> It is also shown that the computational cost of the optimized structure of <b>neural</b> <b>system</b> is also lower than the unoptimized structure...|$|R
40|$|An {{advantage}} of chaotic neural dynamics Abstract—One hypothesis about how biological <b>neural</b> <b>systems</b> work {{suggests that they}} use attractor dynamics to define their behaviour. Such behaviour can be modelled using recurrent neural network models. It {{has been shown that}} such systems can perform a wide range of computational tasks by learning abstract grammars. Here we show that chaotic neural dynamics in recurrent <b>neural</b> <b>systems</b> is advantageous {{in the sense that it}} facilitates the encoding of grammars describing complex behaviour. This result may explain why it is common the observation of chaotic dynamics in biological <b>neural</b> <b>systems...</b>|$|R
40|$|The {{ability to}} {{regulate}} emotions {{is an important}} part of adaptive functioning in society. Advances in cognitive and affective neuroscience and biological psychiatry have facilitated examination of <b>neural</b> <b>systems</b> that may be important for emotion regulation. In this critical review we first develop a neural model of emotion regulation that includes <b>neural</b> <b>systems</b> implicated in different voluntary and automatic emotion regulatory subprocesses. We then use this model as a theoretical framework to examine functional neural abnormalities in these <b>neural</b> <b>systems</b> that may predispose to the development of a major psychiatric disorder characterized by severe emotion dysregulation, bipolar disorder...|$|R
40|$|Analog VLSI neuromorphic {{computation}} {{has become}} an active eld of research [Mead, 1990] [Andreou et al., 1991] [Cohen and Andreou, 1992] {{in the last few}} years. Indeed, arti cial <b>neural</b> <b>systems</b> inspired by biological neural networks are becoming an increasingly popular topic among analog VLSI designers. Biological <b>neural</b> <b>systems</b> for sensory perception and moto...|$|R
50|$|S. Wermter and R. Sun, (eds.) Hybrid <b>Neural</b> <b>Systems.</b> Springer-Verlag, Heidelberg. 2000.|$|R
5000|$|Associate Editor, IEEE Transactions on <b>Neural</b> <b>Systems</b> and Rehabilitation Engineering, January 2006 ...|$|R
40|$|In {{this chapter}} I {{will give a}} {{overview}} {{of the role of}} time delays in understanding <b>neural</b> <b>systems.</b> The main focus will be on models of <b>neural</b> <b>systems</b> in terms of delay differential equations. Later in this section, I will discuss how such models arise. The goal of the chapter is two-fold: (1) to give the reade...|$|R
50|$|Microneurography {{recordings}} have elucidated {{the organization}} {{as well as}} normal and pathological function of {{a fair number of}} <b>neural</b> <b>systems</b> in man, whereas the technique is not useful in clinical routine for diagnostic purposes to clarify the condition of the individual patient. Three main groups of <b>neural</b> <b>systems</b> have been explored, i.e. proprioception, cutaneous sensibility, and sympathetic efferent activity.|$|R
40|$|This paper reviews {{our recent}} brain imaging studies that {{indicate}} that the left middle frontal gyrus {{plays a crucial role}} in explicit Chinese character recognition and reading. The left middle frontal gyrus seems to serve as a <b>neural</b> <b>system</b> for coordinating and integrating visuo-orthographic information with phonological and semantic elements in written Chinese, as seen in several paradigms including word generation, homophone decision, and semantic judgment (all relative to fixation baseline). This <b>neural</b> <b>system</b> is responsible for the orthography-to-phonology conversion as well as the orthography-to-semantics mapping. Neuroimaging research with Chinese-English bilinguals indicates that Chinese bilinguals apply the <b>neural</b> <b>system</b> for native language to the learning of English. link_to_subscribed_fulltex...|$|R
40|$|Distribution code {{is defined}} as a code that uses the joint {{probability}} distribution of a vector of binary-valued random variables to represent numeric values. When applied to <b>neural</b> <b>systems,</b> the values of the source variables (i. e., input variables) determine the relative frequencies of input vectors either deterministically or stochastically. Similarly, the relative frequencies of the output vectors determine the values of the target variables (i. e., output variables). A mathematical model is proposed allowing unified treatment of biological <b>neural</b> <b>systems</b> and binary-valued artificial <b>neural</b> <b>systems.</b> The distribution function of a <b>neural</b> <b>system</b> {{is defined as}} the mapping from the distribution of the input vectors to the distribution of output vectors. It is conceptually similar to the input-output function. Information-theoretic properties of probabilistic and deterministic one-dimensional distribution codes are studied. One result is that the channel capacity of such codes has an upper limit with logarithmic asymptotic behaviour in terms {{of the size of the}} sample set and that there are codes whose channel capacity reaches the upper limit. The distribution function of a deterministic memoryless <b>neural</b> <b>system</b> using a one-dimensional distribution code is shown to be monotonic. Several other kinds of <b>neural</b> <b>systems</b> are studied and shown not to have this limitation. It is shown that, when the input weights are fixed, the distribution function of a binary neuron can be controlled to much finer degree – it is an adjustable linear combination of several parts – than the input-output function of a real-valued neuron, which can merely be translated. Multidimensional distribution codes can be used to encode source variable values whose number greatly exceeds the number of the physical inputs of the <b>neural</b> <b>system.</b> There are multidimensional distribution codes that make it possible to change the output distribution of the system without changing any of the marginal distributions of the physical inputs. It can be argued that real-valued neurons do not have an analogue for this property. The last part of this work focuses on experimental work and biological <b>neural</b> <b>systems.</b> A literature survey of information theoretic study on biological <b>neural</b> <b>systems</b> shows a need for new methods for generating data in a controlled and easy manner. A simulation-based methodology is proposed, implemented and evaluated. Two sets of simulations are carried out as a proof of concept. They focus on studying the information-theoretic implications of the topology of a pyramidal neuron. reviewe...|$|R
5000|$|Chairman IEEE Circuits and <b>Systems</b> (CAS) Society, <b>Neural</b> <b>Systems</b> and Applications Technical Committee (2002-2003) ...|$|R
5000|$|Peter Ford - {{news anchor}} (1988-1992); now CEO of Control Bionics <b>Neural</b> <b>System</b> Technologies ...|$|R
40|$|This paper {{presents}} VHDL-AMS {{models and}} simulation results for a complex, self-organizing <b>neural</b> <b>system</b> {{based on the}} adaptive resonance theory. Such <b>neural</b> <b>systems</b> exhibit both discrete and continuous dynamic behavior and consist {{of a large number}} of analog equations, a digital controller with analog and digital feedback paths resulting in the complexity that would prohibit analysis with conventional mixed-signal simulation tools...|$|R
