3|10000|Public
40|$|Support for the European Convention’s Double Majority {{proposal}} {{hinges on}} its supposed simplicity and efficiency. In fact, {{there is little}} difference in efficiency between the Double Majority proposal and the weighted voting system of Nice. Further, a <b>reweighting</b> <b>of</b> <b>votes</b> is introduced that is simpler to implement than the Double Majority, and which represents a redistribution of power that is ‘halfway’ between the voting system of Nice and the massive redistribution of power implied by the Convention proposal. New insights into the source of power and each Member State’s blocking leverage are presented. Efficiency of decision making is not a decisive factor Since {{the beginning of the}} IGC that has followed on from the Constitutional Convention there have been continuing reports about member states being in favour or opposed to the Double Majority proposal set out in the Draft Constitution. Particular prominence has been given by acolytes of the Double Majority to the issue of the future efficiency of decision making in the Council, in terms of the ease or difficulty of reaching qualified majorities...|$|E
40|$|Summary]. After {{long and}} {{difficult}} negotiation, a Treaty was agreed at Nice in December 2000, concluding the Intergovernmental Conference convened {{to deal with the}} ‘left-overs’ from Amsterdam. There were criticisms of the conduct and tone of the discussions. Yet the basic goal was achieved: the possible institutional obstacles to enlargement were removed. There was an agreement to have one Commissioner per Member State as of 2005 and a reduction to an unspecified number less than that of the Member States once there are 27 countries in the EU; a complex system of <b>reweighting</b> <b>of</b> <b>votes</b> with a triple threshold for qualified majority; a limited extension of qualified-majority voting; and some relaxation of the conditions for 'enhanced cooperation'. It is not possible to foresee exactly how the new arrangements may work, and they may be modified before they come into force. Nonetheless, there are concerns that decision-making will not be easier while transparency may suffer; that attention has been distracted from non-treaty reforms and other issues of policy management; and that solidarity may have been weakened. The limited scope and particular nature of this agenda made it inevitable that bargaining should often seem zero-sum, while national positions proved unusually difficult to change. Any EU Presidency would have had great difficulty in managing these questions. For the future, improvements {{to the way in which}} Intergovernmental Conferences are structured and managed can be envisaged. Equally important will be how effectively diplomacy can be prepared and accompanied by other forms of European public deliberation...|$|E
40|$|The Intergovernmental Conference {{which should}} {{conclude}} at Nice in December 2000 deals {{with issues of}} institutional reform which must be resolved before proceeding with enlargement. There are four main questions. Should all countries be able to name a Member of the European Commission, or should the number of Commissioners be ‘capped’ at a number lower {{than the number of}} Member States? How should the weighting of Member States’ votes in the Council be adjusted to ensure that winning coalitions under qualified-majority voting represent an adequate proportion of the total EU population – as well as to ‘compensate’ those five Member States which lose their second Commissioner? How far should qualified-majority voting be extended? Should the conditions for ‘closer cooperation’ be relaxed {{to make it easier to}} press ahead with integration in particular areas without the participation of all Member States? A deal must be reached at Nice, but the IGC has revealed serious differences between the Member States. There is likely to be an agreement: for one Commissioner per Member State, probably with an internal hierarchy; a significant <b>reweighting</b> <b>of</b> <b>votes</b> in favour of the big Member States; a moderate extension of qualified-majority voting; and at least the removal of the veto regarding closer cooperation. Yet relative size has emerged as a source of frictions and concerns about long-term solidarity. The big countries fear being tied down. The smaller ones have long-term concerns about being dominated or absorbed, as well as presentational problems. If all the results of the IGC are seen as concessions to the large countries, it will be hard to sell the Nice Treaty at home – and Denmark has again shown that people can say No. Too much intergovernmentalism is not the answer. The Community institutions cannot do everything, but they have played an essential role in overcoming fears about relative power. They need to be renewed, not replaced...|$|E
40|$|Abstract: The paper applies {{standard}} political-economic {{reasoning and}} game-theoretical concepts to EU enlargement and the Treaty of Nice. The {{starting point is}} the assumption that accession can only be successfully completed if the interests of decisive actors in present EU countries are respected. The Treaty of Nice is reinterpreted as an opportunity of EU- 15 actors to protect their personal interests in an enlarged Community and to overcome a commitment problem {{on the side of the}} newcomers. After the identification of decisive actors and their interests, the results of Nice are analysed with the help of power indices. It is shown that <b>reweighting</b> <b>of</b> Council <b>votes</b> and seat allocation in Parliament favour EU- 15 actors and partially contradict official objectives such as capability to act. Finally, the relative attractiveness of candidate countries is assessed on the basis of indicators that emerge as important from the approach. The paper concludes that Nice has improved the outlook for a successful enlargement because actors with veto-power on enlargement are now less likely to use it with their interests being better protected...|$|R
40|$|Attribution of {{attention}} from observable body posture is plausible, providing additional information for affective computing applications. We previously reported a promissory 69.   72  ±  10.   50 (μ ± σ) of F-measure to use posture {{as a proxy for}} attributed attentional state with implications for affective computing applications. Here, we aim at improving that classification rate by <b>reweighting</b> <b>votes</b> <b>of</b> raters giving higher confidence to those raters that are representative of the raters population. An increase to 75.   35  ±  11.   66 in F-measure was achieved. The improvement in predictive power by the classifier is welcomed and its impact is still being assessed...|$|R
40|$|This paper {{specifies}} {{the main}} features of Brain-like, Neuronal, and Connectionist models; argues for the need for, and usefulness of, structuring networks of neuron-like units into successively larger brain-like modules; and examines Recognition Cone models of perception from this perspective, as examples of such structures. Neuroanatomical, neurophysiological, and behavioral data on the structure, function, {{and development of the}} visual system are briefly summarized to motivate the architecture of brain-structured networks for perceptual recognition. The structural and functional architecture of Recognition Cones, the flow of information and the parallel-distributed nature of processing and control in Recognition Cones are described. The results from the simulation of carefully designed Recognition Cone structures that perceive objects (e. g., houses) in digitized photographs are presented. A framework for perceptual learning, including mechanisms for generation-discovery, that involves feedback-guided growth of new links between neuron-like units as needed, within a dynamically emerging network topology, subject to brain-like constraints on the network connectivity (e. g., local receptive fields, global convergence-divergence) is introduced. The information processing transforms discovered through generation are fine-tuned by feedback-guided <b>reweighting</b> <b>of</b> links. A case is made for the need for generation and discarding of transforms in addition to <b>reweighting</b> <b>of</b> links in Connectionist networks for perceptual learning. Some preliminary results from the simulation of brain-structured networks that learn to recognize simple objects (e. g., letters of the alphabet, cups, apples, bananas) through feedback-guided generation and <b>reweighting</b> <b>of</b> transforms are presented. Experimental comparisons indicate that such networks can give large improvements over networks that either lack brain-like structure or/and learn by <b>reweighting</b> <b>of</b> links alone. The role of brain-like structures and generation in perceptual learning is examined. Some directions for future research are outlined...|$|R
40|$|We {{study the}} update of the {{distribution}} in Estimation of Distribution Algorithms, and show that a simple modifica-tion leads to unbiased estimates of the optimum. The simple modification (based on a proper <b>reweighting</b> <b>of</b> estimates) leads to a strongly improved behavior in front of premature convergence...|$|R
40|$|A folk theorem {{implies a}} simple {{reduction}} which allows anyone to turn an arbitrary cost-insensitive classi - cation algorithm into a cost-sensitive classi cation algorithm. The reduction works using a particular <b>reweighting</b> <b>of</b> the examples {{which can be}} satis ed either by feeding the weights to the classi cation algorithm (as often done in boosting), or by resampling...|$|R
40|$|This paper {{presents}} and compares results for {{three types of}} connectionist networks on perceptual learning tasks: [A] Multi-layered converging networks of neuron-like units, with each unit connected to a small randomly chosen subset of units in the adjacent layers, that learn by re-weighting of their links; [B] Networks of neuron-like units structured into successively larger modules under brain-like topological constraints (such as layered, converging-diverging hierarchies and local receptive fields) that learn by re-weighting of their links; [C] Networks with brain-like structures that learn by generation-discovery, which involves the growth of links and recruiting of units in addition to <b>reweighting</b> <b>of</b> links. Preliminary empirical results from simulation of these networks for perceptual recognition tasks show significant improvements in learning from using brain-like structures (e. g., local receptive fields, global convergence) over networks that lack such structure; further improvements in learning result {{from the use of}} generation in addition to <b>reweighting</b> <b>of</b> links...|$|R
30|$|A {{complete}} covariate {{shift process}} {{is divided into}} two stages: <b>reweighting</b> importance <b>of</b> training data, and training a weighted machine learning model for prediction on the test dataset. In the first stage, we <b>reweight</b> the importance <b>of</b> training instances by estimating the ratio P_te(x_tr)/P_tr(x_tr).|$|R
40|$|FIGURE 17. Phylogram of {{the strict}} {{consensus}} of the 330 trees obtained after successive <b>reweighting</b> <b>of</b> the characters (in the tree, the character weights were reset to unity, so {{the scale of the}} branch lengths is uniform across the tree). Taxa with identical character states were lumped in a single terminal taxon except the genera of the Antrocharis group (see Appendix 2) ...|$|R
3000|$|... 6 For the {{reweighting}} procedure, {{we follow}} the approach of Immvervoll et al. (2006), who have also simulated an increase in unemployment through <b>reweighting</b> <b>of</b> the sample. Their analysis focuses on changes in absolute and relative poverty rates after changes in the income distribution and the employment rate. The reweighting approach is the only feasible option for this scenario as EUROMOD does not simulate unemployment benefits for all countries (but takes it from the data).|$|R
40|$|We {{estimate}} the quark-mass {{dependence of the}} topological susceptibility with dynamical overlap and clover fermions. Unquenching effects on the susceptibility {{turn out to be}} well approximated by a <b>reweighting</b> <b>of</b> a quenched ensemble with a low-eigenmode truncation of the fermionic determinant. We find that it is most likely due to the explicit chiral symmetry breaking of the fermion action that present day dynamical simulations do not show the expected suppression of the topological susceptibility...|$|R
30|$|The {{increase}} of {{the unemployment rate is}} modeled through <b>reweighting</b> <b>of</b> our samples 6. The weights of the unemployed are increased while those of the employed with similar characteristics are decreased, i.e., in effect, a fraction of employed households is made unemployed. With this reweighting approach we control for several individual and household characteristics that determine the risk of becoming unemployed. The implicit assumption behind this approach is that the socio-demographic characteristics of the unemployed remain constant 7.|$|R
40|$|We {{present a}} {{content-based}} {{image retrieval system}} INDI that combines the use of low-level pattern recognition techniques, machine learning and an intuitive human-computer interface {{in order to support}} intelligent and user-friendly semantic navigation in large image databases. To keep independence from specific image domains and to encompass different search tasks, the system is highly modular and contains a hierarchical mechanism for the adaptive <b>reweighting</b> <b>of</b> similarity measures implemented by dynamically reloadable modules at different semantic levels...|$|R
40|$|Objectives: Knee {{osteoarthritis}} (OA) {{is highly}} prevalent in people above {{the age of}} 60, and is typically associated with pain, stiffness, muscle weakness and proprioceptive deficits. Muscle-tendon vibration {{has been used to}} assess the spatial <b>reweighting</b> <b>of</b> proprioceptive input during standing. The current study aimed to investigate whether weighting of proprioceptive input is altered in patients with early and established knee OA compared to asymptomatic controls. Methods: The upright posture of 27 participants with early OA, 26 with established OA, and 27 asymptomatic controls was perturbed by vibrating (frequency: 70 Hz and amplitude: approximately 0. 5 mm) ankle muscles (i. e. tibialis anterior and triceps surae) and knee muscles (vastus medialis). Center of pressure displacements of the participants were recorded using a force plate. Results: Both patients with early and established OA were more sensitive to triceps surae vibration compared to their healthy peers (P < 0. 01 for both). No such difference was found for the vibration of tibialis anterior or vastus medialis muscles between patients with knee OA and healthy controls. Conclusions: These results suggest that the early stages of knee OA may already lead to <b>reweighting</b> <b>of</b> proprioceptive information, suggesting more reliance on ankle proprioceptive input for postural control. status: publishe...|$|R
40|$|Inspired by the multicanonical {{approach}} to simulations of first-order phase transitions we propose for q-state Potts models {{a combination of}} cluster updates with <b>reweighting</b> <b>of</b> the bond configurations in the Fortuin-Kastelein-Swendsen-Wang representation of this model. Numerical tests for the two-dimensional models with q= 7, 10 and 20 show that the autocorrelation times of this algorithm grow with the system size V as τ∝ V^α, where the exponent takes the optimal random walk value of α≈ 1. Comment: 13 pages, LaTeX + 4 postscript files as uuencoded compressed tar file, Mainz preprin...|$|R
40|$|We {{estimate}} the quark-mass {{dependence of the}} topological susceptibility with dynamical overlap and clover fermions. Unquenching effects on the susceptibility {{turn out to be}} well approximated by a <b>reweighting</b> <b>of</b> a quenched ensemble with a low-eigenmode truncation of the fermionic determinant. We find that it is most likely due to the explicit chiral symmetry breaking of the fermion action that present day dynamical simulations do not show the expected suppression of the topological susceptibility. (orig.) SIGLEAvailable from TIB Hannover: RA 2999 (01 - 209) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|R
40|$|Promotor: Mariusz Przybycień, Leszek Adamczyk. Recenzent: Mariusz Sadzikowski, Janusz Chwastowski. Niepublikowana praca doktorska. Tyt. z ekranu tyt. Praca doktorska. AGH University of Science and Technology. Faculty of Physics and Applied Computer Science, 2015. Zawiera bibliogr. Dostępna również w wersji drukowanej. Tryb dostępu: Internet. Quark Parton Model and Deep Inelastic Scattering, DGLAP Equation, BFKL Equation, Hadronisation, Diffraction, Soft Diffraction, Hard Diffraction, Diffractive DIS, Photoproduction of Dijets in Diffraction, Notation and Definitions of Kinematic Variables, HERA and the ZEUS Detector, HERA, ZEUS Detector, central {{tracking}} detector, silicon micro vertex detector, uranium calorimeter, Luminosity Monitor, Trigger, Monte Carlo Samples, Diffractive Monte Carlo, Non-diffractive Monte Carlo, Proton-dissociative Monte Carlo, Event Reconstruction, Track Reconstruction and Vertexing, Calorimeter Reconstruction, EFO Reconstruction, Scattered Lepton Identification, Jet Reconstruction, Reconstruction of Kinematic Variables, Data Sample and Event Selection, Data Sample, Trigger selection, Quality Cuts, PHP Cuts, Dijet Cuts, Diffractive Cuts, Cosmic Cuts, Summary of the Selection Cuts, Background Estimation, Description of Data by the Monte Carlo Simulation, Normalisation <b>of</b> MC, <b>Reweighting</b> <b>of</b> MC, <b>Reweighting</b> <b>of</b> Signal, Estimation of Proton-dissociative Background, Control Distributions, Measurement of Cross-Section, Control Plots, Acceptance, Purity and Efficiency, Unfolding, Systematic Uncertainties, Comparison of Acceptance and SVD Unfolding Methods, Comparison of Single and Double Differential Cross Sections, Comparison of HERA I and HERA II Result, Comparison with H 1 Result, kinematic {{variables and}} their reconstruction, Double Differential Cross Sections, Single Differential Cross Section...|$|R
30|$|Another {{approach}} {{that has been}} applied in image restoration tasks, and specifically to STEM image restoration is the non-local means algorithm [16, 28]. Non-local means uses all of the image patches simultaneously to find a <b>reweighting</b> <b>of</b> the central pixel of each patch. Sparse representation, on the other hand, finds a subset of elements from a dictionary and the corresponding weights to reconstruct an entire patch (dictionary learning simultaneously finds a dictionary). Non-local means is a kernel density estimation method, and when employing the Gaussian kernel, it {{is closely related to}} the GMM, which will be explained in detail.|$|R
40|$|We {{present a}} new {{algorithm}} for domain adaptation improving upon a discrepancy minimiza-tion algorithm previously shown to outperform {{a number of}} algorithms for this task. Unlike many previous algorithms for domain adaptation, our algorithm does not consist <b>of</b> a fixed <b>reweighting</b> <b>of</b> the losses over the training sample. We show that our algorithm benefits from a solid theoretical foundation and more favorable learning bounds than discrepancy minimization. We present a de-tailed description of our algorithm and give several efficient solutions for solving its optimization problem. We also report the results of several experiments showing that it outperforms discrepancy minimization. 1...|$|R
40|$|We {{discuss how}} the {{experimental}} information from longitudinal single-spin asymmetries for W^± boson production in polarised proton-proton collisions can {{be included in}} a polarised parton determination by Bayesian <b>reweighting</b> <b>of</b> a Monte Carlo set of polarised PDF replicas. We explicitly construct a prior ensemble of polarised parton distributions using available fits to inclusive and semi-inclusive DIS data and we discuss the potential impact of existing and future RHIC measurements on it. Comment: 5 pages, 4 figures, to appear in the proceedings of the 3 rd Workshop on the QCD Structure of the Nucleon (QCD-N' 12), Bilbao October 201...|$|R
40|$|The {{reweighting}} {{method is}} applied to improve the chiral property of domain-wall fermions. One way to achieve this is to enlarge $L_s$, the size of fifth dimension, which controls {{the size of the}} induced chiral symmetry breaking. While this is a type <b>of</b> <b>reweighting</b> method for shifting the action parameter, it seems non-trivial since this <b>reweighting</b> means change <b>of</b> the five dimensional lattice volume. In this report, we address issues in this direction <b>of</b> <b>reweighting</b> and evaluate its effectiveness. Comment: 7 pages, talk presented at The XXVII International Symposium on Lattice Field Theory, July 26 - 31 2009, Peking University, Beijing, Chin...|$|R
40|$|The {{geometry}} {{dependence of}} Casimir forces is significantly {{more pronounced in}} the presence of thermal fluctuations due to a generic geometry-temperature interplay. We show that the thermal force for standard sphere-plate or cylinder-plate geometries develops a non-monotonic behavior already in the simple case of a fluctuating Dirichlet scalar. In particular, the attractive thermal force can increase for increasing distances below a critical temperature. This anomalous behavior is triggered by a <b>reweighting</b> <b>of</b> relevant fluctuations on the scale of the thermal wavelength. The essence of the phenomenon becomes transparent within the worldline picture of the Casimir effect. Comment: 4 pages, 4 figure...|$|R
40|$|The use <b>of</b> a <b>reweighting</b> {{technique}} <b>of</b> Montecarlo {{events can}} help in {{the reduction of the}} simulated statistics needed in 4 fermion physics studies at LEP 200. A routine for the <b>reweighting</b> <b>of</b> events generated with the DELPHI customized version of the EXCALIBUR 4 fermion code is presented. Some examples of application for the W mass measurement are discussed. 1 Reweighting techniques for 4 fermion generators An important part of the standard physics studied at LEP 200 is linked to 4 fermion processes e + e Γ ! f 1 f 2 f 3 f 4; the measurement of the W boson mass, of the TGCs, of the cross sections are relevant examples. In several analyses it is necessary to know the variations of physical observables {{as a function of the}}oretical model parameters (for instance the experimentally reconstructed W mass as a function of the true one). A trivial solution is to generate many samples of events corresponding to different sets of input parameters, and to obtain the observable distribut [...] ...|$|R
40|$|We present {{extensive}} Monte Carlo simulations on {{a two-dimensional}} XY {{model with a}} modified form of interaction potential. Thermodynamic quantities other than energy, specific heat etc (such as magnetization, susceptibility, fourth order cumulant of magnetization) are obtained using multiple-histogram <b>reweighting</b> <b>of</b> the data obtained from the simulations. We employ an approach which eliminates the need to construct two-dimensional histograms. This approach makes judicious use of computer memory as well as CPU time. Lee-kosterlitz's method of finite size scaling for a first order transition and analysis using Binder's cumulant method allow us to make an accurate determination of the transition temperature. Comment: 4 pages (in double column), 6 figures, Published in Phys. Rev. E 87, 054102 (2013...|$|R
40|$|We {{test the}} <b>reweighting</b> <b>of</b> the quark {{determinant}} of O(a) improved Wilson fermions in the domain-decomposed hybrid Monte-Carlo algorithm. Specifically, we implement a reweighting in a twisted-mass parameter proposed by Palombi and Lüscher in N_ f= 2 QCD. We find that at equal acceptance rate, the algorithm is significantly more stable on a 32 × 64 ^ 3 lattice upon switching on the reweighting parameter. At the same time, the reweighting factor does not fluctuate strongly and hence is under control. At equal statistics, the uncertainty on the pion correlator {{is comparable to}} the case of the standard, unreweighted algorithm. Comment: 7 pages, 5 figures, XXIX International Symposium On Lattice Field Theor...|$|R
40|$|We {{introduce}} the Hessian <b>reweighting</b> <b>of</b> parton distribution functions (PDFs). Similarly to the better-known Bayesian methods, {{its purpose is}} to address the compatibility of new data and the quantitative modifications they induce within an existing set of PDFs. By construction, the method discussed here applies to the PDF fits that carried out a Hessian error analysis using a non-zero tolerance Δ χ 2. The principle is validated by considering a simple, transparent example. We are also able to establish {{an agreement with the}} Bayesian technique provided that the tolerance criterion is appropriately accounted for and that a purely exponential Bayesian likelihood is assumed. As a practical example, we discuss the inclusive jet production at the LHC...|$|R
40|$|Example-Based Machine Translation (EBMT) {{systems have}} {{typically}} operated on individual sentences without {{taking into account}} prior context. By adding a simple <b>reweighting</b> <b>of</b> retrieved fragments of training examples {{on the basis of}} whether the previous translation retrieved any fragments from examples within a small window of the current instance, translation performance is improved. A further improvement is seen by performing a similar reweighting when another fragment of the current input sentence was retrieved from the same training example. Together, a simple, straightforward implementation of these two factors results in an improvement on the order of 1. 0 – 1. 6 % in the BLEU metric across multiple data sets in multiple languages. ...|$|R
40|$|Unusual visual {{phenomena}} {{are used}} to study perception and the following stages, characterized by: aesthetic appreciation and judgment; contributions from cognitive and emotional factors - and a combined cognitive judgment, wonder and a strong positive emotion, colloquially known as 'the wow factor'. Examples of the latter are impressions of 'super depth' and 'super sharpness'; they may occur after cataract operations but also may follow less dramatic visual events. The research methods used are personal observation with introspection, and interviews. An important feature of many unusual visual phenomena is their temporariness, with, however, often the possibility to re-evoke them. Explanations {{to a certain extent}} may be found in Bayesian <b>reweighting</b> <b>of</b> perceptual criteria and also in neuroscience, in particular neuroaesthetics...|$|R
40|$|Molecular {{dynamics}} (MD) simulations allow {{investigating the}} structural dynamics of biomolecular systems with unrivaled {{time and space}} resolution. However, in order {{to compensate for the}} inaccuracies of the utilized empirical force fields, it is becoming common to integrate MD simulations with experimental data obtained from ensemble measurements. We here review the approaches {{that can be used to}} combine MD and experiment under the guidance of the maximum entropy principle. We mostly focus on methods based on Lagrangian multipliers, either implemented as <b>reweighting</b> <b>of</b> existing simulations or through an on-the-fly optimization. We discuss how errors in the experimental data can be modeled and accounted for. Finally, we use simple model systems to illustrate the typical difficulties arising when applying these methods. Comment: Submitted to Computatio...|$|R
40|$|Personalisation in {{full text}} {{retrieval}} or full text filtering implies <b>reweighting</b> <b>of</b> the query terms {{based on some}} explicit or implicit feedback from the user. Relevance feedback inputs the user's judgements on previously retrieved documents to construct a personalised query or user profile. This paper studies relevance feedback within two probabilistic models of information retrieval: the first based on statistical language models and the second based on the binary independence probabilistic model. The paper shows the resemblance of the approaches to relevance feedback of these models, introduces new approaches to relevance feedback for both models, and evaluates the new relevance feedback algorithms on the TREC collection. The paper shows {{that there are no}} significant differences between simple and sophisticated approaches to relevance feedback. ...|$|R
40|$|Abstract: Theories of new physics often {{involve a}} large number of unknown {{parameters}} which need to be scanned. Additionally, a putative signal in a particular channel may be due to a variety of distinct models of new physics. This makes experimental attempts to constrain the parameter space of motivated new physics models {{with a high degree of}} generality quite challenging. We describe how the <b>reweighting</b> <b>of</b> events may allow this challenge to be met, as fully simulated Monte Carlo samples generated for arbitrary benchmark models can be effectively re-used. In particular, we suggest procedures that allow more efficient collaboration between theorists and experimentalists in exploring large theory parameter spaces in a rigorous way at the LHC. 1 Corresponding author. ar X i...|$|R
40|$|The {{presence}} of a phase transition in a finite system can be deduced, together with its order, from {{the shape of the}} distribution of the order parameter. This issue has been extensively studied in multifragmentation experiments, with results that do not appear fully consistent. In this paper we discuss the effect of the statistical ensemble or sorting conditions on the shape of fragment distributions, and propose a new method, which can be easily implemented experimentally, to discriminate between different fragmentation scenarii. This method, based on a <b>reweighting</b> <b>of</b> the measured distribution to account for the experimental constraints linked to the energy deposit, is tested on different simple models, and appears to provide a powerful discrimination. Comment: 11 pages, 7 figure...|$|R
40|$|International audienceHow sensory {{organization}} for postural control matures in children {{is not clear}} at this time. The present study examined, in children aged 7 to 11 and in adults, the postural control modifications in quiet standing when somatosensory inputs from the ankle were disturbed. Since the <b>reweighting</b> <b>of</b> sensory inputs is not mature before 10, we hypothesized that postural stability was more affected in children than in adults when somatosensory inputs were altered and that this postural instability decreased as age increased during childhood. 37 children aged 7 to 11 years and 9 adults participated in the experiments. The postural task was a semi-tandem position with the right {{foot in front of}} the left one. Postural performance was measured by means of a force platform. Two experimental conditions were presented to the participants to maintain quiet standing: With or without altered somatosensory inputs (i. e., with or without ankles vibration). Results showed that postural stability [...] and thus how the <b>reweighting</b> process <b>of</b> the visual/somatosensory inputs matured [...] increased non-monotonically between 7 years of age and adult age: There was a linear improvement of postural stability from 7 to 10, followed by a more steady behaviour between 10 and 11 and then postural stability increased to reach the adults' level of performance...|$|R
50|$|In 2008 local {{elections}} in Serbia, {{the expectations of}} the Hungarian Coalition were to win majority <b>of</b> <b>votes</b> in the local parliaments of municipalities of Serbia with ethnic Hungarian majority, but this was the case only in municipality of Kanjiža, where Hungarian Coalition won 50.91% <b>of</b> <b>votes.</b> The Coalition also won the plurality <b>of</b> <b>votes</b> in municipalities <b>of</b> Senta (31.87%), Bačka Topola (46.25%), and Mali Iđoš (37.18%), while in municipalities of Čoka and Ada, the Hungarian Coalition was second largest political option, after Democratic Party (In Čoka, Democratic Party won 29.08% <b>of</b> <b>votes</b> and Hungarian Coalition won 24.47% of votes; in Ada, the coalition led by Democratic Party won 29.25% <b>of</b> <b>votes</b> and Hungarian Coalition won 25.70% <b>of</b> <b>votes).</b> In ethnically mixed municipality of Subotica, the Hungarian Coalition was also second largest political option after coalition led by Democratic Party (Democratic Party coalition won 40.16% <b>of</b> <b>votes</b> and Hungarian Coalition won 27.14% <b>of</b> <b>votes</b> in Subotica), while in ethnically mixed municipality of Bečej, the Hungarian Coalition won the plurality <b>of</b> <b>votes</b> (29.63%). In municipality of Novi Kneževac with ethnic Serb majority (claimed by Hungarian Coalition as part of future autonomous region), the Hungarian Coalition was third largest political option with 17.63% <b>of</b> <b>votes</b> (Largest political option in Novi Kneževac municipality was coalition led by Democratic Party with 27.18% <b>of</b> <b>votes,</b> and second largest was Serbian Radical Party with 22.46% <b>of</b> <b>votes).</b>|$|R
