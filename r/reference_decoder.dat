36|15|Public
50|$|In the H.264 and VC-1 standards, the VBV is {{replaced}} with generalized version called Hypothetical <b>Reference</b> <b>Decoder</b> (HRD).|$|E
50|$|Xiph.Org has {{expressed}} interest in modifying Tremor into a floating-point version, which would replace the current floating-point <b>reference</b> <b>decoder,</b> {{after the release of}} libogg2.|$|E
5000|$|Players {{supporting}} the HD DVD standard can transcode the decoded audio into another format. Depending upon the method and {{options available to}} the player, {{this can be done}} with relatively little quality loss. Dolby's <b>reference</b> <b>decoder,</b> available to all licensees, exploits the common heritage between AC-3 and DD+ by performing the operation in the frequency domain. Hybrid re-compression avoids unnecessary end-to-end decompression and subsequent recompression (DD+ → LPCM → AC-3.) In addition to AC-3, some HD DVD players transcode audio compatible with S/PDIF into 1.5 Mbit/s DTS audio. While S/PDIF can carry Dolby Digital Plus at lower bitrates, the HD DVD standard specifies a bitrate for DD+ which is too high for a S/PDIF interface to transmit.|$|E
5000|$|FLAC, the <b>reference</b> FLAC <b>decoder</b> {{can create}} a new copy with ReplayGain applied, through the undocumented option [...] as of version 1.1.1 ...|$|R
40|$|Structured Audio (SA) is an MPEG 4 Audio {{standard}} for algorithmic sound encoding, using the programming language SAOL. The paper describes a SA decoder, sfront, that translates a SAOL program into a C program, {{which is then}} compiled and executed to create audio. Performance data shows a 7. 6 x to 20. 4 x speedup compared to the SA <b>reference</b> MPEG <b>decoder...</b>|$|R
3000|$|... {{decoding}} {{script that}} automates the decoding {{process of the}} different videos. Such script invokes the original H. 264 /AVC JM 18.2 <b>Reference</b> Software <b>decoder,</b> configuring it automatically for the decoding process and {{making it possible to}} analyze a remarkable number of videos in a minimum amount of time. The output of the decoder for each video is stored in a different text file, which is parsed by two scripts to obtain the graphs that show the image quality and the percentage of recovered GOPs.|$|R
40|$|Hypothetical <b>Reference</b> <b>Decoder</b> is a {{hypothetical}} decoder model that specifies {{constraints on the}} variability of conforming network abstraction layer unit streams or conforming byte streams that an encoding process may produce. High Efficiency Video Coding (HEVC) builds upon and improves {{the design of the}} generalized hypothetical <b>reference</b> <b>decoder</b> of H. 264 / AVC. This paper describes some of the main improvements of hypothetical <b>reference</b> <b>decoder</b> of HEVC...|$|E
40|$|Abstract—In video coding standards, a {{compliant}} {{bit stream}} must be decoded by a hypothetical decoder that is conceptually {{connected to the}} output of an encoder and consists of a decoder buffer, a decoder, and a display unit. This virtual decoder {{is known as the}} hypothetical <b>reference</b> <b>decoder</b> (HRD) in H. 263 and the video buffering verifier in MPEG. The encoder must create a bit stream so that the hypothetical decoder buffer does not overflow or underflow. These previous decoder models assume that a given bit stream will be transmitted through a channel of a known bit rate and will be decoded (after a given buffering delay) by a device of some given buffer size. Therefore, these models are quite rigid and do not address the requirements of many of today’s important video applications such as broadcasting video live or streaming pre-encoded video on demand over network paths with various peak bit rates to devices with various buffer sizes. In this paper, we present a new HRD for H. 264 /AVC that is more general and flexible than those defined in prior standards and provides significant additional benefits. Index Terms—Hypothetical <b>reference</b> <b>decoder</b> (HRD), video buffering verifier (VBV). I...|$|E
40|$|Coding) decoder {{based on}} an {{optimized}} platform-based design methodology. With this methodology, we jointly optimize the software and hardware design of the decoder. Overall decoding throughput is increased by synchronizing the software and the dedicated co-processors. The synchronization is achieved at macroblock-level pipelining. In addition, we optimize the decoder software by enhancing the frame buffer management, boundary padding, and content aware inverse transform. To speed up motion compensation and inverse transform, which are the most computationally intensive modules, two dedicated acceleration modules are realized. For comparison, the proposed prototype decoder and MPEG- 4 AVC <b>reference</b> <b>decoder</b> are evaluated on an ARM platform, {{which is one of}} most popular portable devices. Our experiments show that the throughput of the MPEG- 4 <b>reference</b> <b>decoder</b> can be improved by 6 to 7 times. On an ARM 966 board, the optimized software without hardware acceleration can achieve a decoding rate up to 5 frames per second (fps) for QCIF video sequences. With the dedicated accelerators, the overall throughput is increased by about 30 % to reach 6. 6 fps on the average and is up to 10. 3 fps for slow motion video sequences. 1...|$|E
40|$|The {{frequency}} selective extrapolation extends {{an image}} signal beyond {{a limited number}} of known samples. This problem arises in image and video communication in error prone environments where transmission errors may lead to data losses. In order to estimate the lost image areas, the missing pixels are extrapolated from the available correctly received surrounding area which is approximated by a weighted linear combination of basis functions. In this contribution, we integrate the frequency selective extrapolation into the H. 264 /AVC coder as spatial concealment method. The <b>decoder</b> <b>reference</b> software uses spatial concealment only for I frames. Therefore, we investigate the performance of our concealment scheme for I frames and its impact on following P frames caused by error propagation due to predictive coding. Further, we compare the performance for coded video sequences in TV quality against the non-normative concealment feature of the <b>decoder</b> <b>reference</b> software. The investigations are done for slice patterns causing chequerboard and raster scan losses enabled by Flexible Macrobloc...|$|R
50|$|The yEncode draft {{proposal}} document was made available on 31 July 2001. A <b>reference</b> encoder and <b>decoder</b> {{was included in}} the MyNews 1.9 freeware version in November that year. yDec, a freeware win32 decoder came on 14 November 2001. On 21 March 2002, Agent supported yEnc with version 1.91. Due to feedback of Juergen Helbing, the release was postponed by one week. A couple of days after the release Jürgen Helbing wrote that Forté implemented yEnc in the best way imaginable.|$|R
30|$|For each of {{the twelve}} {{original}} H. 264 /AVC bitstreams, a number of corrupted bitstreams were generated, by dropping packets according to a given error pattern [15]. Coded slices belonging to the first frames were not corrupted, as they contained header information (Picture Parameter Set (PPS) and Sequence Parameter Set (SPS)). Conversely, the remaining slices might be discarded from the coded bitstream. To simulate burst errors, the patterns were generated at six different PLRs, 0.1 %, 0.4 %, 1 %, 3 %, 5 %, 10 %, with a two-state Gilbert's model [16]. The model parameters were tuned to obtain an average burst length of 3 packets, which is a typical characteristic of IP networks [17]. The two-state Gilbert's model generated, for each PLR, several error patterns. For each PLR and content, two decoded video sequences were manually selected in order to uniformly span {{a wide range of}} distortions, that is, perceived video quality, while keeping the size of the dataset manageable. The details of the selection procedure can be found in [6]. A total of 72 CIF sequences with packet losses and 72 4 CIF sequences with packet losses were included in the test material. Each bitstream was decoded with the H. 264 /AVC <b>reference</b> software <b>decoder</b> with motion-compensated error concealment turned on [18].|$|R
30|$|Due to {{the novelty}} and {{advantages}} of the on-the-fly adaptation of SVC, the input video is a 500 frames (17 s) long SVC-encoded sequence. The well-known Foreman and Hall were chosen for the test sequences. Foreman contains partitions of relatively static background, average motion, and a moving camera. On the contrary, Hall has a static camera with {{only a couple of}} slowly moving objects. We use the JSVM 9.15 reference encoder and the same version of the <b>reference</b> <b>decoder</b> extended with three error concealment algorithms [17].|$|E
40|$|Moving picture experts group (MPEG) - 4 visual {{conformance}} standard specifies {{methods to}} verify whether bitstreams and decoders {{meet the requirements}} at the specified profile and level. The test of decoders {{can be divided into}} two parts: the static test and the dynamic test. The static test can be performed by examining the decoder output with that of a <b>reference</b> <b>decoder</b> using test bitstreams. This paper proposes design methodologies of MPEG- 4 visual test bitstreams, and presents experimental results on DCT scan type, DCIAC coefficient prediction, inverse quantization, and various macroblock type verifications. ...|$|E
40|$|International audienceJoint source-channel {{decoding}} (JSCD) exploits residual redundancy in compressed bitstreams {{to improve}} the robustness to transmission errors of multimedia coding schemes. This paper proposes an architecture to introduce some additional side information in compressed streams to help JSCD. This architecture exploits a <b>reference</b> <b>decoder</b> already present or introduced at the encoder side. An application to the robust decoding of 3 D-ESCOT encoded bitstreams generated within the Vidwav video coder is presented. The layered bitstream generated by this encoder allows SNR scalability, and moreover, when processed by a JSCD, provides increased robustness to transmission errors compared with a single layered bitstream...|$|E
40|$|Digital {{compression}} of audio data is important {{due to the}} bandwidth and storage limitations inherent in networks and computers. Algorithms based on perceptual coding are effective and have become feasible with faster computers. The ISO standard 11172 - 3 MPEG- 1 layer III (a. k. a. MP 3) is a perceptual codec that is presently very common for {{compression of}} CD quality music. An MP 3 decoder has a complex structure and is computationally demanding. The purpose of this master’s thesis is to present a tutorial on the standard. We have analysed several algorithms suitable for implementing an MP 3 decoder, their advantages and disadvantages with respect to speed, memory demands and implementation complexity. We have also designed and implemented a portable <b>reference</b> MP 3 <b>decoder</b> in C...|$|R
40|$|Abstract—This {{paper is}} {{concerned}} with optimization of the motion compensated prediction framework to improve the error resilience of video coding for transmission over lossy networks. First, accurate end-to-end distortion estimation is employed to optimize both motion estimation and prediction within an overall rate-distortion framework. Low complexity practical variants are proposed: a method to approximate the optimal motion via simple distortion and source coding rate models, and a source-channel prediction method that uses the expected <b>decoder</b> <b>reference</b> frame for prediction. Second, reference frame generation is revisited as a problem of filter design to optimize the error resilience versus coding efficiency tradeoff. The special cases of leaky prediction and weighted prediction (i. e., finite impulse response filtering), are analyzed. A novel reference frame generation approach, called “generalized source-channel prediction”, is proposed, which involves infinite impulse response filtering. Experimental results show significant performance gains and substantiate {{the effectiveness of the}} proposed encoder optimization approaches. Index Terms—Error resilience, motion compensation, prediction, rate-distortion, source-channel prediction, weighted prediction. I...|$|R
40|$|This {{application}} note describes a parameterizable 8 b/ 10 b Decoder, and {{is accompanied by}} a reference design that replaces the 8 b/ 10 b Decoder core previously delivered through the CORE Generator software. The implemented 8 b/ 10 b coding scheme is an industry standard, DC-balanced, byte-oriented transmission code ideally suited for high-speed local area networks and serial data links. For all new FPGA designs targeting Virtex®- 5, Virtex- 4, Virtex-II, Virtex-II Pro, Spartan®- 3, Spartan- 3 E, Spartan- 3 A, Spartan- 3 A DSP FPGAs, and newer architectures, use the 8 b/ 10 b <b>Decoder</b> <b>reference</b> design. All the features and interfaces included in the reference design are backward compatible with the LogiCORE IP 8 b/ 10 b Decoder v 7. 1 core. In addition, because the reference design is provided in plain text VHDL format, users have full visibility into the implementation of the function and can easily debug and modify the code...|$|R
40|$|Abstract—In this paper, an {{efficient}} rate-control scheme for H. 264 /AVC video encoding is proposed. The redesign of the quantization scheme in H. 264 /AVC results {{in that the}} relationship between the quantization parameter and the true quantization stepsize is no longer linear. Based on this observation, we propose a new rate-distortion (R-D) model by utilizing the true quantization stepsize and then develop an improved rate-control scheme for the H. 264 /AVC encoder based on this new R-D model. In general, the current R-D optimization (RDO) mode-selection scheme in H. 264 /AVC test model is difficult for rate control, because rate control usually requires a predetermined set of motion vectors and coding modes to select the quantization parameter, whereas the RDO does in the different order and requires a predetermined quantization parameter to select motion vectors and coding modes. To tackle this problem, we develop a complexity-adjustable rate-control scheme based on the proposed R-D model. Briefly, the proposed scheme is a one-pass process at frame level and a partial two-pass process at macroblock level. Since the number of macroblocks with the two-pass processing can be controlled by an encoder parameter, the fully one-pass implementation is a subset of the proposed algorithm. An additional topic discussed in this paper is about video buffering. Since a hypothetical <b>reference</b> <b>decoder</b> (HRD) has been defined in H. 264 /AVC to guarantee that the buffers never overflow or underflow, the more accurate rate-allocation schemes are proposed to satisfy these requirements of HRD. Index Terms—H. 264 /AVC, hypothetical <b>reference</b> <b>decoder</b> (HRD), rate control, rate-distortion optimization (RDO), video coding. I...|$|E
40|$|Abstract: The goal of Variable Bit-Rate (VBR) {{encoding}} is {{to maintain}} a constantly high visual quality within the target bit-rate, during whole encoding process, thus saving and accumulating bits during low complexity scenes and reusing those bits in higher complexity scenes. Such a goal can be quite easily achieved by off-line encoding, since {{it is possible to}} measure the whole sequence complexity distribution a priori and to use multi pass processing algorithms; however, real time encoding requires completely different approaches. This paper describes a single-pass, real-time VBR control method that achieves excellent and constant visual quality for H. 264 /AVC online encoding. It is also totally compliant with the Hypothetical <b>Reference</b> <b>Decoder</b> (HRD) model of H. 264 /AVC...|$|E
40|$|The {{effects of}} using limited {{precision}} floating point for intermediate storage in an embedded MP 3 decoder are investigated in this thesis. The advantages of using limited precision {{is that the}} values need shorter word lengths and thus a smaller memory for storage. The official <b>reference</b> <b>decoder</b> was modified so {{that the effects of}} different word lengths and algorithms could be examined. Finally, a software and hardware prototype was implemented that uses 16 -bit wide memory for intermediate storage. The prototype is classified as a limited accuracy MP 3 decoder. Only layer III is supported. The decoder could easily be extended to a full precision MP 3 decoder if a corresponding increase in memory usage was accepted...|$|E
40|$|H. 264 / MPEG- 4 Part 10, a {{recently}} developed international standard for video compression, offers significantly better video compression efficiency than previous international standards. Since {{it is impossible}} to implement a real-time H. 264 video coder using a state-of-the-art embedded processor alone, in this thesis, we developed an efficient FPGA-based H. 264 intra frame coder hardware for real-time portable applications targeting level 2. 0 of baseline profile. We first designed a high performance and low cost hardware architecture for realtime implementation of entropy coding algorithms, context adaptive variable length coding and exp-golomb coding, used in H. 264 video coding standard. The hardware is implemented in Verilog HDL and verified with RTL simulations using Mentor Graphics Modelsim. We then designed a high performance and low cost hardware architecture for real-time implementation of intra prediction algorithm used in H. 264 video coding standard. This hardware is also implemented in Verilog HDL and verified with RTL simulations using Mentor Graphics Modelsim. We then designed and implemented the top-level H. 264 intra frame coder hardware. The hardware is implemented by integrating intra prediction, mode decision, transform-quant and entropy coding modules. The H. 264 intra frame coder hardware is verified to be compliant with H. 264 standard and it can code 35 CIF (352 x 288) frames per second. The hardware is first verified with RTL simulations using Mentor Graphics Modelsim. It is then verified to work at 71 MHz on a Xilinx Virtex II FPGA on an ARM Versatile Platform development board. The bitstream generated by the H. 264 intra frame coder hardware for an input frame is successfully decoded by H. 264 Joint Model (JM) <b>reference</b> software <b>decoder</b> and the decoded frame is displayed using a YUV Player tool for visual verification...|$|R
40|$|International audienceThis paper {{demonstrates}} {{that it is}} possible to produce automatic, reconfigurable, and portable implementations of multimedia decoders onto platforms with the help of the MPEG Reconfigurable Video Coding (RVC) standard. MPEG RVC is a new formalism standardized by the MPEGconsortium used to specify multimedia decoders. It produces visual representations of <b>decoder</b> <b>reference</b> software, with the help of graphs that connect several coding tools from MPEG standards. The approach developed in this paper draws on Dataflow Process Networks to produce a Minimal and Canonical Representation (MCR) of specifications. The makes it possible to form automatic and reconfigurable implementations of decoders which can match any actual platforms. The contribution is demonstrated on one case study where a generic decoder needs to process a multimedia content with the help of the specification of the decoder required to process it. The overall approach is tested on two decoders from MPEG, namely MPEG- 4 part 2 Simple Profile and MPEG- 4 part 10 Constrained Baseline Profile. The results validate the following benefits on the of decoders: compact representation, low overhead induced by its compilation, reconfiguration and multi-core abilities...|$|R
40|$|Abstract. This paper {{proposes a}} subband {{adaptive}} motion compensated temporal filtering (MCTF) technique for {{scalable video coding}}. In scalable video coding schemes, hierarchical MCTF is widely adopted to exploit the temporal correlation across frames, for its good performance in energy compaction and its ability in providing efficient SNR scalability. In this hierarchical MCTF structure, the temporal correlation of neighboring frames has different strength at various MCTF levels. Furthermore, the temporal correlation exploited in motion compensation has diverse strength for various spatial frequency signal components. When SNR scalability is present, the <b>reference</b> frame at <b>decoder</b> is variable random signal, with reconstruction noises added on the references used at encoder. According to the correlation and noise characteristic of various spatial subbands between reference frame and target frame, we can adjust the strength of MCTF to maximally take advantage of temporal correlation but restrict the propagation of uncorrelated reconstruction noise signal. In this way an adaptive MCTF scheme is formed and the proposed technique can improve the performance of scalable video coding by up to 0. 5 dB. Index Terms—scalable video coding, motion compensated temporal filtering, temporal correlation 1...|$|R
30|$|At the receiver, {{we apply}} an {{iterative}} decoding {{based on information}} exchange between a low-complexity SISO Chase-like arithmetic decoder, detailed below, and the RSCC decoder using the optimal MAP algorithm. Performances of the iterative decoding scheme involving the Chase-like algorithm are evaluated and compared to tandem decoding results. As mentioned, major JSC iterative decoding contributions consider trellis-based algorithms for arithmetic SISO decoding. To evaluate the efficiency of our decoder with respect to such schemes, a comparison to an iterative decoding scheme with an arithmetic trellis-based de-coder is proposed. The <b>reference</b> <b>decoder</b> was presented in [17, 18], and the authors used a bi-dimensional bit-clock trellis to model the arithmetic encoding machine. Then, to generate soft bit-reliability estimates, a modified SOVA [22] algorithm was proposed.|$|E
40|$|In this paper, {{we propose}} a simple {{iterative}} method to verify whether a coded bitstream conforms to a hypothetical <b>reference</b> <b>decoder</b> (HRD). A concept of maximum tolerate delay (MTD) is introduced {{to study the}} possible low-delay operation such that we can bound the degree of incorrect motion rendition caused by the variation in end to end delay {{in the neighborhood of}} big pictures. Our method can be used in the design of a rate control algorithm to improve the possibility for the coded bitstream that conforms to the HRD. 1. INTRODUCTION. When a digital video is compressed, the coded bit rate may vary significantly over time. The bitstream is usually transmitted over a channel at a constant bit rate (CBR). The buffer size of an encoded picture buffer (EPB) associated with an encoding process and tha...|$|E
40|$|For {{streaming}} of pre-encoded bitstreams over constant {{bit rate}} (CBR) channels, the channel bandwidth, the receiver buffer capacity {{as well as the}} latency requirement vary greatly from application to application. In this paper, we attempt to determine the minimum buffer size and the minimum start-up delay required for streaming a pre-encoded bitstream over CBR channels at any specific bit rate. The proposed method employs geometric operations to derive the optimal determination for low or high bit rates and sub-optimal determination for medium bit rates. The algorithm developed requires little extra information from the encoder and is easy to implement. Our algorithm is implemented in a H. 264 /AVC video encoder and its performance is compared with that of H. 264 /AVC hypothetical <b>reference</b> <b>decoder.</b> Our approach provides new theoretical insight and an excellent solution for determining the leaky bucket parameters for video streaming over CBR channel...|$|E
40|$|Ankara : The Department of Electrical and Electronics Engineering and the Institute of Engineering and Sciences of Bilkent University, 2009. Thesis (Master's) [...] Bilkent University, 2009. Includes bibliographical {{references}} leaves 83 - 87. With {{the evolution}} of the wireless communication technologies and the multimedia capabilities of the mobile phones, it is expected that three-dimensional (3 D) video technologies will soon get adapted to the mobile phones. This raises the problem of choosing the best 3 D video representation and the most efficient coding method for the selected representation for mobile platforms. Since the latest 2 D video coding standard, H. 264 /MPEG- 4 AVC, provides better coding efficiency over its predecessors, coding methods of the most common 3 D video representations are based on this standard. Among the most common 3 D video representations, there are multi-view video, video plus depth, multi-view video plus depth and layered depth video. For using on mobile platforms, we selected the conventional stereo video (CSV), which is a special case of multi-view video, since it is the simplest among the available representations. To determine the best coding method for CSV, we compared the simulcast coding, multi-view coding (MVC) and mixed-resolution stereoscopic coding (MRSC) without inter-view prediction, with subjective tests using simple coding schemes. From these tests, MVC is found to provide the best visual quality for the testbed we used, but MRSC without inter-view prediction still came out to be promising for some of the test sequences and especially for low bit rates. Then we adapted the Joint Video Team’s <b>reference</b> multi-view <b>decoder</b> to run on ZOOMTM OMAP 34 xTM Mobile Development Kit (MDK). The first decoding performance tests on the MDK resulted with around four stereo frames per second with frame resolutions of 640 × 352. To further improve the performance, the decoder software is profiled and the most demanding algorithms are ported to run on the embedded DSP core. Tests resulted with performance gains ranging from 25...|$|R
40|$|The {{recently}} developed H. 264 / MPEG- 4 Part 10 video compression standard achieves better video compression efficiency than previous video compression standards {{at the expense}} of increased computational complexity and power consumption. Multiple reference frame (MRF) Motion Estimation (ME) is the most computationally intensive and power consuming part of H. 264 video encoders. Therefore, in this thesis, we designed and implemented a reconfigurable baseline H. 264 video encoder hardware for real-time portable applications in which the number of reference frames used for MRF ME can be configured based on the application requirements in order to trade-off video coding efficiency and power consumption. The proposed H. 264 video encoder hardware is based on an existing low cost H. 264 intra frame coder hardware and it includes new reconfigurable MRF ME, mode decision and motion compensation hardware. We first proposed a low complexity H. 264 MRF ME algorithm and a low energy adaptive hardware for its real-time implementation. The proposed MRF ME algorithm reduces the computational complexity of MRF ME by using a dynamically determined number of reference frames for each Macroblock and early termination. The proposed MRF ME hardware architecture is implemented in Verilog HDL and mapped to a Xilinx Spartan 6 FPGA. The FPGA implementation is verified with post place & route simulations. The proposed H. 264 MRF ME hardware has 29 - 72 % less energy consumption on this FPGA than an H. 264 MRF ME hardware using 5 reference frames for all MBs with a negligible PSNR loss. We then designed the H. 264 video encoder hardware and implemented it in Verilog HDL. The proposed video encoder hardware is mapped to a Xilinx Virtex 6 FPGA and verified with post place & route simulations. The bitstream generated by the proposed video encoder hardware for an input frame is successfully decoded by H. 264 Joint Model <b>reference</b> software <b>decoder</b> and the decoded frame is displayed using a YUV Player tool for visual verification. The FPGA implementation of the proposed H. 264 video encoder hardware works at 135 MHz, it can code 55 CIF (352 x 288) frames per second, and its power consumption ranges between 115 mW and 235 mW depending on the number of reference frames used for MRF ME...|$|R
40|$|MPEG- 1 Layer 3, {{known as}} MP 3, has {{generated}} a significant popularity for distributing digital music over the Internet. MP 3 compresses digital music with high ratio while keeping high sound quality. However, copyright issue is raised because of illegal copy, redistribution and various malicious attacks. Digital watermarking is {{a technology that}} allows users to embed some imperceptible data into digital contents such as image, movie and audio data. Once a watermark is embedded into the original MP 3 signal, {{it can be used}} to identify the copyright holder in order to prevent illegal copy and to verify the modification from the original content. This thesis presents two novel adaptive watermarking algorithms for MP 3 compressed audio signals for copyright protection. Based on Human Auditory System, the proposed algorithms calculate the energy of the original audio signal and apply Gaussian analysis on MP 3 frames to adaptively adjust the watermarking coefficients. Watermark is embedded adaptively and transparently during the MP 3 compression. The first watermarking algorithm detects watermark based on Gaussian distribution analysis. To enhance the security of the watermark, the second watermarking algorithm embeds random watermark pattern and uses correlation coefficient to detect watermark. Both algorithms support blind watermark detection and perform well. The first algorithm is more robust while the second algorithm is more secure. LAME 3. 96. 2 open source was used as standard ISO MP 3 encoder and <b>decoder</b> <b>reference</b> in this study. The experimental results show that the proposed watermarking algorithms can work on a variety of audio signals and survive most common signal manipulation and malicious attacks. As expected, the watermarking algorithms provide superior performance on MP 3 compression...|$|R
40|$|We {{consider}} distributed video coding in a monoview video-plus-depth scenario, {{aiming at}} coding textures jointly with their corresponding depth stream. Distributed Video Coding (DVC) is a video coding paradigm {{in which the}} complexity is shifted from the encoder to the decoder. The Side Informa-tion (SI) generation is {{an important element of}} the decoder, since the SI is the estimation of the to-be-decoded frame. Depth maps enable the calculation of the distance of an ob-ject from the camera. The motion between depth frames and their corresponding texture frames (luminance and chromi-nance components) is strongly correlated, so the additional depth information may be used to generate more accurate SI for the texture stream, increasing the efficiency of the system. In this paper we propose various methods for accurate texture SI generation, comparing them with other state-of-the-art so-lutions. The proposed system achieves gains on the <b>reference</b> <b>decoder</b> up to 1. 49 dB...|$|E
40|$|Nowadays, the {{multicore}} {{architecture is}} adopted {{everywhere in the}} design of contemporary processors in order to boost up the performance of multitasking applications. This paper mainly exploits the multicore capability for full HD video decoding speedup to meet realtime display. Hantro 6100 H. 264 decoder is chosen as the <b>reference</b> <b>decoder.</b> The serial decoding algorithm in the Hantro 6100 H. 264 decoder is replaced with a parallel decoding algorithm. In this research work, macroblock level parallelism is implemented using the enhanced version of macroblock region partitioning (MBRP) is implemented for the parallel video decoding of H. 264 video. The results show that the workloads are well-balanced among the processor cores. It is observed that the maximum speedup values are attained when the decoder is running with 4 threads on a 4 core system and 8 logical core system configuration. Moreover, it is also observed that there is no degradation of visual quality throughout the decoding process...|$|E
40|$|Ogg/Vorbis is {{currently}} a growing audio format, mainly used for online distribution of music. The number of available encoded audio files is quickly increasing even though MP 3 still is the most used format. Many internet radio stations have begun streaming in Ogg/Vorbis and even more are examining the possibilities. In contrast with other renown formats such as AAC and MP 3, Ogg/Vorbis is totally license and royalty free. For embedded platforms the licensing and royalty cost for supporting commercial formats can be quite taxing as payments are often per device. The aim of this thesis is to implement an embedded Ogg/Vorbis system under strict memory and CPU usage constraints. As opposed to most other audio formats, Ogg/Vorbis includes codebooks and other data structures in the data stream, thus greatly increasing dynamic memory usage. Furthermore, the <b>reference</b> <b>decoder</b> is based on floating point math, albeit a fixed-point implementation also exists. These problems paired with the short time elapsed since Ogg/Vorbis was introduced has ha...|$|E
40|$|The recent JVT video {{coding scheme}} (MPEG- 4 AVC/H. 264) is a {{promising}} technique {{due to its}} high coding efficiency. Hypothetical <b>Reference</b> <b>Decoder</b> (HRD) {{is a very important}} part in JVT video coding, which represents a set of normative requirements on bitstream for the purpose of avoiding buffer overflow and underflow. The problem of HRD requirements can be solved by rate control. This paper proposes an effective rate control scheme for JVT video coding with HRD considerations. First, bit allocation with HRD constraints is presented, and second, based on a simple rate distortion model, a single pass rate control is implemented on both frame level and macroblock level. Experimental results show that the proposed rate control algorithm can achieve the target bit rate with very little bit rate or image quality fluctuation, and meanwhile it can well meet the HRD requirements. Furthermore, the proposed algorithm is so simple that it only introduces little computation complexity. Therefore, it can be used in real time video coding. 1...|$|E
40|$|I {{would like}} to thank Dr. Erik Perrins for giving me the {{opportunity}} to work on this project and also for introducing me to the wonderful world of error control coding. Without his support, {{none of this would have}} been possible. I would also like to thank Dr. Andrew Gill and Dr. Perry Alexander for taking time to serve on my committee, as well as everyone at KU who has helped me over the years. Finally, I {{would like to}} thank my family for all their love, support, and for always believing in me. This thesis outlines the hardware design of a soft output Viterbi algorithm decoder for use in a serially concatenated convolutional code system. Convolutional codes and their related structures are described, as well as the algorithms used to decode them. A decoder design intended for a field-programmable gate array is presented. Simulations of the proposed design are compared with simulations of a software <b>reference</b> <b>decoder</b> that is known to be correct. Results of the simulations are shown and interpreted, and suggestions for future improvements are given. iv Contents Acceptance Pag...|$|E
30|$|Both the {{duration}} and the annoyance {{level of the}} visible artifacts contribute to the perceived video quality degradation. The annoyance level of artifacts produced by packet loss depends heavily on the EC scheme of a decoder. The goal of EC is to estimate the missing MBs in a compressed video bitstream with packet losses, {{in order to provide}} a minimum degree of perceptual quality degradation. EC methods that have been developed roughly fall into two categories: spatial EC approach and temporal EC approach. In the spatial EC class, spatial correlation between local pixels is exploited; missing MBs are recovered by interpolation from neighbor pixels. In the temporal EC class, both the coherence of motion field and the spatial smoothness of pixels along edges cross block boundary are exploited to estimate motion vector (MV) of a lost MB. In H. 264 JM <b>reference</b> <b>decoder,</b> spatial approach is applied to conceal lost MBs of Intra-coded frame (I-frame) using bilinear interpolation technique; temporal approach is applied to conceal lost MBs for inter-predicted frame (P-frame, B-frame) by estimating MV of the lost MB based on the neighbor MBs' MVs. Minimum boundary discontinuity criterion is used to select the best MV estimate.|$|E
