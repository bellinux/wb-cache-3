0|10000|Public
40|$|In {{the past}} few decades, {{mathematics}} <b>based</b> <b>approaches</b> have been widely adopted in various image restora-tion problems, among which the partial differential equation (PDE) <b>based</b> <b>approach</b> (e. g. the total variation model [56] and its generalizations, nonlinear diffusions [15, 52], etc.), and wavelet frame <b>based</b> <b>approach</b> are some of successful examples. These approaches were developed through different paths and generally provided understandings from different angles of the same problem. As shown in numerical simulations, implementa-tions of wavelet frame <b>based</b> <b>approach</b> and PDE <b>based</b> <b>approach</b> quite often end up with solving a similar numerical problem with similar numerical behaviors, even though different approaches have advantages in different applications. Since wavelet frame based and PDE <b>based</b> <b>approaches</b> have all been modeling {{the same type of}} problems with success, it is natural to ask whether wavelet frame <b>based</b> <b>approach</b> is fundamentally connected with PDE <b>based</b> <b>approach</b> when we trace {{all the way back to}} their roots. A fundamental connection of a wavelet frame <b>based</b> <b>approach</b> with total variation model and its generalizations were established in [8]. This connection gives wavelet frame <b>based</b> <b>approach</b> a geometric explanation and, at the same time, it equips a PDE <b>based</b> <b>approach</b> with a time frequency analysis. It was shown in [8] that a special type of wavelet frame model using generic wavelet frame systems can be regarded as an approximation of a generic variational mode...|$|R
40|$|Abstract- Text mining {{is nothing}} but the {{discovery}} of interesting knowledge in text documents. But {{there is a big}} challenging issue that how to guarantee the quality of discovered relevant features. And that are in the text documents for describing user preferences because of the large number of terms, patterns and noise. For text mining there are basically two types of approaches; one is term <b>based</b> <b>approach</b> and another is phrase <b>based</b> <b>approach.</b> But term <b>based</b> <b>approach</b> suffered with the problem of polysemy and synonymy. And phrase <b>based</b> <b>approach</b> suffered with low frequency occurrence. But phrase <b>based</b> <b>approachs</b> are better than the term <b>based</b> <b>approachs.</b> But pattern <b>based</b> <b>approach</b> is better than the term based and phrase <b>based</b> <b>approach.</b> The proposed method is an innovative and effective pattern discovery technique. This method includes two main processes pattern deploying and inner pattern evaluation. This paper presents an effective technique to improve the effectiveness of using and updating discovered patterns for finding relevant and interesting information. Using Baysian filtering algorithm and effective pattern Discovery technique we can detect the spam mails from the email dataset with good correctness of term. Index Terms — Text mining, information filtering, pattern mining, sequential pattern, closed sequential patterns...|$|R
40|$|Abstract. String based {{as well as}} tree based {{methods have}} been used to learn {{wrappers}} for extraction from semi-structured docu-ments (e. g., HTML documents). Previous work has shown that tree <b>based</b> <b>approaches</b> perform better while needing less examples than string <b>based</b> <b>approaches.</b> A disadvantage is that they can only extract complete text nodes, whereas string <b>based</b> <b>approaches</b> can extract within text nodes. This paper proposes a hybrid approach that com-bines the advantages of both systems and compares it experimentally with a string <b>based</b> <b>approach</b> on some sub node extraction tasks. ...|$|R
40|$|The {{present study}} on Activity <b>Based</b> <b>Approach</b> enhance {{achievement}} in sciences of class-VII students. Activity <b>Based</b> <b>Approach</b> consisted of different {{activities for the}} all around development of children at the elementary level. Activity should be prepared by low cost material which {{is available in the}} locality. Hence it is concluded that Activity <b>Based</b> <b>Approach</b> is significantly effective than the traditional approach of teaching...|$|R
30|$|In this section, some {{relevant}} approaches presenting similar concept are comprehensively elaborated. These {{approaches are}} broadly categorized into (1) MEC <b>based</b> <b>approaches</b> (2) Cloudlets <b>based</b> <b>approaches</b> and (3) Open Fog Consortium.|$|R
40|$|Software Maintenance Testing is {{essential}} during software testing phase. All defects found during testing must undergo a re-test process {{in order to}} eliminate the flaws. By doing so, test cases are absolutely needed to evolve and change accordingly. In this paper, several maintenance testing approaches namely regression test suite <b>approach,</b> heuristic <b>based</b> <b>approach,</b> keyword <b>based</b> <b>approach,</b> GUI <b>based</b> <b>approach</b> and model <b>based</b> <b>approach</b> are evaluated <b>based</b> on software evolution taxonomy framework. Some of the discussed approaches support changes of test cases. Out of the review study, a couple of results are postulated and highlighted including the limitation of the existing approaches...|$|R
40|$|Abstract. The {{approaches}} to learn wrappers for extraction from semi-structured documents (like HTML documents) {{are divided into}} string based ones, and tree based ones. In previous papers we have shown that tree <b>based</b> <b>approaches</b> perform much better and need less examples than string <b>based</b> <b>approaches,</b> but have the disadvantage that they can only extract complete text nodes, whereas string <b>based</b> <b>approaches</b> can extract within text nodes. In this {{paper we propose a}} hybrid approach that combines the advantages of both systems. We compare this approach experimentally with a string <b>based</b> <b>approach</b> on some sub node extraction tasks. ...|$|R
50|$|Medical {{professionals}} {{recommend a}} preventative <b>based</b> <b>approach</b> of stopping fungus before it occurs. Prevention is preferable over a reactive treatment <b>approach.</b> The preventative <b>based</b> <b>approach</b> involves removing heat and moisture to the groin area.|$|R
40|$|We {{propose a}} self-supervised word-segmentation {{technique}} for Chinese information retrieval. This method combines {{the advantages of}} traditional dictionary <b>based</b> <b>approaches</b> with character <b>based</b> <b>approaches,</b> while overcoming many of their shortcomings. Experiments on TREC data show comparable performance to both the dictionary based and the character <b>based</b> <b>approaches.</b> However, our method is completely language independent and unsupervised, which provides a promising avenue for constructing accurate multilingual or cross-lingual information retrieval systems that are exible and adaptive...|$|R
40|$|Abstract — Fingerprint {{technique}} {{is used for}} identification and verification purposes as it develops a low cost and fast computing system. There are many approaches for fingerprint recognition. The two basic approaches for fingerprint identification are minutiae <b>based</b> <b>approach</b> and Pattern recognition approach. Now a day’s wavelet <b>based</b> <b>approach</b> is most preferred due to its time-frequency. We are presenting here this new Wavelet <b>based</b> <b>approach</b> and compare the results by Traditional DFT, Traditional FFT, FRIRV techniques...|$|R
40|$|The aim of {{this paper}} is to measure {{security}} in requirement engineering using questionnaire <b>based</b> <b>approach.</b> The questionnaire is applied in the four stages of requirement engineering (Elicitation, analyses, validation, management). The questionnaire <b>based</b> <b>approach</b> is composing of three main parts. First the security questions part. Second the evaluation part which should be filled by the stakeholders. Third the assessment part. Finally A case study conducted to apply Questionnaire <b>based</b> <b>approach</b> and to measure security in requirement engineering. 1...|$|R
40|$|Abstract. Distributed Constraint Satisfaction Problems (DCSPs) {{provide a}} model to capture {{a broad range of}} {{cooperative}} multi-agent problem solving settings. Researchers have generally proposed two different sets of approaches for solving DCSPs, backtracking <b>based</b> <b>approaches,</b> such as Asynchronous Backtracking (ABT), and mediation <b>based</b> <b>approaches,</b> such as Asynchronous Partial Overlay (APO). These sets of approaches differ in the levels of coordination employed during conflict resolution. While the computational and communication complexity of the backtracking <b>based</b> <b>approaches</b> is well understood, the tradeoffs in complexity involved in moving toward mediation <b>based</b> <b>approaches</b> are not. In this paper we comprehensively reexamine the space of mediation <b>based</b> <b>approaches</b> for DCSP and fill gaps in existing frameworks with new strategies. We present different mediation session selection rules, including a rule that favors smaller mediation sessions, and different mediation strategies, including a decentralized hybrid strategy based on ABT. We present empirical results on solvable 3 -coloring and random binary DCSP problems, that accurately capture the computational and communication tradeoffs between ABT and various mediation <b>based</b> <b>approaches.</b> Our results confirm that under some circumstances the newly presented strategies dominate previously proposed techniques. ...|$|R
5000|$|... Africa Contact {{follows a}} rights <b>based</b> <b>approach</b> <b>based</b> on the UN Convention on Social and Economic Rights.|$|R
30|$|Evaluation {{showed that}} the {{proposed}} utility based solution outperformed the existing heuristic <b>based</b> <b>approach</b> in terms of energy savings and minimizing SLAVs in both lightly loaded and more heavily loaded cloud data centers. Perhaps the key factor that differentiates the approaches is that the heuristics <b>based</b> <b>approach</b> adapts whenever {{there is a problem}} (PM overload, or PM under-load). On the contrary, the utility <b>based</b> <b>approach</b> adapts only if it can identify an adaptation that is expected to improve on the current allocation.|$|R
40|$|Abstract – The {{present study}} on Activity <b>Based</b> <b>Approach</b> enhance {{achievement}} in sciences of class-VII students. Activity <b>Based</b> <b>Approach</b> consisted of different {{activities for the}} all around development of children at the elementary level. Activity should be prepared by low cost material which {{is available in the}} locality. Hence it is concluded that Activity <b>Based</b> <b>Approach</b> is significantly effective than the traditional approach of teaching. Key Words – Effect of activity based; approach on achievement in science; students at elementary stage...|$|R
40|$|Text mining {{is nothing}} but the {{discovery}} ofinteresting knowledge in text documents. But there is a bigchallenging issue that how to guarantee the quality of discoveredrelevant features. And {{that are in the}} text documents fordescribing user preferences because of the large number ofterms, patterns and noise. For text mining there are basically twotypes of approaches; one is term <b>based</b> <b>approach</b> and another isphrase <b>based</b> <b>approach.</b> But term <b>based</b> <b>approach</b> suffered withthe problem of polysemy and synonymy. And phrase basedapproach suffered with low frequency occurrence. But phrasebased approachs are better than the term <b>based</b> <b>approachs.</b> Butpattern <b>based</b> <b>approach</b> is better than the term <b>based</b> and phrasebased <b>approach.</b> The proposed method is an innovative andeffective pattern discovery technique. This method includes twomain processes pattern deploying and inner pattern evaluation. This paper presents an effective technique to improve theeffectiveness of using and updating discovered patterns forfinding relevant and interesting information. Using Baysianfiltering algorithm and effective pattern Discovery technique wecan detect the spam mails from the email dataset with goodcorrectness of term...|$|R
40|$|In {{this paper}} we present {{work on a}} {{scenario}} and persona <b>based</b> <b>approach</b> to exploring social software solutions for a globally distributed network of researchers, designers and artists. We discuss issues identified with scenario <b>based</b> <b>approaches</b> and a potential participatory solution adopted in this project...|$|R
40|$|Object {{detection}} {{is a part}} of {{our everyday}} lives, however, automatic object detection by computer is still an open question. In 30 years of research in computer vision, little progress has been made. This report is a survey on the most recent techniques in object detection research. First, we introduce the definition, challenges, applications and general components of the object detection system. This is followed by a review of various appearance <b>based</b> <b>approaches</b> and feature <b>based</b> <b>approaches.</b> Appearance <b>based</b> <b>approaches</b> are classified <b>based</b> on different classifiers into linear representation, distribution-based, support vector machines, sparse Winnow network. Meanwhile different feature <b>based</b> <b>approaches</b> are distinguished from each other by what features are being used- texture, shape, context and multiple features. Then a framework of an object detection system i...|$|R
40|$|In speaker {{verification}} {{the world}} model <b>based</b> <b>approach</b> and the cohort model <b>based</b> <b>approach</b> {{have been used}} for better HMM score measurements for verification comparison. From theoretical analysis these two approaches represent two different paradigms for verification decision-making strategy. Two techniques could be combined for a better solution. In the paper we present a hybrid score measurement which combines the world model based technique and the cohort model based technique together. The method is evaluated with the YOHO database. The results show that the combination can lead a better score measurement which improves speaker verification performance. An experimental comparison between the world model <b>based</b> <b>approach</b> and the cohort model <b>based</b> <b>approach</b> with the YOHO database can also be found in the paper. 1...|$|R
40|$|Texture {{segmentation}} is {{the process}} of partitioning an image into regions with different textures containing similar group of pixels. This paper presents a comparative study of four texture segmentation methods based on the following features: descriptors, heuristic function, fuzzy logic and Mask based features. Many types of textures are considered for analysis. The comparative results show that descriptor <b>based</b> <b>approach</b> is the most suitable for segmenting both natural and mosaic textures whereas heuristic function <b>based</b> <b>approach</b> is most suitable for random textures. Fuzzy features <b>based</b> <b>approach</b> is found to yield better segments for regular patterns while Mask feature <b>based</b> <b>approach</b> is the best for segmenting Natural images, but fails miserably on Mosaic textures. Fuzzy C-means classification is used for achieving texture segmentation. 1...|$|R
40|$|Remote sensing imagery {{needs to}} be {{converted}} into tangible information which can be utilized {{in conjunction with other}} data sets, often within widely used Geospatial Information Systems (GIS). Remote sensing data help in mapping land resources, especially in mountainous areas where accessibility is limited. Classification of remote sensing data in mountainous terrain is problematic because of variations in the sun illumination angle. Traditional approaches have many problems in these conditions. In object <b>based</b> <b>approach</b> can utilized GIS tools for improvement of classification results. In the present work we used pixel based and object <b>based</b> <b>approaches</b> that in both we imported GIS concepts and ancillary data for refining of classification results. The results showed that object <b>based</b> <b>approach</b> have higher accuracy than pixel <b>based</b> <b>approach.</b> 1...|$|R
40|$|While {{billions of}} dollars have been spent in {{development}} projects in least developed countries, poverty continues to increase. This study proposes human-rights <b>based</b> <b>approach</b> to poverty eradication. To this end, the study seeks to assess the key determinants of use of rights- <b>based</b> <b>approaches</b> to poverty reduction and it’s usefulness in Kenya with special reference to NGOs in Kibera. The study further high lights {{some of the basic}} skills of implementing the rights <b>based</b> <b>approach</b> to poverty reduction. The attempts to establish the proportion of NGOs applying rights <b>based</b> <b>approach</b> to poverty reduction in Kibera Division as well. The review of relevant literature has been undertaken and a field study done. The study is informed by a qualitative human rights framework. </em...|$|R
40|$|Performance {{estimation}} is {{a crucial}} operation which drives the design space exploration in Application Speci c Instruction Set Processors (ASIP) synthesis. The usual approach to estimate performance is to do simulation. With increasing dimensions of the design space, simulator <b>based</b> <b>approaches</b> become too time consuming. This problem can be solved by scheduler <b>based</b> <b>approaches,</b> which are much faster. However existing scheduler <b>based</b> <b>approaches</b> do not help in exploring storage organization. This paper presents a scheduler based technique for exploring register le size in ASIP synthesis...|$|R
40|$|Performance {{estimation}} which {{drives the}} design space exploration is usually done by simulation. With increasing {{dimensions of the}} design space, simulator <b>based</b> <b>approaches</b> become too time consuming. In the domain of Application Specific Instruction set Processors (ASIP), this problem can be solved by scheduler <b>based</b> <b>approaches,</b> which are much faster. However, existing scheduler <b>based</b> <b>approaches</b> do not help in exploring storage organization. We present a scheduler based technique for exploring register file size, number of register windows and cache configurations in an integrated manner...|$|R
40|$|Common Representation Learning (CRL), wherein {{different}} descriptions (or views) of {{the data}} are embedded in a common subspace, is receiving {{a lot of attention}} recently. Two popular paradigms here are Canonical Correlation Analysis (CCA) <b>based</b> <b>approaches</b> and Autoencoder (AE) <b>based</b> <b>approaches.</b> CCA <b>based</b> <b>approaches</b> learn a joint representation by maximizing correlation of the views when projected to the common subspace. AE based methods learn a common representation by minimizing the error of reconstructing the two views. Each of these approaches has its own advantages and disadvantages. For example, while CCA <b>based</b> <b>approaches</b> outperform AE <b>based</b> <b>approaches</b> for the task of transfer learning, they are not as scalable as the latter. In this work we propose an AE <b>based</b> <b>approach</b> called Correlational Neural Network (CorrNet), that explicitly maximizes correlation among the views when projected to the common subspace. Through a series of experiments, we demonstrate that the proposed CorrNet is better than the above mentioned approaches with respect to its ability to learn correlated common representations. Further, we employ CorrNet for several cross language tasks and show that the representations learned using CorrNet perform better than the ones learned using other state of the art approaches. Comment: 27 pages. To Appear in Neural Computatio...|$|R
50|$|Higher noise than cooled {{semiconductor}} <b>based</b> <b>approaches.</b>|$|R
5000|$|... #Subtitle level 2: Response surface {{methodology}} <b>based</b> <b>approaches</b> ...|$|R
40|$|Perceptual-cognitive tasks {{used for}} both testing and {{training}} in sport {{will benefit from the}} inclusion and/or emphasis of knowledge <b>base</b> <b>approaches</b> as a key driving mechanism. In particular, training and testing of decision making skill is discussed. The distinction is made between the isolated decision making approach and the tactics and knowledge <b>base</b> <b>approach</b> to action choices. Knowledge <b>base</b> <b>approaches</b> are seen to provide a more sensitive and mechanistic assessment of skill and underlying response selection processes, and are better able to examine individual differences in the progression from action prediction to action control. ...|$|R
40|$|Abstract—Association rule mining {{techniques}} discover {{associations between}} entities. Some techniques are single minimum support based while some are multiple minimum support based. Single minimum support <b>based</b> <b>approach</b> suffer from rare item problem dilemma while multiple support <b>based</b> <b>approach</b> considers rare items for mining association rules. In this paper we have evaluated performance of Apriori-T and MSApriori-T Algorithms that are single and multiple minimum <b>based</b> <b>approaches</b> respectively. These Algorithms uses an efficient data storage mechanism Total support tree for storing item sets. Index Terms—Apriori-T, Association rule mining, MSApriori-T, Total support tree...|$|R
40|$|In this paper, {{we present}} a novel {{principal}} component analysis (PCA) <b>based</b> <b>approach</b> towards modeling the object trajectory in a video clip. An eigenspace decomposition of highdimensional trajectory data leads to very compact representation, which is then used as indexing structure. To cutback on PCA computation during indexing, we first segment the trajectories into atomic subtrajectories using a curvature zero-crossing <b>based</b> <b>approach</b> followed by clustering of these subtrajectories. A two-level PCA operation with coarse-to-fine retrieval for query trajectory is then performed to generate retrieval results. Our experimental results show that our global PCA <b>based</b> <b>approach</b> performs better when input query trajectory is of similar length compared to the matching trajectories in the database. However, when partial trajectories are posed as queries our segmented trajectory <b>based</b> <b>approach</b> provides superior results for all Precision-Recall ratios...|$|R
40|$|Scenarios {{have proven}} useful to elicit, {{validate}} and document requirements but {{the development of}} new methods and tools for Requirements Engineering integrating scenario <b>based</b> <b>approaches</b> has been limited. The view developed in this paper is that scenario <b>based</b> <b>approaches</b> should be looked upon as reusable components. Our concern is therefore twofold: first, to represent scenario <b>based</b> <b>approaches</b> in a modular way which eases their reusability and second, to specify the design context in which these approaches can be reused in order to facilitate their integration in existing methods. The paper presents also an implementation of our proposal using SGML-HTML to store scenario <b>based</b> <b>approaches</b> in the multimedia hypertext documents and illustrates the retrieval of components meeting the requirements of the user by the means of SGMLQL queries. 1...|$|R
5000|$|... {{stakeholder}} <b>based</b> <b>approaches</b> including metagame {{analysis and}} drama theory ...|$|R
5000|$|... #Subtitle level 3: Risk <b>Based</b> <b>Approach</b> To Computer Validation ...|$|R
5000|$|... object <b>based</b> <b>approach</b> ideally {{accessing}} {{shared data}} through object-oriented discipline.|$|R
5000|$|... #Subtitle level 3: Data mining <b>based</b> <b>approach</b> to {{activity}} recognition ...|$|R
30|$|Conclusion Static PVC {{value is}} a low preload-dependency surrogate. When LVEF is low a {{pressure}} evaluation <b>based</b> <b>approach</b> seems more accurate. When LVEF is normal a volume evaluation <b>based</b> <b>approach</b> seems informative as predicted by {{the slope of the}} end diastolic pressure volume curve. Those both static approaches remain of poor diagnosis accuracy.|$|R
