11|233|Public
50|$|In {{audio signal}} processing, {{convolution}} reverb {{is a process}} used for digitally simulating the reverberation of a physical or virtual space {{through the use of}} software profiles; a piece of software (or algorithm) that creates a simulation of an audio environment. It is based on the mathematical convolution operation, and uses a pre-recorded audio sample of the impulse response of the space being modeled. To apply the reverberation effect, the impulse-response recording is first stored in a digital signal-processing system. This is then convolved with the incoming audio signal to be processed. The process of convolution multiplies each sample of the audio to be processed (reverberated) with the samples in the impulse <b>response</b> <b>file.</b>|$|E
30|$|After {{format and}} {{measurement}} files are loaded, users need {{to load the}} <b>response</b> <b>file</b> (see Table  1 and “Acquisition and preparation of magnetometer sensor response” section) by clicking on the third icon on the toolbar to locate and load the <b>response</b> <b>file.</b> If the <b>response</b> <b>file</b> is appropriately formatted and successfully loaded, UDECON will automatically plot the <b>response</b> <b>file</b> data and show {{the name of the}} <b>response</b> <b>file</b> just beneath the measurement file name (Fig.  2 c). The procedures of loading format and measurement files followed by <b>response</b> <b>file,</b> are typical for deconvolution of a measurement file for the first time. If users have previously conducted deconvolution with these loaded files and saved a “.mat” file using UDECON (see “Saving deconvolution data and plots” section), deconvolution optimization analysis can be continued by directly loading the “.mat” file without loading any of the three files (see Fig.  1). The “.mat” file stores not only the deconvolution-related data but also the loaded measurement and response data. The “.mat” file can be loaded to UDECON using the fourth icon on the toolbar.|$|E
40|$|Effective Road Profile (ERP) Control is a {{relatively}} new simulator control strategy which shows a great deal of promise in reducing automotive suspension and structural testing times, thus shortening the product development cycle. The key to ERP is a linearly approximated tire model consisting of a characteristic stiffness of the spring elements within the model (K), characteristic damping coefficient of damper elements within the model, (C), and the tire modal mass (MMTM). The tire parameters can be purchased as a data set from MTS Systems Corporation for approximately 6000 US per tire. This thesis offers an alternate method of obtaining the tire characteristics. A rigid two-part frame was installed within the pit of a four-post road test simulator. This frame was assembled around one hydraulic actuator with the test tire secured above the actuator pan. The hydraulic actuator was then used to input a drive file into the tire to produce a tire <b>response</b> <b>file.</b> From that tire <b>response</b> <b>file,</b> radial displacement and radial force are required for tire characterization. The Tire Characterization tool within RPCRTM Pro was used to calculate K, C, and MMTM as defined above. (Abstract shortened by UMI.) Dept. of Mechanical, Automotive, and Materials Engineering. Paper copy at Leddy Library: Theses 2 ̆ 6 Major Papers - Basement, West Bldg. / Call Number: Thesis 2002. M 67. Source: Masters Abstracts International, Volume: 44 - 01, page: 0427. Thesis (M. A. Sc.) [...] University of Windsor (Canada), 2003...|$|E
50|$|A typical ATL server {{application}} consists {{of at least}} one ISAPI extension DLL along with one or a number of Server <b>Response</b> <b>Files</b> (.srf) and their associated application DLL files which provide the application functionality.|$|R
30|$|The {{framework}} of the verification flow shown in Figure 3 is implemented in MATLAB. The interfaces to the simulation tasks are stimuli files stored to disc during stimuli generation. The interfaces to the consolidation steps are the <b>response</b> <b>files</b> written to disc during simulation.|$|R
40|$|The {{calibration}} of the Swift XRT {{effective area}} has been performed by analyzing cosmic sources observed during the in-flight calibration phase and by using laboratory results and ray-tracing simulations as a starting point. This work describes performance of the recent release of ancillary <b>response</b> <b>files</b> (ARF v 8) ...|$|R
40|$|To submit an upload/download request {{through a}} web browser the user will select the Browse button {{as noted in the}} figure below and select the file {{containing}} the upload/download request details. Once the file has been selected, the User will click the Upload button to initiate the data exchange with the JESS application. The web browser will present the user with a response which the user may view on the page and save. The content and structure of the <b>response</b> <b>file</b> is specific to each of the templates. In the event that the file submitted by the user fails any validations steps, the user will be presented with an error. Details regarding error messages are noted below in Section 3. 4 Note that in order to access the upload function in JESS, the user must have a valid NYISO digital certificate. See Section 1. ...|$|E
40|$|Now in {{its third}} edition, Harlan Carvey has updated "Windows Forensic Analysis Toolkit" to cover Windows 7 systems. The primary {{focus of this edition}} is on {{analyzing}} Windows 7 systems and on processes using free and open-source tools. The book covers live <b>response,</b> <b>file</b> analysis, malware detection, timeline, and much more. The author presents real-life experiences from the trenches, making the material realistic and showing the why behind the how. New to this edition, the companion and toolkit materials are now hosted online. This material consists of electronic printable checklists, cheat sheets, free custom tools, and walk-through demos. This edition complements "Windows Forensic Analysis Toolkit, 2 nd Edition", (ISBN: 9781597494229), which focuses primarily on XP. It includes complete coverage and examples on Windows 7 systems. It contains Lessons from the Field, Case Studies, and War Stories. It features companion online material, including electronic printable checklists, cheat sheets, free custom tools, and walk-through demos...|$|E
40|$|This work {{provides}} an in-depth mathematical {{description of the}} response functions that are used for spatial and spectral analysis of X-ray data. The use of such functions is well-known to anyone familiar with the analysis of X-ray data where they may be identied with the quantities contained in the Ancillary <b>Response</b> <b>File</b> (ARF), the Redistribution Matrix File (RMF), and the Exposure Map. Starting from rst-principles, explicit mathematical expressions for these functions, for both imaging and dispersive modes, are arrived at {{in terms of the}} underlying instrumental characteristics of the telescope including the eects of pointing motion. The response functions are presented in the context of integral equations relating the expected detector count rate to the source spectrum incident upon the telescope. Their application to the analysis of several source distributions is considered. These include multiple, possibly overlapping, and spectrally distinct point sources, as well as extended sources. Assumptions and limitations behind the usage of these functions, as well as their practical computation are addressed...|$|E
25|$|The package {{contains}} Logic Pro, Mainstage, Soundtrack Pro, WaveBurner, Studio Instruments, Studio Effects, Apple Loops, Apple Loops Utility, Impulse Response Utility, Compressor, and QuickTime Pro. It {{also contains}} 6 content DVDs containing Jam Pack collections, sound effects, surround music beds, EXS24 samples, and impulse <b>response</b> <b>files</b> and a demo content DVD.|$|R
3000|$|... (4) Consolidation: The {{consolidation}} step translates the <b>response</b> <b>files,</b> {{which may}} {{differ in their}} format depending on the testbench that collected them, into a unified database appropriate for the subsequent analysis. No intelligence or interpretation of the data is provided in this step to ensure robustness against responses from buggy models.|$|R
50|$|The package {{contains}} Logic Pro, Mainstage, Soundtrack Pro, WaveBurner, Studio Instruments, Studio Effects, Apple Loops, Apple Loops Utility, Impulse Response Utility, Compressor, and QuickTime Pro. It {{also contains}} 6 content DVDs containing Jam Pack collections, sound effects, surround music beds, EXS24 samples, and impulse <b>response</b> <b>files</b> and a demo content DVD.|$|R
40|$|The {{absolute}} {{stability of the}} PACS bolometer response over the entire mission lifetime without applying any corrections is about 0. 5 % (standard deviation) or about 8 % peak-to-peak. This fantastic stability allows us to calibrate all scientific measurements by a fixed and time-independent <b>response</b> <b>file,</b> without using any information from the PACS internal calibration sources. However, the analysis of calibration block observations revealed clear correlations of the internal source signals with the evaporator temperature and a signal drift {{during the first half}} hour after the cooler recycling. These effects are small, but can be seen in repeated measurements of standard stars. From our analysis we established corrections for both effects which push the stability of the PACS bolometer response to about 0. 2 % (stdev) or 2 % in the blue, 3 % in the green and 5 % in the red channel (peak-to-peak). After both corrections we still see a correlation of the signals with PACS FPU temperatures, possibly caused by parasitic heat influences via the Kevlar wires which connect the bolometers with the PACS Focal Plane Unit. No aging effect or degradation of the photometric system during the mission lifetime has been found. Comment: 15 pages, accepted for publication in Experimental Astronom...|$|E
30|$|With the {{preparation}} of a format file, UDECON directly reads pass-through paleomagnetic measurement files produced at different laboratories. Sensor response of an SRM needed for deconvolution can be accurately estimated through repeated measurements of a magnetic point source and prepared as a <b>response</b> <b>file</b> readable by UDECON (see “Acquisition and preparation of magnetometer sensor response” section). Once measured, the same sensor response data of an SRM can be edited and used to deconvolve any pass-through measurement made on that SRM. With a simple click in UDECON, optimized deconvolution can be searched using two different methods (i.e., “Simplex method” or “Grid search”) with adjustable choices of initial values or ranges for smoothness, position shift, and length correction. A suite of tools {{can be used to}} easily view and compare various types of data before and after optimized deconvolution for single or multiple treatment steps. Deconvolution-related ABIC values, error and residual, as well as the parameters used for the calculation, can be conveniently compared to refine the deconvolution optimization. Unsatisfactory or preliminary deconvolution data can be easily removed when not needed. Any plots shown in UDECON can be saved as pdf files, and users can save all measurement, response, and deconvolved data for further analysis later in UDECON, or export just the deconvolved data to text file for editing or plotting in other software.|$|E
30|$|The {{analysis}} part {{is carried}} out by pointing the excitation file and the set of response files to the DATK, after which it plots analysis figures, so that each analysis type is shown as a separate figure, and the analysis results from each <b>response</b> <b>file</b> are illustrated with subfigures. Thus, {{it is easy to}} interpret the effect of control parameter variations on the system response, since each subfigure shows the response to a different value of the varied parameter. The analysis figures can also be saved as.fig files even in standalone mode, allowing further editing with Matlab. The DATK runs on any modern computer, and only requires the use of a simple playback/recording software for playing the excitation signal and recording the responses. For measuring software plugins, the playback/recording software should be able to act as a plugin host. For measuring physical effects devices, an audio interface with adjustable playback/recording gains should be used. Sections 2.2 through 2.6 discuss the analysis functions currently included in the DATK, while Section 2.7 discusses how to develop additional analysis functions. Since the user defines the desired analysis techniques and their parameters by writing a text file, where the different analysis types (or same analysis types with different parameters) are written as separate lines, Sections 2.2 through 2.6 also introduce the syntax for performing each analysis type. The actual use of the DATK software is illustrated in Section 3 with a case study.|$|E
50|$|Ozimals’ {{motion to}} dismiss was granted in part and denied in part. In <b>response,</b> Amaretto <b>filed</b> a Second Amended Complaint.|$|R
50|$|In 1927, Koch {{developed}} {{a more efficient}} thermal cracking process for turning crude oil into gasoline which allowed smaller players in the industry to better compete with the oil majors. The larger oil companies quickly sued in <b>response,</b> <b>filing</b> 44 different lawsuits against Koch, and embroiling him in litigation for years. Koch was to prevail {{in all but one}} of the suits (which was later over-turned due to the fact that the judge had been bribed).|$|R
5000|$|... webfs: a {{file server}} that {{retrieves}} data from URLs and presents the contents and details of <b>responses</b> as <b>files</b> {{in the local}} namespace ...|$|R
40|$|EvoGrader is a free, online, on-demand {{formative}} assessment service {{designed for use}} in undergraduate biology classrooms. EvoGrader's web portal is powered by Amazon's Elastic Cloud and run with LightSIDE Lab's open-source machine-learning tools. The EvoGrader web portal allows biology instructors to upload a <b>response</b> <b>file</b> (. csv) containing unlimited numbers of evolutionary explanations written in response to 86 different ACORNS (Assessing COntextual Reasoning about Natural Selection) instrument items. The system automatically analyzes the responses and provides detailed information about the scientific and naive concepts contained within each student's response, as well as overall student (and sample) reasoning model types. Graphs and visual models provided by EvoGrader summarize class-level responses; downloadable files of raw scores (in. csv format) are also provided for more detailed analyses. Although the computational machinery that EvoGrader employs is complex, using the system is easy. Users only {{need to know how}} to use spreadsheets to organize student responses, upload files to the web, and use a web browser. A series of experiments using new samples of 2, 200 written evolutionary explanations demonstrate that EvoGrader scores are comparable to those of trained human raters, although EvoGrader scoring takes 99 % less time and is free. EvoGrader will be of interest to biology instructors teaching large classes who seek to emphasize scientific practices such as generating scientific explanations, and to teach crosscutting ideas such as evolution and natural selection. The software architecture of EvoGrader is described as it may serve as a template for developing machine-learning portals for other core concepts within biology and across other disciplines...|$|E
40|$|Project (M. S., Computer Science) [...] California State University, Sacramento, 2014 This {{project is}} a {{continuation}} of a previous student???s master???s project, which produced a software engine capable of parsing through XACML policy files and used the collected data to produce role-based access control (RBAC) statements executed in Microsoft SQL Server. However, there were a few important aspects of XACML that still required handling, including XACML request and response files, conflict resolution among policies, and policy refinement. This project handled these additional aspects, as well as performance evaluation, user interface updating, and code cleaning. By making the additions stated above, this project has now fully realized its initial goal of parsing XACML policies into RBAC statements: a software engine has been produced that will completely automate the process of access control, needing nothing more than a set of policies in a simple XML format. Once a user has selected a directory containing the policies, the engine will sequentially select each file residing within, construct the RBAC structure, store the structure in a set of tables, resolve any conflicts arising from the structure, and produce the appropriate SQL commands to represent the structure internally within the database. Additionally, if a user wants to determine if a database member has certain access permissions, the user can submit an XACML request. The engine will determine the result of the request and store it in an XACML <b>response</b> <b>file.</b> A user may also make changes to an existing XACML policy without worrying about conflicts with previously executed statements. Computer Scienc...|$|E
40|$|The current profile {{along the}} 126 ns, multi-bunch beam pulse in the Next Linear Collider Test Accelerator (NLCTA) is {{monitored}} with fast toroids (rise time {approximately} 1 ns). Inserted at several positions along the beam line, they allow one to track current transmission {{as a function}} of position along the bunch train. Various measurements, such as rise time, current, width, and slope, are made on the digitized signals, which can be corrected in software by means of stored frequency <b>response</b> <b>files.</b> The design and implementation of these devices is described...|$|R
3000|$|The {{excitation}} signal was imported by the recording software, {{and it was}} played to the real AC 30 while recording its output onto another track. Three recordings were made with different settings for the [...] "volume bright" [...] knob: 9 o'clock (low-gain), 12 o'clock (middle gain), and full (high gain). The three outputs were individually saved as.wav files within the same directory. Next, the TH 1 plugin with only the Top 30 unit enabled (and the channel gain knob set to 9 o'clock) was added as {{an effect on the}} excitation track, and the response was saved as a wave file to the same directory as the real AC 30 <b>response</b> <b>files.</b> The TH 1 AC 30 response recordings were repeated two times with the virtual channel gain knob set to 12 o'clock and full, in order to obtain <b>response</b> wave <b>files</b> with all three gain settings. Finally, the TH 1 plugin was replaced with the Peavey ReValver plugin with only the FOX ACS- 45 unit enabled, and the same operations (adjust gain, render output wave file, repeat) were carried out three times. Thus in the end, the response directory contained 9 <b>response</b> signals as.wav <b>files</b> with sample rate of 48 [*]kHz and 24 -bit resolution.|$|R
30|$|The floating-point and fixed-point {{models of}} the DUV are written in MATLAB and hence can be {{executed}} directly from within the verification framework. The HDL model, instead, is written in synthesizable VHDL. Although started from within the framework, the HDL simulation is outsourced to an HDL simulator (Modelsim by Mentor, in our case). The interaction with this HDL simulator simply consists of passing {{the location of the}} stimuli files as parameters. In the same way, the HDL testbench is instructed where to dump the <b>response</b> <b>files,</b> so that the MATLAB framework knows which responses to process once the HDL simulation terminates.|$|R
40|$|In {{this paper}} we discuss the methods {{developed}} {{for the production of}} the INTEGRAL/SPI instrument <b>response.</b> The <b>response</b> <b>files</b> were produced using a suite of Monte Carlo simulation software developed at NASA/GSFC based on the GEANT- 3 package available from CERN. The production of the INTEGRAL/SPI instrument response also required the development of a detailed computer mass model for SPI. We discuss our extensive investigations into methods to reduce both the computation time and storage requirements for the SPI response. We also discuss corrections to the simulated response based on our comparison of ground and inflight calibration data with MGEANT simulation...|$|R
30|$|To provide {{convenient}} and rapid {{realization of the}} optimized deconvolution algorithm developed by Oda and Xuan (2014) for pass-through paleomagnetic measurement data, we developed graphical software UDECON using the Graphical User Interface Design Environment (GUIDE) in MATLAB (version R 2014 a) on a Macintosh. Standalone versions of UDECON for both Macintosh and Windows PC are made available using the MATLAB Compiler. UDECON installation includes step-by-step guide to install MATLAB Compiler Runtime needed for the software to run without MATLAB. UDECON installation file, example SRM measurement, format, and <b>response</b> <b>files</b> are available at [URL] A typical workflow for optimized deconvolution of pass-through paleomagnetic data using UDECON is summarized in Fig.  1.|$|R
50|$|In 1774 {{the prior}} {{and members of}} the convent of San Pablo were patrons of the {{memories}} and Waqf founded by Fabio Nelli as well as administrators of their goods on behalf of the Royal Audience. At that time lived as a tenant in the Palace Ramon Castaños Leguizamon, patron of the Church of our Lady of Begoña, Marqués de Vargas and resident of Valladolid. It commissioned by his account the repairs and necessary arrangements in the building, by all which protested the friars masters. Mr Castaños, in <b>response,</b> <b>filed</b> a complaint in the Royal Audience accusing these Friars of dereliction in responsibility. The Royal Audience gave the reason.|$|R
30|$|A {{detailed}} {{literature search}} that was performed for 110 of the 244 identified genes {{indicated that the}} function {{of many of the}} genes, which possessed functional descriptions, could reasonably be linked to embryo development and water deficit stress <b>responses</b> (Supplementary <b>File</b> 5).|$|R
5000|$|In February 2013, Sikol {{faced an}} {{election}} petition regarding {{whether he was}} eligible to be elected under Section 23A of the Representation of the Peoples Act, and in <b>response</b> <b>filed</b> a constitutional case. In April 2013, Chief Justice Vincent Lunabek of the Supreme Court of Vanuatu affirmed the validity of Sikol's election, ruling that regardless of whether Sikol's adoption qualified him as [...] "a native or a person originating from that rural constituency ... who has been adopted by law or custom into a family originating from that rural constituency" [...] as required by Section 23A, that section itself violated the guarantee in Article 5(1) of the Constitution of Vanuatu against discrimination, and did not fall within the exceptions to that article for [...] "legitimate public interest".|$|R
25|$|In <b>response,</b> SCO <b>filed</b> several memoranda {{opposing}} Novell's {{motion to}} dismiss the case. Additionally, SCO filed a motion to remand the case back to State court. Novell countered that, because the case would hinge upon interpretation of Federal copyright law, it should be tried in Federal court.|$|R
30|$|A {{detailed}} {{literature search}} that was performed for 110 of the 244 identified genes {{indicated that the}} function {{of many of the}} genes, which possessed functional descriptions, could reasonably be linked to LEA gene functions during embryo development and water deficit stress <b>responses</b> (Supplementary <b>File</b> 5).|$|R
50|$|In <b>response,</b> SCO <b>filed</b> several memoranda {{opposing}} Novell's {{motion to}} dismiss the case. Additionally, SCO filed a motion to remand the case back to State court. Novell countered that, because the case would hinge upon interpretation of Federal copyright law, it should be tried in Federal court.|$|R
25|$|Journalist Gerald Hannon later {{published}} {{a piece in}} The Globe and Mail accusing Fantino of mounting an anti-gay witch hunt. In <b>response,</b> Fantino <b>filed</b> {{a complaint with the}} Ontario Press Council, which ultimately ruled that the Globe should have more clearly labelled Hannon's article as an opinion piece.|$|R
50|$|The league's {{strained}} {{relationship with}} the Canadian Soccer Association continued before {{the launch of the}} 2014 season with the CSA expelling the CSL from its membership over alleged violations of rules and regulations in order {{to make way for a}} lesser structure in Ontario. After failing to specify which rule violations were made and without providing a formal hearing in order to discuss the issues the CSL in <b>response</b> <b>filed</b> litigation against the CSA. The league operated as a private league for the first time since the 1997 season in its predecessor league the Canadian National Soccer League. Though they did join the newly formed Soccer Federation of Canada, which provides private soccer entities the services needed such as administration of players, non-playing personnel, match officials and insurance.|$|R
30|$|A new {{software}} tool for performing rapid analysis measurements on nonlinearly distorting audio effects was presented. The software is called Distortion Analysis Toolkit (DATK), {{and it is}} freely available for download at [URL] The software operates by first creating an excitation signal as a.wav file according to the specifications set by the user. Next, the user feeds this excitation signal as an input to a physical or virtual distorting audio effect and records the output. Several recordings can be made if the distorting effect's control parameter variations are to be analyzed. Finally, the introduced software analyzes the <b>response</b> <b>files</b> and displays the analysis results with figures. The software is developed in Matlab language, {{but it can also}} be operated in standalone mode. The DATK includes five distortion analysis methods, and additional analysis techniques can be appended to it using Matlab.|$|R
30|$|Evaluation {{of patient}} {{satisfaction}} with provided care The patients’ {{satisfaction with the}} provided care was assessed using 7 questions with “yes” or “no” <b>responses</b> (Additional <b>file</b> 3). A patient was judged as “satisfied with the provided care” if he/she have answered “yes” on more than 4 out of 7 questions (Ronnberg et al. 2007).|$|R
30|$|Evaluation {{of patient}} {{satisfaction}} with given information before the surgery We evaluated patients’ {{satisfaction with the}} information given before the surgery using 6 questions with “yes” or “no” <b>responses</b> (Additional <b>file</b> 2). A patient was judged as “satisfied with the given information” if he/she have answered “yes” on more than 3 out of 6 questions (Ronnberg et al. 2007).|$|R
