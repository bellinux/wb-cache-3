10000|10000|Public
5|$|The {{affinity}} of an antagonist for its {{binding site}} (Ki), i.e. {{its ability to}} bind to a receptor, will determine the duration of inhibition of agonist activity. The affinity of an antagonist can be determined experimentally using Schild <b>regression</b> or for competitive antagonists in radioligand binding studies using the Cheng-Prusoff equation. Schild <b>regression</b> {{can be used to}} determine the nature of antagonism as beginning either competitive or non-competitive and Ki determination is independent of the affinity, efficacy or concentration of the agonist used. However, it is important that equilibrium has been reached. The effects of receptor desensitization on reaching equilibrium must also be taken into account. The affinity constant of antagonists exhibiting two or more effects, such as in competitive neuromuscular-blocking agents that also block ion channels as well as antagonising agonist binding, cannot be analyzed using Schild <b>regression.</b> Schild <b>regression</b> involves comparing the change in the dose ratio, the ratio of the EC50 of an agonist alone compared to the EC50 {{in the presence of a}} competitive antagonist as determined on a dose response curve. Altering the amount of antagonist used in the assay can alter the dose ratio. In Schild <b>regression,</b> a plot is made of the log (dose ratio-1) versus the log concentration of antagonist for a range of antagonist concentrations. The affinity or Ki is where the line cuts the x-axis on the <b>regression</b> plot. Whereas, with Schild <b>regression,</b> antagonist concentration is varied in experiments used to derive Ki values from the Cheng-Prusoff equation, agonist concentrations are varied. Affinity for competitive agonists and antagonists is related by the Cheng-Prusoff factor used to calculate the Ki (affinity constant for an antagonist) from the shift in IC50 that occurs during competitive inhibition. The Cheng-Prusoff factor takes into account the effect of altering agonist concentration and agonist affinity for the receptor on inhibition produced by competitive antagonists.|$|E
5|$|In {{especially}} {{severe cases}} of OFC, parathyroidectomy, or the full {{removal of the}} parathyroid glands, is the chosen route of treatment. Parathyroidectomy {{has been shown to}} result in the reversal of bone resorption and the complete <b>regression</b> of brown tumors. In situations where parathyroid carcinoma is present, surgery to remove the tumors has also led to the <b>regression</b> of hyperparathyroidism as well as the symptoms of OFC.|$|E
25|$|Multinomial {{logistic}} <b>regression</b> and multinomial probit <b>regression</b> for categorical data.|$|E
40|$|This paper derives Lagrange {{multiplier}} tests {{based on}} double-length artificial <b>regressions</b> for testing linear and loglinear error component <b>regressions</b> against Box-Cox alternatives. These tests {{are easy to}} implement and should prove useful in panel data <b>regressions.</b> Lagrange multiplier Double-length <b>regressions</b> Error components Box-Cox transformation...|$|R
5000|$|<b>Regressions</b> with {{discrete}} dependent variables, such as logistic <b>regressions.</b>|$|R
3000|$|Comparing the {{coefficients}} of determination, {{it is observed}} that PO <b>regressions</b> fit well to high frequency data than NB based <b>regressions</b> do. However, comparing of BIC values, we can conclude that the NB based <b>regressions</b> are superior to the PO <b>regressions.</b> Also we can see that the exogenous variables about the solar activities and the magnetospheres improved each GARX model. The improvement of R [...]...|$|R
25|$|Logistic <b>regression</b> and probit <b>regression</b> for binary data.|$|E
25|$|For {{determination}} of soil respiration and {{the slope of}} CO2 increase, researchers have used linear <b>regression</b> analysis, the Pedersen (2001) algorithm, and exponential <b>regression.</b> There are more published references for linear <b>regression</b> analysis; however, the Pedersen algorithm and exponential <b>regression</b> analysis methods also have their following. Some systems offer a choice of mathematical methods.|$|E
25|$|In applied statistics, total {{least squares}} {{is a type}} of errors-in-variables <b>regression,</b> a least squares data {{modeling}} technique in which observational errors on both dependent and independent variables are taken into account. It is a generalization of Deming <b>regression</b> and also of orthogonal <b>regression,</b> and can be applied to both linear and non-linear models.|$|E
30|$|Linear Ordinary Least Squares <b>regressions</b> {{were used}} and {{standard}} errors were adjusted for clustering {{at the country}} level (in European <b>regressions).</b> Switching to Ordered Logit/Probit <b>regressions</b> {{did not lead to}} substantial changes. Population and survey design weights were also taken into account.|$|R
30|$|In Table  2, {{there are}} four <b>regressions</b> {{for each of the}} full sample of cities (Panel A), as well as the large-city-only sample (Panel B) {{providing}} a total of eight <b>regressions</b> in this table. The first two <b>regressions</b> in each panel have neither individual nor area-level characteristics—other than year, region (and average income in Table  2)—while the third and fourth <b>regressions</b> progressively add in the full set of individual and area-level control characteristics. The exception being the immigrant location selection correction (average volunteering in 1989) and measures of income inequality, which are instead included in <b>regressions</b> used for Tables  3, 4, 5 and the appendices.|$|R
30|$|All <b>regressions</b> {{used the}} ratio of average to median income as the {{relevant}} measure of inequality. <b>Regressions</b> using other inequality measures provided similar results.|$|R
25|$|A {{method to}} {{compensate}} for both sources of inaccuracy above is to establish the relative risks by multivariate <b>regression</b> analysis. However, to retain its validity, relative risks established as such must be multiplied {{with all the other}} risk factors in the same <b>regression</b> analysis, and without any addition of other factors beyond the <b>regression</b> analysis.|$|E
25|$|Least-angle <b>regression</b> is an {{estimation}} {{procedure for}} linear <b>regression</b> models {{that was developed}} to handle high-dimensional covariate vectors, potentially with more covariates than observations.|$|E
25|$|R2 is a {{statistic}} {{that will give}} some information about the goodness of fit of a model. In <b>regression,</b> the R2 coefficient of determination is {{a statistic}}al measure of how well the <b>regression</b> line approximates the real data points. An R2 of 1 indicates that the <b>regression</b> line perfectly fits the data.|$|E
40|$|Depending on four controlable {{variables}} used in broilers nutrition: E (energy), P (protein), L(lysine), M (metyonine+ cystine) {{have been}} deduced mathematically multiple curvilinear <b>regressions</b> showing {{the evolution of}} corporal mass during entire growth period. In this paper, using these <b>regressions,</b> we determine the average weekly gain of corporal mass. We test using dispersional analysis if there are significant differences between N. R. C. 1994 and the values given by <b>regressions.</b> Using correlation report we decide which of these <b>regressions</b> is optimum...|$|R
40|$|The paper {{discusses}} {{the issues of}} heterogeneity and stability of cross-country growth <b>regressions</b> {{that have been used}} to study the problem of convergence. Almost all studies use pooled <b>regressions.</b> The paper considers the issue of pooling under heterogeneity using a hierarchical Bayesian method and estimates growth <b>regressions</b> for different panels studied in earlier papers, and different regimes. The conclusion is that the convergence rates are higher than those obtained from pooled <b>regressions</b> under the assumption of homogeneity and that there is instability over time in the relationships. ...|$|R
40|$|We propose {{tests for}} {{structural}} change in conditional distributions via quantile <b>regressions.</b> To avoid misspecification on the conditioning relationship, we construct the tests {{based on the}} residuals from local polynomial quantile <b>regressions.</b> In particular, the tests are based upon the cumulative sums of generalized residuals from quantile <b>regressions</b> and have power against local alternatives at rat...|$|R
25|$|In statistics, linear {{least squares}} {{problems}} correspond to a particularly important type of statistical model called linear <b>regression</b> which arises as a {{particular form of}} <b>regression</b> analysis. One basic form of such a model is an ordinary least squares model. The present article concentrates on the mathematical aspects of linear least squares problems, with discussion of the formulation and interpretation of statistical <b>regression</b> models and statistical inferences related to these being {{dealt with in the}} articles just mentioned. See outline of <b>regression</b> analysis for an outline of the topic.|$|E
25|$|Poisson <b>regression</b> and {{negative}} binomial <b>regression</b> {{are useful for}} analyses where the dependent (response) variable is the count (0,1,2,…) {{of the number of}} events or occurrences in an interval.|$|E
25|$|As {{an attempt}} to correct some of the error due to a non-zero , the usage of local linear {{weighted}} <b>regression</b> with ABC to reduce the variance of the posterior estimates has been suggested. The method assigns weights to the parameters according to how well simulated summaries adhere to the observed ones and performs linear <b>regression</b> between the summaries and the weighted parameters {{in the vicinity of}} observed summaries. The obtained <b>regression</b> coefficients are used to correct sampled parameters in the direction of observed summaries. An improvement was suggested in the form of nonlinear <b>regression</b> using a feed-forward neural network model. However, {{it has been shown that}} the posterior distributions obtained with these approaches are not always consistent with the prior distribution, which did lead to a reformulation of the <b>regression</b> adjustment that respects the prior distribution.|$|E
40|$|FIGURE 3. ShHt versus ShWd (shape) <b>regressions</b> among {{collection}} localities {{within and}} between H. walkeriana and H. morroensis. <b>Regressions</b> for H. morroensis homogeneous among all four localities. Adjusted ShHt for MBSS and LO 1 sites (15. 1 mm) significantly greater than adjusted ShHt for Elfin, MSSB, and LO 2 sites (14. 5 mm). See text for discussion of common <b>regressions...</b>|$|R
40|$|Epipodophyllotoxin (VM 26; 4 ′-demethyl-epipodophyllotoxin-β-D-thenylidene glucoside) {{has been}} proved, in {{clinical}} screening, {{to be able}} to induce apparently complete remissions and pronounced though incomplete <b>regressions</b> in Hodgkin's disease, reticulosarcoma, and bladder cancer, as well as incomplete <b>regressions</b> in lymphosarcoma. Apparently complete <b>regressions</b> of malignant pleural effusions have been obtained after giving this drug systemically. It has a notable toxic action on the bone marrow...|$|R
50|$|Usually also, <b>regressions</b> {{are made}} at the aggregate/zone level. Variability among {{households}} within a zone isn’t measured when data are aggregated. High correlation coefficients are found when <b>regressions</b> are run on aggregate data, say, about 0.90, but lower coefficients, say, about 0.25, are found when <b>regressions</b> are made on observation units such as households. In short, there is much variability that is hidden by aggregation.|$|R
25|$|Sometimes {{one of the}} regressors can be a {{non-linear}} {{function of}} another regressor or of the data, as in polynomial <b>regression</b> and segmented <b>regression.</b> The model remains linear {{as long as it}} is linear in the parameter vector β.|$|E
25|$|The {{liquidus}} temperature has been modeled by non-linear <b>regression</b> using neural networks and disconnected peak functions. The disconnected peak functions approach {{is based on}} the observation that within one primary crystalline phase field linear <b>regression</b> can be applied and at eutectic points sudden changes occur.|$|E
25|$|Early {{evidence}} relating tobacco smoking to {{mortality and}} morbidity came from observational studies employing <b>regression</b> analysis. In {{order to reduce}} spurious correlations when analyzing observational data, researchers usually include several variables in their <b>regression</b> models {{in addition to the}} variable of primary interest. For example, suppose we have a <b>regression</b> model in which cigarette smoking is the independent variable of interest, and the dependent variable is lifespan measured in years. Researchers might include socio-economic status as an additional independent variable, to ensure that any observed effect of smoking on lifespan is not due to some effect of education or income. However, it is never possible to include all possible confounding variables in an empirical analysis. For example, a hypothetical gene might increase mortality and also cause people to smoke more. For this reason, randomized controlled trials are often able to generate more compelling evidence of causal relationships than can be obtained using <b>regression</b> analyses of observational data. When controlled experiments are not feasible, variants of <b>regression</b> analysis such as instrumental variables <b>regression</b> may be used to attempt to estimate causal relationships from observational data.|$|E
40|$|Spurious <b>regressions,</b> i. e. <b>regressions</b> {{in which}} an {{integrated}} process is regressed on another integrated process {{while there is no}} cointegration, are well understood in contemporary time series econometrics. In this paper, I investigate the properties of <b>regressions</b> in which the logarithm of an integrated process is regressed on the logarithm of another integrated process. It is shown that, exactly as in spurious <b>regressions,</b> in this setup too, the estimated slope coefficient is asymptotically random and the t-value for the slope coefficient is of a stochastic order equal to the square root of sample size. Therefore...|$|R
30|$|Following the {{literature}} on earnings <b>regressions,</b> we also estimated the <b>regressions</b> and decompositions without the industry and occupation controls. The results are qualitatively the same and {{are available from the}} authors on request.|$|R
40|$|In {{this article}} I {{describe}} {{the evolution of}} the use of cross-country growth <b>regressions</b> in economics over the last two decades. The rise of cross-country growth <b>regressions</b> was {{an important component of the}} sea change in economic research associated with the new growth economics. By their fall, I do not mean to suggest that such <b>regressions</b> are no longer used; the opposite is very much the case. Rather, the word fall concerns how these <b>regressions</b> have been interpreted in the context of growth theories. Cer-tain forms of these <b>regressions</b> enjoyed a period in which they were taken as the statistical analogs of the law of motion implied by the neoclassical growth model in general and the Solow growth model in particular. 1 Since Robert Solow’s original model is most commonly used to justify both the linear structure of cross-country <b>regressions</b> and the forms in which cer-tain core variables appear, it will be my primary focus; Mankiw, Romer, and Weil 1992 continues to be the standard derivation of cross-countr...|$|R
25|$|An {{advantage}} of this method {{is that it is}} fast (5–20 minutes per sample); a disadvantage is that the solute's chemical structure must be known beforehand. Moreover, since the value of log P is determined by linear <b>regression,</b> several compounds with similar structures must have known log P values, and extrapolation from one chemical class to another—applying a <b>regression</b> equation derived from one chemical class to a second one—may not be reliable, since each chemical classes will have its characteristic <b>regression</b> parameters.|$|E
25|$|Ordered probit <b>regression</b> for ordinal data.|$|E
25|$|Poisson <b>regression</b> for count data.|$|E
40|$|In five {{experiments}} {{new methods}} of computer-supported reading were introduced and tested. Self-pacing was permitted in rapid serial visual presentation (RSVP), in which words are presented sequentially at a fixed locus. In Experiments 2 through 5 <b>regressions</b> were also allowed in RSVP. Larger <b>regressions</b> yielded slower reading. <b>Regressions</b> back to the begin-ning of the sentence were more frequent than <b>regressions</b> back two words. There {{was no difference in}} reading speed or comprehension caused by the nature, analogue (mouse), or digital (keystroke) of the control over reading speed, but there was a greater tendency to change speed in the analogue condition than in the digital condition. In Experiment 5 sub-jects read for over two hours in an RSVP condition with self-pacing and <b>regressions</b> or in a normal page condition: subjective reports of discomfort were not different in the two condi-tions, but reading speed in the RSVP condition was approximately half that in the page condition. Overall these results indicate that permitting reader control in RSVP is feasible but that permitting <b>regressions</b> sometimes results in slow reading...|$|R
40|$|A new {{procedure}} for statistical inference in cointegrating <b>regressions</b> is developed. The author introduces canonical cointegrating <b>regressions</b> (<b>regressions</b> formulated with the transformed data). The required transformations involve simple adjustments of the integrated processes using stationary components in cointegrating models. Canonical cointegrating <b>regressions,</b> therefore, represent the same cointegrating relationships {{as the original}} models. They are, however, constructed {{in such a way}} that the usual least squares procedure yields asymptotically efficient estimators and chi-square tests. The methodology presented here is applicable to a very wide class of cointegrating models, including models with deterministic and singular, as well as stochastic and regular, cointegrations. Copyright 1992 by The Econometric Society. ...|$|R
30|$|In this section, {{the author}} models {{different}} types of interdependence between the stock markets and the government bond markets during the crisis period using Formula (2). The F-statistics of the 39 <b>regressions</b> are significant in the 10 % confidential interval. Therefore, {{there is no significant}} auto-correlation in the error series of these <b>regressions.</b> In addition, {{it should be noted that}} VIF factors are smaller than 10 in most of the 39 <b>regressions,</b> except the models for Mexico, Russia and Turkey, because the financial markets are less efficient in these three emerging countries. For most countries, however, the estimations in the <b>regressions</b> are remarkable and reliable.|$|R
