36|319|Public
25|$|CompuServe {{introduced}} GIF on June 15, 1987 {{to provide}} a color image format for their file downloading areas, replacing their earlier <b>run-length</b> <b>encoding</b> (<b>RLE)</b> format, which was black and white only. GIF became popular because it used LZW data compression, which was more efficient than the run-length encoding that formats such as PCX and MacPaint used, and fairly large images could therefore be downloaded in a reasonably short time, even with very slow modems.|$|E
2500|$|Entropy coding is {{a special}} form of {{lossless}} data compression. It involves arranging the image components in a [...] "zigzag" [...] order employing <b>run-length</b> <b>encoding</b> (<b>RLE)</b> algorithm that groups similar frequencies together, inserting length coding zeros, and then using Huffman coding on what is left.|$|E
5000|$|<b>Run-length</b> <b>encoding</b> (<b>RLE)</b> - Simple {{scheme that}} {{provides}} good compression of data containing lots of runs {{of the same}} value ...|$|E
50|$|Silicon Graphics Image (SGI) or the RGB {{file format}} is the native raster {{graphics}} file format for Silicon Graphics workstations. The format {{was invented by}} Paul Haeberli. It can be <b>run-length</b> <b>encoded</b> (<b>RLE).</b> Among others FFmpeg and ImageMagick support this format.|$|R
40|$|A new {{systolic}} algorithm which computes image {{differences in}} <b>run-length</b> <b>encoded</b> (<b>RLE)</b> format is described. The binary image difference operation {{is commonly used}} in many image processing applications including automated inspection systems, character recognition, fingerprint analysis, and motion detection. The efficiency of these operations can be improved significantly with {{the availability of a}} fast systolic system that computes the image difference as described in this paper. It is shown that for images with a high similarity measure, the time complexity of the systolic algorithm is small and in some cases constant with respect to the image size. The time for the systolic algorithm is proportional to the difference between the number of runs in the two images, while the time for the sequential algorithm is proportional to the total number of runs in the two images together. A formal proof of correctness for the algorithm is also given. 1...|$|R
40|$|Abstract — In the {{constrained}} longest common subsequence (CLCS) problem, we {{are given}} two sequences X, Y and the constrained sequence P in <b>run-length</b> <b>encoded</b> (<b>RLE)</b> format, where |X | = n, |Y | = m and |P | = r and the numbers of runs in RLE format are N, M and R, respectively. In this paper, we show that after the sequences are encoded, the CLCS problem can be solved in O(NMr+ r × min{q 1, q 2 } + q 3) time, where q 1 and q 2 denote the numbers of elements in the bottom and right boundaries of the partially matched blocks on the first layer, and q 3 denotes the number of elements of whole boundaries of all fully matched cuboids in the DP lattice. If the compression ratio is good, our work obviously outperforms the previously known DP algorithm and the Hunt-and-Szymanski-like algorithm. 1...|$|R
5000|$|With a <b>run-length</b> <b>encoding</b> (<b>RLE)</b> data {{compression}} algorithm {{applied to the}} above hypothetical scan line, it can be rendered as follows: ...|$|E
5000|$|Entropy coding is {{a special}} form of {{lossless}} data compression. It involves arranging the image components in a [...] "zigzag" [...] order employing <b>run-length</b> <b>encoding</b> (<b>RLE)</b> algorithm that groups similar frequencies together, inserting length coding zeros, and then using Huffman coding on what is left.|$|E
5000|$|<b>Run-length</b> <b>encoding</b> (<b>RLE)</b> is a {{very simple}} method of {{compressing}} repetition. A sequential string of characters, no matter how long, can be replaced with a few bytes, noting the value that repeats, and how many times. For example, if someone were to say [...] "five nines", you would know they mean the number: 99999.|$|E
40|$|This paper {{presents}} innovative algorithms to efficiently compute erosions and dilations of <b>run-length</b> <b>encoded</b> (<b>RLE)</b> binary {{images with}} arbitrary shaped structuring elements. An RLE image {{is given by}} a set of runs, where a run is a horizontal concatenation of foreground pixels. The proposed algorithms extract the skeleton of the structuring element and build distance tables of the input image, which are storing the distance to the next background pixel on the left and right hand sides. This information is then used to speed up the calculations of the erosion and dilation operator by enabling the use of techniques which allow to skip the analysis of certain pixels whenever a hit or miss occurs. Additionally the input image gets trimmed during the preprocessing steps on the base of two primitive criteria. Experimental results show the advantages over other algorithms. The source code of our algorithms is available in C++. Comment: 17 pages, 2 figures. Submitted to Elsevier (Pattern Recognition). For the associated source code, see [URL]...|$|R
40|$|AbstractThe {{constrained}} LCS (CLCS) problem, {{a recent}} {{variant of the}} longest common subsequence (LCS) problem, has gained much attention. Given two sequences X and Y of lengths n and m, respectively, and the constrained sequence P of length r, previous {{research shows that the}} CLCS problem can be solved by either an O(nmr) -time algorithm based upon dynamic programming (DP) techniques or an O(rRloglog(n+m)) -time Hunt–Szymanski-like algorithm, where R is the total number of ordered pairs of positions at which the two strings match. In this paper, we investigate the case that X, Y and P are all in <b>run-length</b> <b>encoded</b> (<b>RLE)</b> format, where the numbers of runs are N, M and R, respectively. We first show that when the sequences are encoded, the CLCS problem can be solved by a simple algorithm in O(nmR+nMr+Nmr) time without decompressing the sequences. Then, we propose a more efficient algorithm with O(NMr+r×min{q 1,q 2 }+q 3) time, where q 1 and q 2 denote the numbers of elements in the south and east faces of the matched blocks on the first layer, respectively, and q 3 denotes the number of face elements of all fully matched cuboids in the DP lattice...|$|R
5000|$|The older {{version of}} the TGA file format {{specification}} taken from the Appendix C of the Truevision Technical Guide states that <b>run-length</b> <b>encoded</b> (<b>RLE)</b> packets may cross scan lines: [...] "For the run length packet, the header {{is followed by a}} single color value, which is assumed to be repeated the number of times specified in the header. The packet may cross scan lines (begin on one line and end on the next)".However, page 24 of the TGA v2.0 specification states the exact opposite: [...] "Run-length Packets should never encode pixels from more than one scan line. Even if the end of one scan line {{and the beginning of the}} next contain pixels of the same value, the two should be encoded as separate packets. In other words, Run-length Packets should not wrap from one line to another".Consequently TGA readers need to be able to handle RLE data packets that cross scan lines since this was part of the original specification. However, when saving (creating) TGA files it will be necessary to limit RLE data packets to scanline boundaries in order to be compliant with the newer v2.0 TGA specification.|$|R
5000|$|This process uses {{large amounts}} of memory, since it should take [...] (where [...] {{is the number of}} polygons) bits (only visible/hidden {{information}} is needed). John Carmack realized that one area sees just {{a small fraction of the}} other areas, so he compressed this information by using <b>run-length</b> <b>encoding</b> (<b>RLE).</b> This is what allowed Quakes complex geometry to be rendered so quickly on the hardware of the time.|$|E
5000|$|PCX {{image data}} are {{compressed}} using <b>run-length</b> <b>encoding</b> (<b>RLE),</b> a simple lossless compression algorithm that collapses {{a series of}} three or more consecutive bytes with identical values into a two-byte pair. The two most-significant bits of a byte are used to determine whether the given data represent a single pixel of a given palette index or color value, or an RLE pair representing a series of several pixels of a single value: ...|$|E
50|$|CompuServe {{introduced}} the GIF format on June 15, 1987 {{to provide a}} color image format for their file downloading areas, replacing their earlier <b>run-length</b> <b>encoding</b> (<b>RLE)</b> format, which was black and white only. GIF became popular because it used LZW data compression, which was more efficient than the run-length encoding that formats such as PCX and MacPaint used, and fairly large images could therefore be downloaded in a reasonably short time, even with very slow modems.|$|E
40|$|AbstractThe present paper {{introduces}} a new communication and load-balancing {{scheme based on}} a clustering of the grid which we use for the efficient parallelization of simulations on dynamically adaptive grids. With a partitioning based on space-filling curves (SFCs), this yields several advantageous properties regarding the memory requirements and load balancing. However, for such an SFC- based partitioning, additional connectivity information has to be stored and updated for dynamically changing grids. In this work, we present our approach to keep this connectivity information <b>run-length</b> <b>encoded</b> (<b>RLE)</b> only for the interfaces shared between partitions. Using special properties of the underlying grid traversal and used communication scheme, we update this connectivity information implicitly for dynamically changing grids and can represent the connectivity information as a sparse communication graph: graph nodes (partitions) represent bulks of connected grid cells and each graph edge (RLE connectivity information) a unique relation between adjacent partitions. This directly leads to an efficient shared-memory parallelization with graph nodes assigned to computing cores and an efficient en bloc data exchange via graph edges. We further refer to such a partitioning approach with RLE meta information as a cluster-based domain decomposition and to each partition as a cluster. With the sparse communication graph in mind, we then extend the connectivity information represented by the graph edges with MPI ranks, yielding an en bloc communication for distributed-memory systems and a hybrid parallelization. For data migration, the stack-based intra-cluster communication allows a very low memory footprint for data migration and the RLE leads to efficient updates of connectivity information. Our benchmark {{is based on a}} shallow water simulation on a dynamically adaptive grid. We conducted performance studies for MPI-only and hybrid parallelizations, yielding an efficiency of over 90 % on 256 cores. Furthermore, we demonstrate the applicability of cluster-based optimizations on distributed-memory systems...|$|R
40|$|This paper {{presents}} a new compression technique based on <b>Run-Length</b> <b>Encoding</b> scheme (<b>RLE).</b> The technique is semi-lossless and utilizes pixel value rather than bit value. The encoding process starts by mapping {{the colors of}} an image to a vector where each value of the vector is decimal ranging from 0 to 255. To maximize {{the efficiency of the}} decimal RLE, the 4 LSB of each of the values will be reset and utilized for compression purposes. Then, the RLE is applied on the result vector to obtain a new vector of pairs on the form, where each item consists of 8 bits. The frequency of occurrences is stored in the 4 LSB of the color value so as to reduce the total size of the image. The decoding process reverses the encoding process steps to obtain the original image. The experimental results showed that the technique has achieved high compression ratio using different images with multi-features...|$|R
40|$|<b>Run-length</b> <b>encoding</b> is {{a scheme}} {{which has been}} used to remove {{redundancy}} from video signals. Based upon a first-order Markov model of video data, an upper bound on compression ratio is found for <b>run-length</b> <b>encoding.</b> It is shown that at best <b>run-length</b> <b>encoding</b> will give a compression ratio which is approximately 60 % of the maximum attainable value. This percentage is fairly independent of the particular picture involved...|$|R
50|$|<b>Run-length</b> <b>encoding</b> (<b>RLE)</b> is a {{very simple}} form of {{lossless}} data compression in which runs of data (that is, sequences in which the same data value occurs in many consecutive data elements) are stored as a single data value and count, rather than as the original run. This is most useful on data that contains many such runs. Consider, for example, simple graphic images such as icons, line drawings, and animations. It is not useful with files that don't have many runs as it could greatly increase the file size.|$|E
5000|$|The <b>run-length</b> <b>encoding</b> (<b>RLE)</b> level set method, {{introduced}} in 2004, applies the RLE scheme to compress regions {{away from the}} narrow band to just their sign representation while storing with full precision the narrow band. The sequential traversal of the narrow band is optimal and storage efficiency is further improved over the octree level set. The addition of an acceleration lookup table allows for fast [...] random access, where r {{is the number of}} runs per cross section. Additional efficiency is gained by applying the RLE scheme in a dimensional recursive fashion, a technique introduced by Nielsen & Museth's similar DT-Grid.|$|E
5000|$|A DICOM {{data object}} {{consists}} {{of a number of}} attributes, including items such as name, ID, etc., and also one special attribute containing the image pixel data (i.e. logically, the main object has no [...] "header" [...] as such, being merely a list of attributes, including the pixel data). A single DICOM object can have only one attribute containing pixel data. For many modalities, this corresponds to a single image. However, the attribute may contain multiple [...] "frames", allowing storage of cine loops or other multi-frame data. Another example is NM data, where an NM image, by definition, is a multi-dimensional multi-frame image. In these cases, three- or four-dimensional data can be encapsulated in a single DICOM object. Pixel data can be compressed using a variety of standards, including JPEG, lossless JPEG, JPEG 2000, and <b>run-length</b> <b>encoding</b> (<b>RLE).</b> LZW (zip) compression can be used for the whole data set (not just the pixel data), but this has rarely been implemented.|$|E
40|$|We {{consider}} {{the problem of}} computing all maximal repetitions contained in a string that is given in <b>run-length</b> <b>encoding.</b> Given a <b>run-length</b> <b>encoding</b> of a string, we show that {{the maximum number of}} maximal repetitions contained in the string is at most m+k- 1, where m is the size of the <b>run-length</b> <b>encoding,</b> and k is the number of run-length factors whose exponent is at least 2. We also show an algorithm for computing all maximal repetitions in O(m alpha(m)) time and O(m) space, where alpha denotes the inverse Ackermann function...|$|R
5000|$|<b>Run-length</b> <b>encoding</b> data {{compression}} on a block by block basis ...|$|R
5000|$|IMG (Graphics Environment Manager (GEM) image file; planar, <b>run-length</b> <b>encoded)</b> ...|$|R
40|$|The option COMPRESS=YES|CHAR is {{effective}} with character data that contains repeated characters such as blanks. It uses the <b>run-length</b> <b>encoding</b> (<b>RLE)</b> compression algorithm, which compresses repeating consecutive bytes such as trailing blanks or repeated zeroes. options fullstimer; PROC IMPORT OUT= WORK. charcompress(compress=yes...|$|E
30|$|We can quote {{also the}} use of run time of {{different}} filters according to {{the texture of the}} processed image (here it is the type of processing which is variable). Another example of the dynamic applications is video encoding where the <b>run-length</b> <b>encoding</b> (<b>RLE)</b> of frames depends on the information within frames.|$|E
40|$|Bitmap indexes must be {{compressed}} {{to reduce}} input/output costs and minimize CPU usage. To accelerate logical operations (AND, OR, XOR) over bitmaps, we use techniques based on <b>run-length</b> <b>encoding</b> (<b>RLE),</b> such as Word-Aligned Hybrid (WAH) compression. These techniques {{are sensitive to}} the order of the rows: a simple lexicographical sort can divide the index size by 9 and make indexes several times faster. We investigate reordering heuristics based on computed attribute-value histograms. Simply permuting the columns of the table based on these histograms can increase the sorting efficiency by 40 %. Comment: To appear in proceedings of DOLAP 200...|$|E
2500|$|GNU plotutils (supports pseudo-GIF, {{which uses}} <b>run-length</b> <b>encoding</b> rather than LZW) ...|$|R
5000|$|GNU plotutils (supports pseudo-gif format {{which uses}} <b>run-length</b> <b>encoding</b> rather than LZW) ...|$|R
5000|$|Compressed mode: Data is {{compressed}} using {{a simple}} algorithm (usually <b>run-length</b> <b>encoding).</b>|$|R
40|$|We {{consider}} quantization {{of signals}} in probabilistic framework. In prac-tice, signals (or random processes) are observed at sampling points. We study probabilistic models for <b>run-length</b> <b>encoding</b> (<b>RLE)</b> method. This method {{is characterized by}} the compression efficiency coefficient (or quan-tization rate) and is widely used, for example, in digital signal and image compression. Some properties of RLE quantization rate are investigated. Statistical inference for mean RLE quantization rate is considered. In particular, the asymptotical normality of mean RLE quantization rate es-timates is studied. Numerical experiments demonstrating the rate of con-vergence in the obtained asymptotical results are presented...|$|E
40|$|Bitmap indexes are {{commonly}} used in databases and search engines. By exploiting bit-level parallelism, they can significantly accelerate queries. However, they can use much memory, and thus we might prefer compressed bitmap indexes. Following Oracle's lead, bitmaps are often compressed using <b>run-length</b> <b>encoding</b> (<b>RLE).</b> Building on prior work, we introduce the Roaring compressed bitmap format: it uses packed arrays for compression instead of RLE. We compare it to two high-performance RLE-based bitmap encoding techniques: WAH (Word Aligned Hybrid compression scheme) and Concise (Compressed `n' Composable Integer Set). On synthetic and real data, we find that Roaring bitmaps (1) often compress significantly better (e. g., 2 times) and (2) are faster than the compressed alternatives (up to 900 times faster for intersections). Our results challenge the view that RLE-based bitmap compression is best...|$|E
40|$|Bitmap indexes must be {{compressed}} {{to reduce}} input/output costs and minimize CPU usage. To accelerate logical operations (AND, OR, XOR) over bitmaps, we use techniques based on <b>run-length</b> <b>encoding</b> (<b>RLE),</b> such as Word-Aligned Hybrid (WAH) compression. These techniques {{are sensitive to}} the order of the rows: a simple lexicographical sort can divide the index size by 9 and make indexes several times faster. We investigate row-reordering heuristics. Simply permuting the columns of the table can increase the sorting efficiency by 40 %. Secondary contributions include efficient algorithms to construct and aggregate bitmaps. The effect of word length is also reviewed by constructing 16 -bit, 32 -bit and 64 -bit indexes. Using 64 -bit CPUs, we find that 64 -bit indexes are slightly faster than 32 -bit indexes despite being nearly twice as large. Key words...|$|E
50|$|PackBits is a fast, simple {{lossless}} compression scheme for <b>run-length</b> <b>encoding</b> of data.|$|R
50|$|The {{idea of the}} look-and-say {{sequence}} {{is similar to that}} of <b>run-length</b> <b>encoding.</b>|$|R
5000|$|... pseudo-GIF (using <b>run-length</b> <b>encoding</b> {{rather than}} LZW {{to avoid the}} past patent issue) ...|$|R
