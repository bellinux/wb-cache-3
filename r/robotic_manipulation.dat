417|136|Public
5000|$|Matthew T. Mason, Mechanics of <b>Robotic</b> <b>Manipulation,</b> MIT Press: Cambridge, MA. 2001.|$|E
5000|$|Jeff Trinkle (Class of 1979): Professor and Chair of Computer Science at Rensselaer Polytechnic Institute; {{known for}} his work in <b>robotic</b> <b>manipulation,</b> multibody dynamics, and {{automated}} manufacturing.|$|E
5000|$|In The Big Bang Theory, Sheldon wisecracks in {{response}} to Pennys awe over Wolowitzs mechanical robot arm, [...] "At best, it’s a modest leap forward from the basic technology that gave us Country Bear Jamboree" [...] (Series 4 Episode 01 - The <b>Robotic</b> <b>Manipulation).</b>|$|E
40|$|To allow wide-spread {{adoption}} of consumer robotics, robots {{must be able}} to adapt to theirenvironment by learning new skills and communicating with humans. Each chapter explains acontribution to achieve this goal. Chapter One covers a stochastic And-Or knowledgerepresentation framework for <b>robotic</b> <b>manipulations.</b> Chapter Two further expands thisestablished system for robustly learning from perception. Chapter Three unifies perception withnatural language for a joint real-time processing of information. We've successfully tested thegeneralizability and faithfulness of our robotic knowledge acquisition and inference pipeline. Wepresent proof of concepts {{in each of the three}} chapters...|$|R
50|$|Danica Kragic {{from the}} Royal Institute of Technology (KTH), Stockholm, Sweden was named Fellow of the Institute of Electrical and Electronics Engineers (IEEE) in 2016 for {{contributions}} to vision-based systems and <b>robotic</b> object <b>manipulation.</b>|$|R
40|$|Hogan {{recently}} {{provided an}} heuristic technique called family of modes (FOM) to solve model predictive control (MPC) problems under hybrid constraints and underactuation. The {{goal of this}} study is to further develop this new method and to expand its usage in the <b>robotics</b> <b>manipulation</b> community. With that objective in mind, we address some of the method's weaknesses, we provide comparison tools to try to compare the method with traditional MPC solving techniques and we provide a simple and systematic technique to set-up the method's parameters. We conclude the study by presenting our the future lines of research, which consist in generalizing the method for more complex systems and testing it's robustness...|$|R
50|$|Matthew Thomas Mason (born August 24, 1952 in Oklahoma City, Oklahoma) is an American roboticist and the Director of the Robotics Institute at Carnegie Mellon University. Mason is a {{researcher}} {{in the area}} of <b>robotic</b> <b>manipulation,</b> {{and is the author of}} two highly cited textbooks in the field.|$|E
50|$|According to the university's project page, {{some of the}} {{objectives}} of the Kanguera project are to develop strategies for dexterous <b>robotic</b> <b>manipulation</b> and to create new designs for robotic hands which are biologically inspired. These new designs and strategies will be used for user friendly human machine interface and for upper limb rehabilitation technologies.|$|E
5000|$|BTs {{originates}} {{from the}} computer game industry as a powerful tool to model the behavior of non-player characters (NPCs).They have been extensively used in high-profile video games such as Halo, Bioshock, and Spore. Recent works propose BTs as a multi-mission control framework for UAV, complex robots, <b>robotic</b> <b>manipulation,</b> and multi-robot systems.BT have now reached the maturity to be treated in Game AI textbooks ...|$|E
40|$|The Constraint Satisfaction Problem (CSP) {{has been}} a useful model for various {{industrial}} and engineering applications. These include image processing and pattern recognition, VLSI engineering, <b>robotics</b> <b>manipulation,</b> and computer hardware design automation. In this paper, we give a novel AI architecture for discrete relaxation that effectively prunes a backtracking search tree in CSP. This algorithm has been implemented on a finegrained, massively parallel hardware computer architecture. For practical application problems, many orders of magnitude of efficiency improvement can be reached on this hardware architecture. This enables real-time processing of a large class of practical problems. Keywords: Artificial Intelligence, backtrack search, constraint satisfaction problem (CSP), Discrete Relaxation Algorithm (DRA), AI architectures. 1 Introduction Constraint-based search problems have three components: variables, values, and constraints. The goal is to find an assignment of values to [...] ...|$|R
40|$|This paper evaluates {{state-of-the-art}} contact models at {{predicting the}} motions and forces involved in simple in-hand <b>robotic</b> <b>manipulations.</b> In particular {{it focuses on}} three primitive actions [...] linear sliding, pivoting, and rolling [...] that involve contacts between a gripper, a rigid object, and their environment. The evaluation is done through thousands of controlled experiments designed to capture the motion of object and gripper, and all contact forces and torques at 250 Hz. We demonstrate that a contact modeling approach based on Coulomb's friction law and maximum energy principle is effective at reasoning about interaction to first order, but limited for making accurate predictions. We attribute the major limitations to 1) the non-uniqueness of force resolution inherent to grasps with multiple hard contacts of complex geometries, 2) unmodeled dynamics due to contact compliance, and 3) unmodeled geometries dueto manufacturing defects. Comment: International Symposium on Experimental Robotics, ISER 2016, Tokyo, Japa...|$|R
40|$|This book aims at {{reporting}} some of {{the most}} challenging open problems of control theoretic nature raised by robotics applications. Topics covered in the book represent many of the most innovative areas in contemporary robotics research, with special emphasis on vision, sensory-feedback control, human-centered <b>robotics,</b> <b>manipulation,</b> planning, flexible and cooperative robots, or assembly systems. The basic idea behind the book is to present the variety of innovative applications and related technology demands that arise from robotics and automation to a larger community, including in particular, researchers in automatic control, applied mathematics, mechanical engineering, or computer science. The book is intended for an audience of researchers and graduate students in those disciplines and in robotics. It is the outcome of a workshop held in Las Vegas, Nevada on December 14, 2002 jointly sponsored by the IEEE Control Systems Society and the IEEE Robotics and Automation Society...|$|R
50|$|The project aims {{to develop}} a {{multi-purpose}} system capable of docking or mating with special-purpose devices including refueling stations, excavation implements and/or special end effectors. The legs have {{6 degrees of freedom}} for generalized <b>robotic</b> <b>manipulation.</b> Each ATHLETE is intended to have a payload capacity of 450 kg, in Earth's gravity with the capability of docking multiple ATHLETE vehicles together to support larger loads.|$|E
5000|$|Schoenflies (or Schönflies) {{displacement}} (or motion) is a {{rigid body}} motion consisting of linear motion in three dimensional space plus one orientation around an axis with fixed direction. [...] In <b>robotic</b> <b>manipulation</b> {{this is a}} common motion as many pick and place operations require moving an object from one plane and placing it with a different orientation onto another parallel plane (e.g., placement of components on a circuit board).|$|E
50|$|Jeffrey C. Trinkle is Professor {{and former}} Chair of Computer Science at Rensselaer Polytechnic Institute in Troy, New York. He {{is known for}} his work in <b>robotic</b> <b>manipulation,</b> multibody dynamics, and {{automated}} manufacturing. He has bachelor's degrees in physics (1979) and engineering (1979) from Ursinus College and Georgia Institute of Technology, respectively, and a PhD (1987) from the University of Pennsylvania. He has taught at the University of Arizona and Texas A&M University. From 1998 to 2003 he was a research scientist at Sandia National Laboratories in Albuquerque, New Mexico.|$|E
40|$|This paper explores {{a method}} of {{manipulating}} a planar rigid part on a conveyor belt using a robot with just one joint. This approach {{has the potential of}} offering a simple and flexible method for feeding parts in industrial automation applications. In this paper we develop a model of this system and of a variation which requires no sensing. We have been able to characterize these systems and to prove that they can serve as parts feeding devices for planar polygonal parts. We present the planners for these systems and describe our implementations. Key Words. <b>Robotics,</b> <b>Manipulation,</b> Mechanics, Planning, Minimalism, Automation, Manufacturing, Parts feeding. 1. Introduction. The most straightforward approach to planar manipulation is to use a rigid grasp and a robot with at least three joints, corresponding to the three motion freedoms of a planar rigid part, but three joints are not really necessary to manipulate a part in the plane. In this paper we achieve effective control of all t [...] ...|$|R
40|$|Behavior-based mobile {{manipulation}} {{inspired by}} the human example Abstract — This paper presents our approach to extending the niche of behavior-based <b>robotics</b> to <b>manipulation.</b> We use results from neuroscience to define the basic behaviors of the manipulator. Furthermore, we derive some qualitative design rules for {{the mechanics of the}} manipulator. With these principles, we have designed a first demo application: writing on a board with a mobile manipulator. I...|$|R
40|$|This {{activity}} brought two <b>robotic</b> mobile <b>manipulation</b> systems {{developed by}} Sandia National Laboratories to the Maneuver Support Center (MANSCEN) at Ft. Leonard Wood {{for the following}} purposes: Demonstrate advanced manipulation and control capabilities; Apply manipulation to hazardous activities within MANSCEN mission space; Stimulate thought and identify potential applications for future mobile manipulation applications; and Provide introductory knowledge of manipulation to better understand how to specify capability and write requirements...|$|R
50|$|Trinkle's primary {{research}} interests {{lie in the}} areas of <b>robotic</b> <b>manipulation,</b> multibody dynamics, and automated manufacturing. With continuous support from the National Science Foundation since 1988, he has written over 100 technical articles. One of these articles (with David Stewart) was the first to develop a popular method for simulating multibody systems. Variants of this method are key components of several physics engines for computer game development, for example, NVIDIA PhysX and Bullet. For his work in the area of robotic grasping and dexterous manipulation, Trinkle was elected Fellow of the IEEE in 2010. He spent most of 2010 as a Humboldt Fellow at the Institute for Mechatronics and Robotics at the German Aerospace Center and the Institute for Applied Mechanics at Technical University of Munich.|$|E
5000|$|Another {{example of}} an {{application}} has been coined [...] "telepario" [...] by CMU professors Todd Mowry and Seth Goldstein. What the researchers propose to make are moving, physical,three-dimensional replicas of people or objects, so lifelike that human senses would accept them as real. This would {{eliminate the need for}} cumbersome virtual reality gear and overcome the viewing angle limitations of modern 3D approaches. The replicas would mimic the shape and appearance of a person or object being imaged in real time, and as the originals moved, so would their replicas. One aspect of this application is that the main development thrust is geometric representation rather than applying forces to the environment as in a typical <b>robotic</b> <b>manipulation</b> task. This project is widely known as claytronics or Programmable matter (noting that programmable matter is a much more general term, encompassing functional programmable materials, as well).|$|E
50|$|In 1981 Hollerbach co-founded the Year of the Robot {{program at}} the MIT Artificial Intelligence Laboratory funded by the System Development Corporation and the Office of Naval Research {{with the goal of}} {{jump-starting}} serious research in robotics. During the 1970s robotics research was not considered a separate respectable scientific endeavor and was heavily oriented toward industrial robotics with limited vision in potential capabilities. The program aimed to rectify this by accelerating robotics research at MIT over a five year period by supporting writing of a sourcebook on <b>robotic</b> <b>manipulation,</b> starting an annual high-level international academic conference and research journal, outlining an educational program, and building a dexterous and controllable robotic hand. In 1982, Hollerbach co-produced a robot motion sourcebook with J. Michael Brady, Matthew T. Mason, Tomas Lozano-Perez, and Timothy Johnson. The book contained sections on dynamics, trajectory planning, compliance and force control, feedback control, and spatial planning; each section had a substantial introduction that served as a tutorial in addition to research papers by 19 top robotics researchers, including Marc Raibert, Robin Popplestone, and Pat Ambler. An updated version of the sourcebook was published in 1989 edited by J. Michael Brady. In 1983, Hollerbach helped start the International Journal of Robotics Research and the International Symposium of Robotics Research.|$|E
40|$|ATDG), {{a system}} {{implemented}} into a software prototype for teaching {{the operation of}} a robot manipulator deployed on the International Space Station (ISS). The ATDG combines the use of path planning and camera planning {{to take into account}} the complexity of the manipulator, the limited direct view of the ISS exterior, and the unpredictability of lighting conditions in the workspace. The pathplanning algorithm not only avoids obstacles in the workspace as is normal for a path-planner, but in addition takes into account the position of corridors for safe operations and the placement of cameras on the ISS. The camera planner is then invoked to find the right arrangement of cameras to follow the manipulator on its trajectory. This allows the on-the-fly production of useful and pedagogical task demonstrations to help the student carry out tasks involving the manipulation of the robot on the ISS. Even if the system has been developed for <b>robotic</b> <b>manipulations,</b> it could be used for any application involving the filming of unpredictable complex scenes...|$|R
40|$|Abstract—Controlling robotic {{interventions}} {{on small}} devices creates important challenges on the sensing stage as resolution limitations of noncontact sensors are rapidly reached. The inte-gration of haptic sensors to refine {{information provided by}} vision sensors appears as a very promising approach {{in the development of}} autonomous robotic systems because it reproduces the multi-plicity of sensing sources used by humans. This paper discusses an intelligent multimodal sensor system developed to enhance the haptic control of <b>robotic</b> <b>manipulations</b> of small three-dimen-sional (3 -D) objects. The proposed system combines a 16 16 array of force sensing resistor (FSR) elements to refine 3 -D shape measurements in selected areas previously monitored with a laser range finder. Using the integrated technologies, the sensor system is able to recognize small-size objects that cannot be accurately differentiated through range measurements and provides an estimate of the objects orientation. Characteristics of the system are demonstrated {{in the context of a}} robotic intervention that requires fine objects to be localized and identified for their shape and orientation. Index Terms—Haptics, laser measurement applications, micro-processors applications, neural networks, object recognition, robot tactile systems. I...|$|R
40|$|Robot-assisted cell microinjection, {{which is}} precise and can enable a high throughput, is {{attracting}} interest from researchers. Conventional probe-type cell microforce sensors have some real-time injection force measurement limitations, which prevent their integration {{in a cell}} microinjection robot. In this paper, a novel supported-beam based cell micro-force sensor with a piezoelectric polyvinylidine fluoride film used as the sensing element is described, {{which was designed to}} solve the real-time force-sensing problem during a <b>robotic</b> microinjection <b>manipulation,</b> and theoretical mechanical and electrical models of the sensor function are derived. Furthermore, an array based cell-holding device with a trapezoidal microstructure is micro-fabricated, which serves to improve the force sensing speed and cell manipulation rates. Tests confirmed that the sensor showed good repeatability and a linearity of 1. 82 %. Finally, robot-assisted zebrafish embryo microinjection experiments were conducted. These results demonstrated the effectiveness of the sensor working with the <b>robotic</b> cell <b>manipulation</b> system. Moreover, the sensing structure, theoretical model, and fabrication method established in this study are not scale dependent. Smaller cells, e. g., mouse oocytes, could also be manipulated with this approach...|$|R
50|$|He has coauthored over 550 {{technical}} papers and 9 books, including Adaptive Control: Stability, Convergence and Robustness (with M. Bodson, Prentice Hall, 1989) and A Mathematical Introduction to <b>Robotic</b> <b>Manipulation</b> (with R. Murray and Z. Li, CRC Press, 1994), Nonlinear Systems: Analysis, Stability and Control (Springer-Verlag, 1999), and An Invitation to 3D Vision: From Images to Models (Springer Verlag, 2003) (with Y. Ma. S. Soatto, and J. Kosecka). Dr. Sastry served as Associate Editor for numerous publications, including: IEEE Transactions on Automatic Control; IEEE Control Magazine; IEEE Transactions on Circuits and Systems; the Journal of Mathematical Systems, Estimation and Control; IMA Journal of Control and Information; the International Journal of Adaptive Control and Signal Processing; Journal of Biomimetic Systems and Materials. He is currently an Associate Editor of the IEEE Proceedings.Dr. Sastry was elected into the National Academy of Engineering in 2001 and the American Academy of Arts and Sciences (AAAS) in 2004. He also received the President of India Gold Medal in 1977, the IBM Faculty Development award for 1983-1985, the NSF Presidential Young Investigator Award in 1985 and the Eckman Award of the American Automatic Control Council in 1990, the Ragazzini Award for Distinguished Accomplishments in teaching in 2005, an M. A. (honoris causa) from Harvard in 1994, Fellow of the IEEE in 1994, the distinguished Alumnus Award of the Indian Institute of Technology in 1999, and the David Marr prize {{for the best}} paper at the International Conference in Computer Vision in 1999, an honorary doctorate from the KTH Royal Institute of Technology in 2007 and the C.L. Tien Award for Academic Leadership in 2010. He {{has been a member}} of the Air Force Scientific Advisory Board from 2002-5 and the Defense Science Board in 2008 among other national boards. He is currently on the corporate boards of C3-Carbon and HCL Technologies (India). He is on the Scientific Advisory Boards of Interwest LLC, GE Software, and Eriksholm.|$|E
30|$|The {{results have}} shown that the {{proposed}} framework is feasible for <b>robotic</b> <b>manipulation</b> with motion sensing control.|$|E
30|$|To data, {{outside of}} the {{controlled}} environments, robots normally perform manipulation tasks operating with human. This pattern requires the robot operators with high technical skills training for varied teach-pendant operating system. Motion sensing technology, which enables human–machine interaction in a novel and natural interface using gestures, has crucially inspired us to adopt this user-friendly and straightforward operation mode on <b>robotic</b> <b>manipulation.</b> Thus, in this paper, we presented a motion sensing-based framework for <b>robotic</b> <b>manipulation,</b> which recognizes gesture commands captured from motion sensing input device and drives the action of robots. For compatibility, a general hardware interface layer was also developed in the framework. Simulation and physical experiments have been conducted for preliminary validation. The results {{have shown that the}} proposed framework is an effective approach for general <b>robotic</b> <b>manipulation</b> with motion sensing control.|$|E
40|$|Abstract — Better sensing {{is crucial}} to improve <b>robotic</b> {{grasping}} and <b>manipulation.</b> Most robots currently have very limited perception in their manipulators, typically only fingertip position and velocity. Additional sensors make richer interactions with the objects possible. In this paper, we present a versatile, robust and low cost sensor for robot fingertips, that can improve <b>robotic</b> grasping and <b>manipulation</b> in several ways: 3 D reconstruction of the shape of objects, material surface classification, and object slip detection. We extended TUM-Rosie, our robot for mobile manipulation, with fingertip sensors on its humanoid robotic hand, and show {{the advantages of the}} fingertip sensor integrated in our robot system. I...|$|R
40|$|Abstract — This paper {{presents}} {{results from}} the application of dimensionality reduction algorithms to sensory-data time-series that were recorded from Robonaut – NASA’s humanoid robot – while it was being teleoperated through four tool manipulation tasks. The algorithms tested were Principal Component Analysis, Multidimensional Scaling, and Spatio-Temporal Isomap. Structures were shown to exist in some cases, but their detection required careful analysis and a correct choice of parameters. Index Terms — Spatio-temporal learning, dimension reduction, <b>robotics,</b> dexterous <b>manipulation...</b>|$|R
40|$|The LATDYN User's Manual {{presents}} the capabilities and {{instructions for the}} LATDYN (Large Angle Transient DYNamics) computer program. The LATDYN program is a tool for analyzing the controlled or uncontrolled dynamic transient behavior of interconnected deformable multi-body systems which can undergo large angular motions of each body relative other bodies. The program accommodates large structural deformation as well as large rigid body rotations and is applicable, but not limited to, the following areas: (1) development of large flexible space structures; (2) slewing of large space structure components; (3) mechanisms with rigid or elastic components; and (4) <b>robotic</b> <b>manipulations</b> of beam members. Presently the program is limited to two dimensional problems, but in many cases, three dimensional problems can be exactly or approximately reduced to two dimensions. The program uses convected finite elements to affect the large angular motions involved in the analysis. General geometry is permitted. Detailed user input and output specifications are provided and discussed with example runstreams. To date, LATDYN has been configured for CDC/NOS and DEC VAX/VMS machines. All coding is in ANSII- 77 FORTRAN. Detailed instructions regarding interfaces with particular computer operating systems and file structures are provided...|$|R
3000|$|This paper {{proposed}} a motion sensing-based <b>robotic</b> <b>manipulation</b> framework. The framework contains an integrated motion sensing devices driver for gesture commands recognition, a ROS-based framework core to map motion sensing intents to robot operation commands, {{and a general}} robot hardware interface for compatibility with varies robot manipulators. The validation in simulation and physical robot {{have shown that the}} proposed framework is feasible for <b>robotic</b> <b>manipulation</b> with motion sensing control. And hardware driver repository can be found here: [URL] [...]...|$|E
40|$|The {{control of}} <b>robotic</b> <b>manipulation</b> is investigated. Manipulation systemanalysis and control are {{approached}} {{in a general}} framework. The geometric aspectof manipulation system dynamics is strongly emphasized by using the well developedtechniques of geometric multivariable control theory. The {{focus is on the}} control ofthe crucial outputs in <b>robotic</b> <b>manipulation,</b> namely the reachable internal forces andthe rigid{body object motions. A state{feedback control procedure is outlined fordecoupling these outputs and nally special attention is devoted to the synthesis ofthe state observer...|$|E
30|$|The rest of {{this paper}} is {{organized}} as follows. “Framework architecture design” section describes the architecture design of our proposed framework. “Motion sensing commands” section shows how to create the motion sensing commands for <b>robotic</b> <b>manipulation.</b> “Framework core” section depicts the control core for <b>robotic</b> <b>manipulation.</b> “General hardware interface” section depicts realization of hardware interface for hardware abstraction. “Implementation and experiments” section demonstrates implementation and experiments of the proposed framework. “Conclusion” section summarizes our study. And “Discussion and future work” section starts discussions about this research and works out the future work.|$|E
40|$|We {{present an}} easy-to-use, modular {{framework}} for performing computer vision related tasks {{in support of}} cognitive robotics research on the iCub humanoid robot. The aim of this biologically inspired, bottom-up architecture is to facilitate research towards visual perception and cognition processes, especially their influence on <b>robotic</b> object <b>manipulation</b> and environment interaction. The icVision framework described provides capabilities for detection of objects in the 2 D image plane and locate those objects in 3 D space to facilitate {{the creation of a}} world model...|$|R
50|$|RSAT is {{a planned}} 3U CubeSat {{and the first}} USNA Robotics mission. RSAT will carry two remote {{manipulator}} arms for <b>robotic</b> investigations and <b>manipulations</b> in the space environment. Future RSAT models will be attached to a TUGSAT which will provide the needed maneuvering capabilities.|$|R
40|$|We {{provided}} a vision-controlled <b>robotics</b> <b>manipulation</b> {{system with a}} robust, accurate algorithm to predict the translational motion of a 3 -D object; hence, {{making it possible to}} continuously point the video camera at the moving object. The real time video images are fed to a PVM- 1 (a pyramid-based image processor) for image processing and moving object detection. The measured object coordinates are continuously fed to our algorithm for track smoothing and prediction. In this study, we examined several tracking algorithms and adopted an optimal α - β filter for tracking purposes and the α - β -γ filter as part of the initialization procedure. The optimum gains for these 6 lkm are based on the Tracking Index principle which in its turn is based on the measurement noise variance and the object dynamics. We derived an expression for the noise variance corresponding to our application. As for the object dynamics, we developed an adaptive method (using the α - β -γ filter mentioned above) for inferring object dynamics in an iterative learning process that results in an accurate estimate of the Tracking Index. The accuracy of our algorithm realizes that of the Kalman filter but is much simpler computationally...|$|R
