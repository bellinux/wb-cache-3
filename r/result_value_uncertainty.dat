0|10000|Public
40|$|We study two option {{values in}} the {{developable}} land market in a French department (Nord) : the classical option value relating to the short-run volatility of the land price and a long-run option <b>value</b> <b>resulting</b> from <b>uncertainty</b> about demographic change. The findings show that both are significant. First, the land price increases by 7. 4 – 15. 3 % when the standard deviation (STD) of the land price rises by a STD. Second, an increase of one STD in the STD {{of the variation in}} population between 1982 and 1999 entails a 6 % increase in the developable land price...|$|R
40|$|Codes JEL : R 1, D 8 We study two option {{values in}} the {{developable}} land market in a French department (Nord) : the classical option value relating to the short-run volatility of the land price and a long-run option <b>value</b> <b>resulting</b> from <b>uncertainty</b> about demographic change. The findings show that both are significant. First, the land price increases by 7. 4 - 15. 3 % when the standard deviation (STD) of the land price rises by a STD. Second, an increase of one STD in the STD {{of the variation in}} population between 1982 and 1999 entails a 6 % increase in the developable land price...|$|R
40|$|Compressive Sensing is a {{technique}} for simultaneous acquisition and compression of data that is sparse or can be made sparse in some domain. It is currently under intense development and has been profitably employed for industrial and medical applications. We here describe {{the use of this}} technique for the processing of astronomical data. We outline the procedure as applied to exoplanet gravitational microlensing and analyze measurement <b>results</b> and <b>uncertainty</b> <b>values.</b> We describe implications for on-spacecraft data processing for space observatories. Our findings suggest that application of these techniques may yield significant, enabling benefits especially for power and volume-limited space applications such as miniaturized or micro-constellation satellites...|$|R
40|$|The {{purpose of}} this paper is to clarify the role of <b>value</b> <b>uncertainty</b> and <b>value</b> {{instability}} in decision-making that concerns morally controversial issues. <b>Value</b> <b>uncertainty</b> and <b>value</b> instability are distinguished from moral uncertainty, and several types of <b>value</b> <b>uncertainty</b> and <b>value</b> instability are defined and discussed. The relations between <b>value</b> <b>uncertainty</b> and <b>value</b> instability are explored, and <b>value</b> <b>uncertainty</b> is illustrated with examples drawn from the social sciences, medicine and everyday life. Several types of factor producing <b>value</b> <b>uncertainty</b> and/or <b>value</b> instability are then identified. They are grouped into three categories and discussed under the headings ‘value framing’, ‘ambivalence’ and ‘lack of self-knowledge’. The paper then discusses the role of <b>value</b> <b>uncertainty</b> in decision-making. The concluding remarks summarize what has been achieved and what remains to be done in this area...|$|R
40|$|Geographic Information Systems {{automatically}} {{calculate the}} area of a polygon from the coordinate values of the vertices that describe its boundary. Uncertainty in these coordinate <b>values</b> <b>results</b> in <b>uncertainty</b> in area estimates. Earlier articles showed how area uncertainty of individual polygons could be calculated. In this article we propose a covariance equation to quantify the impact of uncertainty {{in the position of}} a vertex on uncertainty in {{the area of}} all polygons sharing this vertex. The approach {{is based on the assumption}} of absence of spatial correlation in positional errors, but includes variation in the positional accuracy. The equations were implemented and applied to a case study area, described by a set of 97 adjacent polygons with different per unit area utility values (/ha). We were then able to calculate how uncertainty in the coordinate <b>values</b> propagated into <b>uncertainty</b> in the utility value of the complete set of polygon...|$|R
5000|$|Decision theory, {{identifying}} the <b>values,</b> <b>uncertainties</b> {{and other issues}} relevant in a decision ...|$|R
40|$|As {{documented}} by a vast empirical literature, {{initial public offerings}} (IPOs) are characterized by underpricing. A number of papers have shown that underpricing {{is directly related to}} the amount of ex ante uncertainty concerning the IPOs valuation. Recent theoretical papers propose that not all <b>value</b> <b>uncertainty</b> is resolved prior to the start of trading, but rather continues to be resolved in the beginning of the after market. We term this type of uncertainty as ex post <b>value</b> <b>uncertainty</b> and develop proxies for it. We find strong support for the existence of ex post <b>value</b> <b>uncertainty</b> and find that including a proxy for it more than doubles the explanatory power of previous models. " Copyright (c) 2009 Financial Management Association International. ...|$|R
5000|$|In statistics, spatial {{autocorrelation}} between {{sample locations}} also helps one estimate mean <b>value</b> <b>uncertainties</b> when sampling a heterogeneous population.|$|R
5000|$|Kandel, E. & Pearson, N. (2002), Option <b>Value,</b> <b>Uncertainty</b> and the Investment Decision, Journal of Financial and Quantitative Analyses 37(2), 341-374.|$|R
25|$|Decision {{theory is}} {{concerned}} with identifying the <b>values,</b> <b>uncertainties</b> and other issues relevant in a given decision, its rationality, and the resulting optimal decision.|$|R
40|$|The Schrodinger {{equation}} {{is used to}} exactly evaluate the propagator, wave function, energy expectation <b>values,</b> <b>uncertainty</b> <b>values,</b> and coherent state for a harmonic oscillator with a time dependent frequency and an external driving time dependent force. These quantities represent {{the solution of the}} classical equation of motion for the time dependent harmonic oscillator...|$|R
40|$|Attribute <b>value</b> <b>uncertainty</b> {{is present}} in a {{decision}} when the consequences are characterized by uncertain estimates of the underlying, unknown true values. Attributes defined based upon measurement data, experimental data, or survey data are subject to attribute <b>value</b> <b>uncertainty.</b> Uncertainty in decision modeling has received significant attention from the community, most notably the methods pertaining to risky decisions and decision ambiguity. These methods, however, proceed with only point estimates representing the attribute <b>values,</b> ignoring the <b>uncertainty</b> in the estimates, which can adversely impact {{the identification of the}} best decision alternative. This work describes a new decision analysis method that incorporates attribute <b>value</b> <b>uncertainty</b> by leveraging the systematic mechanism of the Monte Carlo method. This approach allows for the uncertainty in the attribute values to be propagated through the decision model and reflected in the resulting decision parameter. Several techniques, including stochastic dominance and majority judgment, can be used to identify the most desirable alternative based on the resulting uncertain decision parameter. The approach is illustrated by an example driven by a recent U. S. Department of Homeland Security program to investigate detection systems for screening individuals and their baggage for radioactive materials at U. S. -based international arrival airport terminals...|$|R
40|$|Standard {{practice}} in the residential mortgage underwriting industry is to estimate collateral values via independent appraisals conducted by third parties. This paper empirically examines the role of property value ("i. e. ", appraisal) uncertainty as a determinant of default on residential mortgage loans. Based upon an analysis of 1, 428 residential loans drawn from the portfolio of a national mortgage lender, we find evidence that semivariance in property <b>value</b> <b>uncertainty</b> is related to default risk. Specifically, subject properties that are valued above the sales price of recently sold "similar and proximate" properties show evidence of greater default risk. Interestingly, a variance (range) measure of property <b>value</b> <b>uncertainty</b> is not significantly related to default risk. Copyright Blackwell Publishers Ltd 2001. ...|$|R
25|$|Decision {{theory in}} economics, psychology, philosophy, mathematics, and {{statistics}} {{is concerned with}} identifying the <b>values,</b> <b>uncertainties</b> and other issues relevant in a given decision, its rationality, and the resulting optimal decision. It is very {{closely related to the}} field of game law.|$|R
40|$|Contrary {{to most of}} {{the papers}} in the {{literature}} of investment under uncertainty we study models that not only capture the timing, but also the size of the investment. We consider a monopoly setting as well as a duopoly setting and compare the results with the standard models in which the firms do not have the capacity choice. Our main results are the following. First, for low <b>uncertainty</b> <b>values</b> the follower chooses a higher capacity than the leader and for high <b>uncertainty</b> <b>values</b> the leader chooses a higher capacity. Second, compared to the model without capacity choice, the monopolist and the follower invest later in a higher capacity for higher <b>values</b> of <b>uncertainty.</b> However, the leader will invest earlier in a higher capacity for higher <b>values</b> of <b>uncertainty.</b> The reverse results apply for lower <b>values</b> of <b>uncertainty.</b> ...|$|R
40|$|The {{supplementary}} data {{includes the}} full experimental {{results for the}} three investigated cases, i. e., air-flame, oxy-flame- 1, oxy-flame 2, and oxy-flame 3. Tables include mean <b>values,</b> <b>uncertainty</b> errors, standard deviation, 5 th percentile, 25 thpercentile, 50 th percentile, 75 th percentile, and 95 th percentile...|$|R
40|$|The ISO 10360 2 is {{concerned}} with testing CMMs (Coordinate Measuring Machines) using alternative calibrated test lengths, realised either by material standards or by interferometry. Whatever the calibrated test lengths, the ISO 10360 2 requires {{the evaluation of the}} test <b>value</b> <b>uncertainty,</b> and hence of its several components; {{one of them is the}} uncertainty in realising the calibrated test lengths. This technical report gives guidance on how to evaluate the uncertainty incurred in realising calibrated test lengths by interferometry, equivalent to the calibration uncertainty when the calibrated test lengths are realised by material standards. This uncertainty, u(int), is just a component of the overall test <b>value</b> <b>uncertainty.</b> Other components – such as clamping and overall alignment – are beyond the scope of this technical report. Readers are remembered not to overlook the other uncertainty components...|$|R
40|$|The paper {{considers}} a problem pertaining to determination of a statistical {{estimation of the}} half-hour load maximum of an industrial enterprise on the criterion of a minimum of total expenses. The estimation is {{made on the basis}} of fractile optimization characterizing a corridor width of <b>value</b> <b>uncertainty</b> of the half-hour load</p...|$|R
40|$|This paper {{contributes}} to the widespread discussion {{of the sources of}} the divergence between WTA and WTP values. The paper reports on theoretical and empirical investigations which show that <b>value</b> and outcome <b>uncertainty</b> offer an explanation for this disparity. Given a set of hypotheses generated by the theory, the paper investigates the disparity using an inducedvalue experimental laboratory setting. The incentive-compatible Becker-DeGroot-Marshak mechanism is employed to elicit the WTP and WTA values. Two conclusions can be drawn from the empirical results. First, the WTA - WTP difference is generally increasing in both <b>value</b> and outcome <b>uncertainty.</b> Second, a re-contracting option reduces the disparity when it arises from <b>value</b> <b>uncertainty.</b> Key Words: Experimental, Uncertainty, WTP-WTA disparit...|$|R
40|$|Environmental {{conditions}} and the interplay of cognitive and affective processes both exert influences on bidding behavior. This paper brings the above together, considering how the (external) auction environment determines the impact of (internal) cognitive and affective processes on bidding behavior, assessed {{in comparison to the}} optimal bid. Two aspects of the auction environment were considered, namely auction dynamics (low: first-price sealed-bid auction, high: Dutch auction) and <b>value</b> <b>uncertainty</b> (low, high). In a laboratory experiment, we assess bidders' cognitive workload and emotional arousal through physiological measurements. We find that higher auction dynamics increase the impact of emotional arousal on bid deviations, but not that of cognitive workload. Higher <b>value</b> <b>uncertainty,</b> conversely, increases the impact of cognitive workload on bid deviations, but not that of emotional arousal. Taken together, the auction environment is a critical factor in understanding the nature of the underlying decision process and its impact on bids...|$|R
40|$|Overall {{persistence}} (P OV) and long-range transport potential (LRTP) {{of chemicals}} are two indicators {{used in the}} context of precautionary chemical assessment. Multimedia fate models are used in research and regulatory contexts to calculate numerical indicators of P OV and LRTP. The <b>resulting</b> indicator <b>values</b> exhibit <b>uncertainty</b> due to model uncertainty concerning model design and due to variability and uncertainty in the substance parameters. In this study, we compare the relative magnitude of substance parameter and model uncertainty for a large set of 3175 hypothetical chemicals that evenly cover the chemical parameter space and for eight different multimedia models available for the calculation of P OV and LRTP. The assessment of the relative magnitude of the two types of uncertainty is important to direct further research and to inform the user on the level of confidence he can have in the model results. It is shown that, for P OV, substance parameter uncertainty is larger than model uncertainty in most cases (78 %), and that model uncertainty becomes more important for those chemicals which partition in considerable amounts into more than one environmental compartment. For LRTP, on the other hand, model uncertainty is higher than parameter uncertainty in most cases (61 - 81 %). This dominance of model uncertainty can be explained with known differences in the model designs. Uncertainty of P OV can thus be reduced most effectively by improving data on degradation rate constants. For LRTP, the choice of the model that is best suited for the assessment purpose in question is most essential to reduce uncertainty...|$|R
40|$|Summary. Earthquake {{occurrence}} in the United Kingdom is analysed using Gumbel’s third type asymptotic distribution of extreme <b>values.</b> <b>Uncertainties</b> {{in both the}} parameters and predictions derived from the Gumbel distribution are obtained and it is shown that an earthquake with body-wave magnitude slightly over five is the one {{most likely to be}} perceived at any point in the United Kingdom...|$|R
40|$|This paper {{investigates the}} {{information}} contained in the yields of corporate debt securities using a structural credit risk model. As previous studies have found, credit risk is not the only factor that affects corporate yield spreads. The aim is to decompose credit spreads, using a structural model of credit risk, into credit and non-credit risk components. The contribution relative to the existing literature is the use of contemporaneous forward-looking information on equity risk premia and equity <b>value</b> <b>uncertainty</b> in a structural model. In particular, implied equity risk premia from a three-stage dividend discount model that incorporates analysts' long-term earnings forecasts are used, together with implied measures of equity <b>value</b> <b>uncertainty</b> from option prices. The paper examines the evolution of the different components of spreads across time as well as the effect of particular events. It also analyses the relationship between the derived components and other financial variables, such as swap spreads and the equity risk premium. ...|$|R
40|$|Yucca Mountain (YM), Nevada, {{has been}} {{proposed}} by the U. S. Department of Energy as a geologic repository for spent nuclear fuel and high-level radioactive waste. In this study, we investigate the potential for groundwater advective pathways from underground nuclear testing areas on the Nevada Test Site (NTS) to the YM area by estimating the timeframe for advective travel and its <b>uncertainty</b> <b>resulting</b> from porosity <b>value</b> <b>uncertainty</b> for hydrogeologic units (HGUs) in the region. We perform sensitivity analysis to determine the most influential HGUs on advective radionuclide travel times from the NTS to the YM area. Groundwater pathways and advective travel times are obtained using the particle tracking package MODPATH and flow results from the Death Valley Regional Flow System (DVRFS) model by the U. S. Geological Survey. <b>Values</b> and <b>uncertainties</b> of HGU porosities are quantified through evaluation of existing site porosity data and expert professional judgment and are incorporated through Monte Carlo simulations to estimate mean travel times and uncertainties. We base our simulations on two steady state flow scenarios {{for the purpose of}} long term prediction and monitoring. The first represents pre-pumping conditions prior to groundwater development in the area in 1912 (the initial stress period of the DVRFS model). The second simulates 1998 pumping (assuming steady state conditions resulting from pumping in the last stress period of the DVRFS model). Considering underground tests in a clustered region around Pahute Mesa on the NTS as initial particle positions, we track these particles forward using MODPATH to identify hydraulically downgradient groundwater discharge zones and to determine which flowpaths will intercept the YM area. Out of the 71 tests in the saturated zone, flowpaths of 23 intercept the YM area under the pre-pumping scenario. For the 1998 pumping scenario, flowpaths from 55 of the 71 tests intercept the YM area. The results illustrate that mean minimum travel time from underground testing areas on the NTS to the YM area can vary from just over 700 to nearly 700, 000 years, depending on the locations of the underground tests, the pumping scenarios considered, and the porosity value distributions used. The sensitivity analysis further illustrates that for both pre-pumping and 1998 pumping scenarios, the <b>uncertainties</b> in porosity <b>values</b> for five of the 27 HGUs considered account for well over 90 % of the porosity-related travel time uncertainties for the flow paths having the shortest mean travel times to the YM area...|$|R
40|$|Abstract. In {{this paper}} we present our {{approach}} for extending the OLAP model to include treatment of <b>value</b> <b>uncertainty</b> {{as part of}} a multidimensional model inhabited by flexible data and non-rigid hierarchical structures of organisation. A new multidimensional-cubic model named as the IF-Cube is introduced which is able to operate over data with imprecision either in the facts or in the dimensional hierarchies. 1...|$|R
40|$|We {{consider}} a simple two-period model with irreversible investment with strategic interactions. In this setup, {{we try to}} extend {{the concept of the}} quasi-option value (QOV) by Arrow and Fisher (1974), Henry (1974), Fisher and Hanemann (1987) and Hanemann (1989) to a game-theoretic situation. In doing so, we demostrate some conceptual difficulties with the QOV, and stress the potential importance of information-induced inefficiency. We also show that this inefficiency can be remedied by incorporating sophisticated control of information flow. Our model is potentially applicable to various global environmental problems. Biodiversity, Irreversibility, Quasi-option <b>value,</b> <b>Uncertainty,</b> <b>Value</b> of Information...|$|R
40|$|This paper {{considers}} optimal auctions where individuals' valuations {{have both}} a private and common value component. We show {{that when the}} set of potential buyers and seller are symmetrically uninformed regarding the common value component, it may be socially optimal not to resolve this common uncertainty. Under the sufficient conditions provided to generate this outcome, efficiency will be restored in the optimal auction. Auctions, Efficiency, Common <b>value,</b> <b>Uncertainty...</b>|$|R
40|$|The payoff method showed {{distinctive}} {{advantages in}} the valuation of the cost-effectiveness of competing health care interventions, essentially {{determined by the}} replacement of the nonfuzzy numbers that are commonly used in cost-effectiveness analysis models, with fuzzy numbers as an input to inform the real option pricing method. The real option approach to <b>value</b> <b>uncertainty</b> makes policy making in health care an evolutionary process and creates a new "space" for decision-making choices...|$|R
40|$|Using an induced-value {{experimental}} design that varies whether values for a “good” are certain or uncertain and whether payment is real or hypothetical, this study investigates issues of demand revelation, hypothetical bias, and <b>value</b> <b>uncertainty</b> for four elicitation mechanisms used in contingent valuation surveys: dichotomous choice, dichotomous choice with follow-up certainty question, payment card, and multiple-bounded discrete choice. For all elicitation mechanisms, we find {{no evidence of}} hypothetical bias: voting decisions do not vary systematically when payment is hypothetical versus when it is real. Under all design conditions we find the fewest deviations between stated and induced values and the strongest evidence of demand revelation with dichotomous choice. Stated uncertainty in dichotomous choice follow-up and multiple-bounded discrete choice questions does correlate with uncertain induced values, but the signal is noisy. We discuss the implications of our findings {{for the design of}} contingent valuation surveys. Copyright Springer Science+Business Media, Inc. 2006 contingent valuation, demand revelation, elicitation effects, experiments, hypothetical bias, <b>value</b> <b>uncertainty,</b> willingness to pay, C 91, Q 51,...|$|R
30|$|Once pairing {{process is}} complete, {{authentication}} module returns <b>result</b> <b>values</b> to a relevant module. The <b>results</b> <b>values</b> are module ID, the creation {{time of the}} <b>results</b> <b>value,</b> module name, module version, and checked flag. They are encrypted with a manufacturer’s public key before being transmitted. If authentication successes, checked flag has “Permitted”; if authentication fails, it has “not permitted”. Authentication module saves <b>result</b> <b>values.</b> After that, if the same module is inserted, the module checks checked flag of the <b>result</b> <b>values,</b> and, if “not Permitted”, it makes an authentication request again.|$|R
40|$|Abstract – Classical {{decision}} tree classifiers {{are constructed using}} certain or point data only. But in many real life applications inherently data is always uncertain. Attribute or <b>value</b> <b>uncertainty</b> is inherently associated with data values during data collection process. Attributes in the training data sets are of two types – numerical (continuous) and categorical (discrete) attributes. Data uncertainty exists in both numerical and categorical attributes. Data uncertainty in numerical attributes means range of <b>values</b> and data <b>uncertainty</b> in categorical attributes means set or collection of values. In this {{paper we propose a}} method for handling data uncertainty in numerical attributes. One of the simplest and easiest methods of handling dat...|$|R
40|$|This {{report is}} {{announcement}} of the specialized package for application into Mathematica environment. The package consists of the data base, containing 100 physical constant values (recommended by CODATA and/or Particle Data Group in the main), interpreter of the constant values and data presentation module. This package one can consider as enhancement of the Mathematica standard package Miscellaneous`PhysicalConstants`. It includes more constants and presents more complete data set (mean <b>value,</b> <b>uncertainty,</b> relative uncertainty) ...|$|R
40|$|Uncertain data streams {{can have}} tuples with both <b>value</b> and existential <b>uncertainty.</b> A tuple has <b>value</b> <b>uncertainty</b> {{when it can}} assume {{multiple}} possible values. A tuple is existentially uncertain when {{the sum of the}} probabilities of its possible values is $$<$$< 1. A situation where existential uncertainty can arise is when applying relational operators to streams with <b>value</b> <b>uncertainty.</b> Several prior works have focused on querying and mining data streams with both <b>value</b> and existential <b>uncertainty.</b> However, none of them have studied, in depth, the implications of existential uncertainty on sliding window processing, even though it naturally arises when processing uncertain data. In this work, we study the challenges arising from existential uncertainty, more specifically the management of count-based sliding windows, which are a basic building block of stream processing applications. We extend the semantics of sliding window to define the novel concept of uncertain sliding windows and provide both exact and approximate algorithms for managing windows under existential uncertainty. We also show how current state-of-the-art techniques for answering similarity join queries can be easily adapted to be used with uncertain sliding windows. We evaluate our proposed techniques under a variety of configurations using real data. The results show that the algorithms used to maintain uncertain sliding windows can efficiently operate while providing a high-quality approximation in query answering. In addition, we show that sort-based similarity join algorithms can perform better than index-based techniques (on 17 real datasets) when the number of possible values per tuple is low, as in many real-world applications. © 2014, Springer-Verlag London...|$|R
40|$|Abstract. Uncertain data streams {{can have}} tuples with both value and existential un-certainty. A tuple has <b>value</b> <b>uncertainty</b> {{when it can}} assume {{multiple}} possible values. A tuple is existentially uncertain when {{the sum of the}} probabilities of its possible values is less than 1. A situation where existential uncertainty can arise is when applying rela-tional operators to streams with <b>value</b> <b>uncertainty.</b> Several prior works have focused on querying and mining data streams with both <b>value</b> and existential <b>uncertainty.</b> How-ever, none of them have studied, in depth, the implications of existential uncertainty on sliding window processing, even though it naturally arises when processing uncertain data. In this work, we study the challenges arising from existential uncertainty, more specifically the management of count-based sliding windows, which are a basic building block of stream processing applications. We extend the semantics of sliding window to define the novel concept of uncertain sliding windows, and provide both exact and approximate algorithms for managing windows under existential uncertainty. We also show how current state-of-the-art techniques for answering similarity join queries can be easily adapted to be used with uncertain sliding windows. We evaluate our proposed techniques under a variety of configurations using real data. The results show that the algorithms used to maintain uncertain sliding windows can efficiently operate while providing a high quality approximation in query answering. In addition, we show tha...|$|R
40|$|We {{present an}} {{extension}} of the classical Ambrosio-Tortorelli approximation of the Mumford-Shah approach for the segmentation of images with uncertain gray <b>values</b> <b>resulting</b> from measurement errors and noise. Our approach yields a reliable precision estimate for the segmentation result, and it allows to quantify the robustness of edges in noisy images and under gray <b>value</b> <b>uncertainty.</b> We develop an ansatz space for such images by identifying gray values with random variables. The use of these stochastic images in the minimization of energies of Ambrosio-Tortorelli type leads to stochastic partial differential equations for the stochastic smoothed image and a stochastic phase field for the edge set. For their discretization we utilize the generalized polynomial chaos expansion and the generalized spectral decomposition (GSD) method. We demonstrate the performance of the method on artificial data as well as real medical ultrasound data...|$|R
40|$|We discuss methods {{based on}} {{stochastic}} PDEs for the segmentation of images with uncertain gray <b>values</b> <b>resulting</b> from measurement errors and noise. Our approach yields a reliable precision estimate for the segmentation result, {{and it allows}} us to quantify the robustness of edges in noisy images and under gray <b>value</b> <b>uncertainty.</b> The ansatz space for such images identifies gray values with random variables. For their discretization we utilize generalized polynomial chaos expansions and the generalized spectral decomposition method. This leads to the stochastic generalization of the Ambrosio-Tortorelli approximation of the Mumford-Shah functional. Moreover, we present the extension of the random walker segmentation for our stochastic images, which is based on an identification of the graph weights with random variables. We demonstrate the performance of the methods on a data set obtained from a digital camera as well as real medical ultrasound data...|$|R
