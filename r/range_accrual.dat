11|8|Public
5000|$|In finance, a <b>range</b> <b>accrual</b> {{is a type}} of {{derivative}} product very popular among structured-note investors. It is estimated that more than US$160 billion of <b>Range</b> <b>Accrual</b> indexed on interest rates only have been sold to investors between 2004 and 2007. It {{is one of the most}} popular non-vanilla financial derivatives. In essence the investor in a <b>range</b> <b>accrual</b> is betting that the reference [...] "index" [...] - usually interest rates or currency exchange rates - will stay within a predefined range.|$|E
50|$|The {{receiver}} of the <b>range</b> <b>accrual</b> coupons {{is selling}} binary options. The {{value of these}} options is used to enhance the coupon paid.|$|E
50|$|If {{furthermore}} the <b>range</b> <b>accrual</b> is callable, {{then the}} valuation model {{also needs to}} take into account the dynamic between the swaption and the underlying.|$|E
40|$|We {{develop a}} new Monte Carlo {{variance}} reduction method to estimate the expectation of two commonly encountered path-dependent functionals: first-passage times and occupation times of sets. The method {{is based on a}} recursive approximation of the first-passage time probability and expected occupation time of sets of a Levy bridge process that relies in part on a randomisation of the time parameter. We establish this recursion for general Levy processes and derive its explicit form for mixed-exponential jump-diffusions, a dense subclass (in the sense of weak approximation) of Levy processes, which includes Brownian motion with drift, Kou's double-exponential model and hyper-exponential jump-diffusion models. We present a highly accurate numerical realisation and derive error estimates. By way of illustration the method is applied to the valuation of <b>range</b> <b>accruals</b> and barrier options under exponential Levy models and Bates-type stochastic volatility models with exponential jumps. Compared with standard Monte Carlo methods, we find that the method is significantly more efficient...|$|R
40|$|Abstract. Although {{economically}} {{more meaningful}} than the alternatives, short rate {{models have been}} dismissed for financial engineering applications in favor of market models as the latter are more flexible and best suited to cluster computing implementations. In this paper, we argue that the paradigm shift toward GPU architectures currently {{taking place in the}} high performance computing world can potentially change the situation and tilt the balance back in favor {{of a new generation of}} short rate models. We find that operator methods provide a natural mathematical framework for the implementation of realistic short rate models that match features of the historical process such as stochastic monetary policy, calibrate well to liquid derivatives and provide new insights on complex structures. In this paper, we show that callable swaps, callable <b>range</b> <b>accruals,</b> target redemption notes (TARNs) and various flavors of snowballs and snowblades can be priced with methods numerically as precise, fast and stable as the ones based on analytic closed form solutions by means of BLAS level- 3 methods on massively parallel GPU architectures. 1...|$|R
40|$|This paper investigates {{whether the}} planned {{revision}} of the IMF’s A Manual on Government Finance Statistics should advocate an accrual basis of recording over the essentially cash basis of recording in the previous manual. The paper concludes that the revised manual should advocate an accrual basis {{in order to address}} deficiencies of the existing modified cash basis and enable a greater degree of harmonization with other macroeconomic statistical systems. The paper suggests a strategy that would enable countries to move progressively to compiling an extensive <b>range</b> of <b>accrual</b> information reconciling data on economic and financial flows and stocks. ...|$|R
50|$|Let's take {{an example}} of a 5 years <b>range</b> <b>accrual</b> note linked to USD 3 months Libor, with range set as 6.00% and a {{conditional}} coupon of 5.00%. Let's assume the note to start on January 1, 2009 and the first coupon payment to happen on July 1, 2009.|$|E
50|$|A <b>range</b> <b>accrual</b> {{can be seen}} as a {{strip of}} binary options, with a {{decreasing}} lag between fixing date and payment date. For this reason, it is important the valuation model is well calibrated to the volatility term structure of the underlying, at least at the strikes implied by the range.|$|E
40|$|We derive {{analytic}} valuation formulas for <b>range</b> <b>accrual</b> {{notes and}} spread <b>range</b> <b>accrual</b> notes under an affine term structure model with jump risks. We {{show that the}} value of a <b>range</b> <b>accrual</b> note can be significantly affected by the choice of interest rate model and the arrival intensity of jump risks. We also show that misuse of the correlation between reference rates of a spread <b>range</b> <b>accrual</b> note may lead traders and risk managers to mispricing of the note. Range note Structured note Hybrid note Affine term structure Jump diffusion Equilibrium model...|$|E
40|$|Several studies {{report an}} {{asymmetry}} {{in the distribution}} of earnings around specified benchmarks. However, doubt has arisen over whether the observed 'kink' {{in the distribution of}} earnings is solely caused by earnings management. We use a ratio analysis approach to examine a <b>range</b> of specific <b>accruals</b> for evidence of earnings management. We find little evidence that firms immediately above the benchmark have abnormal receivables, inventories or provisions. However, they do increase cash-from-customers and reduce inventory. Thus, our results support the recent research that suggests that firms engage in real actions to meet earnings benchmarks. Copyright (c) 2010 The Authors. Accounting and Finance (c) 2010 AFAANZ. ...|$|R
40|$|The aim of {{this thesis}} is to develop {{efficient}} valuation methods for nancial contracts under models with jumps and stochastic volatility, and to present their rigorous mathematical underpinning. For efficient risk management, large books of exotic options need to be priced and hedged under models that are exible enough to describe the observed option prices at speeds close to real time. To do so, hundreds of vanilla options, which are quoted in terms of implied volatility, need to be calibrated to market prices quickly and accurately on a regular basis. With this in mind we develop efficient methods {{for the evaluation of}} (i) vanilla options, (ii) implied volatility and (iii) common path-dependent options. Firstly, we derive a new numerical method for the classical problem of pricing vanilla options quickly in time-changed Brownian motion models. The method is based on ra- tional function approximations of the Black-Scholes formula. Detailed numerical results are given for a number of widely used models. In particular, we use the variance-gamma model, the CGMY model and the Heston model without correlation to illustrate our results. Comparison to the standard fast Fourier option pricing method with respect to speed appears to favour our newly developed method in the cases considered. Secondly, we use this method to derive a procedure to compute, for a given set of arbitrage-free European call option prices, the corresponding Black-Scholes implied volatility surface. In order to achieve this, rational function approximations of the inverse of the Black-Scholes formula are used. We are thus able to work out implied volatilities more efficiently than is possible using other common methods. Error estimates are presented {{for a wide range of}} parameters. Thirdly, we develop a new Monte Carlo variance reduction method to estimate the expectations of path-dependent functionals, such as first-passage times and occupation times, under a class of stochastic volatility models with jumps. The method is based on a recursive approximation of the rst-passage time probabilities and expected oc- cupation times of Levy bridge processes that relies in part on a randomisation of the time- parameter. We derive the explicit form of the recursive approximation in the case of bridge processes corresponding to the class of Levy processes with mixed-exponential jumps, and present a highly accurate numerical realisation. This class includes the linear Brownian motion, Kou's double-exponential jump-di usion model and the hyper-exponential jump- difusion model, and it is dense in the class of all Levy processes. We determine the rate of convergence of the randomisation method and con rm it numerically. Subsequently, we combine the randomisation method with a continuous Euler-Maruyama scheme to es- timate path-functionals under stochastic volatility models with jumps. Compared with standard Monte Carlo methods, we nd that the method is signi cantly more efficient. To illustrate the efficiency of the method, it is applied to the valuation of <b>range</b> <b>accruals</b> and barrier options. Open Acces...|$|R
40|$|Argumentative Reasoning Theory (ART) is {{a theory}} of {{knowledge}} representation, reasoning, explanation, and argument interaction. It is designed to support intelligent human-computer collaboration. ART provides the ability to represent reasoning {{in a form that}} is computable, intuitive, and amenable to discovery. By integrating Toulmin’s model of argumentation, Mann and Thompson’s Rhetorical Structure Theory, and Perelman and Olbrechts-Tyteca’s strategic forms of associative and dissociative reasoning, ART defines an ontology for representing and manipulating of argument structures. Arguments, when satisfied, are instantiated into a dynamic rhetorical network that represents the system’s model of the situation. Two modalities of instantiation are used: inferential instantiation is used when the claim is inferred from the ground; synthetic instantiation is used for descriptive argumentation where both ground and claim must be satisfied for the argument to be instantiated. The instantiation process maps arguments into the network using interaction links. Links are defined for a <b>range</b> interactions, including <b>accrual,</b> concomitance, backing, substantiation, dissociation, rebuttal, undercut, and confusion. Interaction detection may be accomplished using logical, ontological, and inventive-dissociative detection. Knowledge discovery is supported through logical and analogical means. Through ontologically normalized representation of argumentative knowledge, it becomes possible to detect the opportunity for analogical discovery...|$|R
40|$|We provide {{analytic}} pricing formulas for Fixed and Floating <b>Range</b> <b>Accrual</b> Notes {{within the}} multifactor Wishart affine framework which extends significantly the standard affine model. Using estimates for three short rate models, {{two of which}} are based on the Wishart process whilst the third one belongs to the standard affine framework, we price these structured products using the FFT methodology. Thanks to the Wishart tractability the hedge ratios are also easily computed. As the models are estimated on the same dataset, our results illustrate how the fit discrepancies (meaning differences in the likelihood functions) between models translate in terms of derivatives pricing errors, and we show that the models can produce different price evolutions for the <b>Range</b> <b>Accrual</b> Notes. The differences can be substantial and underline the importance of model risk both from a static and a dynamic perspective. These results are confirmed by an analysis performed at the hedge ratios level...|$|E
40|$|The {{purpose of}} this thesis is to compare the Hull-White short rate model to the Cheyette short rate model. The Cheyette short rate model is a {{stochastic}} volatility model, that is introduced to improve the fit of the implied volatility skew to the market skew. Both models are implemented with piecewise constant parameters to match the term structure. We calibrate the Cheyette model to the EURO, USD and KRW swaption markets and compare the calibration results to the Hull-White model. We propose an efficient implementation method {{to speed up the}} calibration process. In general we see that the Cheyette model gives indeed a better fit, in particular for the EURO and KRW markets. The models with calibrated parameters are used to price exotic interest rate derivatives by Monte Carlo simulation. Comparing the results of the Cheyette model to the results of the Hull-White model, can give insight in the skew and curvature impact on exotic interest rate derivatives. We consider digital caplets, digital caps, <b>range</b> <b>accrual</b> swaps, callable range acrruals and a callable remaining maturity swap. The price impact on digital caplets and digital caps are in line with static replication. By this we mean that the prices computed with static replication are better matched by the Cheyette model than by the Hull-White model. For the callable <b>range</b> <b>accrual</b> on LIBOR we have to be more careful, since a one-factor model cannot be calibrated to two market skews per option maturity. This implies that the price of the underlying <b>range</b> <b>accrual</b> is not in line with static replication, since we calibrate to co-terminal swaptions, while the underlying depends on the cap market. For the callable remaining maturity swap we do not encounter this issue, since the underlying depends on the same co-terminal swaption skews. For a callable RMS we observe that the Hull and White model underestimates the option price, compared to the Cheyette model. Numerical analysisApplied MathematicsElectrical Engineering, Mathematics and Computer Scienc...|$|E
40|$|Low market rates {{call for}} special types of debt instruments. This report {{discusses}} the tax questions presented by {{several of those}} instruments, including fixed-to-floating rate instruments, <b>range</b> <b>accrual</b> debt instruments, and callable step-up instruments. The authors note several ambiguities in the regulations regarding variable-rate and contingent payment debt instruments and call for clarification. They also explore some counterintuitive results of the technical operation of the regulations and argue that a possible explanation {{may be that the}} regulations were drafted during times of different market characteristics...|$|E
40|$|This paper first {{refers to}} the key concept of {{recognition}} of asset losses under the corporate tax law. The tax law basically restricts the loss deduction and imposes requirements of "settlements" with a fact of physical or monetary damage for the special loss deduction unless potential nonrecognized losses may be deducted under the accounting standards {{from the viewpoint of}} disclosure for asset fair values. This loss deduction rule is derived from the foreseeability and legal stability in calculation of taxable income. This paper secondly explains the content and legislative context of the recent amendments in the depreciation system and allowance expenses. Some allowance systems has been repealed in order to enlarge the tax base and increase the tax revenue, however, the accelerated depreciation, newly introduced system in the recent corporate tax reform, brought a broad accrual expense, where it caused an opposite result to the tax base. I would rather mention the background of the past tax reforms and suggest the <b>range</b> of estimated <b>accrual</b> expenses should be more broadened. Finally, this paper would clarify the contemporary signification in the loss deduction rule. ASBJ has issued the cumulative accounting standards for the global convergence, and is now required the final decision for the IFRS adoption. It would likely be said that harmonization between the accounting and tax enforcement would be continuously pursed through this convergence process. The loss deduction rule would have a vital role in the fair value measurement in tax accounting, where tax income and each tax item on a balance sheet are measured by an index with high accuracy and legal settlement...|$|R
40|$|After an {{introduce}} to {{theory of}} stochastic analysis used in financial mathematics the structured products and their pricing are {{studied in the}} present work. Particularly one type of barrier options (down-and-out call options) and one type of structured swaps (<b>range</b> <b>accrual</b> swaps) are focused. First the analytical formulae are derived and then numerical results of analytical formulae are compared with the results estimated {{on the basis of}} simulation Monte Carlo. In the final part of the work some variables like Greeks, duration, convexity and VaR used in quantitative analysis are mentioned...|$|E
40|$|As an {{important}} economic index, {{interest rates are}} assumed to be constant in the Black and Scholes model (1973); however, they actually fluctuate due to economic factors. Using a constant interest rate to evaluate derivatives in a stochastic model will produce biased results. This research derives the LIBOR market model with jump risks, assuming that interest rates follow a continuous time path and tend to jump in response to sudden economic shocks. We then use the LIBOR model with jump risk to price a <b>Range</b> <b>Accrual</b> Interest Rate Swap (RAIRS). Given that the multiple jump processes are independent, we employ numerical analysis to further demonstrate the influence of jump size, jump volatility, and jump frequency on the pricing of RAIRS. Our results show a negative relation between jump size, jump frequency, and the swap rate of RAIRS, but a positive relation between jump volatility and the swap rate of RAIRS. When new information emerges, the resulting increase in jump size reduces the value of LIBOR, which in turn lowers the value of RAIRS. Similarly, the value of RAIRS declines when the jump frequency of LIBOR increases. This is because jump frequency is associated with higher uncertainty risk, and the market pays out a premium for bearing such risk. On the other hand, when jump volatility increases, both parties must agree to a higher swap rate because the floating rate payer is subsidized by the fixed rate payer for bearing risk...|$|E

