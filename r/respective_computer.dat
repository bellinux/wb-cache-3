24|35|Public
50|$|A {{divergence}} between, {{on the one}} hand, decisions T 163/85 and T 190/94, {{according to}} which a technical effect on a physical entity {{in the real world}} is required (to escape the exclusion under Article 52(2)(c) and (3)), and, on the other hand, T 125/01 and T 424/03, according to which the technical effects can be essentially confined to the <b>respective</b> <b>computer</b> programs, is cited as justifying this question.|$|E
50|$|Four {{computers}} {{were the first}} connected in the original ARPAnet. They were located in the <b>respective</b> <b>computer</b> research labs of UCLA, Stanford, UC Santa Barbara, and the University of Utah. ARPAnet protected {{the flow of information}} between military installations by creating a network of geographically separated computers that could exchange information via a newly developed protocol (rule for how computers interact) called NCP (Network Control Protocol). One opposing view to ARPAnet's origins comes from Charles M. Herzfeld, the former director of ARPA. Herzfeld claimed that ARPAnet was not created {{as a result of a}} military need. He felt that the frustration from investigators across the country of only having a limited number of supercomputers for research caused them to create ARPAnet so that they could be connected while in different locations throughout the country. This made it easier to communicate the possible nuclear threats. However, as early as the mid 1980s, Soviet intelligence had access to Western computer networks.|$|E
40|$|The {{problem of}} {{evaluating}} clustering algorithms and their <b>respective</b> <b>computer</b> programs {{for use in}} a preprocessing step for classification is addressed. In clustering for classification the probability of correct classification is suggested as the ultimate measure of accuracy on training data. A means of implementing this criterion and a measure of cluster purity are discussed. Examples are given. A procedure for cluster labeling that is based on cluster purity and sample size is presented...|$|E
40|$|In this paper, {{we aim at}} {{realization}} of grid computing based on CORBA, which is practical for grid computing because the operation of CORBA is independent from a platform. One {{of the problems in}} realizing grid computing is the un-uniformity in the performance of <b>respective</b> <b>computers.</b> In this paper, we propose the dispatch algorithm that assigns the tasks adaptively considering the performance of the <b>respective</b> <b>computers.</b> In order to evaluate the algorithm, we applied it to the problem of parallel genetic algorithm. From results, we confirmed that we could succeed in reducing the processing time among different computers...|$|R
50|$|Both players sit in {{a typical}} chess-playing room, {{equipped}} with fast PCs of equal hardware strength. It {{is the duty of}} the tournament organizers {{to make sure that the}} players are familiar with the pertinent hardware and software. Unlike the traditional face-to-face chess, the players usually face their <b>respective</b> <b>computers.</b> Each player is typically allotted one hour of thinking time (as was the time control used in all Advanced Chess events in León), though the particular tournament regulations may vary regarding this matter.|$|R
50|$|Universities may confer {{degrees of}} ICS and CIS, {{not to be}} {{confused}} with a more specific Bachelor of <b>Computer</b> Science or <b>respective</b> graduate <b>Computer</b> Science degrees.|$|R
40|$|During recent years, {{biological}} {{research has}} become increasingly based on large-scale experimentation such that data may be collected on an organismic scale. These data are voluminous, they are often very noisy, and their interpretation � and {{the configuration of the}} experiments involved � necessitates complex computer analysis. The <b>respective</b> <b>computer</b> methods are themselves an object of intensive research in a scientific discipline known as "computational biology" or "bioinformatics. " Computational biology has a wide variety of facets that range from experiment configuration and low-level data analysis to computer-generated hypotheses...|$|E
40|$|Positive Matrix Factorization (PMF) is {{a multivariate}} factor {{analysis}} technique used successfully among {{others at the}} US Environmental Protection Agency for the chemometric evaluation and modelling of environmental data sets. Compared to other methods it offers some advantage that consent to better resolve the problem under analysis. In this report, the algorithm to solve PMF and the <b>respective</b> <b>computer</b> application, PMF 2, is illustrated and, in particular, different parameters involved in the computation are examined. Finally, a first application study on PMF 2 parameters setting is conducted {{with the help of}} a real environmental data-set produced in the laboratories of the JRC Rural, Water and Ecosystem Resource Unit. JRC. H. 5 -Rural, water and ecosystem resource...|$|E
40|$|Abstract — At our {{institute}} {{we built}} a variety of robots. As these robots are quite different as well in size, shape and in actuation principle {{it would be very}} time consuming and inefficient to build a computer and hardware architecture especially tailored to the specific robot. In this paper it will be described how common aspects in robot control can be identified and how a modular software framework and a <b>respective</b> <b>computer</b> architecture can be mapped to modular components on the hardware side. A decentralized computer architecture based on embedded PC systems connected to local controller modules via CAN-Bus was developed. The requirements and restrictions that {{led to the development of}} these controller modules and their associated power amplifier boards will be described I...|$|E
50|$|Application sharing is {{an element}} of remote access, falling under the {{collaborative}} software umbrella, that enables two or more users to access a shared application or document from their <b>respective</b> <b>computers</b> simultaneously in real time. Generally, the shared application or document will be running on a host computer, and remote access to the shared content will be provided to other users by the host user. To transfer one application from one computer to another, The application must reside on only one of the machines connected with each other.|$|R
40|$|This paper {{explores the}} use of the TCP {{timestamp}} option and associated timestamp values to comprehend how different operating systems react to manipulated timestamp values. This is valuable knowledge for an intrusion detection system (IDS) or intrusion prevention system (IPS) to possess and implement to avoid evasions that employ TCP timestamp value mutations. Introduction to Timestamps The TCP timestamp option is used by many current operating systems. There are two timestamp values associated with the TCP timestamp options field – the sender’s timestamp followed by the receiver’s echoed timestamp. Each timestamp value represents the <b>respective</b> <b>computer’s</b> “up time”, the number of units that have passed since the last reboot. According to RFC 1323 “TC...|$|R
40|$|This paper {{presents}} {{a new system}} based on a wireless 6 DOFs interaction device, which is able to combine both traditional interaction possibilities that are required by common legacy point-and-click applications, with immersive point-and-interact techniques within a virtual environment. This device, associated with both standard and stereoscopic displays connected to their <b>respective</b> <b>computers,</b> defines an innovative type of distributed platform which is directly compatible with traditional legacy applications that can be augmented with an immersive environment, enabling the user to steer and control hybrid 2 D/ 3 D environments. Those concepts are illustrated by presenting an application that we are developing in the multidisciplinary context of engineering, a typical situation in which supporting the pre-existing user's environment is mandatory for the take-up and acceptance of innovative techniques from virtual reality...|$|R
40|$|Abstract—The present {{paper is}} devoted to the {{evaluation}} of energy detection based spectrum sensing over different multipath fading and shadowing conditions. This is realized by means of a unified and versatile approach that is based on the particularly flexible mixture gamma distribution. To this end, novel analytic expressions are firstly derived for the probability of detection over MG fading channels for the conventional single-channel communication scenario. These expressions are subsequently em-ployed in deriving closed-form expressions for the case of square-law combining and square-law selection diversity methods. The validity of the offered expressions is verified through comparisons with results from <b>respective</b> <b>computer</b> simulations. Furthermore, they are employed in analyzing the performance of energy detection over multipath fading, shadowing and composite fading conditions, which provides useful insighs on the performance and design of future cognitive radio based communication systems. I...|$|E
40|$|The {{fission product}} release {{out of the}} core of a high {{temperature}} reactor during hypothetical heat up accidents has been investigated. This has been attained on support to a physical model, taking into account the micro- and macro-structures of the pyrolytical and graphitical reactor components as well as renouncing an introduction of effektive diffusion coefficients by the description of the fission products transport through the coated particle layers and the fuel elements and renouncing an assuption of the spontaneously adsorption-desorption equilibrium {{on the surface of the}} fuel elements. The solving method and the <b>respective</b> <b>computer</b> codes were also developped. In addition the theoretically calculated and the experimentally determined results regarding the caesium release from single coated particles as well as fuel elements at accident temperatures were compared. Finally the caesium release from the core of the PNP- 500 reactor during a heat up accident has been estimated and discussed...|$|E
40|$|This paper {{provides}} an analytic performance {{evaluation of the}} bit error rate (BER) of underlay decode-and-forward cognitive networks with best relay selection over Rayleigh multipath fading channels. A generalized BER expression valid for arbitrary operational parameters is firstly presented {{in the form of}} a single integral, which is then employed for determining the diversity order and coding gain for different best relay selection scenarios. Furthermore, a novel and highly accurate closed-form approximate BER expression is derived for the specific case where relays are located relatively close to each other. The presented results are rather convenient to handle both analytically and numerically, while they are shown to be in good agreement with results from <b>respective</b> <b>computer</b> simulations. In addition, it is shown that as in the case of conventional relaying networks, the behaviour of underlay relaying cognitive networks with best relay selection depends significantly on the number of involved relays...|$|E
50|$|The game {{consists}} of four different game modes, each featuring a different character from a <b>respective</b> Sony <b>Computer</b> Entertainment video game franchise. This includes Nathan Drake from Uncharted, Sackboy from LittleBigPlanet, Cole MacGrath from Infamous, and Kat from Gravity Rush. The four mini-games all loosely play as endless runners, though each have separate elements from their respective series as well; Nathan Drake runs though ancient ruins, Sack Boy races through levels similarly to LittleBigPlanet Karting, and Kat retains her ability to shift gravity.|$|R
2500|$|In June 2015, it {{was decided}} that the team match format was to be {{replaced}} by a two-game match (two days per game) between the winners of <b>respective</b> human and <b>computer</b> qualifying tournaments sponsored by the JSA and telecommunications company Dwango. Takayuki Yamazaki and the program [...] "Ponanza" [...] started the best-of-two game 1st Denō Match in April 2016, and Yamazaki lost the match 20.|$|R
2500|$|The {{music video}} for [...] "Hunter" [...] was {{directed}} by longtime collaborator Paul White from Me Company, the design firm that produced the artwork of Homogenic and Post, and their <b>respective</b> singles. <b>Computer</b> animation was handled by Digital Domain. The live-action portion of the video was shot in London in 12 takes, with Björk performing {{in front of a}} green screen; she wore makeup to simulate baldness and tracking markers were applied to her head and face for subsequent computer graphics work. A second performance was later shot with the singer's face marked up with infrared dots as a reference for animators to create convincing facial contortions, and a paper clay polar bear head was scanned next to Björk's head for modeling guidelines.|$|R
40|$|The present {{paper is}} devoted to the {{evaluation}} of energy detection based spectrum sensing over different multipath fading and shadowing conditions. This is realized by means of a unified and versatile approach that is based on the particularly flexible mixture gamma distribution. To this end, novel analytic expressions are firstly derived for the probability of detection over MG fading channels for the conventional single-channel communication scenario. These expressions are subsequently employed in deriving closed-form expressions for the case of square-law combining and square-law selection diversity methods. The validity of the offered expressions is verified through comparisons with results from <b>respective</b> <b>computer</b> simulations. Furthermore, they are employed in analyzing the performance of energy detection over multipath fading, shadowing and composite fading conditions, which provides useful insighs on the performance and design of future cognitive radio based communication systems. Comment: To appear in the IEEE WiMob 2015 conference proceeding...|$|E
40|$|The {{computer}} aided {{engineering and}} the <b>respective</b> <b>computer</b> aided design tools compose a modern mechanical modelling environment for the textile materials. The numerical mechanical models of the textile structures are a strong tool for the in-depth study of the mechanical properties and the behaviour of the textiles. The precision of these models {{in terms of their}} accuracy in representing the exact geometry of the real textile structures is the fundamental factor affecting the overall success of the idealisation. This paper discusses older traditional analytical models (Peirce, Saw-tooth, Kemp) as well as some variations of these fundamental models. Their numerical solutions are successfully compared to the experimental measurements of the yarn longitudinal deformation parameters using microscopic and digital image processing techniques. The results of the analytical models are compared with the actual measurements and the more precise models are indicated. © Emerald Group Publishing Limited...|$|E
40|$|Approved {{for public}} release; {{distribution}} unlimited. Efficient performance and high throughput {{are the major}} goals of the network performance management. How can we achieve these goal? First, {{it is necessary to}} know the network traffic situations. This thesis research implements a network traffic query utility for users to monitor the network traffic situations. There are several network traffic situation reports available for users to understand the traffic situation over the network. The network users also can query the network/system status of their <b>respective</b> <b>computer</b> hosts. This information would help users to diagnose the network problems. Realizing the network traffic situation, manager and users can schedule the network applications, reconfigure the network configuration, or reallocate the network resources to improve the network performance and throughput. The Naval Postgraduate School campus network will be used as an example to demonstrate and illustrate the usage of this network traffic query utility. [URL] R. O. C. Arm...|$|E
40|$|In the {{discipline}} of librarianship {{there is very little}} existing research from which conclusions regarding attitudes toward computers and related technology can be drawn. Furthermore, there is no significant data available which indicates that attitudes differ between various groups or types of librarians. It is reasonable to assume that librarians' attitudes toward computers vary. This study examines a group of academic librarians and a group of public librarians and tests for significant differences in their <b>respective</b> attitudes toward <b>computers,</b> desktop publishing systems and expert systems...|$|R
40|$|In this {{preliminary}} study eighteen p-substituted benzoic acid [(5 -nitro-thiophen- 2 -yl) -methylene]-hydrazides with antimicrobial activity were evaluated against multidrug-resistant Staphylococcus aureus, correlating the three-dimensional {{characteristics of the}} ligands with their <b>respective</b> bioactivities. The <b>computer</b> programs Sybyl and CORINA were used, respectively, for the design and three-dimensional conversion of the ligands. Molecular interaction fields were calculated using GRID program. Calculations using Volsurf resulted in a statistically consistent model with 48 structural descriptors showing that hydrophobicity is a fundamental property in the analyzed biological response. CAPESFAPESPCNP...|$|R
40|$|Dimirovski, Georgi M. (Dogus Author) [...] Conference full title: 2007 American Control Conference : New York, NY, USA, July 9 - 13, 2007 A {{class of}} {{uncertain}} time-varying complex dynamical networks is studied {{in this paper}} and a model introduced. On the grounds of that model then the locally and globally decentralized synchronization of these networks are thoroughly investigated. Several network synchronization criteria are deduced. Especially, the assumptions adopted and decentralized control laws designed are considerably simple. An illustrative example along with the <b>respective</b> numerical and <b>computer</b> simulation results is also given to demonstrate {{the effectiveness of the}} proposed synchronization control synthesis...|$|R
40|$|Where {{customers}} with different membership and position, use computers {{as in the}} university network systems, it often takes much time and efforts for them {{to cope with the}} change of the system management. This is because the requirements for the <b>respective</b> <b>computer</b> usage are different in the network and security policies. In this paper, a new destination addressing control system (DACS) scheme for the university network services is proposed. The DACS Scheme performs the network services efficiently through the communication management of a client. As the characteristic of DACS Scheme, only the setup modification is required by a system administrator, when the configuration change is needed in the network server. Then, the setup modification is unnecessary by a customer, which shows a merit for both a system administrator and a customer. This paper describes the instruction and the prototype for DACS Protocol as the implementation of DACS Scheme. Then, the simplicity of the system management in DACS Scheme, is examined from the customer and the system administrator viewpoints. Key words: destination nat, packet filtering, name resolution 1...|$|E
40|$|Georgi M. Dimirovski (Dogus Author) [...] Full conference title: 3 rd IEEE Multi-conference on Systems and Control: IEEE International Conference on Control Applications; IEEE International Symposium on Intelligent Control: July, 8 - 10, 2009. Saint Petersburg, RussiaSynchronization {{problem for}} a class of complex {{networks}} consisting of N nonlinear dynamical nodes that are nonlinearly and diffusively coupled is solved in here. The global synchronization of such networks is investigated via Lyapunov stability theory. Under assumptions that measurements full state vectors of each node are available and coupling coefficients are known, a family of decentralized nonlinear feedback controllers are designed to globally synchronize the network system. When coupling coefficients are unavailable, an adaptive mechanism is introduced to synthesize a family of decentralized adaptive controllers which guarantee the global synchronization. An illustrative example with Lorenz node systems along with the <b>respective</b> <b>computer</b> simulation results is given to demonstrate {{the effectiveness of the}} proposed solution to controlled synchronization. This work {{was supported in part by}} the NSF of the P. R. China (Grant 60574013) and the Ministry of Education& Science of the R. Macedonia (Grant 14 - 3154 / 1 / 17. 12. 2007) ...|$|E
40|$|This paper {{presents}} {{the final results}} of a pilot-project, for mapping an accurate geoid of the State of Israel. The purpose {{of the project was}} to develop a feasible methodology, assemble all necessary data, design and test field procedures and finally to work out a suitable analysis algorithm, including the <b>respective</b> <b>computer</b> programs. The project was funded and supported by the Survey of Israel over a period of five years between 1994 and 1999. An area of about 600 -sq. km on and around the Carmel Mountains served as a field laboratory and proving ground. The ultimate goal was to render a geoid map of the pilot area with a one-sigma accuracy of 4 cm. The geoid map was compiled from three independent data sources that complement each other: (a) Measured geoid undulations (indirectly- by GPS and trigonometric leveling) at a network of control points. The network density was set intentionally high by a factor of three to four in order to provide means for testing the quality of the map. (b) A global gravity model of the highest order available. Over the years 1994 - 1999 a number of gravity models were used, beginning with OSU' 91, followed by EGM' 9...|$|E
40|$|We proposes an ultra {{low power}} {{wideband}} spectrum sensing architecture by utilizing a one-bit quantization at the cognitive radio (CR) receiver. The {{impact of this}} aggressive quantization is quantified and it is shown that the proposed method is robust to low signal-to-noise ratios (SNR). We derive closed-form expressions for both false alarm and detection probabilities. The sensing performance and the analytical results are assessed through comparisons with <b>respective</b> results from <b>computer</b> simulations. The {{results indicate that the}} proposed method provides significant saving in power, complexity, and sensing period on the account of an acceptable range of performance degradation...|$|R
40|$|This {{exploratory}} {{study investigated the}} influence of two recreational computer games on children 2 ̆ 7 s subsequent performance on computer-based instructional tasks. Children were assigned to three groups: two were invited to play their <b>respective</b> recreational <b>computer</b> games, and the third acted as a control group. All three groups then worked on {{a common set of}} educational tasks from environmental education software. The three groups 2 ̆ 7 performances on a set of educational tasks were compared using quantitative analysis for speed and correct solutions, and then qualitatively for the cognitive manoeuvres engaged in to accomplish the tasks. The findings suggest that playing recreational computer games may influence children 2 ̆ 7 s performance on subsequent computer-based educational tasks. However, the extent of this influence depended on how closely the recreational computer game types matched the design of the tasks in the educational software. The cognitive manoeuvres used by game players also depended on the types of games played during the learning phase. Linear cause-and-effect games tended to encourage means-end analysis strategy, whereas adventure games encouraged inferential and proactive thinking. Though {{the findings of this study}} are encouraging, further studies need to be undertaken to replicate the results...|$|R
40|$|PostScript ® is a {{trademark}} of Adobe Systems Incorporated. Microsoft ® is a US registered trademark of Microsoft Corporation. All other product names mentioned herein may be trademarks of their <b>respective</b> companies. Proprietary <b>computer</b> software. Valid license from HP required for possession, use or copying. Consistent with FAR 12. 211 and 12. 212, Commercial Computer Software, Computer Software Documentation, and Technical Data for Commercial Items are licensed to the U. S. Government under vendor's standard commercial license. The information contained herein {{is subject to}} change without notice. The only warranties for HP products and services are {{set forth in the}} express warranty statements accompanying such products and services. Nothing herein should be construed as constituting an additional warranty. HP shall not be liable fo...|$|R
40|$|This {{research}} {{deals with}} computer-generated simulations of urban or natural environments; these are increasingly utilized {{in planning and}} design {{as well as in}} perception research. While the <b>respective</b> <b>computer</b> tools have become highly sophisticated, the quality and utility of such presentation technologies still need validation. This issue was addressed in a series of lab and field studies. In study , variations of a simulation of a suburban environment were presented to respondents (N= 120) to investigate the effects of lighting (daysun/ day-fog / night), shadows(yes/no) and sound (on/off) on perceived simulation quality. In study , 50 subjects were presented with a computer simulation and a video-recording of the same environment. In study , the focus is on a comparison between judgments about the actual environment (collected during a site visit) and its computer-simulation, for both day and night conditions (N= 80). In all studies, comprehensive questionnaires measuring cognitive and affective aspects by quantitative and qualitative means were employed. These include: assessments of realism, content recall, comprehension/legibility, appreciation of the environment, and preferences for presentation modes. Main results so far are that simulations are perceived as valid and acceptable but not fully matching the perceptions induced by the respective reality nor the realism of video recordings; that appraisals differ significantly according to lighting and time-of-day conditions; and tha...|$|E
40|$|Subject of investigation: {{production}} {{operation of}} the cylindrical and surface grinding with the periphery of a straight wheel. Purpose of the work: development of calculation methods for selection of the grinding wheel characteristic and cutting conditions to provide for burn-free grinding of parts. The theoretical results include {{the determination of the}} interconnection between the wheel characteristic and the parameters of force interaction of the wheel and blank, the development of a thermophysical model of the grinding process accounting for the interconnection between the wheel characteristic and the cutting conditions, {{and the development of a}} burn-free feed. Developed are the standard charts for assigning the wheel characteristic and burn-free grinding conditions. The general methods are improved for setting the norms of grinding operations for general mechanical engineering standards. The <b>respective</b> <b>computer</b> implementation is introduced in computer-aided design "Norma". Introduced are the general mechanical engineering standards for time and cutting conditions as well as computer-aided standardization systems. The new methods increase the efficiency by 30 %. Field of application: plants of the automobile and other industries where use is made of the cylindrical and surface grinding with the periphery of a straight wheel; design agenciesAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|E
40|$|Spatial scaling, or an {{understanding}} of how distances in different-sized spaces relate to each other, is fundamental for many spatial tasks and relevant for success in numerous professions. Previous research has suggested that adults use mental transformation strategies to mentally scale spatial input, as indicated by linear increases in response times and accuracies with larger scaling magnitudes. However, prior research has not accounted for possible difficulties in encoding spatial information within smaller spaces. Thus, the present study used a discrimination task in which we systematically pitted absolute size of the spaces against scaling magnitude. Adults (N = 48) were presented with 2 pictures, side-by-side on a computer display, each of which contained a target. Adults were asked to decide whether the targets were in the same position or not, by pressing the <b>respective</b> <b>computer</b> key. In the constant-large condition, the constant space was kept large, whereas the size of the other space was variable and smaller. In the constant-small condition, the constant space was small, whereas the size of the other space was variable and larger. Irrespective of condition, adults' discrimination performance (d-primes) and response times were linear functions of scaling magnitude, supporting the notion that analog imagery strategies are used in spatial scaling. (PsycINFO Database Recor...|$|E
40|$|Accurate fading {{characterization}} {{and channel}} capacity determination are {{of paramount importance}} in both conventional and emerging communication systems. The present work addresses the nonlinearity of the propagation medium {{and its effects on}} the channel capacity. Such fading conditions are first characterized using information theoretic measures, namely, Shannon entropy, cross entropy and relative entropy. The corresponding effects on the channel capacity with and without power adaptation are then analyzed. Closed-form expressions are derived and validated through comparisons with <b>respective</b> results from <b>computer</b> simulations. It is shown that the effects of fading nonlinearities are significantly larger than those of fading parameters such as the scattered-wave power ratio, and the correlation coefficient between the in-phase and quadrature components in each cluster of multipath components. Comment: Latest/Priprint versio...|$|R
40|$|Blockchain is {{essentially}} a set of protocols previously known as a “distributed ledger” system. An Economist article published in March 2016, describes it well: Blockchain is… a database that is maintained not by a single actor, such as a bank, but collaboratively {{by a number of}} participants. Their <b>respective</b> <b>computers</b> regularly agree on how to update the database using a “consensus mechanism”, after which the modifications they have settled on are rendered unchangeable with the help of complex cryptography. Once information has been immortalised in this way, it can be used as proof of ownership. The reason why this has become such a hot topic is that technologists and business people see, in these basic characteristics, immense potential for using blockchain beyond the financial services sector where it was conceived, in many different areas of the economy from energy to health, from transport to music and even as a form of digital democracy in society as a whole. The key characteristics that are attracting so much attention are the efficiencies to be derived from a network that is distributed and not centralised, combined with the permanence of the record or ledger at its heart that is cryptographically secured. This attracts those that see profound ideological implications in something that is an alternative to systems that are controlled from a single central point. For the music industry, some of these characterstics might mean that creators could, in theory, radically reduce the cost of unit transactions, thus potentially enabling content licensing for very small sums to be viable. Equally, the transparent record keeping inherent in the system has the potential to lead incrementally {{to the creation of a}} Global Repertoire Database (GRD), a kind of holy grail of the digital music industry. Some other functions that potentially could be performed on blockchain networks could relate to the establishment, validation and tracking of identities, so that individuals could be uniquely identified (e. g., as the performer on a recording). Equally good behaviour in, for example, transactions or in rights distribution speediness could contribute to developing an online reputation, which in turn could effect the sorts of terms that are made available for a particular individual or business. This paper takes a look at how bitcoin and blockchain captured the public imagination, some of the technology issues at the heart of blockchain and a key dispute that is taking the bitcoin community in different directions and has a bearing on any possible music applications. The paper explores the initially superficial ways in which blockchain represented an attractive technology and then captures some of the voices that have been generating so much deeper interest in the subject in relation to music. The paper concludes with an assessment of opportunities and obstacles...|$|R
2500|$|As the {{movement}} began to slow down, many acts began to falter and broke up. The {{popularity of the}} pop group the Spice Girls {{has been seen as}} having [...] "snatched the spirit of the age from those responsible for Britpop." [...] While established acts struggled, attention began to turn to the likes of Radiohead and The Verve, who had been previously overlooked by the British media. These two bands—in particular Radiohead—showed considerably more esoteric influences from the 1960s and 1970s that were uncommon among earlier Britpop acts. In 1997, Radiohead and The Verve released their <b>respective</b> efforts OK <b>Computer</b> and Urban Hymns, both of which were widely acclaimed. Post-Britpop bands like Travis, Stereophonics and Coldplay, influenced by Britpop acts, particularly Oasis, with more introspective lyrics, were some of the most successful rock acts of the late 1990s and early 2000s.|$|R
