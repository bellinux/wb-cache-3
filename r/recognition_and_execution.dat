15|10000|Public
50|$|Temescal Canyon High School has an extraordinary, top ranking ASB Program. The Associated Student Body is {{responsible}} for planning many school events, academic recognition, teacher appreciation, Link Crew (Freshmen involvement program), and Titan Pride (including blue hole). Its leaders devote their time to make Temescal Canyon a place where all students and staff feel safe, empowered, encouraged and supported. Over the past four years, a new class was added each year resulting in four current leadership classes. The House of Representatives class {{is responsible}} for all academic <b>recognition</b> <b>and</b> <b>execution</b> of our Renaissance program. This class is run by Ms. Melissa Fink. The Executive Assembly class {{is responsible for}} running the ASB program, sports recognition, Titan pride, Winter Formal, pep rallies, and sound and video. This class is run by Mrs. Cari Strange. The Link Crew class is responsible for assisting the Freshmen class in transitioning to their move into high school. They strive to make the freshmen feel welcome to Temescal and support them through activities, tutoring, etc. This class is run by Mrs. Jill Carter. The Senate class is responsible for staff appreciation, special activities, peer buddies (special education program), Homecoming, community service, recycling program, and random acts of kindness (RAOK). This class is also run by Mrs. Cari Strange.|$|E
40|$|After {{describing}} {{the evolution of}} the Quebec private international law rules concerning the execution of foreign judgments (Section I), this paper outlines the current procedures of recognition (Section II). Section III explains the statutory provisions designed to facilitate <b>recognition</b> <b>and</b> <b>execution</b> of foreign judgments or to prevent it. In particular, the paper focusses on recent efforts in Quebec towards international cooperation...|$|E
40|$|The {{purpose of}} the {{following}} commentary is to address the relative question of the applicable law to the formal validity of a mortis causa provision to {{the basis of the}} July Fourth, 2012 Regulation 650 / 2012 (Regulation 650 / 2012 or Regulation) of the European Parliament and Council, concerning the competence, applicable law, <b>recognition</b> <b>and</b> <b>execution</b> of resoluitions, acceptance and execution of public documents in the field of mortis causa inheritance and {{to the creation of a}} European certificate of inheritance...|$|E
40|$|Abstract. This paper proposes an {{embedded}} {{face recognition}} system solution. The core of hardware {{architecture of the}} system is TMS 320 DM 642 digital signal processor (DSP). The face recognition algorithm of the system mainly comprises improved face detection algorithm which is based on skin color, Gabor wavelet feature extraction algorithm, Principal Component Analysis (PCA) algorithm and nearest neighbor classifier algorithm. The results of testing on <b>recognition</b> efficiency <b>and</b> <b>execution</b> time show that the system can work stably <b>and</b> realize face <b>recognition</b> quickly <b>and</b> accurately...|$|R
40|$|We {{describe}} {{a variety of}} machine-learning techniques that are being applied to social multiuser human [...] robot interaction using a robot bartender in our scenario. We first present a data-driven approach to social state recognition based on supervised learning. We then {{describe a}}n approach to social skills execution—that is, action selection for generating socially appropriate robot behavior—which is based on reinforcement learning, using a data-driven simulation of multiple users to train execution policies for social skills. Next, we describe how these components for social state <b>recognition</b> <b>and</b> skills <b>execution</b> have been integrated into an end-to-end robot bartender system, and we discuss {{the results of a}} user evaluation. Finally, we present an alternative unsupervised learning framework that combines social state <b>recognition</b> <b>and</b> social skills <b>execution</b> based on hierarchical Dirichlet processes and an infinite POMDP interaction manager. The models make use of data from both human [...] human interactions collected in a number of German bars and human [...] robot interactions recorded in the evaluation of an initial version of the system...|$|R
40|$|This paper {{presents}} a fully automated system for automatic assembly of aluminum profile constructions. This high grade of automation {{of the entire}} process chain requires novel strategies in <b>recognition,</b> planning <b>and</b> <b>execution.</b> The system includes an assembly sequence planner integrated with a grasp planning tool, a knowledge-based reasoning method, a skill-based code generation, and an error tolerant execution engine. The modular structure of the system allows its adaptation to new products, which can prove especially useful for SMEs producing small lot sizes. The system is robust and stable, as demonstrated with the repeated execution of different geometric assemblies...|$|R
40|$|SummaryStudies in nonhuman {{and human}} {{primates}} {{have demonstrated that}} sound-producing actions are mapped on the same mirror circuits that are activated during the visual <b>recognition</b> <b>and</b> <b>execution</b> of actions [1 – 12]. However, no causative link between the auditory <b>recognition</b> <b>and</b> <b>execution</b> of actions has been provided thus far. Here, we sought to determine whether patients with apraxia, who are by definition impaired in performing specific gestures, are also impaired in recognizing sounds specifically linked to human actions. Twenty-eight left-hemisphere-damaged patients with or without limb and/or buccofacial apraxia and seven right-hemisphere-damaged patients with no apraxia were asked to match sounds evoking human-related actions or nonhuman action sounds with specific visual pictures. Hand and mouth action-related sound recognition were specifically impaired in limb and buccofacial apraxia patients, respectively. Lesional mapping revealed that the left frontoparietal cortex is crucial for recognizing the sound of limb movements. By contrast, the left inferior frontal gyrus and adjacent insular cortex are causatively associated with recognition of buccofacial-related action sounds. These behavioral and neural double dissociations indicate that a left-lateralized multimodal mirror network is {{actively involved in the}} body-part-specific motor mapping of limb and mouth action-related sounds, {{as well as in the}} execution of the very same actions...|$|E
40|$|Studies in nonhuman {{and human}} {{primates}} {{have demonstrated that}} sound-producing actions are mapped on the same mirror circuits that are activated during the visual <b>recognition</b> <b>and</b> <b>execution</b> of actions [1 - 12]. However, no causative link between the auditory <b>recognition</b> <b>and</b> <b>execution</b> of actions has been provided thus far. Here, we sought to determine whether patients with apraxia, who are by definition impaired in performing specific gestures, are also impaired in recognizing sounds specifically linked to human actions. Twenty-eight left-hemisphere-damaged patients with or without limb and/or buccofacial apraxia and seven right-hemisphere-damaged patients with no apraxia were asked to match sounds evoking human-related actions or nonhuman action sounds with specific visual pictures. Hand and mouth action-related sound recognition were specifically impaired in limb and buccofacial apraxia patients, respectively. Lesional mapping revealed that the left frontoparietal cortex is crucial for recognizing the sound of limb movements. By contrast, the left inferior frontal gyrus and adjacent insular cortex are causatively associated with recognition of buccofacial-related action sounds. These behavioral and neural double dissociations indicate that a left-lateralized multimodal mirror network is {{actively involved in the}} body-part-specific motor mapping of limb and mouth action-related sounds, {{as well as in the}} execution of the very same actions. © 2008 Elsevier Ltd. All rights reserved...|$|E
40|$|Studies in nonhuman {{and human}} {{primates}} have demon-strated that sound-producing actions are mapped {{on the same}} mirror circuits that are activated during the visual rec-ognition and execution of actions [1 – 12]. However, no caus-ative link between the auditory <b>recognition</b> <b>and</b> <b>execution</b> of actions has been provided thus far. Here, we sought to deter-mine whether patients with apraxia, who are by definition impaired in performing specific gestures, are also impaired in recognizing sounds specifically linked to human actions. Twenty-eight left-hemisphere-damaged patients with or without limb and/or buccofacial apraxia and seven right-hemisphere-damaged patients with no apraxia were asked to match sounds evoking human-related actions or nonhu-man action sounds with specific visual pictures. Hand and mouth action-related sound recognitionwere specifically im...|$|E
40|$|Mobile devices {{will become}} an {{important}} platform for Internet access. Due to size constraints, in many circumstances speech is the most desirable mode of input. We have developed a system for spoken query based web navigation and searching. The spoken query is recorded by a lightweight client and transmitted to a server where the computationally intensive continuous speech <b>recognition</b> <b>and</b> query <b>execution</b> are performed. Lightweight clients have been developed that can either be a small downloadable Active X component running within a browser or a small application running on a handheld PocketPC. Through these interfaces, users can search for contents in an Encarta encyclopedia, content of a particular website, or navigate to popular websites...|$|R
40|$|Abstract — In this paper, {{we present}} a system for vision-based grasp <b>recognition,</b> mapping <b>and</b> <b>execution</b> on a {{humanoid}} robot to provide an intuitive and natural communication channel between humans and humanoids. This channel enables a human user to teach a robot how to grasp an object. The system comprises three components: human upper body motion capture system which provides the approaching direction towards an object, hand pose estimation <b>and</b> grasp <b>recognition</b> system, which provides the grasp type performed by the human {{as well as a}} grasp mapping <b>and</b> <b>execution</b> system for grasp reproduction on a humanoid robot with five-fingered hands. All three components are real-time and markerless. Once an object is reached, the hand posture is estimated, including hand orientation and grasp type. For the execution on a robot, hand posture and approach movement are mapped and optimized according to the kinematic limitations of the robot. Experimental results are performed on the humanoid robot ARMAR-IIIb. I...|$|R
40|$|The rise of {{ubiquitous}} computing systems in our environment is engendering a strong need for novel approaches of human-computer interaction. Either for ex-tending the existing {{range of possibilities}} and services available to people or for providing assistance the ones with limited conditions. Human Activity Recognition (HAR) is playing {{a central role in}} this task by offering the input for the development of more interactive and cognitive environments. This has motivated the organiza-tion of the ESANN 2013 Special Session in Human Activity <b>and</b> Motion Disorder <b>Recognition</b> <b>and</b> the <b>execution</b> of a competition in HAR. Here, a compilation of the most recent proposals in the area are exposed accompanied by the results of the contest calling for innovative approaches to recognize activities of daily living (ADL) from a recently published data set. ...|$|R
40|$|Part 3 : Big and Open DataInternational audienceOperational {{business}} intelligence (OpBI) integrates data of business processes to analyse their performance {{in relation to}} organizational goals. The consequent decision-making concerns a timely <b>recognition</b> <b>and</b> <b>execution</b> of actions to maintain performant business processes. OpBI systems can be designed according to a firm-specific definition of requirements guided by considerations from business model, business process and information system perspective. However, there is no approach to link the design of OpBI jointly with characteristics of business models and business processes, yet. The paper uses therefore an action research method and proposes a business approach that combines e 3 value with the work system framework to set up conceptual application designs for an OpBI-reliant decision support. We report on results of a long-term research project to demonstrate the development and application of our approach in four different business scenarios. The findings include implications towards a business-oriented application design of OpBI systems...|$|E
40|$|Humans {{can perform}} a {{multitude}} of different actions with their hands (manipulations). In spite of this, so far {{there have been only}} a few attempts to represent manipulation types trying to understand the underlying principles. Here we first discuss how manipulation actions are structured in space and time. For this we use as temporal anchor points those moments where two objects (or hand and object) touch or un-touch each other during a manipulation. We show that by this one can define a relatively small tree-like manipulation ontology. We find less than 30 fundamental manipulations. The temporal anchors also provide us with information about when to pay attention to additional important information, for example when to consider trajectory shapes and relative poses between objects. As a consequence a highly condensed representation emerges by which different manipulations can be recognized and encoded. Examples of manipulations <b>recognition</b> <b>and</b> <b>execution</b> by a robot based on this representation are given {{at the end of this}} study. I...|$|E
40|$|The primary aim of {{this article}} is to propose an answer if U. S. punitive damages {{judgments}} should be recognized in Germany. First, the article will give an overview about punitive damages under American Law and then will analyze the German doctrinal framework of damages. On this basis, the paper will provide an overview of the proceeding of the <b>recognition</b> <b>and</b> <b>execution</b> of foreign judgments in Germany, including the German ordre public. The comparative analysis of this paper will identify parallels between U. S. punitive damages and German damages and will show penal elements within the German civil law. The enforceability of punitive damages in Germany depends on the German point of view towards punitive damages. Thus, this article will identify penal elements in the German civil law. Even if the German civil law would be unacquainted with punishment, it could be imaginable that the German law could tolerate the objectives of punitive damages. Therefore it will be discussed, if the German law or jurisprudence contains aspects that correspond to the intention of American punitive damages...|$|E
40|$|In 2012 Bulgaria {{transposed}} Council Framework Decision 2008 / 947 /JHA by way {{of passing}} the Act on <b>Recognition,</b> <b>Execution</b> <b>and</b> Forwarding of Judgments and Probation Decisions with a View to Exercising Supervision of Probation Measures and Alternative Sanctions. This legislative act provides a legal opportunity for the execution of probation measures, issued by other EU countries (probation measures transfer) and sets out the rules governing the transfer. This paper examines the transfer procedure rule...|$|R
40|$|In {{this paper}} an error-correcting parsing {{algorithm}} and {{its application to}} a postprocessing task {{in the context of}} automatic check processing is described. The proposed method has shown very good results in terms of <b>recognition</b> accuracy <b>and</b> <b>execution</b> speed on both real and synthetic data. 1 Introduction The recognition of machine printed characters has been intensively studied during the past years and significant progress has been made [1]. For example, there exist commercial OCR systems that achieve a correct recognition rate of over 99 % today [2]. But depending on the particular application, such a high recognition rate may be still insufficient. In order to further improve recognition accuracy, contextual postprocessing is often very useful. Different contextual postprocessing methods have been proposed in the literature. They are based, for example, on n-gram statistics [3, 4], or dictionary search [5, 6]. A recent survey on contextual processing has been given in [7]. For earli [...] ...|$|R
40|$|This article {{addresses}} the broad question of enforcement of ICSID arbitral awards under the Convention, {{with the goal}} of analyzing the attendant issues. The article is divided into four parts. Part Two deals with background issues such as the purpose of ICSID as envisaged by the ICSID Convention and the composition of the ICSID. Part Three analyzes the ICSID arbitral process and discusses the ICSID 2 ̆ 7 s jurisdiction and the constitution of its arbitral panel. Part Four, the main section, discusses the <b>recognition</b> <b>and</b> enforcement of awards. This section will analyze the various steps of enforcement: <b>recognition,</b> enforcement itself, <b>and</b> <b>execution</b> of awards that have been adjudged enforceable. The article will examine the jurisprudence that has been developed in some ICSID cases before domestic courts of member states to the ICSID Convention. Part Four also discusses the practical effects of these cases and analyzes the impact of the annulment provision and process under the Convention on the ICSID mechanism...|$|R
40|$|This thesis {{proposes a}} {{framework}} that enables a biped humanoid robot to learn and reproduce whole body motions from human motions. This ability can increase the usefulness of biped humanoid robots, which have a potential to perform human-like motions of the whole body. We achieve this goal {{on the basis of}} the Learning from Observation (LFO) paradigm, and prove that the paradigm is valid for whole body motions. In our framework, the target motions are dances, and a robot uses its own legs to support its body during a dance performance. Reproducing such motions from human motions is a novel attempt. This thesis especially focuses on leg motions, which present a serious challenge to the achievement of our goal. LFO is a paradigm of teaching a task to a robot. It consists of three processes: observation, <b>recognition,</b> <b>and</b> <b>execution.</b> First, a human instructor demonstrates a task and a robot observes the demonstration. Then the robot recognizes what is done in the observed motion. After that, the robot can execute the task according to the recognition results. In this paradigm, all an instructor has to do is to demonstrate...|$|E
40|$|The summon for {{the payment}} procedure, {{regulated}} by the 1896 / 2006 Regulation that is to beapplied to all the state members of the European Union and which aims at simplifying and accelerating theprocedures referring to the recuperation of the debts expressed in figures, that are both due and uncontested. This procedure helps in sensibly reducing the sum of judging expenses, and the juridical protection is ensured inthose states where the payment summon is not stipulated by internal regulations. The payment summon has theexecutory character of an internal title in all the state memebers, the <b>recognition</b> <b>and</b> <b>execution</b> procedure notbeing necessary. The regulation is applied in civil and commercial matters, the extracontractual parties beingexcluded. This procedure is started through the claimer’s request who has the obligation to declare (in his/herrequest) that he/she takes entire responsability for what he/she has asserted and that he/she knows exactly thatany false statement can fall under the law sanctions stipulated by the legislation of the origin state. In case therequest is justified, the instance will send an European summon order that will be declared as Europeanexecutory order if an objection has not been formulated in the origin instance...|$|E
40|$|In {{the context}} of EU extension, the main way to prevent and fight against crime of all kinds is {{represented}} by the intensification in the specific activities of judicial cooperation in criminal mattersin all member states, based on a legislation anchored in the present realities. The most important form of judicial cooperation in criminal matters, based on mutual confidence in the decision taken by the competent judicial organisms is, in our opinion, the <b>recognition</b> <b>and</b> <b>execution</b> of foreign criminal decisions and judicial acts. One {{of the ways in which}} this type of cooperation is accomplished {{is represented by the}} mutual recognition and monitoring of suspended sentences, sentences with postponement of execution of the conviction, alternative penalties and decisions on probation, that have the purpose of increasing the chances for social reintegration of the convicted person. Recognizing and executing such an injunction in another member state than the one in which the conviction was established imposes, for the executing member state, the necessity of taking the most efficient measures for each singular case. The critical examination of the dispositions of the Council’s Decision Frame 2008 / 947 /JAI, that regulates this procedure, as well as the special internal law leas to the conclusion of the existence of provisions that are at least debatable and the necessity of urgent transposition of theEuropean normative act’s provisions in our internal legislation...|$|E
40|$|The launch site {{processing}} flow involves operations such as functional verification, preflight servicing and launch. These operations often include hazards {{that must be}} controlled to protect human life and critical space hardware assets. Existing command and control capabilities are limited to simple limit checking durig automated monitoring. Contingency actions are highly dependent on human <b>recognition,</b> decision making, <b>and</b> <b>execution.</b> Many opportunities for Integrated System Health Engineering and Management (ISHEM) exist throughout the {{processing flow}}. This paper will present the current human-centered approach to health management as performed today for the shuttle and space station programs. In addition, it will {{address some of the}} more critical ISHEM needs, and provide recommendations for future implementation of ISHEM at the launch site...|$|R
40|$|AbstractThis study {{improves}} the <b>recognition</b> accuracy <b>and</b> <b>execution</b> time of facial expression recognition system. Various techniques were utilized to achieve this. The face detection component is {{implemented by the}} adoption of Viola–Jones descriptor. The detected face is down-sampled by Bessel transform to reduce the feature extraction space to improve processing time then. Gabor feature extraction techniques were employed to extract thousands of facial features which represent various facial deformation patterns. An AdaBoost-based hypothesis is formulated to select a few hundreds of the numerous extracted features to speed up classification. The selected features were fed into a well designed 3 -layer neural network classifier that is trained by a back-propagation algorithm. The system is trained and tested with datasets from JAFFE and Yale facial expression databases. An average recognition rate of 96. 83 % and 92. 22 % are registered in JAFFE and Yale databases, respectively. The execution time for a 100 × 100 pixel size is 14. 5 ms. The general results of the proposed techniques are very encouraging when compared with others...|$|R
40|$|Intention {{recognition}} can use multiple {{factors as}} inputs such as gestures, face images and eye gaze position. On the other hand，eye tracking technology，with its special advantages of applying to Human-Computer Interaction (HCI) ，can be utilized to develop assistant systems {{for people with}} mobility difficulties. In this paper, we propose gaze estimation position information as input of fuzzy inference to achieve intention recognition based on object recongition and construct an assistant system by using humanoid robot. Our approach {{is divided into three}} parts: user's gaze estimation, intention <b>recognition</b> <b>and</b> behavior <b>execution.</b> In gaze estimation part, differing from the previous studies, neural network has been used as the decision making unit, and then gaze position on computer screen is estimated. In intention recognition part, user intention is recognized by using gaze frequency and continuous gaze staying time as input of fuzzy inference after an initial intention region set has been found. At last, by using an autonomous humanoid robot, experiments are performed based on the result of intention recognition. after confirmed by user, the robot was controlled with and assistant task for user precisely...|$|R
40|$|According to {{the special}} Romanian law, one of the forms of {{judicial}} assistance in criminal matters recognized in {{the relations between the}} EU member states is, among others, the one referringto the cooperation in applying the principle of mutual recognition of financial penalties. The European normative act that establishes the general cooperation norms in this matter is the Council’sDecision Frame 2005 / 214 /JAI on February 24, 2005 on the application of the principle of mutual recognition of financial penalties. This European normative act has been transposed in the internallegislation through Law no. 302 / 2004, according to the international judicial cooperation in criminal matters, with the subsequent amendments and completions, the latter being represented by Lawno. 222 / 2008. The amendments and completions instituted by the abovementioned normative act establish the procedure of transmitting the decision, the procedures for <b>recognition</b> <b>and</b> <b>execution</b> ofsuch a decision by the competent Romanian judicial authorities, the grounds of non recognition and non execution, the definition of used terms, as well as other aspects referring to the recognition andexecution of such decisions. Commenting refers to a number of provisions in the law under both European and domestic in the special law, comments aimed in particular the replacement of terms ofrecognition or non-performance reasons, the procedure of identification of persons convicted when they are evade the enforcement of financial obligations and failure to transpose into national law of subsequent changes to European law...|$|E
40|$|Today, the {{physical}} capabilities of robots {{enable them to}} perform {{a wide variety of}} useful tasks for humans, making the need for simple and intuitive interaction between humans and robots readily apparent. Taking natural language as a key element of this interaction, we present a novel framework that enables robots to learn qualitative models of the semantics of an important class of verb phrases, such as "follow me to the kitchen," and leverage these verb models to perform two tasks: Executing verb phrase commands, and recognizing when another agent has performed a given verb. This framework is based on a qualitative, relational model of verb semantics called the Verb Finite State Machine, or VFSM. We describe the VFSM in detail, motivating its design and providing a characterization of the class of verbs it can represent. The VFSM supports the recognition task natively, and we show how to combine it with modern planning techniques to support verb execution in complex environments. Grounded natural language semantics must be learned through interaction with humans, so we describe methods from learning VFSM verb models through natural interaction with a human teacher in the apprenticeship learning paradigm. To demonstrate the efficacy of our framework, we present empirical results showing rapid learning and high performance on both the <b>recognition</b> <b>and</b> <b>execution</b> tasks. In these experiments, the VFSM is able to consistently outperform a baseline method based on recent work in the verb learning literature. We close with a discussion of some of the current limitations of the framework, and a roadmap for future work in this area...|$|E
40|$|Maintaining and {{developing}} {{the area of}} freedom, security and justice is a major objective of theEuropean Community, which guarantees the free movement of persons. As a result of litigations regardingthe applications with a reduced value arising among physical or legal persons, it was felt the need for acommunity legislation that would guarantee identical conditions, both for creditors and debtors throughoutthe entire European Union territory. The European procedure regarding the debts recovery of reducedvalue facilitates the access to justice and it is characterized by simplifying and expediting the settling of thetransboundary litigations, reducing costs, the <b>recognition</b> <b>and</b> <b>execution</b> of the court order in a MemberState given in another Member State. This procedure is available to litigants {{as an alternative to}} theprocedures provided by the laws of Member States. The Regulation (EC) no. 861 / 2007 establishing aEuropean procedure regarding the applications with reduced value applies in civil and commercial matters inthe transboundary cases, regardless the nature of the court when the application value, without taking intoaccount the interest, expenditures and other costs, does not exceed 2000 Euro at the time of receiving theapplication form by the competent court. This procedure does not apply to revenue, customs oradministrative matters or in regard to state responsibility for acts or omissions in exercising the publicauthority, and other matters specifically referred to in the Regulation. A cause is transboundary in naturewhen one of the parties has its habitual residence in a Member State, other than the one where the courtreceives such application. The proper procedure of application resolution for the recovery of debts withreduced value is governed by the rules of procedural law of the Member State in which the proceedings areconducted, and the execution of court of law is made by state legislation in which it takes place. TheRegulation expressly provides that the court order in this matter can not be, in any form, the subject ofreexamination, in the State member in which its execution is requested. As regards the linguistic regime,the application will be written in the language or in one of the procedure languages of the court; the costsare incurred by the losing party in the application. But the court will not grant the party that won thelawsuit the expenses that were not necessary or the ones that have a disproportionate value in relation tothe application...|$|E
40|$|Brain-computer {{interfaces}} (BCIs) {{allow you}} to control things directly with your mind. Unfortunately, such input devices based on observations of the body are plagued by noise, non-stationarities, and ambiguity. In the lab, we can protect systems somewhat from these influences, but in ‘the real world’, BCIs {{could use a little}} help. How important is good control anyway? How well can users even assess their level of control? Fourteen participants evaluated three sets of mental tasks each for five weeks. Most important to them was good task <b>recognition</b> <b>and</b> easy task <b>execution.</b> When people know the input they provide, they have a good perception of their level of control. Eighty-seven participants played a browser game with varying levels of control. The actual amount of control explained 72...|$|R
40|$|Abstract — This paper {{presents}} {{a prototype of}} a secure, dependable, real-time weather-responsive system. The prototype performs two operations: 1) it accesses weather information that provides near-real-time atmospheric and pavement observations and 2) it adapts signal timing in response to inclement weather. Since this real-time control system operates in a critical infrastructure, it must be designed with built-in security and survivability mechanisms. For this purpose a software architecture is presented that uses real-time monitoring to detect precedence violations <b>and</b> off-nominal system <b>execution</b> {{in order to provide}} effective contingency management. The focus of these systems is the autonomous <b>recognition</b> <b>and</b> reaction to <b>execution</b> patterns that have not been previously observed and thus fall outside of the known behavior. Because the described system has very similar requirements to other traffic control applications, it serves as a milestone in the development of secure and dependable real-time traffic control systems. I...|$|R
40|$|The use of {{smoothing}} kernels in boundary curvature calculations, affects both object {{shape and}} the localization of edges. The Global-Local transformation (GLT), addresses this issue {{by providing a}} framework for shape representation, such that local and global features are simultaneously represented, even in noisy shapes, {{without the need for}} smoothing. By means of two-dimensional manifolds (surfaces), embedded into the unit cube, useful properties of the transform space are explored. The expressive power of the GLT is demonstrated by means of a global descriptor, called View Area Representation (VAR). VAR is an intuitive and physically meaningful shape descriptor which is robust to noise, captures curvature and leads to the introduction of novel and hybrid (global/local) shape features. A series of proofs is presented that link VAR and its derivatives to those shape features, providing the basis for shape representation involving global and local features in the presence of noise. The theoretical results are shown to be effective in matching noisy shapes by improving the recognition capability, of Local Area Integral Invariant (LAII), a relevant state of the art method of low complexity. A combination of GLT with VAR is used to define a new matching method certain advantages of which, in <b>recognition</b> ability <b>and</b> <b>execution</b> time, renders the intuitive properties of VAR significant for complexity reduction. (C) 2011 Elsevier Inc. All rights reserved...|$|R
40|$|We {{propose a}} new deflationary {{interpretation}} for the functional role of mirror neurons discovered by Rizzolatti and colleagues into the macaque’s F 5 motor area. Several functional {{interpretations of the}} mirror activity have been proposed, emphasizing their role in action understanding and representing, language evolution, or mind-reading abilities. However, according to the interpretation presented here, full understanding of agent goals and intentional action are related to mirror neuron activity only insofar as the process of understanding an intentional action necessarily involves the capability of assigning a “structural description ” to the action. In particular, we argue that mirror activity is involved in both recognizing action structural features and associating these features to motor commands. Our functional interpretation includes an anticipatory mechanism, enabling one to verify whether the actual, suitably coded visual input, matches an expected visual input computed {{on the basis of}} a motor command sequence. This mechanism is involved in both action <b>recognition</b> <b>and</b> action <b>execution</b> control. We believe that this mirror neuron model could fit biological data better than the Oztop and Arbib model. Starting from this interpretation, we propose a biologically inspired visuo-motor control model merging basic elements of the Oztop and Arbib model with an expected perception mechanism. This model has been formalized within an algorithmic stance however actual implementation is in progress...|$|R
30|$|The model {{introduced}} in Section 2 presents a general framework for environment <b>recognition,</b> decision-making, <b>and</b> action <b>execution</b> in automation systems based on neuro-congitive insights {{about the human}} brain. The first simulation and validation of this framework was presented in Section 3. In this simulation, the different modules were implemented in a rule-based form (hard-coded rules and fuzzy rules) {{in order to determine}} output data based on incoming data. In further development steps, it was then aimed to substitute these rules by approaches that are closer to the neurophysiological and neuropsychological information processing principles of the brain. The result of this research effort was the elaboration of the so-called neurosymbolic information processing principle [3]. The first module to which this method was applied was the recognition module [29]. In later steps, it was also attempted to apply this mechanisms to the action <b>execution</b> module <b>and</b> for the representation of emotions, drives, and desires. An overview of the neuro-symbolic principle is given in the following with focuses on the <b>recognition</b> system <b>and</b> further remarks on the application to other areas.|$|R
40|$|AbstractProtein name {{recognition}} aims to detect {{each and every}} protein names appearing in a PubMed abstract. The task is not simple, as the graphic word boundary (space separator) assumed in conventional preprocessing does not necessarily coincide with the protein name boundary. Such boundary disagreement caused by tokenization ambiguity has usually been ignored in conventional preprocessing of general English. In this paper, we argue that boundary disagreement poses serious limitations in biomedical English text processing, not to mention protein {{name recognition}}. Our key idea {{for dealing with the}} boundary disagreement is to apply techniques used in Japanese morphological analysis where there are no word boundaries. Having evaluated the proposed method with GENIA corpus 3. 02, we obtain F-measure of 69. 01 on a strict criterion and 79. 32 on a relaxed criterion. The result is comparable to other published work in protein name recognition, without resorting to manually prepared ad hoc feature engineering. Further, compared to the conventional preprocessing, the use of morphological analysis as preprocessing improves the performance of protein name <b>recognition</b> <b>and</b> reduces the <b>execution</b> time...|$|R
40|$|Computing with Words based Question Answering (CWQA) system {{provides}} a foundation to develop futuristic search engines where more of reasoning {{and less of}} pattern matching and statistical methods are used for information retrieval. In order to perform successful reasoning, these systems should analyze the semantic of the query and the related information in the Knowledge Base. The concept of Computing with Words (CW) which {{is a kind of}} perception based reasoning where manipulation of perceptions using fuzzy set theory and fuzzy logic {{play a key role in}} <b>recognition,</b> decision <b>and</b> <b>execution</b> processes can be utilized for this purpose. Two concepts that were introduced by Computing with Words are the Generalized Constraint Language (GCL) and the Generalized Theory of Uncertainty (GTU). In GCL propositions, i. e. perceptions in natural language, are denoted using generalized constraints. The Generalized Theory of Uncertainty (GTU) uses GCL to express proposition drawn from natural language as a generalized constraint. The GCL plays a fundamental role in GTU by serving as a precisiation language for propositions, commands and questions in natural language. In GTU, deduction rules are used to propagate generalized constraints to accomplish reasoning under uncertainty. In the previous work a CW-based QA-system methodology was introduced which uses a knowledge tree data structure, called as a Constraint Propagation Tree (CPT) that utilizes the concepts briefed above. The realization of Constraint Propagation Tree, the first phase, and partial implementation of constraint propagation and node combination, the second phase, is the main goal of this work...|$|R
40|$|Computing, in {{its usual}} sense, is {{centered}} on manipulation of numbers and symbols. In contrast, computing with words, or CW for short, is a methodology in which the objects of computation are words and propositions drawn from a natural language, e. g., small, large, far, heavy, not very likely, {{the price of gas}} is low and declining, Berkeley is near San Francisco, it is very unlikely {{that there will be a}} significant increase in the price of oil in the near future, etc. Computing with words is inspired by the remarkable human capability to perform a wide variety of physical and mental tasks without any measurements and any computations. Familiar examples of such tasks are parking a car, driving in heavy traffic, playing golf, riding a bicycle, understanding speech and summarizing a story. Underlying this remarkable capability is the brain’s crucial ability to manipulate perceptions – perceptions of distance, size, weight, color, speed, time, direction, force, number, truth, likelihood and other characteristics of physical and mental objects. Manipulation of perceptions plays a key role in human <b>recognition,</b> decision <b>and</b> <b>execution</b> processes. As a methodology, computing with words provides a foundation for a computational theory of perceptions – a theory which may have an important bearing on how humans make – and machines might make – perception-based rational decisions in an environment of imprecision, uncertainty and partial truth. A basic difference between perceptions and measurements is that, in general, measurements are crisp whereas perceptions are fuzzy. One of the fundamental aims of science has been and continues to be that of progressing from perceptions to measurements. Pursuit of this aim has led to brilliant successes. We have sent men to the moon; we can build computer...|$|R
40|$|Recent {{advances}} in technology have increased awareness of the necessity for automated systems in people’s everyday lives. Artificial systems are more frequently being introduced into environments previously thought to be too perilous for humans to operate in. Some robots {{can be used to}} extract potentially hazardous materials from sites inaccessible to humans, while others are being developed to aid humans with laborious tasks. A crucial aspect of all artificial systems is {{the manner in which they}} interact with their immediate surroundings. Developing such a deceivingly simply aspect has proven to be significantly challenging, as it not only entails the methods through which the system perceives its environment, but also its ability to perform critical tasks. These undertakings often involve the coordination of numerous subsystems, each performing its own complex duty. To complicate matters further, it is nowadays becoming increasingly important for these artificial systems to be able to perform their tasks in real-time. The task of object recognition is typically described as the process of retrieving the object in a database that is most similar to an unknown, or query, object. Pose estimation, on the other hand, involves estimating the position and orientation of an object in three-dimensional space, as seen from an observer’s viewpoint. These two tasks are regarded as vital to many computer vision techniques and and regularly serve as input to more complex perception algorithms. An approach is presented which regards the object <b>recognition</b> <b>and</b> pose estimation procedures as mutually dependent. The core idea is that dissimilar objects might appear similar when observed from certain viewpoints. A feature-based conceptualisation, which makes use of a database, is implemented and used to perform simultaneous object <b>recognition</b> <b>and</b> pose estimation. The design incorporates data compression techniques, originally suggested by the image-processing community, to facilitate fast processing of large databases. System performance is quantified primarily on object <b>recognition,</b> pose estimation <b>and</b> <b>execution</b> time characteristics. These aspects are investigated under ideal conditions by exploiting three-dimensional models of relevant objects. The performance of the system is also analysed for practical scenarios by acquiring input data from a structured light implementation, which resembles that obtained from many commercial range scanners. Practical experiments indicate that the system was capable of performing simultaneous object <b>recognition</b> <b>and</b> pose estimation in approximately 230 ms once a novel object has been sensed. An average object recognition accuracy of approximately 73 % was achieved. The pose estimation results were reasonable but prompted further research. The results are comparable to what has been achieved using other suggested approaches such as Viewpoint Feature Histograms and Spin Images. Dissertation (MEng) [...] University of Pretoria, 2013. gm 2014 Electrical, Electronic and Computer Engineeringunrestricte...|$|R
