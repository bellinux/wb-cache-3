1|10000|Public
40|$|Pearson's {{unrestricted}} chi-square {{procedure is}} reviewed, and an historical presentation of Neyman's <b>restricted</b> <b>chi-square</b> <b>test</b> is introduced {{with a discussion}} of its theory and applicability to education. An example of the Neyman procedure is discussed in detail to tamiliarize researchers with this useful technique for analyzing contingency tables. The analysis also displays the need for researchers to check model assumptions and power in order to produce constructive analysis. This presentation of a statistical procedure developed by mathematical statisticians allows researchers in the behavioral sciences a facility with the method for application in their particular research. (Author/PR...|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimited. 13. ABSTRACT (Maximum 200 words) This report describes the growth curve {{approach to the}} modeling of longitudinal data from Project Proteus. Desirable properties of the model are presented along with the basic model. Using Project Proteus and data from the Officer Longitudinal Research Data Base (OLRDB), two variables reflecting career intentions and social support were modeled longitudinally. The models were evaluated using <b>chi-square</b> and <b>restricted</b> <b>chi-square</b> <b>tests</b> in LISREL. The results of the exploratory analyses indicate significant effects for cohort and length {{of time in the}} Army...|$|R
30|$|London {{properties}} are more constant {{in terms of}} the number of traps laid over the years and the nature of the properties, so seemed possible to test whether the distributions of trapped insects show different statistics. The low catch of many insects <b>restricted</b> the <b>chi-square</b> <b>test</b> to a contingency table of the most abundant insects: woolly bears, booklice, silverfish and woodlice. The test suggested that counts of these insects from the seven London properties do not follow a consistent distribution (p[*]=[*] 0.001, <b>Chi-squared</b> <b>test,</b> DoF[*]=[*] 18). This lends support to the individualistic nature of the properties with respect to the insects trapped.|$|R
50|$|Just as the Wilson {{interval}} mirrors Pearson's <b>chi-squared</b> <b>test,</b> the Wilson interval with continuity correction {{mirrors the}} equivalent Yates' <b>chi-squared</b> <b>test.</b>|$|R
5000|$|For {{samples of}} a {{reasonable}} size, the G-test and the <b>chi-squared</b> <b>test</b> {{will lead to}} the same conclusions. However, the approximation to the theoretical chi-squared distribution for the G-test is better than for the Pearson's <b>chi-squared</b> <b>test.</b> In cases where [...] for some cell case the G-test is always better than the <b>chi-squared</b> <b>test.</b>|$|R
30|$|Horie et al. [3] {{evaluated}} the strength data of structural lumber, and used <b>Chi-square</b> <b>test</b> and KS test as goodness-of-fit measures. In the current study, however, the <b>Chi-square</b> <b>test</b> was not used, because the sample data {{had to be}} binned before generating the <b>Chi-square</b> <b>test.</b> As we know, {{the value of the}} <b>Chi-square</b> <b>test</b> statistic is dependent on how the data are binned. In addition, the Weibull distribution employed in this study was not 3 P Weibull but 2 P Weibull, because the theoretical and physical meanings of the location parameter in 3 P Weibull distribution were not clear [3].|$|R
30|$|In general, the <b>chi-square</b> <b>test</b> is less {{sensitive}} and less efficient than the Kolmogorov test or the Anderson-Darling test {{due to the}} fact that the <b>chi-square</b> <b>test</b> coarsens data by placing data into discrete bins.|$|R
40|$|Applied {{researchers}} have employed <b>chi-square</b> <b>tests</b> {{for more than}} one hundred years. This paper addresses the question of how one should follow a statistically significant <b>chi-square</b> <b>test</b> result {{in order to determine the}} source of that result. Four approaches were evaluated: calculating residuals, comparing cells, ransacking, and partitioning. Data from two recent journal articles were used to illustrate these approaches. A call is made for greater consideration of foundational techniques such as the <b>chi-square</b> <b>tests...</b>|$|R
50|$|Cochran-Mantel-Haenszel <b>chi-squared</b> <b>test.</b>|$|R
5000|$|Goodness of fit: Kolmogorov-Smirnov <b>test,</b> <b>chi-squared</b> <b>test,</b> Shapiro-Wilk test, Lilliefors test, Anderson-Darling test, Cramér-von Mises {{statistic}} ...|$|R
30|$|Huang et al. (2007) {{proposed}} a statistical method {{that uses the}} <b>chi-square</b> <b>test</b> and conditional probability. The study sought to determine any drug-drug interaction for the ADRs. Firstly, a <b>chi-square</b> <b>test</b> {{is used to calculate}} the dependency of all drug and symptom pairs. The <b>chi-square</b> <b>test,</b> however, can only show the relative strength of association, but cannot distinguish whether the ADR is caused by drug-drug interaction or a single drug. The use of a conditional probability resolves this problem.|$|R
30|$|All {{data are}} {{reported}} as descriptive variables, normal distributed data should be displayed as means ± standard deviations (SD) and non-parametric data as median (interquartile range, IQR). Accordingly, to compare distributions between groups, we used T-test, non-parametric Kruskal-Wallis <b>test</b> or <b>chi-square</b> <b>test.</b> Pairwise post-hoc comparisons were performed with unpaired-samples t-test, Mann-Whitney <b>test</b> or <b>chi-square</b> <b>test,</b> as appropriate; {{in all cases}} we used a Sidak correction. <b>Chi-square</b> <b>test</b> was computed with Yates’ continuity correction for 2 [*]×[*] 2 contingency tables.|$|R
40|$|This {{paper is}} the sixth {{in a series}} of {{statistics}} articles recently published by Australian Critical Care. In this paper we explore the most commonly used statistical tests to compare groups of data at the nominal level of measurement. The chosen statistical <b>tests</b> are the <b>chi-square</b> <b>test,</b> <b>chi-square</b> <b>test</b> for goodness of fit, <b>chi-square</b> <b>test</b> for independence, Fisher's exact test, McNemar's test and the use of confidence intervals for proportions. Examples of how to use and interpret the tests are provided. Full Tex...|$|R
5000|$|A <b>chi-squared</b> <b>test,</b> {{also written}} as [...] test, is any {{statistical}} hypothesis test wherein the sampling {{distribution of the}} test statistic is a chi-squared distribution when the null hypothesis is true. Without other qualification, 'chi-squared test' often is used as short for Pearson's <b>chi-squared</b> <b>test.</b>|$|R
40|$|A location-dispersion test f o r 2 x k contingency, tables is proposed. The {{asymptotic}} {{distributions of}} the proposed test are obtained both under the null and alternative hypotheses, and also its power and efficiency are studied. The proposed test is compared with several other <b>chi-squared</b> <b>tests</b> by Monte Carlo studies and it is shown that the test is superior to Pearson 2 ̆ 7 s <b>chi-squared</b> <b>test,</b> Nair 2 ̆ 7 s location and dispersion tests and to the cumulative <b>chi-squared</b> <b>test</b> in many cases...|$|R
30|$|Mortality of O. nubilalis and A. bipunctata {{was tested}} for {{significant}} differences using a two-sided Cochran-Mantel-Haenszel <b>chi-squared</b> <b>test</b> for O. nubilalis bioassay data and a one-sided Cochran-Mantel-Haenszel <b>chi-squared</b> <b>test</b> for the A. bipunctata bioassay data. All analyses {{were carried out}} using the statistics software R [18].|$|R
40|$|The <b>chi-squared</b> <b>test</b> of Markov chain lumpability {{is shown}} to operate {{reliably}} under a corrected derivation of the degrees of freedom. The test is used to screen out lumping schemes that corrupt the Markov property and give rise to higher order dependence. Time series Markov chain Lumpability <b>Chi-squared</b> <b>tests...</b>|$|R
30|$|POSAS {{scores were}} {{compared}} by McNemar’s paired <b>chi-squared</b> <b>test.</b>|$|R
5000|$|... #Subtitle level 2: Example <b>chi-squared</b> <b>test</b> for {{categorical}} data ...|$|R
30|$|The {{values are}} {{expressed}} as means with 95 % confidence intervals (CI). The Mc Nemar <b>chi-square</b> <b>test</b> {{was performed to}} compare the sensitivity and specificity between 4 DST and FDG, and the <b>chi-square</b> <b>test</b> for independence was performed to compare spread lesion or the recurrence rate between 4 DST and FDG.|$|R
40|$|In this paper, {{we suggest}} {{the use of}} the <b>chi-square</b> <b>test</b> for {{detecting}} backoff misbehaviour in IEEE 802. 11 EDCA networks. A performance evaluation is performed to compare the <b>chi-square</b> <b>test</b> with two other methods, known in the literature. To perform a suitable comparison, these two methods are extended to support EDCA and the BEB mechanism. We assume a misbehaviour model, which can be easily executed by a selfish user. We show that the <b>chi-square</b> <b>test</b> outperforms the other methods in terms of the probability of misbehaviour detection and time required to positively identify a misbehaving node...|$|R
50|$|Cramér's V - {{a measure}} of {{correlation}} for the <b>chi-squared</b> <b>test.</b>|$|R
5000|$|... #Subtitle level 2: <b>Chi-squared</b> <b>test</b> for {{variance}} {{in a normal}} population ...|$|R
5000|$|Normality test using Jarque-Bera test, Shapiro-Wilk <b>test,</b> and <b>Chi-square</b> <b>test</b> methods.|$|R
5000|$|... #Subtitle level 2: Example: Pearson's <b>chi-squared</b> <b>test</b> versus {{an exact}} test ...|$|R
40|$|An {{upper and}} lower bound are {{presented}} for {{the difference between the}} distribution functions of noncentral chi-square variables with the same degrees of freedom and different noncentralities. The inequalities are applied in a comparison of two approximations to the power of Pearson's <b>chi-square</b> <b>test.</b> Noncentral [chi] 2 distribution Pearson's <b>chi-square</b> <b>test</b> contamination family exponential family...|$|R
25|$|Pearson's <b>chi-squared</b> <b>test.</b> A {{hypothesis}} test using normal approximation for discrete data.|$|R
30|$|On {{the basis}} of a <b>chi-squared</b> <b>test</b> for {{equality}} of regression coefficients.|$|R
50|$|Pearson's <b>chi-squared</b> <b>test.</b> A {{hypothesis}} test using normal approximation for discrete data.|$|R
50|$|Similar themes appear when {{comparing}} Fisher's exact <b>test</b> with Pearson's <b>chi-squared</b> <b>test.</b>|$|R
5000|$|<b>Chi-squared</b> <b>test</b> of {{goodness}} of fit of observed data to hypothetical distributions ...|$|R
5000|$|The null {{hypothesis}} {{can also be}} tested by using Pearson's <b>chi-squared</b> <b>test</b> ...|$|R
30|$|Categorical {{variables}} {{were analyzed using}} the <b>chi-square</b> <b>test.</b> Fisher’s exact test was used whenever {{the distribution of the}} variable under analysis rendered the <b>chi-square</b> <b>test</b> inviable. The continuous quantitative {{variables were}} compared using Student’s t test. All statistical analyses were performed using the SPSS statistical software program (SPSS Inc., USA), adopting a significance level of 5  %.|$|R
40|$|We {{show that}} the {{sequence}} of <b>chi-square</b> <b>tests</b> is asymptotically minimax if a number of cells increases with increasing sample size. The proof utilizes theorem about asymptotic normality of <b>chi-square</b> <b>test</b> statistics obtained under new compact assumptions. (orig.) Available from TIB Hannover: RR 5549 (185) +a / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|R
30|$|The {{quantitative}} analysis {{was carried out}} via a <b>Chi-square</b> <b>test</b> {{to examine the relationship}} between nominal variables. Moreover, the analysis of the deviations of the observed frequencies from a theoretical random distribution was carried out by a Binomial test in the case of the study of two categories and by <b>Chi-square</b> <b>test</b> when more categories were involved.|$|R
40|$|The {{examination}} of cross-classified category data {{is common in}} evaluation and research, with Karl Pearson’s family of <b>chi-square</b> <b>tests</b> representing {{one of the most}} utilized statistical analyses for answering questions about the association or difference between categorical variables. Unfortu-nately, these tests are also among the more commonly misinterpreted statistical tests in the field. The problem is not that researchers and evaluators misapply the results of <b>chi-square</b> <b>tests,</b> but rather they tend to over interpret or incorrectly interpret the results, leading to statements that may have limited or no statistical support based on the analyses preformed. This paper attempts to clarify any confusion about the uses and interpretations of the family of <b>chi-square</b> <b>tests</b> developed by Pearson, focusing primarily on the <b>chi-square</b> <b>tests</b> of independence and homogeneity of variance (identity of distributions). A brief survey of the recent evaluation lit-erature is presented to illustrate the prevalence of the <b>chi-square</b> <b>test</b> and to offer examples of how these tests are misinterpreted. While the omnibus form of all three tests in the Karl Pearson family of chi-square tests—independence, homogeneity, and goodness-of-fit,—use essentially the same formula, each of these three tests is, in fact, distinct with specific hypotheses, sampling approaches, interpretations, and options following rejection of the null hypothesis. Finally, a little known option, the use and interpretation of post hoc comparisons based on Goodman’s procedure (Goodman, 1963) following the rejection of the <b>chi-square</b> <b>test</b> of homogeneity, is described in detail...|$|R
