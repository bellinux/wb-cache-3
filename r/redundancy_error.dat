10|177|Public
50|$|A very {{accurate}} transmission system with constant sampling rate may be formed using the full arrangement shown here by transmitting the {{samples from the}} buffer protected with <b>redundancy</b> <b>error</b> correction. In this case {{there will be a}} trade off between bandwidth and N, the size of the buffer. The signal recovery system will require <b>redundancy</b> <b>error</b> checking, digital to analog conversion, and sample and hold circuitry. A possible further enhancement is to include some form of slope regeneration. This amounts to PCM (pulse code modulation) with digitization performed by a sigma-delta ADC.|$|E
30|$|Combining Table  2 and Fig.  6, it {{is obvious}} that the three methods are the worst in DMES, the second in AUA, and the best in this paper. Among them, the {{performance}} of DMES and AUA is not much different, AUA is 0.55 % lower than DMES in missing error, AUA is 0.06 % lower than DMES in <b>redundancy</b> <b>error,</b> and AUA is 1.24 % higher than DMES in accuracy. The method proposed in this paper is better than DMES and AUA, and the missing error of this method is 2.04 % lower than AUA, 2.59 % lower than DMES, 0.4 lower than AUA, and 0.46 % lower than DMES in <b>redundancy</b> <b>error.</b> In terms of accuracy, this method is 3.46 lower than AUA and 4.7 lower than DMES. Through numerical comparison, we can find that the proposed method has a great improvement in the performance of the three indicators, which shows that the proposed method has better road information extraction performance than DMES and AUA.|$|E
3000|$|... {{is a small}} {{constant}} and varies depending on concrete algorithms, such as Reed-Solomon codes or Tornado codes. Compared with retransmission-based reliable transport schemes, redundancy-based schemes can avoid the inconveniences caused by feedback. However, {{in the case of}} sensor nodes, for both kinds of <b>redundancy,</b> <b>error</b> control parities consume valuable transceiver energy which must be taken into account. The encoding/decoding energy also needs to be incorporated.|$|E
5000|$|Provides {{real-time}} information, {{reducing the}} possibility of <b>redundancy</b> <b>errors</b> ...|$|R
50|$|Genetic code as an {{efficient}} digital information store, containing built in codon <b>redundancy</b> for <b>error</b> correction in transcription.|$|R
30|$|One {{example of}} the multi-relational {{algorithm}} is the MRFP-Growth [27] based on FP-growth. In a first stage it finds local frequent patterns {{from each of the}} tables and, in the next stage, these patterns are verified to obtain multi-relational patterns. Another example is the Apriori-Group [28] which is based on the Apriori. By means of the clustering obtained with this algorithm, data <b>redundancy</b> <b>errors,</b> deriving from the junction operations of multiple tables, are corrected.|$|R
40|$|In {{order to}} {{simultaneously}} obtain better error resilient performance and preserve original coding efficiency {{in the video}} stream, a low <b>redundancy</b> <b>error</b> resilient scheme for H. 264 video transmission in packet-switched environment is proposed in this chapter. In the following of this chapter, a review on various error resilient techniques for wireless video transmission will be reviewed in section 2. A new error resilient scheme for H. 264 video will then be described in section 4. Simulation results will be presented and discussed in section 4. Finally, some concluding remarks will be given in section 5. Department of Electronic and Information Engineerin...|$|E
30|$|Combining Table  1 and Fig.  5, {{it can be}} seen {{clearly that}} only {{convolutional}} neural network can extract road information smoothly, but because of non-road noise caused by natural scene factors such as house and tree shadow, the values of the three indexes are relatively large. After re-processing with wavelet packet, {{it can be seen}} that the values of the three indexes decrease obviously, among which the omission error decreases by 3.22 %, the <b>redundancy</b> <b>error</b> decreases by 0.52 %, and the accuracy increases by 6.36 %. The improvement of the values of the three indicators shows that the non-road noise caused by the shadows of houses and trees can be effectively reduced by the wavelet packet algorithm after the convolutional neural network is used to extract road information.|$|E
40|$|This paper {{addresses}} {{the problem of}} streaming packetized media over a lossy packet network to a wireless client, in a rate-distortion optimized way. We introduce an incremental <b>redundancy</b> <b>error</b> correction scheme that combats the effects of both packet loss and bit errors in an end-to-end fashion, without support from the underlying network or from an intermediate base station. The scheme is employed within an optimization framework that enables the sender to compute which packets it should send, {{out of all the}} packets it could send at a given transmission opportunity, in order to meet an average transmission rate constraint while minimizing the average end-to-end distortion. Experimental results show that our system is robust and maintains quality of service over a wide range of channel conditions. Up to 8 dB performance gains are registered over systems that are not rate-distortion optimized, at bit error rates as large as 10...|$|E
50|$|These {{can result}} in both <b>redundancy</b> and image <b>error.</b>|$|R
5000|$|Information <b>redundancy,</b> such as <b>error</b> {{detection}} and correction methods ...|$|R
5000|$|Encoding: varies {{based on}} encoder/decoder chips used. Usually {{includes}} some <b>redundancy</b> for <b>error</b> detection or correction. For example, some NEC chips send the same code four times (inverted {{the second and}} fourth time).|$|R
40|$|Technology-based {{training}} is being increasingly adopted by organizations of all sizes. It allows employers {{to cut costs}} and to train more employees at the same time. However, arguably the greatest benefit of computer-based {{training is}} that it is very flexible and can be customized {{to the needs of the}} organization as well as to the individual needs of the trainees. This paper explores what adjustments can be made to computerized training programs for older employees to make their learning most effective. The results of the literature review show that older adults benefit from simple and consistent interface design, large font and empty video background, instructional coherence, <b>redundancy,</b> <b>error</b> management approaches, and goal-setting strategies. Specific goals are better than general goals, and learning goals are more effective than performance goals. Conceptual mapping was found to be a very effective metacognitive strategy. Previous experience with technology was an important factor in predicting older trainees’ cognitive workload and frustration levels. Some of these factors, especially those oriented towards reducing cognitive load may be equally helpful for younger trainees; however, some like redundancy may be detrimental to younger trainees’ learning. More research is needed to determine the interaction between individual variables and different training strategies...|$|E
40|$|International Telemetering Conference Proceedings / October 26 - 29, 1987 / Town and Country Hotel, San Diego, CaliforniaWe design {{telemetry}} systems which instrument {{weapons in}} the Joint DoD/DOE flight test program. These telemetry systems gather data {{which can be used}} to determine if a weapon functioned as intended. Traditionally, a telemetry system has been designed to fit the individual requirements of each of the many weapons which have gone into production. The process of defining requirements, designing the system, and getting it into production with the quality assurance demanded of all weapon components takes considerable time, manpower, and money. Due to the rapid advancement of electronics and computer technology, these telemetry systems and their production testers become difficult to support if the weapon service time is extended or if aging test equipment breaks down. We are designing a telemetry system to support new programs for the next decade and to replace old telemetry systems which can no longer be produced. This multi-system Joint Test Assembly (JTA) is being designed to be modular, flexible, and testable. New techniques for increasing reliability, such as <b>redundancy,</b> <b>error</b> detection and correction, and microprocessor recovery will be employed. The requirements for each program can be met by choosing the necessary circuitry from a "shopping list" and packaging to meet the mechanical constraints for each system. Production specifications and test equipment will be in place to support any telemetry which is composed of the previously-designed modules. Modifications of hardware and software to support individual requirements will be kept to a minimum. We expect this new approach to telemetry system development to significantly reduce cost and lead time for every program on which it is employed. The use of this telemetry system on multiple programs should also enhance reliability...|$|E
40|$|The {{aim of this}} {{research}} is to enhance the quality of service in video applications when they are operating over error prone environments. With high compression ratio and low complexity block transform video coders, such as ITU-T H. 263 standard algorithm for very low bit rate video coding, compressed video streams can be used for multimedia services. However, when transmitting compressed video streams over channels with degraded conditions, several problems arise and undermine the video decoder from correctly reconstructing the video signal. This thesis presents several techniques employed to enhance the quality of service of a video communication application under erroneous conditions. First, block transform methods for video coding are examined, and their strengths and weaknesses are assessed in terms of performance and error robustness. Packetised video signals are considered and two different techniques are implemented for packet video networks {{to improve the quality of}} service on one hand and help resolve the state of congestion that might occur on any video communication medium on the other hand. Additionally, zero <b>redundancy</b> <b>error</b> concealment techniques are considered and applied on the block based video decoder to improve the quality of the reconstructed video signal without any redundancy added on the video bitstream. Then, the aspects of error resilience issues in block transfom video coders are discussed. Based on the different categories of errors encountered in coded video streams, several novel techniques are implemented to render the video coder more immune to channel deterioration. Some of these techniques are combined to form an error resilience algorithm that is implemented on H. 263 to enhance its performance over error prone environments such as mobile radio links. In parallel with the development process of the MPEG- 4 video coder, we apply the two-way decoding with reversible codewords on the H. 263 standard. Results are shown throughout the thesis to evidence the effectiveness of the proposed techniques and illustrate the improvement on the quality of service on both the objective and subjective scales. We conclude with thoughts for future expansion of error control strategies in block based video coding for mobile multimedia services over the foreseen universal mobile telecommunication systems (UMTS) network...|$|E
25|$|Error-correcting codes (channel coding): While data {{compression}} removes as much redundancy as possible, an {{error correcting code}} adds just {{the right kind of}} <b>redundancy</b> (i.e., <b>error</b> correction) needed to transmit the data efficiently and faithfully across a noisy channel.|$|R
40|$|International audienceThis paper {{presents}} a new hybrid fault-tolerant architecture for robustness improvement of digital CMOS circuits and systems. It targets {{all kinds of}} errors in combinational part of logic circuits and thus, can be combined with advanced SEU protection techniques for sequential elements while reducing the power consumption. The proposed architecture combines different types of redundancies: information <b>redundancy</b> for <b>error</b> detection, temporal <b>redundancy</b> for soft <b>error</b> correction and hardware <b>redundancy</b> for hard <b>error</b> correction. Moreover, it uses a pseudo-dynamic comparator for SET and timing errors detection. Besides, the proposed method also aims to reduce power consumption of fault-tolerant architectures while keeping a comparable area overhead compared to existing solutions. Results on the largest ISCAS' 85 and ITC' 99 benchmark circuits show that our approach has an area cost of about 3  % to 6  % with a power consumption saving of about 33  % compared to TMR architectures...|$|R
40|$|This {{paper had}} been {{presented}} for promotion at the University of Khartoum. To {{get the full}} text please contact the other at gamaralbooni@gmail. comThis paper sets out to examine the English proficiency of 50 Sudanese students at the School of Management Studies at the University of Khartoum when using the English articles. The students were enrolled in a low intermediate English course for two semesters. Written and oral samples were taken {{at the end of}} the first and second semesters. Omission, substitution and <b>redundancy</b> <b>errors</b> were identified, and analysed in terms of performance mistakes, interference of mother tongue, over-learning and overgeneralization. The results provide useful information to teachers of Arabic speakers studying English and to researchers investigating the phenomenon of second language acquisition in general...|$|R
40|$|ISBN 978 - 1 - 4673 - 5542 - 1 International audienceToday, {{there are}} several trends that are making the {{reliability}} analysis of complex integrated circuits an important challenge in industry. As transistor geometries shrink, the number of physical failure mechanisms is increasing {{while at the same}} time the number of transistors per chip is still growing. The rollout of new services is pushing compute demands both in handheld devices and in the data center which is driving up complexity and the level of integration. People are becoming critically dependent on mobile services and expect high availability. Looking forward to the deployment of the Internet of Things (IoT) where processors and routers will be embedded in billions of end-points, we are only going to see an increased demand for reliable computing. In this session, we bring together three different industrial perspectives on reliability. The first looks at the end-points, the second looks at the servers and the last looks at the economic drivers for reliability and the demand for new EDA tools for reliability analysis. In the first talk, Rob Aitken from ARM will discuss the reliability challenges in mobile applications. As mobile systems continue to increase in size and complexity, and user requirements are also becoming more stringent, it is important for designers of mobile systems to be aware of reliability issues, and to adapt their methodologies accordingly. This talk discusses the issues involved, from latent defects, through soft errors, aging and wearout, and shows how to consider these as part of the design process, how to quantify their effects, and how to mitigate them through design changes. In the second presentation, Burcin Aktan from Intel is going to discuss the evolution of the reliability features that are found in server applications. With so many processing units packed in data centers the reliability requirements on an individual device is growing, especially with integrated memory controllers and very high bandwidth data pathways. What- was an "add-on" to a device function, 10 - 15 years ago, now needs to be considered carefully with stringent budgets distributed to each functional block that contribute to overall error rates. This talk will focus on the evolution of reliability features in a number of server products leading into the current state and look at how today's designers are dealing with the challenges of gathering requirements, translating these to design implementation and delivering quality features to customers. Finally we will close with remarks on future directions and possible research areas. In the final presentation, Olivier Lauzeral from iROC Technologies will discuss the importance of methodologies for the reliability analysis of complex SoCs. There is an inherent cost to adding reliability features in a complex IC and designers need to be able to make informed decisions about how much hardware to allocate for mitigation (<b>redundancy,</b> <b>error</b> correction, repair). A prerequisite to make such choices is clearly defined targets and this requires an economic framework where the cost of failures is understood. Once the reliability targets for a system and individual devices are established, there is a need for EDA tools which allow designers to compute the failure rate and failure modes within the device. This analysis must include all failure mechanisms (radiation effects, lifetime effects, manufacturing detects) and take into account the relevant de-ratings between faults and observed errors. This new EDA infra-structure is key for designers to make effective trade-offs in order to arrive at a cost effective design...|$|E
50|$|Integrated {{e-commerce}} is upcoming. With integrated e-commerce, part of {{the software}} solution is installed inside the ERP back-end system. This means that {{the connection between the}} business logic and database of a back-end system is configured automatically. Information that is available in the back-end system, for example article numbers, prices and current stock availability of products, is leveraged, without being copied to another system, and displayed in the front/back end of the e-commerce system. An integrated e-commerce software solution thus does not require investments in recreating and maintaining a separate database or business logic. Instead, it re-uses those of the back-end system, so all data are stored in one, single place. This can prevent input <b>redundancy,</b> <b>errors</b> and synchronization time.|$|R
5000|$|Lockstep {{systems are}} {{fault-tolerant}} computer systems that run {{the same set}} of operations {{at the same time in}} parallel. The <b>redundancy</b> allows <b>error</b> detection and error correction: the output from lockstep operations can be compared to determine if there has been a fault if there are at least two systems (dual modular <b>redundancy),</b> and the <b>error</b> can be automatically corrected if there are at least three systems (triple modular redundancy), via majority vote. The term [...] "lockstep" [...] originates in the army usage, where it refers to the synchronized walking, in which the marchers walk as closely together as physically practical.|$|R
50|$|The {{inability}} to store a NUL requires that string data and binary data be kept distinct and handled by different functions (with the latter requiring {{the length of}} the data to also be supplied). This can lead to code <b>redundancy</b> and <b>errors</b> when the wrong function is used.|$|R
40|$|Advanced {{aircraft}} {{will require}} flight critical computer systems for stability augmentation {{as well as}} guidance and control that must perform reliably in adverse, as well as nominal, operating environments. Digital system upset is a functional error mode that can occur in electromagnetically harsh environments, involves no component damage, can occur simultaneously in all channels of a redundant control computer, and is software dependent. A strategy is presented for dynamic upset detection {{to be used in}} the evaluation of critical digital controllers during the design and/or validation phases of development. Critical controllers must be able to be used in adverse environments that result from disturbances caused by an electromagnetic source such as lightning, high intensity radiated field (HIRF), and nuclear electromagnetic pulses (NEMP). The upset detection strategy presented provides dynamic monitoring of a given control computer for degraded functional integrity that can result from <b>redundancy</b> management <b>errors</b> and control command calculation error that could occur in an electromagnetically harsh operating environment. The use is discussed of Kalman filtering, data fusion, and decision theory in monitoring a given digital controller for control calculation <b>errors,</b> <b>redundancy</b> management <b>errors,</b> and control effectiveness...|$|R
30|$|How are errors detected? The {{answer to}} this {{question}} can be either by comparison or by checking a single result. It aims to identify functionalities whose validity can be verified through acceptance tests, with no need of <b>redundancy</b> for <b>error</b> detection. The answer can also affect the number of variants required for fault tolerance.|$|R
40|$|It is {{believed}} {{that the increase in}} SEUs with more modern devices may have serious consequences for future space missions. The physics behind an SEU is discussed as well as SEU test philosophy and equipment, and testing results. It is concluded that the problem may be ameliorated by careful device selection and the use of <b>redundancy</b> or <b>error</b> correction...|$|R
40|$|A {{properly}} configured firewall is a {{good starting}} point in securing a computer network. However, complex network environments that involve higher number of participants and endpoints require better security infrastructure. Intrusion Detection Systems (IDS), proposed as a solution to perimeter defense, have many open problems and it is clear that better solutions must be found. Due to many unsolved problems associated with IDS, Intrusion Prevention Systems (IPS) is introduced. The main idea in IPS is to be proactive. Network intrusion prevention system (NIPS) becomes more complex due to the rapid growth of network bandwidth and requirement of network security. However existing solutions, either hardware-based or software-based cannot obtain a good tradeoff between performance and flexibility. In this paper, intrusion prevention can be used to and block malicious activity upon detection. To be specific intrusion prevention may involve dropping packets that can be considered malicious, blocking any traffic from an IP address that may be offending, sending alarms, resetting of connections, correcting cyclic <b>redundancy</b> <b>errors</b> etc...|$|R
40|$|For {{practical}} communications which transmit finite {{blocks of}} source data over noisy channels, we question the common practice to compress (C) {{the source and}} then to add <b>redundancy</b> for <b>error</b> control. Rather we exploit the redundancy of the noncompressed source (NC) at the channel decoder by source-controlled channel decoding. For a simple binary Markov source and a Rayleigh fading channel we simulated in a fair comparison the 2 systems (C and NC) using an ARQ/FEC scheme with RCPC codes, LempelZiv compression and a modified Viterbi decoder. We indicate parameter regions where it is better not to compress. I. Introduction In today's digital storage and transmission systems for data, text, speech, audio, fax, image and video the source is compressed {{as much as possible}} and the resulting bits are transmitted. For noisy channels one has to add <b>redundancy</b> for <b>error</b> correction and detection. Supposedly this two step method is supported by Shannon's famous separation theorem [1], which states [...] ...|$|R
40|$|Proposes {{a theory}} of stare decisis which draws upon the {{insights}} of communications theory {{as well as the}} decision-making process in tort law. Branches of communications theory; Discussion on the information and redundancy concepts of syntactics; Model which have overshadowed the importance of <b>redundancy</b> in <b>error</b> correction; Key activity of the tort organization and its litigational market operating under the rules of stare decisis; Reason behind the survival of stare decisis...|$|R
40|$|A task {{common to}} nearly {{all types of}} {{election}} auditing is that of human auditors physically counting ballots by hand. This task, fundamental {{to the goal of}} accuracy in an audit, can be a source of error. While somewhat basic in its nature, the process of counting can be strongly influenced by many procedural and legal factors. In the current study, we examine how specific group counting procedures and ballot types affect the accuracy, efficiency, and subjective judgments of usability of a post-election audit. These two procedures, quite different in their implementation and employed in real elections in two U. S. states, have built-in redundant checks and multiple tallies to help bolster accuracy; we found that even with this <b>redundancy,</b> <b>errors</b> are surprisingly frequent. Additionally, certain counting procedures are more efficient, as well as less variable in the amount of error they introduce into the audit process. We found that well-specified procedures, as well as division of labor amongst group counting members, help ensure more accurate and efficient ballot audits...|$|R
5000|$|In many safety-critical systems, such as {{fly-by-wire}} and {{hydraulic systems}} in aircraft, {{some parts of}} the control system may be triplicated, which is formally termed triple modular <b>redundancy</b> (TMR). An <b>error</b> in one component may then be out-voted by the other two. In a triply redundant system, the system has three sub components, all three of which must fail before the system fails. Since each one rarely fails, and the sub components are expected to fail independently, the probability of all three failing is calculated to be extraordinarily small; often outweighed by other risk factors, such as human <b>error.</b> <b>Redundancy</b> may also be known by the terms [...] "majority voting systems" [...] or [...] "voting logic".|$|R
3000|$|... spread: If {{one only}} needs to {{identify}} and wrap a few top sites {{in order to build}} a comprehensive set of sources, the spread is low. A comprehensive set should also include some <b>redundancy</b> to overcome <b>errors</b> introduced by a single source; [...]...|$|R
5000|$|The {{position}} of the bursts is signaled {{in terms of the}} relative time difference between two consecutive bursts of the same service. This information is called [...] "delta t". It is transmitted multiple times within a single burst as to provide <b>error</b> <b>redundancy.</b>|$|R
50|$|On April 13, 2007, NASA {{announced}} {{the loss of}} the spacecraft was caused by a flaw in a parameter update to the spacecraft's system software. The spacecraft was designed to hold two identical copies of the system software for <b>redundancy</b> and <b>error</b> checking. Subsequent updates to the software encountered a human error when two independent operators updated separate copies with differing parameters. This was followed by a corrective update that unknowingly included a memory fault which resulted in {{the loss of the}} spacecraft.|$|R
40|$|STL文件因其简单和通用性好,一直作为快速成型领域的准标准。但是由于其本身的缺陷,造成切片之后的轮廓信息数据有大量的冗余数据甚至错误。该文针对切片轮廓的不封闭,给出了有效的修正算法;通过对轮廓信息中冗余数据的分析,提出了一种冗余数据的滤除算法。该算法高效简单,提高了后续的数据处理的效率和成型件的加工质量,改善了零件成型的加工性能。国家 863 高技术研究发展计划(编号: 2001 AA 421160) STL file is the {{de facto}} {{criterion}} in rapid prototyping field because of its simpleness and currency. But  for its defection,there are large number of <b>redundancy</b> and <b>error</b> in slice profile data. In this paper an effective modification algorithm is proposed for non-closed slice profile. After analyzing the redundancy of profile data,a filtering algorithm is introduced. This algorithm is simple and effective,it advances the efficiency of later data process and machine quality of part and improving the machine capability...|$|R
40|$|Abstract: A {{properly}} configured firewall is a {{good starting}} point in securing a computer network. However, complex network environments that involve higher number of participants and endpoints require better security infrastructure. Intrusion Detection Systems (IDS), proposed as a solution to perimeter defense, have many open problems and it is clear that better solutions must be found. Due to many unsolved problems associated with IDS, Intrusion Prevention Systems (IPS) is introduced. The main idea in IPS is to be proactive. Network intrusion prevention system (NIPS) becomes more complex due to the rapid growth of network bandwidth and requirement of network security. However existing solutions, either hardware-based or software-based cannot obtain a good tradeoff between performance and flexibility. In this paper, intrusion prevention can be used to and block malicious activity upon detection. To be specific intrusion prevention may involve dropping packets that can be considered malicious, blocking any traffic from an IP address that may be offending, sending alarms, resetting of connections, correcting cyclic <b>redundancy</b> <b>errors</b> etc. Networks refer to an interconnection of computers. Intrusion prevention, therefore, refers to the act of blocking, stopping or reporting activities or accesses that are unauthorized or malicious to a network. Intrusion prevention involves monitoring activities of all the network systems running and the network traffic. This means that intrusio...|$|R
30|$|To {{integrate}} battery {{energy storage}} system (BESS) installations to the grid, power converters should have the following features: (1) fault ride-through capability; (2) high <b>redundancy</b> and <b>error</b> correction capabilities. For megawatt-scale medium-voltage (MV) application, multilevel converters show significant advantages over conventional topologies [12]. Among them, the most promising concept for renewable energy integration and power transmission is the modular multilevel converter (MMC) [13, 14, 15]. Compared with conventional multilevel converters, MMCs provide advantages of high modularity, better harmonic spectra, lower switching frequency, higher efficiency, and reduced weight of the filtering components.|$|R
