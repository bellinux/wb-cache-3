134|142|Public
50|$|The {{optimization}} {{of existing}} (production) processes always increases {{the competitiveness of}} the entrepreneur. The implementation of advanced process analysis into existing systems allows {{the performance of the}} plants to be optimized further. On a daily basis sensor technology provides new and improved options for the collection of measuring data. Processing data can consequently be compiled with much higher precision and at shorter intervals. This allows the optimization of production parameters such as quality, pieces/minute, <b>reject</b> <b>rate</b> - no matter whether it's anticipatory (e.g. by assessing the products introduced into the process) or downstream (e.g. control {{at the end of each}} process stage). This is where the value of the information becomes most visible. Many production plants are still not yet operating to their performance capabilities. There are many possibilities for process analysis to further improve the quality achieved so far.|$|E
40|$|Absrract-The <b>reject</b> <b>rate</b> of LSI chips due to {{incomplete}} {{fault coverage}} of the tests is the fraction of faulty chips, among the chips that pass the tests. This <b>reject</b> <b>rate,</b> which {{is a measure of}} the tested chip quality, contributes to the field returns. It is, however, difficult to determine the tested chip quality from the field return data which may also include rejects due to handling damages, infant mortality, etc. Also, a large number of chips must be in use in the field before an adequate amount of field return data can be obtained. This paper gives a method of forecasting the <b>reject</b> <b>rate</b> from the test data alone before any field trials are made. BACKGROUND In a recent paper [11 ~ the <b>reject</b> <b>rate</b> of the tested chips was obtained as where f = no...|$|E
40|$|The <b>reject</b> <b>rate</b> of LSI chips due to {{incomplete}} {{fault coverage}} of the tests is the fraction of faulty chips, among the chips that pass the tests. This <b>reject</b> <b>rate,</b> which {{is a measure of}} the tested chip quality, contributes to the field returns. It is, however, difficult to determine the tested chip quality from the field return data which may also include rejects due to handling damages, infant mortality, etc. Also, a large number of chips must be in use in the field before an adequate amount of field return data can be obtained. This paper gives a method of forecasting the <b>reject</b> <b>rate</b> from the test data alone before any field trials are made...|$|E
30|$|This case {{corresponds}} to the minimization of the <b>rejected</b> heat <b>rate.</b> Satisfaction of this objective is important because if this <b>rejected</b> heat <b>rate</b> is not used, it {{corresponds to}} heat pollution.|$|R
5000|$|Common {{elements}} of praise centered upon the film's atmosphere and visuals, which Twitch Film called [...] "stylish and mesmerizing". Film School <b>Rejects</b> <b>rated</b> the film positively, praising it for its jump scares and stating that it [...] "shows {{love and affection}} for genre".|$|R
50|$|The recent {{commercial}} {{adoption of}} hyperspectral sensor-based food sorters is most advanced in the nut industry where installed systems maximize {{the removal of}} stones, shells and other foreign material (FM) and extraneous vegetable matter (EVM) from walnuts, pecans, almonds, pistachios, peanuts and other nuts. Here, improved product quality, low false <b>reject</b> <b>rates</b> {{and the ability to}} handle high incoming defect loads often justify the cost of the technology.|$|R
30|$|The {{performance}} of all algorithms is measured and reported by equal error rate (EER). EER {{is defined as}} the point that false <b>reject</b> <b>rate</b> (FRR) and false accept rate (FAR) have the same value. EER is also used to compare the efficiency of the implemented methods under different conditions.|$|E
40|$|Background: It is not {{uncommon}} to encounter patients undergo repeat x-ray examinations after their initial x-rays are rejected for poor image quality thereby subjecting them to excess radiation exposure and avoidable extra cost. This creates a situation which necessitates the need to explore causes of reject and repeat of x-ray examinations. The employment of reject analysis as part of overall Quality Assurance (QA) programmes in clinical radiography and radiology services in the evaluation of image quality is a well established practice. The role of reject analysis in providing relevant information that would help achieve sound reduction in radiation exposure and cost as well as develop acceptable image quality was explored in this study. Objective: To assess the <b>reject</b> <b>rate</b> of x-ray films and obtain information for further recommendation on quality, cost, and radiation exposure in the two hospitals. Methods: Prospective and cross-sectional study approaches were employed. <b>Reject</b> <b>rate</b> was measured for two x-ray departments (one from public and the other from private) across all plain x-ray films examinations using a structured format on which relevant data for reject were recorded by investigators (radiologists and a medical physicist). Results were then collected and entered into a database for analysis. Results: <b>Reject</b> <b>rate</b> along with exposure rate was measured across all plain film exams for the hospitals. Analysis ha...|$|E
40|$|Background: Improper {{practices}} in radiography {{that lead to}} possible repeating of procedures predispose patients for additional cost, more waiting time, and excess dose of ionizing radiation, leading to various dose dependent and dose independent health problems including cancer. In {{the face of such}} problems and the scarcity of resources, improving the quality and efficiency of radiology services is imperative. Objective: The purpose of this research was to identify the main causes of film faults as well as the pattern and magnitude of film rejection. Methods: Using a prospective cross-sectional hospital based approach; eight public hospitals were selected in Addis Ababa through convenience sampling. Adult and pediatrics radiographs with film faults were reviewed using a standardized checklist of common causes of reject. The collected data were then entered into a database for analysis using descriptive statistics. Results: <b>Reject</b> <b>rate</b> was calculated in eight governmental hospitals across all plain film examinations. The overall <b>reject</b> <b>rate</b> was 374 (3. 1 %) in 12, 165 x-ray exposures. Total <b>reject</b> <b>rate</b> by hospital showed 10. 5 % for Zewditu and 1. 53 % and 1. 87 % for Tikur Anbessa Specialized Hospital (TASH) and the Police Hospital, respectively. Conclusions: Rejected films were found to have been caused by numerous factors including poor technical judgment, patient motion, and poor supervision of staff. Hence, strategies need to be developed within medical imaging departments to improve the situation. [Ethiop. J. Health Dev. 2012; 26 (1) : 54 - 59...|$|E
40|$|The {{purpose of}} this study was to {{determine}} the rejection of digital image analysis procedure CR softcopy hereinafter referred to as RFA, and describe the profile and characteristics of the proportion image rejection (rejection rates) based on the operational conditions of CR. Quantitative research was conducted with the observational approach. Data were collected by random sampling from 1181 digital image system CR- 1137 type 1 at A hospital and the total number of CR type 2 digital image at B hospital on the status of post-image processing. Profiles and characteristics of the CR-system rejection rate was 9. 15 % while the type 1 for type 2 CR-system is 4. 57 %. Largest percentage of CR image rejection on both failitas dominated by chest radiographic anatomy of the organ which is 69. 44 % (A) and 48. 08 % (B). The findings <b>reject</b> <b>rates</b> of 15. 87 % due to poor performance of x-ray equipment and distribution teridenfitikasinya <b>reject</b> <b>rates</b> based on radiographer in A hospital deserves special attention. Though the radiographer and the employment <b>rate</b> figures <b>reject</b> individually in “ A” hospital not correlated (0. 67 > p-value) ...|$|R
2500|$|McIntyre, Stephen L. [...] "The Failure of Fordism: Reform of the Automobile Repair Industry, 1913–1940: Technology and Culture 2000 41(2): 269–299. repair shops <b>rejected</b> flat <b>rates</b> ...|$|R
40|$|It is a newer {{method of}} {{biometric}} authentication that uses specific pattern recognition techniques based on high-resolution {{images of the}} iris of an individual's eyes. Iris scanning system {{is considered to be}} the best biometric performer because it has very low false <b>reject</b> <b>rates</b> and also faster identification facilities. The technique is gaining importance amidst modern threats of Terrorism, High security needs in order to ensure safety of people around the world. Even lesser developed nations do not want to compromise on security issues...|$|R
40|$|Sensors, {{and also}} {{actuators}} or external {{sources such as}} databases, serve as data sources in order to realise condition monitoring of industrial applications or the acquisition of characteristic parameters like production speed or <b>reject</b> <b>rate.</b> Modern facilities create such {{a large amount of}} complex data that a machine operator is unable to comprehend and process the information contained in the data...|$|E
40|$|This study {{discusses}} reject film analyses (RFAs) {{before and}} after the implementation of a quality improvement intervention. RFAs were undertaken to investigate the effect of the introduction and use of exposure charts (ECs) on department and student reject rates of extremity radiographs. Methods: A quantitative comparative pre and post-treatment research design was used. Data was collected from the x-ray departments of two training hospitals in Windhoek, Namibia over a five month period. A retrospective RFA was conducted to determine the department and student reject rates for both departments before intervention. Emphasis was placed on exposure related reject films. ECs were compiled and introduced at Katutura State Hospital (venue B) by the researcher. The students were instructed to use these charts. At Windhoek Central Hospital (venue A) no ECs were used. A prospective RFA was conducted to establish department and student reject rates at both hospitals after the intervention at venue B. Results: During the retrospective phase the department <b>reject</b> <b>rate</b> for venue A was 21 percent while the student <b>reject</b> <b>rate</b> was 23 percent. At venue B 24 percent and 26 percent were scored respectively. Students at venue A produced rejected radiographs due to overexposure (49 percent) and underexposure (23 percent), whilst 37 percent was recorded for both causes at venue B. At venue A, 35 percent of films were rejected due to incorrect mAs selection, at venue B the figure was 42 percent. Undiagnostic radiographs due to inaccurate kV selection comprised 62 percent for venue A and 59 percent for venue B. During the prospective phase the department <b>reject</b> <b>rate</b> for venue A was 20 percent and that of the students was 19 percent. For venue B 12 percent and 11 percent were scored respectively. At venue A radiographs rejected due to over and underexposure were 43 percent and 33 percent respectively while those at venue B were 33 percent and 34 percent. Incorrect mAs selection caused 33 percent of discarded films at venue A and 38 percent at venue B. The figures for inaccurate kV selection were 68 percent and 62 percent for venues A and B. Conclusions: The introduction and use of ECs lowered the student <b>reject</b> <b>rate</b> at venue B in the prospective phas...|$|E
40|$|Abstract Using a {{data set}} with {{approximately}} {{four years of}} elapsed time between the earliest and most recent images of an iris (23 subjects, 46 irises, 6, 797 images), we investigate template aging for iris biometrics. We compare the match and nonmatch distributions for short-time-lapse image pairs, acquired {{with no more than}} 120 days of time lapse between them, to the distributions for long-time-lapse image pairs, with at least 1, 200 days of time lapse. We find no substantial difference in the non-match, or impostor, distribution between the short-time-lapse and the longtime-lapse data. We do find a difference in the match, or authentic, distributions. For the image dataset and iris biometric systems used in this work, the false <b>reject</b> <b>rate</b> increases by about 50 % or greater for the long-time-lapse data relative to the short-time-lapse data. The magnitude of the increase in the false <b>reject</b> <b>rate</b> varies with changes in the decision threshold, and with different matching algorithms. Our results demonstrate that iris biometrics is subject to a template aging effect. ...|$|E
40|$|Four {{methods of}} {{converting}} paper documents to computer-readable form are compared {{with regard to}} hypothetical labor cost: keyboarding, omnifont OCR, stylespecific OCR, and style-constrained or styleadaptive OCR. The best choice is determined primarily by (1) the <b>reject</b> <b>rates</b> of the various OCR systems at a given error rate, (2) the fraction of the material that must be labeled for training the system, and (3) the cost of partitioning the material according to style. For large corpora, sampling strategies are proposed both for estimating conversion costs and for taking advantage of style homogeneity. 1...|$|R
50|$|The {{shelf life}} of a product can be {{extended}} either by adding artificial preservatives or by taking hygienic measures during the manufacturing process. As the consumer trend today is towards preservative-free foods with a long shelf-life, industry is being forced to rethink its manufacturing methods. Instead of adding preservative agents, increased hygienic precautions can be taken during production. A clean and hygienic manufacturing environment is an essential prerequisite {{in order to keep}} contamination-related <b>reject</b> <b>rates</b> low. The utilization of surfaces in the manufacturing environment with antibacterial properties can significantly reduce contamination risks.|$|R
5000|$|With a {{production}} yield {{of a few}} percent, {{a significant amount of}} circuits failed to pass the acceptance criteria. The components were called [...] "Anfalltyp" [...] or [...] "rejects". Most of them were functional, but exceed allowed tolerances. Within limits, e.g. speed or access time, they may work fine. Therefore, the manufacturing companies pushed for a development of simple fault-tolerant learning or hobby computers which can make use of the rejects. The use of waste production could lower the reported <b>reject</b> <b>rates</b> and partly close gap in demand for home computers.|$|R
40|$|We are {{developing}} a hand-printed character recognition system using a multi-layered neural net trained through backpropagation. We report on results of training nets with samples of hand-printed digits scanned off of bank checks and hand-printed letters interactively entered into a computer through a sty-lus digitizer. Given a large training set, and a net with sufficient capacity to achieve high performance on the training set, nets typically achieved error rates of 4 - 5 % at a 0 % <b>reject</b> <b>rate</b> and 1 - 2 % at a 10 % <b>reject</b> <b>rate.</b> The topology and capacity of the system, {{as measured by the}} number of connections in the net, have surprisingly little effect on generalization. For those developing practical pattern recognition systems, these results suggest that a large and representative training sample may be the single, most important factor in achieving high recognition accuracy. From a scientific standpoint, these re-sults raise doubts about the relevance to backpropagation of learning models that estimate the likelihood of high generalization from estimates of capacity...|$|E
40|$|Iris {{recognition}} {{is emerging as}} one of the important methods of biometrics-based identification systems. Biometric verification systems employing images of the iris are claimed to be extremely accurate, yielding no false accepts at any reasonable false <b>reject</b> <b>rate.</b> This paper demonstrates that a more accurate iris segmentation helps to improve the overall system performance, and that the inaccuracy of iris segmentation and noise detection could be partly compensated for with optimizations in the matching stage...|$|E
40|$|For {{different}} {{document automation}} operations {{it is always}} needed to have an OCR evaluation phase to select the most interesting OCRs for the document class studied. The evaluation should indicate the defects and drawbacks of each OCR and allow to determine the required heuristics to combine these OCRs {{in order to obtain}} the highest performances in production: the lowest <b>reject</b> <b>rate</b> for a predefined confusion rate (in general 1 / 10000). Th...|$|E
40|$|Iris {{biometric}} {{is considered}} {{as one of the}} most efficient and trusted biometric methods for authenticating users. This thesis proposed an effective iris recognition system based on two different hybrid algorithms. Firstly, both Gray Level Co-occurrence Matrix (GLCM) and (2 D) Gabor filters were hybridized to extract iris features. Secondly, the hybrid of Principal Component Analysis (PCA) and GLCM were used to obtain a secure iris recognition system. The features extracted by the hybrids methods were normalized and Euclidean distance was used to classify the features. Furthermore, the proposed designed system was tested in many cases and their performances were measured and compared in both algorithms. The processes of Path Analysis Test Case of the two algorithms were performed through the use of three classes of the image to evaluate the performance of the designed system and their reliability was measured. The results show that the overall system accuracy obtained by the Gabor and GLCM was 99. 17 % success rate with 0. 82 % false accepted rate and 0. 83 % false <b>rejected</b> <b>rate</b> while, the overall success rate obtained by the PCA algorithm was 99. 15 % with 0. 82 % false accepted rate and 0. 85 % false <b>rejected</b> <b>rate.</b> The reliability of Gabor filter was given as 95 % and for PCA, 94 %. The Gabor method overcame the PCA in all the tested cases...|$|R
40|$|This paper {{presents}} a robust minutiae based method for fingerprint verification. The proposed method uses Delaunay Triangulation to represent minutiae as nodes of a connected graph composed of triangles. The minimum angle over all triangulations is maximized, which gives local stability to the constructed structures against rotation and translation variations. Geometric thresholds and minutiae data {{were used to}} characterize the triangulations created from input and template fingerprint images. The effectiveness of the proposed method is confirmed through calculations of false acceptance <b>rate</b> (FAR), false <b>rejected</b> <b>rate</b> (FRR) and equal error rate (EER) over FVC 2002 databases compared {{to the results of}} other approaches...|$|R
40|$|We {{show that}} when users make errors on mobile devices they make {{immediate}} and distinct physical responses {{that can be}} observed with standard sensors. We used three standard cognitive tasks (Flanker, Stroop and SART) to induce errors from 20 participants. Using simple low-resolution capacitive touch sensors placed around a standard mobile device and the builtin accelerometer, we demonstrate that errors can be predicted at low error rates from micro-adjustments to hand grip and movement in the period shortly after swiping the touchscreen. Specifically, when combining features derived from hand grip and movement we obtain a mean AUC of 0. 96 (with false accept and <b>reject</b> <b>rates</b> both below 10...|$|R
40|$|In {{this paper}} we analyze the {{relationship}} between the accuracy of the segmentation algorithm and the error rates of typical iris recognition systems. We selected 1000 images from the UBIRIS database that the segmentation algorithm can accurately segment and artificially introduced segmentation inaccuracies. We repeated the recognition tests and concluded about the strong relationship between the errors in the pupil segmentation and the overall false <b>reject</b> <b>rate.</b> Based on this fact, we propose a method to identify these inaccuracies...|$|E
40|$|At present, the {{relationship}} between fault coverage of LSl circuit tests and the tested product quality is not satisfactorily understood. Reported work on integrated circuits predicts, for an acceptable field <b>reject</b> <b>rate,</b> a fault coverage that is too high (99 percent or higher). This fault coverage is difficult to achieve for LSl circuits. This paper proposes a model of fault distribution for a chip. The number of faults on a defective chip is assumed to have a Poisson density for which the average value is determined through experiment on actual chips. The procedure, which relates the model to the chip being studied, is simple; one or more fabricated chip lots must be tested by a few preliminary test patterns. Once the model is characterized, the required value of fault coverage can be easily determined for any given field <b>reject</b> <b>rate.</b> The main advantage of such a model is that it adapts itself to the various characteristics of the chip (technology, feature size, manufacturing environment, etc.) and the fault model (e. g., stuck-type faults). As an example, the technique was applied to an LSl circuit; realistic results were obtained...|$|E
40|$|This paper {{presents}} a person identiﬁcation mechanism in irregular cardiac conditions using ECG signals. A total of 30 subjects {{were used in}} the study from three different public ECG databases containing various abnormal heart conditions from the Paroxysmal Atrial Fibrillation Predicition Challenge database (AFPDB), MIT-BIH Supraventricular Arrthymia database (SVDB) and T-Wave Alternans Challenge database (TWADB). Cross correlation (CC) was used as the biometric matching algorithm with deﬁned threshold values to evaluate the performance. In order to measure the efﬁciency of this simple yet effective matching algorithm, two biometric performance metrics were used which are false acceptance rate (FAR) and false <b>reject</b> <b>rate</b> (FRR). Our experimentation results suggest that ECG based biometric identiﬁcation with irregular cardiac condition gives a higher recognition rate of different ECG signals when tested for three different abnormal cardiac databases yielding false acceptance rate (FAR) of 2 %, 3 % and 2 % and false <b>reject</b> <b>rate</b> (FRR) of 1 %, 2 % and 0 % for AFPDB, SVDB and TWADB respectively. These results also indicate the existence of salient biometric characteristics in the ECG morphology within the QRS complex that tends to differentiate individuals...|$|E
40|$|Slaughter by Jewish {{religious}} rite is {{the killing}} of an animal by cutting the trachea and oesophagus and major blood vessels using a very sharp blade. This operation is subject to strict rules laid down by religious authorities that characterize its sacredness. The aim {{of the study was}} to evaluate the specific criteria inherent in the Jewish religious rite, by analysing <b>reject</b> <b>rates</b> during the different phases. In this study, 52. 4 % of the carcasses failed to quality as Kosher, with 22. 9 % being rejected due to pulmonary lesions and only 3 % for miscuts. The study also revealed legal vacuums in the field of labelling rules...|$|R
40|$|In {{the context}} of {{deployed}} spoken dialogue telecom services, we introduce a preprocessor called Fiction into the Spoken Language Understanding (SLU) component. It acts as an intermediate between the speech recognition and interpretation processes {{in order to increase}} the rate of utterances that are correctly rejected (CRR for Correctly <b>Rejected</b> <b>Rate)</b> without decreasing the rate of appropriately interpreted utterances. This component is based on statistical approaches of natural language treatment and contextual information. We also use active learning methods to determine the best training corpus size. On a deployed test corpus, the CRR increases from 60 % to 86 % and active learning method's results show that better performance can be achieved using fewer training data...|$|R
40|$|Informed {{technology}} decision-making {{requires a}} structured understanding of cost evolution over time. A dynamic approach integrating learning curves and process-based cost modeling is introduced to examine learning in manufacturing. The approach {{is applied to}} the case of a hydroforming process, and quantifies the cost impacts of learning improvements in cycle time, downtime, and <b>reject</b> <b>rates.</b> A comparison with cases of automotive assembly and wire drawing illustrates that variation in learning is tied to the individual process cost structure. The results show aggregate cost evolution is strongly dependent on cost structure and that major cost elements may not align with major cost improvement-through-learning opportunities. The analyses can be used to focus intentional learning activities on primary learning operational drivers. Learning Manufacturing Process-based cost modeling...|$|R
40|$|Non-destructive thermographic {{techniques}} for detection of flaws in massive forging. The application fields {{and limitations of}} induction thermography were studied with respect to non-destructive testing of cold and warm forged components for shallow defects. In series investigations thermography {{turned out to be}} a technique with high probability of detection and low pseudo <b>reject</b> <b>rate.</b> Concept for production testing systems were worked out that suggest that the required testing cycle times can be achieved. The cost-effectiveness of the running costs is better than that of magnetic particle inspection...|$|E
40|$|Patients usually undergo {{repeated}} X-ray examinations {{after their}} initial X-ray radiographs are rejected due to poor image quality. This subjects the patients to an excess radiation exposure and extra cost and necessitates {{the need to}} investigate the causes of reject. The use of reject analysis {{as part of the}} overall quality assurance programs in clinical radiography and radiology services is vital in the evaluation of image quality of a well-established practice. It is shown that, in spite of good quality control maintained by the Radiology Department of a Teaching hospital in Ghana, reject analysis performed on a number of radiographic films developed indicated 14. 1 % <b>reject</b> <b>rate</b> against 85. 9 % accepted films. The highest <b>reject</b> <b>rate</b> was 57. 1  ±  0. 7 % which occurs in cervical spine and the lowest was 7. 7  ±  0. 5 % for lumbar spine. The major factors contributing to film rejection were found to be over exposure and patient positioning in cervical spine examinations. The most frequent examination was chest X-ray which accounts for about 42. 2 % of the total examinations. The results show low reject rates by considering the factors for radiographic rejection analysis in relation to both equipment functionality and film development in the facility...|$|E
40|$|AbstractIn {{order to}} fulfill demands for quality and {{efficiency}} {{in the field}} of welding engineering, numerous works in research on the optimization of the welding processes are in progress. [1] Aims of this research are increasing the welding speed, stabilizing the welding processes, decreasing the <b>reject</b> <b>rate</b> and reducing the pre and post welding machining. This work relates {{to the development of a}} new plasma-laser hybrid welding method in order to increase the productivity of the existing technologies of plasma arc welding and laser beam welding and to compensate their disadvantages, by using common machinery...|$|E
40|$|This Project Report {{deals with}} the {{investigation}} of quality improvement at Afrox Limited: Gas Equipment Factory (G. E. F),Germiston,South Africa, which employs the Just-In-Time/Total Quality Control (JIT/TQC) manufacturing philosophy. The investigation was carried out to determine {{the underlying causes of}} inconsistent product quality, high scrap and <b>reject</b> <b>rates,</b> and excessive rework in the Regulator cell. The Project Report documents a Quality Improvement Programme aimed specifically at the improvement of the tool setters' performance which was found to be largely responsible for poor quality. The programme is designed to organize the. 'tool setters' machine setup activities in the most efficient and regulated way possible in order to achieve maximum quality and productivity improvement. The design of the Quality Improvement Programme is presently under consideration for implementation...|$|R
40|$|The {{performance}} of an iris recognition {{system can be}} undermined by poor quality images and result in high false <b>reject</b> <b>rates</b> (FRR) and failure to enroll (FTE) rates. In this paper, a wavelet-based quality measure for iris images is proposed. The merit of the this approach lies {{in its ability to}} deliver good spatial adaptivity and determine local quality measures for different regions of an iris image. Our experiments demonstrate that the proposed quality index can reliably predict the matching {{performance of}} an iris recognition system. By incorporating local quality measures in the matching algorithm, we also observe a relative matching performance improvement of about 20 % and 10 % at the equal error rate (EER), respectively, on the CASIA and WVU iris databases. ...|$|R
40|$|Modern {{production}} machines offer a {{wide range}} of supervisions of all set values; the reaction in the mold itself during the production cycle of reactive polymethane can not be monitored with these systems because of missing technology. With the use of the dielectric spectroscopy an online control of the reaction of the most important process value is now possible. Monitoring the electrical conductance of the reacting polyurethane system leads to an improvement of quality calculations based upon statistical process models and neural networks. By using information of the dielectric behavior of the reaction the accuracy for the calculation of the E-modulus has been increased by 2 - 4 %. Process deviations can be detected and removed early during the production cycle. Consequences are lower <b>reject</b> <b>rates</b> and improved productivity. status: publishe...|$|R
